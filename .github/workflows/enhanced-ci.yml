# Enhanced AI Company CI/CD Pipeline v2.0
name: ğŸš€ Enhanced CI/CD Pipeline

"on":
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
      coverage_threshold:
        description: 'Coverage threshold (%)'
        required: false
        default: '80'
        type: string

env:
  PYTHON_VERSION: '3.12'
  NODE_VERSION: '20'
  COVERAGE_THRESHOLD: ${{ github.event.inputs.coverage_threshold || '80' }}

jobs:
  setup:
    name: ğŸ”§ Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      cache-key: ${{ steps.cache-key.outputs.key }}
    steps:
      - uses: actions/checkout@v4

      - name: Generate cache key
        id: cache-key
        run: |
          echo "key=${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}-${{ hashFiles('**/pyproject.toml') }}" >> $GITHUB_OUTPUT

      - name: Set test matrix
        id: set-matrix
        run: |
          if [ "${{ github.event.inputs.test_type }}" = "all" ] || [ -z "${{ github.event.inputs.test_type }}" ]; then
            echo 'matrix=["unit", "integration", "e2e", "performance"]' >> $GITHUB_OUTPUT
          else
            echo 'matrix=["${{ github.event.inputs.test_type }}"]' >> $GITHUB_OUTPUT
          fi

  pre-commit:
    name: ğŸ¨ Pre-commit Checks
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install pre-commit and dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install pre-commit
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}

      - name: Run pre-commit
        run: pre-commit run --all-files

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  test:
    name: ğŸ§ª Tests (${{ matrix.test-type }})
    runs-on: ubuntu-latest
    needs: [setup, pre-commit]
    strategy:
      matrix:
        test-type: ${{ fromJson(needs.setup.outputs.matrix) }}
      fail-fast: false

    services:
      rabbitmq:
        image: rabbitmq:3-management
        ports:
          - 5672:5672
          - 15672:15672
        options: >-
          --health-cmd "rabbitmq-diagnostics -q ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y git curl jq sqlite3

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-asyncio pytest-timeout pytest-mock pytest-benchmark pytest-xdist
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-test.txt ]; then pip install -r requirements-test.txt; fi

      - name: Create test directories
        run: |
          mkdir -p junit coverage-reports benchmark-reports

      - name: Run ${{ matrix.test-type }} tests
        run: |
          case "${{ matrix.test-type }}" in
            "unit")
              pytest tests/unit/ -v --junitxml=junit/test-results-unit.xml \
                --cov=core --cov=workers --cov=libs \
                --cov-report=xml:coverage-reports/coverage-unit.xml \
                --cov-report=html:coverage-reports/htmlcov-unit \
                --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
                -n auto
              ;;
            "integration")
              pytest tests/integration/ -v --junitxml=junit/test-results-integration.xml \
                --timeout=30
              ;;
            "e2e")
              pytest tests/e2e/ -v --junitxml=junit/test-results-e2e.xml \
                --timeout=60
              ;;
            "performance")
              pytest tests/performance/ -v --junitxml=junit/test-results-performance.xml \
                --benchmark-only --benchmark-json=benchmark-reports/benchmark-${{ matrix.test-type }}.json \
                --benchmark-sort=mean
              ;;
          esac
        env:
          RABBITMQ_HOST: localhost
          RABBITMQ_PORT: 5672
          REDIS_HOST: localhost
          REDIS_PORT: 6379
          PYTHONPATH: ${{ github.workspace }}

      - name: Generate coverage badge
        if: matrix.test-type == 'unit'
        run: |
          COVERAGE=$(python -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage-reports/coverage-unit.xml'); root = tree.getroot(); print(f\"{float(root.attrib['line-rate'])*100:.1f}\")")
          echo "COVERAGE_PERCENTAGE=$COVERAGE" >> $GITHUB_ENV

          # Generate badge color
          if (( $(echo "$COVERAGE >= 90" | bc -l) )); then
            COLOR="brightgreen"
          elif (( $(echo "$COVERAGE >= 80" | bc -l) )); then
            COLOR="green"
          elif (( $(echo "$COVERAGE >= 70" | bc -l) )); then
            COLOR="yellow"
          elif (( $(echo "$COVERAGE >= 60" | bc -l) )); then
            COLOR="orange"
          else
            COLOR="red"
          fi
          echo "BADGE_COLOR=$COLOR" >> $GITHUB_ENV

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            junit/test-results-${{ matrix.test-type }}.xml
            coverage-reports/
            benchmark-reports/

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.test-type == 'unit'
        with:
          file: ./coverage-reports/coverage-unit.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: true

  performance-analysis:
    name: ğŸ“Š Performance Analysis
    runs-on: ubuntu-latest
    needs: test
    if: contains(needs.test.strategy.matrix.test-type, 'performance')
    steps:
      - uses: actions/checkout@v4

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: test-results-performance
          path: benchmark-reports/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install matplotlib pandas jinja2

      - name: Generate performance report
        run: |
          python scripts/generate_performance_report.py \
            --input benchmark-reports/benchmark-performance.json \
            --output performance-report.html \
            --format html

      - name: Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.html

      - name: Performance regression check
        run: |
          python scripts/check_performance_regression.py \
            --current benchmark-reports/benchmark-performance.json \
            --threshold 10

  security-advanced:
    name: ğŸ›¡ï¸ Advanced Security Scan
    runs-on: ubuntu-latest
    needs: pre-commit
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Run CodeQL Analysis
        uses: github/codeql-action/init@v3
        with:
          languages: python

      - name: Autobuild
        uses: github/codeql-action/autobuild@v3

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  build:
    name: ğŸ”¨ Build & Package
    runs-on: ubuntu-latest
    needs: [test, security-advanced]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip build wheel setuptools

      - name: Build package
        run: |
          python -m build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: python-package
          path: dist/

  deploy-staging:
    name: ğŸ§ª Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment: staging
    steps:
      - uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: dist/

      - name: Deploy to staging
        run: |
          echo "ğŸ§ª Deploying to staging environment..."
          # ã“ã“ã«å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

      - name: Run smoke tests
        run: |
          python scripts/smoke_tests.py --environment staging

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            ğŸ§ª AI Company deployed to staging!
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            Branch: ${{ github.ref_name }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK_STAGING }}
        if: always()

  deploy-production:
    name: ğŸš€ Deploy to Production
    runs-on: ubuntu-latest
    needs: [build, deploy-staging]
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: dist/

      - name: Pre-deployment health check
        run: |
          python scripts/pre_deployment_check.py --environment production

      - name: Deploy to production
        run: |
          echo "ğŸš€ Deploying to production environment..."
          # ã“ã“ã«å®Ÿéš›ã®æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

      - name: Post-deployment verification
        run: |
          python scripts/post_deployment_verification.py --environment production

      - name: Update deployment status
        run: |
          echo "âœ… Deployment completed successfully"
          echo "ğŸ”— Production URL: https://ai-company.example.com"

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            ğŸš€ AI Company deployed to production!
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            Version: ${{ github.ref_name }}
            ğŸ”— https://ai-company.example.com
          webhook_url: ${{ secrets.SLACK_WEBHOOK_PRODUCTION }}
        if: always()

  ai-insights:
    name: ğŸ¤– AI Code Analysis
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true

      - name: AI Code Review
        run: |
          python scripts/ai_code_review.py \
            --pr-number ${{ github.event.number }} \
            --base-branch ${{ github.base_ref }} \
            --head-branch ${{ github.head_ref }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}

      - name: Generate test suggestions
        run: |
          python scripts/ai_test_suggestions.py \
            --coverage-reports coverage-reports/ \
            --output ai-test-suggestions.md
        env:
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}

      - name: Comment PR with AI insights
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('ai-test-suggestions.md')) {
              const suggestions = fs.readFileSync('ai-test-suggestions.md', 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `## ğŸ¤– AI Code Analysis\n\n${suggestions}`
              });
            }

  cleanup:
    name: ğŸ§¹ Cleanup
    runs-on: ubuntu-latest
    needs: [deploy-production, deploy-staging, ai-insights]
    if: always()
    steps:
      - name: Clean up artifacts
        run: |
          echo "ğŸ§¹ Cleaning up temporary artifacts..."
          # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

      - name: Report final status
        run: |
          echo "ğŸ‰ CI/CD Pipeline completed!"
          echo "Status: ${{ needs.deploy-production.result || needs.deploy-staging.result || 'completed' }}"
