#!/usr/bin/env python3
"""
å®Ÿéš›ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¨ãƒ©ãƒ¼åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œ
242ä¸‡ä»¶ã®ã€ŒOtherã€ã‚¨ãƒ©ãƒ¼ã‚’è©³ç´°åˆ†é¡
"""

import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

import json

from libs.enhanced_error_classifier import EnhancedErrorClassifier


def main():
    """å®Ÿéš›ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§åˆ†æå®Ÿè¡Œ"""
    print("ğŸ” Elders Guild ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« ã‚¨ãƒ©ãƒ¼åˆ†é¡å®Ÿè¡Œ")
    print("=" * 60)

    classifier = EnhancedErrorClassifier()

    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
    logs_dir = Path("/home/aicompany/ai_co/logs")

    if not logs_dir.exists():
        print("âŒ ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    log_files = list(logs_dir.glob("*.log"))

    if not log_files:
        print("âš ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    print(f"ğŸ“ ç™ºè¦‹ã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {len(log_files)}å€‹")

    total_errors = 0
    all_categories = {}
    analysis_results = []

    # å„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
    for log_file in log_files[-5:]:  # æœ€æ–°5ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
        print(f"\nğŸ”„ åˆ†æä¸­: {log_file.name}")

        analysis = classifier.analyze_log_file(str(log_file))

        if "error" in analysis:
            print(f"   âŒ {analysis['error']}")
            continue

        errors_found = analysis["total_errors"]
        total_errors += errors_found

        print(f"   ğŸ“Š ã‚¨ãƒ©ãƒ¼æ•°: {errors_found}")

        # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆã‚’é›†è¨ˆ
        for category, count in analysis["categories"].items():
            all_categories[category] = all_categories.get(category, 0) + count
            print(f"     {category}: {count}ä»¶")

        analysis_results.append(analysis)

    # å…¨ä½“çµ±è¨ˆè¡¨ç¤º
    print(f"\nğŸ“ˆ å…¨ä½“çµ±è¨ˆ:")
    print(f"   ç·ã‚¨ãƒ©ãƒ¼æ•°: {total_errors:,}")
    print(f"   åˆ†é¡ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª: {len(all_categories)}")

    print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ:")
    sorted_categories = sorted(all_categories.items(), key=lambda x: x[1], reverse=True)

    for category, count in sorted_categories:
        percentage = (count / total_errors * 100) if total_errors > 0 else 0
        print(f"   {category}: {count:,}ä»¶ ({percentage:.1f}%)")

    # æ”¹å–„ææ¡ˆç”Ÿæˆ
    print(f"\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
    if sorted_categories:
        top_category, top_count = sorted_categories[0]
        print(f"   1. æœ€å¤šã®{top_category}ã‚¨ãƒ©ãƒ¼({top_count:,}ä»¶)ã®å¯¾ç­–ã‚’å„ªå…ˆå®Ÿæ–½")

        if top_category == "system":
            print("      â†’ ä¾å­˜é–¢ä¿‚ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª")
        elif top_category == "network":
            print("      â†’ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã®èª¿æ•´")
        elif top_category == "database":
            print("      â†’ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–")
        elif top_category == "memory":
            print("      â†’ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–")
        elif top_category == "other":
            print("      â†’ æœªåˆ†é¡ã‚¨ãƒ©ãƒ¼ã®è©³ç´°èª¿æŸ»ã¨æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ ")

    if len(sorted_categories) > 1:
        print("   2. è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹åŒ…æ‹¬çš„å¯¾ç­–")
        print("   3. ã‚¨ãƒ©ãƒ¼äºˆé˜²ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…")

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆClassifiedErrorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›ï¼‰
    simplified_analysis = []
    for analysis in analysis_results:
        simplified = analysis.copy()
        # ClassifiedErrorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
        if "classified_errors" in simplified:
            simplified["classified_errors"] = [
                {
                    "original_error": err.original_error,
                    "category": err.category,
                    "subcategory": err.subcategory,
                    "severity": err.severity,
                    "confidence": err.confidence,
                    "auto_fix_suggestion": err.auto_fix_suggestion,
                    "timestamp": err.timestamp,
                }
                for err in simplified["classified_errors"]
            ]
        simplified_analysis.append(simplified)

    output_data = {
        "analysis_timestamp": classifier.get_statistics()["timestamp"],
        "total_errors_analyzed": total_errors,
        "category_statistics": all_categories,
        "log_files_analyzed": [str(f) for f in log_files[-5:]],
        "detailed_analysis": simplified_analysis,
        "improvement_recommendations": [
            f"æœ€å¤šã®{sorted_categories[0][0]}ã‚¨ãƒ©ãƒ¼å¯¾ç­–ã‚’å„ªå…ˆå®Ÿæ–½"
            if sorted_categories
            else "ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æãŒå¿…è¦",
            "ã‚¨ãƒ©ãƒ¼äºˆé˜²ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…",
            "å®šæœŸçš„ãªã‚¨ãƒ©ãƒ¼åˆ†æã®è‡ªå‹•åŒ–",
        ],
    }

    output_file = Path(
        "/home/aicompany/ai_co/ai_todo/error_classification_results.json"
    )
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… åˆ†æçµæœã‚’ä¿å­˜: {output_file}")

    # åˆ†é¡å™¨ã®çµ±è¨ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    classifier.export_results(
        "/home/aicompany/ai_co/ai_todo/classified_errors_export.json"
    )

    print("ğŸ‰ ã‚¨ãƒ©ãƒ¼åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼")
    print("\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. æœ€å¤šã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®å¯¾ç­–å®Ÿæ–½")
    print("2. è‡ªå‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é–‹ç™º")
    print("3. äºˆé˜²çš„ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰")

    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
