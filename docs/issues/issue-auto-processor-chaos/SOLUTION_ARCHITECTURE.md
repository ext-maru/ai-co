# Auto Issue Processor ã‚«ã‚ªã‚¹å•é¡Œ - æ ¹æœ¬çš„è§£æ±ºã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**ä½œæˆæ—¥**: 2025-07-22  
**ä½œæˆè€…**: ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ï¼ˆClaude Elderï¼‰  
**æ–‡æ›¸ç¨®åˆ¥**: æŠ€è¡“è¨­è¨ˆæ›¸

## ğŸ¯ è§£æ±ºæ–¹é‡

### åŸºæœ¬åŸå‰‡

1. **Single Source of Truth**: 1ã¤ã®çµ±åˆå®Ÿè£…ã®ã¿ã‚’ç¶­æŒ
2. **Explicit over Implicit**: æ˜ç¤ºçš„ãªè¨­å®šã¨å‹•ä½œ
3. **Fail Safe**: ã‚¨ãƒ©ãƒ¼æ™‚ã¯å®‰å…¨å´ã«å€’ã‚Œã‚‹
4. **Observable**: ã™ã¹ã¦ã®å‹•ä½œãŒç›£è¦–å¯èƒ½

## ğŸ—ï¸ æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### 1. çµ±åˆå®Ÿè£…ã®æ§‹é€ 

```
libs/auto_issue_processor/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ processor.py          # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ãƒƒã‚µ
â”‚   â”œâ”€â”€ config.py            # è¨­å®šç®¡ç†
â”‚   â””â”€â”€ exceptions.py        # ä¾‹å¤–å®šç¾©
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ error_handling.py    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½
â”‚   â”œâ”€â”€ pr_creation.py       # PRä½œæˆæ©Ÿèƒ½
â”‚   â”œâ”€â”€ parallel_processing.py # ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½
â”‚   â””â”€â”€ github_integration.py  # GitHubçµ±åˆ
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ locking.py           # ãƒ—ãƒ­ã‚»ã‚¹ãƒ­ãƒƒã‚¯
â”‚   â”œâ”€â”€ logging.py           # ãƒ­ã‚®ãƒ³ã‚°
â”‚   â””â”€â”€ metrics.py           # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
â””â”€â”€ tests/
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

### 2. ã‚³ã‚¢å®Ÿè£…

```python
# libs/auto_issue_processor/core/processor.py

from typing import Optional, List, Dict, Any
import asyncio
from ..utils.locking import ProcessLock
from ..features import ErrorHandler, PRCreator, ParallelProcessor
from .config import ProcessorConfig

class UnifiedAutoIssueProcessor:
    """çµ±åˆã•ã‚ŒãŸAuto Issue Processor
    
    ã™ã¹ã¦ã®æ©Ÿèƒ½ã‚’çµ±åˆã—ã€è¨­å®šã«ã‚ˆã‚Šå‹•ä½œã‚’åˆ¶å¾¡ã™ã‚‹å˜ä¸€ã®å®Ÿè£…ã€‚
    """
    
    def __init__(self, config: Optional[ProcessorConfig] = None):
        self.config = config or ProcessorConfig.from_env()
        self.lock_manager = ProcessLock(self.config.lock_backend)
        self.error_handler = ErrorHandler(self.config.error_handling)
        self.pr_creator = PRCreator(self.config.pr_creation) if self.config.features.pr_creation else None
        self.parallel_processor = ParallelProcessor(self.config.parallel) if self.config.features.parallel else None
        
    async def process_issue(self, issue_number: int) -> Dict[str, Any]:
        """å˜ä¸€ã®Issueã‚’å‡¦ç†"""
        
        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ­ãƒƒã‚¯ã®å–å¾—
        lock_acquired = await self.lock_manager.acquire(
            f"issue_{issue_number}",
            ttl=self.config.processing_timeout
        )
        
        if not lock_acquired:
            return {
                "success": False,
                "error": "Issue is already being processed",
                "issue_number": issue_number
            }
        
        try:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã§ãƒ©ãƒƒãƒ—
            async with self.error_handler.context(issue_number):
                result = await self._process_issue_impl(issue_number)
                
                # PRä½œæˆãŒæœ‰åŠ¹ãªå ´åˆ
                if self.pr_creator and result.get("success"):
                    pr_result = await self.pr_creator.create_pr(result)
                    result["pr"] = pr_result
                
                return result
                
        finally:
            await self.lock_manager.release(f"issue_{issue_number}")
    
    async def process_issues_batch(self, issue_numbers: List[int]) -> List[Dict[str, Any]]:
        """è¤‡æ•°ã®Issueã‚’ãƒãƒƒãƒå‡¦ç†"""
        
        if self.parallel_processor:
            return await self.parallel_processor.process_batch(
                issue_numbers,
                self.process_issue
            )
        else:
            # é †æ¬¡å‡¦ç†
            results = []
            for issue_number in issue_numbers:
                result = await self.process_issue(issue_number)
                results.append(result)
            return results
```

### 3. è¨­å®šç®¡ç†

```python
# libs/auto_issue_processor/core/config.py

from dataclasses import dataclass
from typing import Optional
import yaml
import os

@dataclass
class FeatureFlags:
    """æ©Ÿèƒ½ãƒ•ãƒ©ã‚°"""
    pr_creation: bool = True
    error_recovery: bool = True
    parallel_processing: bool = False
    smart_merge: bool = False
    four_sages_integration: bool = True

@dataclass
class ProcessorConfig:
    """ãƒ—ãƒ­ã‚»ãƒƒã‚µè¨­å®š"""
    
    # åŸºæœ¬è¨­å®š
    enabled: bool = True
    interval_minutes: int = 10
    max_issues_per_run: int = 5
    processing_timeout: int = 300  # ç§’
    
    # æ©Ÿèƒ½ãƒ•ãƒ©ã‚°
    features: FeatureFlags = None
    
    # ãƒ­ãƒƒã‚¯è¨­å®š
    lock_backend: str = "file"  # file, redis, memory
    lock_dir: str = "./.issue_locks"
    
    # GitHubè¨­å®š
    github_token: Optional[str] = None
    github_repo: Optional[str] = None
    rate_limit_buffer: int = 100
    
    # ãƒ­ã‚°è¨­å®š
    log_level: str = "INFO"
    log_file: str = "logs/auto_issue_processor.log"
    
    @classmethod
    def from_file(cls, path: str) -> "ProcessorConfig":
        """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
        with open(path, 'r') as f:
            data = yaml.safe_load(f)
        return cls(**data)
    
    @classmethod
    def from_env(cls) -> "ProcessorConfig":
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
        config = cls()
        
        # ç’°å¢ƒå¤‰æ•°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
        if os.getenv("AUTO_ISSUE_PROCESSOR_ENABLED"):
            config.enabled = os.getenv("AUTO_ISSUE_PROCESSOR_ENABLED").lower() == "true"
        
        if os.getenv("GITHUB_TOKEN"):
            config.github_token = os.getenv("GITHUB_TOKEN")
            
        return config
```

### 4. ãƒ—ãƒ­ã‚»ã‚¹ãƒ­ãƒƒã‚¯å®Ÿè£…

```python
# libs/auto_issue_processor/utils/locking.py

import asyncio
import aiofiles
import os
import json
import time
from typing import Optional
from abc import ABC, abstractmethod

class LockBackend(ABC):
    """ãƒ­ãƒƒã‚¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    async def acquire(self, key: str, ttl: int) -> bool:
        pass
    
    @abstractmethod
    async def release(self, key: str) -> bool:
        pass
    
    @abstractmethod
    async def is_locked(self, key: str) -> bool:
        pass

class FileLockBackend(LockBackend):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒƒã‚¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰"""
    
    def __init__(self, lock_dir: str = "./.issue_locks"):
        self.lock_dir = lock_dir
        os.makedirs(lock_dir, exist_ok=True)
    
    async def acquire(self, key: str, ttl: int) -> bool:
        lock_file = os.path.join(self.lock_dir, f"{key}.lock")
        
        # æ—¢å­˜ãƒ­ãƒƒã‚¯ã®ç¢ºèª
        if await self.is_locked(key):
            return False
        
        # ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        lock_data = {
            "key": key,
            "pid": os.getpid(),
            "acquired_at": time.time(),
            "ttl": ttl
        }
        
        try:
            async with aiofiles.open(lock_file, 'w') as f:
                await f.write(json.dumps(lock_data))
            return True
        except:
            return False
    
    async def release(self, key: str) -> bool:
        lock_file = os.path.join(self.lock_dir, f"{key}.lock")
        try:
            os.remove(lock_file)
            return True
        except:
            return False
    
    async def is_locked(self, key: str) -> bool:
        lock_file = os.path.join(self.lock_dir, f"{key}.lock")
        
        if not os.path.exists(lock_file):
            return False
        
        try:
            async with aiofiles.open(lock_file, 'r') as f:
                data = json.loads(await f.read())
            
            # TTLãƒã‚§ãƒƒã‚¯
            elapsed = time.time() - data["acquired_at"]
            if elapsed > data["ttl"]:
                # æœŸé™åˆ‡ã‚Œãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤
                await self.release(key)
                return False
            
            return True
        except:
            return False

class ProcessLock:
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ­ãƒƒã‚¯ç®¡ç†"""
    
    def __init__(self, backend: str = "file", **kwargs):
        if backend == "file":
            self.backend = FileLockBackend(**kwargs)
        else:
            raise ValueError(f"Unknown lock backend: {backend}")
    
    async def acquire(self, key: str, ttl: int = 300) -> bool:
        return await self.backend.acquire(key, ttl)
    
    async def release(self, key: str) -> bool:
        return await self.backend.release(key)
    
    async def is_locked(self, key: str) -> bool:
        return await self.backend.is_locked(key)
```

### 5. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çµ±åˆ

```python
# libs/auto_issue_processor/scheduler.py

import asyncio
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from .core.processor import UnifiedAutoIssueProcessor
from .core.config import ProcessorConfig
import logging

logger = logging.getLogger(__name__)

class AutoIssueProcessorScheduler:
    """Auto Issue Processorã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self, config: ProcessorConfig):
        self.config = config
        self.processor = UnifiedAutoIssueProcessor(config)
        self.scheduler = AsyncIOScheduler()
        self._job = None
    
    async def process_batch(self):
        """å®šæœŸå®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†"""
        if not self.config.enabled:
            logger.info("Auto Issue Processor is disabled")
            return
        
        logger.info("Starting scheduled Auto Issue Processor run")
        
        try:
            # å‡¦ç†å¯¾è±¡ã®Issueã‚’å–å¾—
            issues = await self._get_processable_issues()
            
            if not issues:
                logger.info("No processable issues found")
                return
            
            # ãƒãƒƒãƒå‡¦ç†
            results = await self.processor.process_issues_batch(
                issues[:self.config.max_issues_per_run]
            )
            
            # çµæœã®ãƒ­ã‚°
            success_count = sum(1 for r in results if r.get("success"))
            logger.info(f"Processed {len(results)} issues, {success_count} successful")
            
        except Exception as e:
            logger.error(f"Error in scheduled processing: {e}", exc_info=True)
    
    def start(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
        if self._job:
            logger.warning("Scheduler already started")
            return
        
        trigger = IntervalTrigger(minutes=self.config.interval_minutes)
        self._job = self.scheduler.add_job(
            self.process_batch,
            trigger=trigger,
            id="auto_issue_processor",
            replace_existing=True
        )
        
        self.scheduler.start()
        logger.info(f"Scheduler started with {self.config.interval_minutes} minute interval")
    
    def stop(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢"""
        if self._job:
            self._job.remove()
            self._job = None
        
        self.scheduler.shutdown()
        logger.info("Scheduler stopped")
```

## ğŸ”§ å®Ÿè£…æ‰‹é †

### Phase 1: åŸºç›¤æ§‹ç¯‰ï¼ˆDay 1-2ï¼‰

1. **ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ**
   ```bash
   mkdir -p libs/auto_issue_processor/{core,features,utils,tests}
   ```

2. **æ—¢å­˜å®Ÿè£…ã®åˆ†æã¨ãƒãƒƒãƒ”ãƒ³ã‚°**
   - å„å®Ÿè£…ã®æ©Ÿèƒ½ã‚’æŠ½å‡º
   - å…±é€šéƒ¨åˆ†ã¨ç‹¬è‡ªéƒ¨åˆ†ã®è­˜åˆ¥

3. **ã‚³ã‚¢å®Ÿè£…ã®ä½œæˆ**
   - `processor.py`ã®åŸºæœ¬å®Ÿè£…
   - `config.py`ã®è¨­å®šç®¡ç†

### Phase 2: æ©Ÿèƒ½ç§»æ¤ï¼ˆDay 3-5ï¼‰

1. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½**
   - `auto_issue_processor_enhanced.py`ã‹ã‚‰ç§»æ¤

2. **PRä½œæˆæ©Ÿèƒ½**
   - `enhanced_auto_issue_processor.py`ã‹ã‚‰ç§»æ¤

3. **ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½**
   - `optimized_auto_issue_processor.py`ã‹ã‚‰ç§»æ¤

### Phase 3: çµ±åˆã¨ãƒ†ã‚¹ãƒˆï¼ˆDay 6-7ï¼‰

1. **çµ±åˆãƒ†ã‚¹ãƒˆä½œæˆ**
2. **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§ç¢ºèª**
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ**

### Phase 4: ç§»è¡Œï¼ˆDay 8-10ï¼‰

1. **æ—¢å­˜å®Ÿè£…ã®ç„¡åŠ¹åŒ–**
2. **æ–°å®Ÿè£…ã¸ã®åˆ‡ã‚Šæ›¿ãˆ**
3. **ç›£è¦–ã¨ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—**

## ğŸ“Š æˆåŠŸæŒ‡æ¨™

1. **æ©Ÿèƒ½çš„æˆåŠŸ**
   - [ ] ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šæ›¸ãå•é¡Œã®è§£æ±º
   - [ ] é‡è¤‡å‡¦ç†ã®é˜²æ­¢
   - [ ] ã™ã¹ã¦ã®æ—¢å­˜æ©Ÿèƒ½ã®ç¶­æŒ

2. **éæ©Ÿèƒ½çš„æˆåŠŸ**
   - [ ] å‡¦ç†æ™‚é–“ã®æ”¹å–„ï¼ˆ20%ä»¥ä¸Šï¼‰
   - [ ] ã‚¨ãƒ©ãƒ¼ç‡ã®ä½ä¸‹ï¼ˆ50%ä»¥ä¸Šï¼‰
   - [ ] ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã®æœ€é©åŒ–

3. **é‹ç”¨çš„æˆåŠŸ**
   - [ ] çµ±ä¸€ã•ã‚ŒãŸãƒ­ã‚°å‡ºåŠ›
   - [ ] åŒ…æ‹¬çš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
   - [ ] æ˜ç¢ºãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## ğŸš€ å°†æ¥ã®æ‹¡å¼µæ€§

1. **ãƒ—ãƒ©ã‚¬ãƒ–ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
   - æ–°æ©Ÿèƒ½ã®è¿½åŠ ãŒå®¹æ˜“
   - æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿æœ€å°åŒ–

2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**
   - æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ
   - åˆ†æ•£ãƒ­ãƒƒã‚¯å¯¾å¿œ

3. **å¯è¦³æ¸¬æ€§**
   - OpenTelemetryçµ±åˆ
   - è©³ç´°ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹

---

**ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€Auto Issue Processorã‚·ã‚¹ãƒ†ãƒ ã®æ··ä¹±ã‚’æ ¹æœ¬çš„ã«è§£æ±ºã—ã€æŒç¶šå¯èƒ½ãªé–‹ç™ºåŸºç›¤ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚**