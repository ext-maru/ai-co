#!/usr/bin/env python3
"""
"ğŸ”" Conflict Analyzer
ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†æã‚¨ãƒ³ã‚¸ãƒ³

æ©Ÿèƒ½:
- ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡
- è‡ªå‹•è§£æ±ºå¯èƒ½æ€§ã®åˆ¤å®š
- ãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
- å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
- è§£æ±ºæˆ¦ç•¥ã®ææ¡ˆ
"""

import logging
import re
import os
from datetime import datetime
from typing import Any, Dict, List, Optional, Set, Tuple
from dataclasses import dataclass
from enum import Enum
import subprocess

logger = logging.getLogger(__name__)

class ConflictType(Enum):
    """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã‚¿ã‚¤ãƒ—"""
    MERGE_CONFLICT = "merge_conflict"
    DEPENDENCY_CONFLICT = "dependency_conflict"
    VERSION_CONFLICT = "version_conflict"
    CHANGELOG_CONFLICT = "changelog_conflict"
    DOCUMENTATION_CONFLICT = "documentation_conflict"
    IMPORT_CONFLICT = "import_conflict"
    FORMATTING_CONFLICT = "formatting_conflict"
    WHITESPACE_CONFLICT = "whitespace_conflict"
    CONFIG_CONFLICT = "config_conflict"
    UNKNOWN_CONFLICT = "unknown_conflict"

class RiskLevel(Enum):
    """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"""
    SAFE = "safe"           # è‡ªå‹•è§£æ±ºå®‰å…¨
    LOW = "low"             # æ³¨æ„ã—ã¦è‡ªå‹•è§£æ±ºå¯èƒ½
    MEDIUM = "medium"       # æ…é‡ãªæ¤œè¨å¿…è¦
    HIGH = "high"           # æ‰‹å‹•å¯¾å¿œæ¨å¥¨
    CRITICAL = "critical"   # çµ¶å¯¾æ‰‹å‹•å¯¾å¿œ

class ResolutionStrategy(Enum):
    """è§£æ±ºæˆ¦ç•¥"""
    AUTO_MERGE_DEPENDENCIES = "auto_merge_dependencies"
    AUTO_APPEND_CHANGELOG = "auto_append_changelog"
    AUTO_FORMAT_CODE = "auto_format_code"
    AUTO_MERGE_IMPORTS = "auto_merge_imports"
    AUTO_UPDATE_VERSION = "auto_update_version"
    MANUAL_REVIEW = "manual_review"
    NO_RESOLUTION = "no_resolution"

@dataclass
class ConflictedFile:
    """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±"""
    file_path: str
    conflict_type: ConflictType
    risk_level: RiskLevel
    conflict_markers: List[str]
    auto_resolvable: bool
    resolution_strategy: Optional[ResolutionStrategy]
    confidence_score: float  # 0.0-1.0
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "file_path": self.file_path,
            "conflict_type": self.conflict_type.value,
            "risk_level": self.risk_level.value,
            "conflict_markers": self.conflict_markers,
            "auto_resolvable": self.auto_resolvable,
            "resolution_strategy": self.resolution_strategy.value if self.resolution_strategy else None,
            "confidence_score": self.confidence_score
        }

@dataclass
class ConflictAnalysisResult:
    """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†æçµæœ"""
    total_conflicts: int
    conflicted_files: List[ConflictedFile]
    auto_resolvable_files: List[ConflictedFile]
    manual_required_files: List[ConflictedFile]
    overall_risk_level: RiskLevel
    estimated_resolution_time: int  # åˆ†
    safety_score: float  # 0.0-1.0
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "total_conflicts": self.total_conflicts,
            "conflicted_files": [f.to_dict() for f in self.conflicted_files],
            "auto_resolvable_count": len(self.auto_resolvable_files),
            "manual_required_count": len(self.manual_required_files),
            "overall_risk_level": self.overall_risk_level.value,
            "estimated_resolution_time": self.estimated_resolution_time,
            "safety_score": self.safety_score
        }

class ConflictAnalyzer:
    """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    # å®‰å…¨ã«è‡ªå‹•è§£æ±ºå¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    SAFE_AUTO_RESOLVE_PATTERNS = {
        r"package\.json$": {
            "type": ConflictType.DEPENDENCY_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_MERGE_DEPENDENCIES,
            "risk": RiskLevel.SAFE
        },
        r"package-lock\.json$": {
            "type": ConflictType.DEPENDENCY_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_MERGE_DEPENDENCIES,
            "risk": RiskLevel.LOW
        },
        r"CHANGELOG\.md$": {
            "type": ConflictType.CHANGELOG_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_APPEND_CHANGELOG,
            "risk": RiskLevel.SAFE
        },
        r"changelog\.md$": {
            "type": ConflictType.CHANGELOG_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_APPEND_CHANGELOG,
            "risk": RiskLevel.SAFE
        },
        r"\.gitignore$": {
            "type": ConflictType.CONFIG_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_MERGE_DEPENDENCIES,
            "risk": RiskLevel.LOW
        },
        r"requirements\.txt$": {
            "type": ConflictType.DEPENDENCY_CONFLICT,
            "strategy": ResolutionStrategy.AUTO_MERGE_DEPENDENCIES,
            "risk": RiskLevel.LOW
        }
    }
    
    # æ‰‹å‹•å¯¾å¿œå¿…é ˆãƒ‘ã‚¿ãƒ¼ãƒ³
    MANUAL_REQUIRED_PATTERNS = {
        r"\.py$": RiskLevel.MEDIUM,  # Pythonã‚³ãƒ¼ãƒ‰
        r"\.js$": RiskLevel.MEDIUM,  # JavaScriptã‚³ãƒ¼ãƒ‰
        r"\.ts$": RiskLevel.MEDIUM,  # TypeScriptã‚³ãƒ¼ãƒ‰
        r"\.sql$": RiskLevel.HIGH,   # SQLã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        r"config\.(json|yaml|yml)$": RiskLevel.HIGH,  # é‡è¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        r"\.env": RiskLevel.CRITICAL,  # ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«
        r"Dockerfile$": RiskLevel.HIGH,  # Dockerè¨­å®š
        r"docker-compose\.ya?ml$": RiskLevel.HIGH,  # Docker Compose
    }
    
    # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
    CONFLICT_MARKERS = [
        r"<{7}\s",      # <<<<<<< HEAD
        r"={7}",        # =======
        r">{7}\s",      # >>>>>>> branch
        r"\|{7}",       # |||||||
    ]
    
    def __init__(self, repo_path: str = None):
        """
        åˆæœŸåŒ–
        
        Args:
            repo_path: Gitãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.repo_path = repo_path or os.getcwd()
        
    async def analyze_conflicts(
        self, 
        base_branch: str = "main",
        head_branch: str = None,
        pr_number: int = None
    ) -> ConflictAnalysisResult:
        """
        ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã‚’åˆ†æ
        
        Args:
            base_branch: ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒ
            head_branch: ãƒ˜ãƒƒãƒ‰ãƒ–ãƒ©ãƒ³ãƒ
            pr_number: PRç•ªå·ï¼ˆæŒ‡å®šæ™‚ã¯PRã®æƒ…å ±ã‚’ä½¿ç”¨ï¼‰
            
        Returns:
            ConflictAnalysisResult: åˆ†æçµæœ
        """
        try:
            # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            conflicted_files_info = await self._get_conflicted_files(
                base_branch, head_branch, pr_number
            )
            
            if not conflicted_files_info:
                # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãªã—
                return ConflictAnalysisResult(
                    total_conflicts=0,
                    conflicted_files=[],
                    auto_resolvable_files=[],
                    manual_required_files=[],
                    overall_risk_level=RiskLevel.SAFE,
                    estimated_resolution_time=0,
                    safety_score=1.0
                )
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
            conflicted_files = []
            for file_info in conflicted_files_info:
                analyzed_file = await self._analyze_single_file(file_info)
                conflicted_files.append(analyzed_file)
            
            # çµæœã‚’åˆ†é¡
            auto_resolvable = [f for f in conflicted_files if f.auto_resolvable]
            manual_required = [f for f in conflicted_files if not f.auto_resolvable]
            
            # å…¨ä½“ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ç®—å‡º
            overall_risk = self._calculate_overall_risk(conflicted_files)
            
            # è§£æ±ºæ™‚é–“ã‚’æ¨å®š
            estimated_time = self._estimate_resolution_time(conflicted_files)
            
            # å®‰å…¨æ€§ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
            safety_score = self._calculate_safety_score(conflicted_files)
            
            return ConflictAnalysisResult(
                total_conflicts=len(conflicted_files),
                conflicted_files=conflicted_files,
                auto_resolvable_files=auto_resolvable,
                manual_required_files=manual_required,
                overall_risk_level=overall_risk,
                estimated_resolution_time=estimated_time,
                safety_score=safety_score
            )
            
        except Exception as e:
            logger.error(f"Conflict analysis failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿å®ˆçš„ãªçµæœã‚’è¿”ã™
            return ConflictAnalysisResult(
                total_conflicts=1,
                conflicted_files=[],
                auto_resolvable_files=[],
                manual_required_files=[],
                overall_risk_level=RiskLevel.CRITICAL,
                estimated_resolution_time=60,
                safety_score=0.0
            )
    
    async def _get_conflicted_files(
        self, 
        base_branch: str, 
        head_branch: str, 
        pr_number: int
    ) -> List[Dict[str, Any]]:
        """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            # Git merge-tree ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã‚’æ¤œå‡º
            if head_branch:
                # ãƒ–ãƒ©ãƒ³ãƒæŒ‡å®šæ™‚
                cmd = [
                    "git", "merge-tree", 
                    f"origin/{base_branch}", 
                    f"origin/{head_branch}"
                ]
            else:
                # PRç•ªå·æŒ‡å®šæ™‚ï¼ˆç°¡ç•¥åŒ–ï¼‰
                cmd = ["git", "status", "--porcelain"]
            
            result = subprocess.run(
                cmd, 
                cwd=self.repo_path,
                capture_output=True, 
                text=True, 
                check=False
            )
            
            if result.returncode != 0 and not result.stdout:
                return []
            
            # çµæœã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡ç•¥åŒ–ï¼‰
            conflicted_files = []
            for line in result.stdout.split('\n'):
                if line.strip():
                    # ç°¡å˜ãªè§£æ
                    if 'UU' in line or '<<<<<<< ' in line:
                        file_path = line.split()[-1] if line.split() else "unknown"
                        conflicted_files.append({
                            "file_path": file_path,
                            "status": "conflicted"
                        })
            
            return conflicted_files
            
        except Exception as e:
            logger.error(f"Failed to get conflicted files: {e}")
            return []
    
    async def _analyze_single_file(self, file_info: Dict[str, Any]) -> ConflictedFile:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†æ"""
        file_path = file_info["file_path"]
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            conflict_type, risk_level, strategy = self._classify_file_conflict(file_path)
            
            # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ã‚’æ¤œå‡º
            conflict_markers = await self._detect_conflict_markers(file_path)
            
            # è‡ªå‹•è§£æ±ºå¯èƒ½æ€§ã‚’åˆ¤å®š
            auto_resolvable = self._is_auto_resolvable(file_path, conflict_type, risk_level)
            
            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
            confidence = self._calculate_confidence_score(
                file_path, conflict_type, conflict_markers, auto_resolvable
            )
            
            return ConflictedFile(
                file_path=file_path,
                conflict_type=conflict_type,
                risk_level=risk_level,
                conflict_markers=conflict_markers,
                auto_resolvable=auto_resolvable,
                resolution_strategy=strategy if auto_resolvable else None,
                confidence_score=confidence
            )
            
        except Exception as e:
            logger.error(f"Failed to analyze file {file_path}: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿å®ˆçš„ãªè¨­å®š
            return ConflictedFile(
                file_path=file_path,
                conflict_type=ConflictType.UNKNOWN_CONFLICT,
                risk_level=RiskLevel.CRITICAL,
                conflict_markers=[],
                auto_resolvable=False,
                resolution_strategy=None,
                confidence_score=0.0
            )
    
    def _classify_file_conflict(
        self, 
        file_path: str
    ) -> Tuple[ConflictType, RiskLevel, Optional[ResolutionStrategy]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†é¡"""
        
        # å®‰å…¨ãªè‡ªå‹•è§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern, config in self.SAFE_AUTO_RESOLVE_PATTERNS.items():
            if re.search(pattern, file_path):
                return (
                    config["type"],
                    config["risk"],
                    config["strategy"]
                )
        
        # æ‰‹å‹•å¯¾å¿œå¿…é ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern, risk in self.MANUAL_REQUIRED_PATTERNS.items():
            if re.search(pattern, file_path):
                return (
                    ConflictType.MERGE_CONFLICT,
                    risk,
                    ResolutionStrategy.MANUAL_REVIEW
                )
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return (
            ConflictType.UNKNOWN_CONFLICT,
            RiskLevel.MEDIUM,
            ResolutionStrategy.MANUAL_REVIEW
        )
    
    async def _detect_conflict_markers(self, file_path: str) -> List[str]:
        """ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ã®æ¤œå‡º"""
        try:
            full_path = os.path.join(self.repo_path, file_path)
            if not os.path.exists(full_path):
                return []
            
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            markers = []
            for pattern in self.CONFLICT_MARKERS:
                matches = re.findall(pattern, content)
                markers.extend(matches)
            
            return markers
            
        except Exception as e:
            logger.warning(f"Failed to detect conflict markers in {file_path}: {e}")
            return []
    
    def _is_auto_resolvable(
        self, 
        file_path: str, 
        conflict_type: ConflictType, 
        risk_level: RiskLevel
    ) -> bool:
        """è‡ªå‹•è§£æ±ºå¯èƒ½æ€§ã®åˆ¤å®š"""
        
        # é«˜ãƒªã‚¹ã‚¯ãƒ»ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã¯æ‰‹å‹•å¯¾å¿œ
        if risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
            return False
        
        # å®‰å…¨ãƒ»ä½ãƒªã‚¹ã‚¯ã§ç‰¹å®šã®ã‚¿ã‚¤ãƒ—ã¯è‡ªå‹•è§£æ±ºå¯èƒ½
        if risk_level in [RiskLevel.SAFE, RiskLevel.LOW]:
            auto_resolvable_types = [
                ConflictType.DEPENDENCY_CONFLICT,
                ConflictType.CHANGELOG_CONFLICT,
                ConflictType.VERSION_CONFLICT,
                ConflictType.FORMATTING_CONFLICT,
                ConflictType.WHITESPACE_CONFLICT
            ]
            return conflict_type in auto_resolvable_types
        
        # ä¸­ãƒªã‚¹ã‚¯ã¯æ…é‡ã«åˆ¤å®š
        if risk_level == RiskLevel.MEDIUM:
            # ç‰¹å®šã®å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
            safe_patterns = [r"\.md$", r"\.txt$", r"\.gitignore$"]
            return any(re.search(pattern, file_path) for pattern in safe_patterns)
        
        return False
    
    def _calculate_confidence_score(
        self, 
        file_path: str, 
        conflict_type: ConflictType, 
        conflict_markers: List[str],
        auto_resolvable: bool
    ) -> float:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®ç®—å‡º"""
        score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹èª¿æ•´
        if conflict_type in [ConflictType.DEPENDENCY_CONFLICT, ConflictType.CHANGELOG_CONFLICT]:
            score += 0.3
        
        # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ã®æ•°ã«ã‚ˆã‚‹èª¿æ•´
        marker_count = len(conflict_markers)
        if marker_count == 0:
            score += 0.2
        elif marker_count <= 3:
            score += 0.1
        else:
            score -= 0.1
        
        # è‡ªå‹•è§£æ±ºå¯èƒ½æ€§ã«ã‚ˆã‚‹èª¿æ•´
        if auto_resolvable:
            score += 0.2
        else:
            score -= 0.2
        
        # 0.0-1.0ã®ç¯„å›²ã«æ­£è¦åŒ–
        return max(0.0, min(1.0, score))
    
    def _calculate_overall_risk(self, conflicted_files: List[ConflictedFile]) -> RiskLevel:
        """å…¨ä½“ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ç®—å‡º"""
        if not conflicted_files:
            return RiskLevel.SAFE
        
        risk_levels = [f.risk_level for f in conflicted_files]
        
        # æœ€ã‚‚é«˜ã„ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’æ¡ç”¨
        if RiskLevel.CRITICAL in risk_levels:
            return RiskLevel.CRITICAL
        elif RiskLevel.HIGH in risk_levels:
            return RiskLevel.HIGH
        elif RiskLevel.MEDIUM in risk_levels:
            return RiskLevel.MEDIUM
        elif RiskLevel.LOW in risk_levels:
            return RiskLevel.LOW
        else:
            return RiskLevel.SAFE
    
    def _estimate_resolution_time(self, conflicted_files: List[ConflictedFile]) -> int:
        """è§£æ±ºæ™‚é–“ã®æ¨å®šï¼ˆåˆ†ï¼‰"""
        total_time = 0
        
        time_estimates = {
            ConflictType.DEPENDENCY_CONFLICT: 2,
            ConflictType.CHANGELOG_CONFLICT: 1,
            ConflictType.VERSION_CONFLICT: 1,
            ConflictType.DOCUMENTATION_CONFLICT: 3,
            ConflictType.FORMATTING_CONFLICT: 1,
            ConflictType.WHITESPACE_CONFLICT: 1,
            ConflictType.CONFIG_CONFLICT: 5,
            ConflictType.MERGE_CONFLICT: 10,
            ConflictType.UNKNOWN_CONFLICT: 15
        }
        
        for file in conflicted_files:
            base_time = time_estimates.get(file.conflict_type, 10)
            
            # è‡ªå‹•è§£æ±ºå¯èƒ½ãªå ´åˆã¯æ™‚é–“çŸ­ç¸®
            if file.auto_resolvable:
                base_time = max(1, base_time // 3)
            
            total_time += base_time
        
        return total_time
    
    def _calculate_safety_score(self, conflicted_files: List[ConflictedFile]) -> float:
        """å®‰å…¨æ€§ã‚¹ã‚³ã‚¢ã®ç®—å‡º"""
        if not conflicted_files:
            return 1.0
        
        auto_resolvable_count = sum(1 for f in conflicted_files if f.auto_resolvable)
        safety_ratio = auto_resolvable_count / len(conflicted_files)
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚‚è€ƒæ…®
        avg_confidence = sum(f.confidence_score for f in conflicted_files) / len(conflicted_files)
        
        return (safety_ratio * 0.7) + (avg_confidence * 0.3)

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
async def example_usage():
    """ä½¿ç”¨ä¾‹"""
    analyzer = ConflictAnalyzer("/path/to/repo")
    
    # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆåˆ†æå®Ÿè¡Œ
    result = await analyzer.analyze_conflicts(
        base_branch="main",
        head_branch="feature/new-feature"
    )
    
    print(f"ç·ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆæ•°: {result.total_conflicts}")
    print(f"è‡ªå‹•è§£æ±ºå¯èƒ½: {len(result.auto_resolvable_files)}")
    print(f"æ‰‹å‹•å¯¾å¿œå¿…è¦: {len(result.manual_required_files)}")
    print(f"å…¨ä½“ãƒªã‚¹ã‚¯: {result.overall_risk_level.value}")
    print(f"æ¨å®šè§£æ±ºæ™‚é–“: {result.estimated_resolution_time}åˆ†")
    print(f"å®‰å…¨æ€§ã‚¹ã‚³ã‚¢: {result.safety_score:0.2f}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(example_usage())