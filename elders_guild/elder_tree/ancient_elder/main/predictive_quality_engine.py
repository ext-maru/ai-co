#!/usr/bin/env python3
"""
ğŸ›ï¸ ã‚¨ãƒ³ã‚·ã‚§ãƒ³ãƒˆã‚¨ãƒ«ãƒ€ãƒ¼å¤ä»£é­”æ³• - PredictiveQualityEngine

äºˆæ¸¬å“è³ªåˆ†æã‚·ã‚¹ãƒ†ãƒ 
Tier 4: Predictive Quality Analysis (äºˆæ¸¬å“è³ªåˆ†æ)

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®äºˆæ¸¬æ©Ÿèƒ½ã‚’å®Ÿè£…ï¼š
- ãƒã‚°ç™ºç”Ÿç¢ºç‡è¨ˆç®— (æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«)
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–äºˆæ¸¬
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯å…ˆèª­ã¿
- æŠ€è¡“è² å‚µäºˆæ¸¬
- ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å›°é›£åº¦äºˆæ¸¬
"""

import ast
import re
import json
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
import statistics
import time
from pathlib import Path
import pickle

# åŸºåº•ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from elders_guild.elder_tree.ancient_elder.base import AncientMagicBase
except ImportError:
    logging.warning("AncientMagicBase not available")
    AncientMagicBase = object

@dataclass
class PredictionResult:
    """äºˆæ¸¬çµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""

    performance_risk: float  # æ€§èƒ½åŠ£åŒ–ãƒªã‚¹ã‚¯ 0-1
    security_risk: float  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ 0-1
    technical_debt_score: float  # æŠ€è¡“è² å‚µã‚¹ã‚³ã‚¢ 0-100
    maintainability_prediction: float  # ä¿å®ˆæ€§äºˆæ¸¬ 0-100
    confidence: float  # äºˆæ¸¬ä¿¡é ¼åº¦ 0-1
    recommendations: List[str]  # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    risk_factors: List[Dict[str, Any]]  # ãƒªã‚¹ã‚¯è¦å› 
    prediction_time: float  # äºˆæ¸¬å®Ÿè¡Œæ™‚é–“

class RiskLevel(Enum):
    """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"""
    VERY_LOW = 1
    LOW = 2
    MEDIUM = 3
    HIGH = 4
    CRITICAL = 5

class PredictiveQualityEngine(AncientMagicBase):
    """ğŸ”® äºˆæ¸¬å“è³ªåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        """äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–"""
        super().__init__()
        
        # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–

        self.performance_model = self._initialize_performance_model()
        self.security_model = self._initialize_security_model()
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.historical_data = self._load_historical_data()

        self.performance_patterns = self._load_performance_patterns()
        self.security_patterns = self._load_security_patterns()
        
        # äºˆæ¸¬çµ±è¨ˆ
        self.prediction_history = []
        
    def predict_quality_issues(
        self,
        code: str,
        metadata: Optional[Dict] = None
    ) -> PredictionResult:
        """å“è³ªå•é¡Œã®äºˆæ¸¬åˆ†æ
        
        Args:
            code: åˆ†æå¯¾è±¡ã®ã‚³ãƒ¼ãƒ‰
            metadata: è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆé–‹ç™ºè€…æƒ…å ±ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ç­‰ï¼‰
            
        Returns:
            PredictionResult: åŒ…æ‹¬çš„äºˆæ¸¬çµæœ
        """
        start_time = time.time()
        
        try:
            # ã‚³ãƒ¼ãƒ‰ç‰¹å¾´é‡ã®æŠ½å‡º
            features = self._extract_code_features(code)
            
            # å„ç¨®äºˆæ¸¬ã®å®Ÿè¡Œ

            perf_risk = self._predict_performance_risk(features, code)
            sec_risk = self._predict_security_risk(features, code)
            debt_score = self._predict_technical_debt(features, code)
            maintain_pred = self._predict_maintainability(features, code)
            
            # äºˆæ¸¬ä¿¡é ¼åº¦ã®è¨ˆç®—
            confidence = self._calculate_prediction_confidence(features)
            
            # ãƒªã‚¹ã‚¯è¦å› ã®ç‰¹å®š
            risk_factors = self._identify_risk_factors(code, features)
            
            # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
            recommendations = self._generate_recommendations(

            )
            
            result = PredictionResult(

                performance_risk=perf_risk,
                security_risk=sec_risk,
                technical_debt_score=debt_score,
                maintainability_prediction=maintain_pred,
                confidence=confidence,
                recommendations=recommendations,
                risk_factors=risk_factors,
                prediction_time=time.time() - start_time
            )
            
            # äºˆæ¸¬å±¥æ­´ã«è¿½åŠ 
            self.prediction_history.append(result)
            
            return result
            
        except Exception as e:
            logging.error(f"Prediction error: {e}")
            return PredictionResult(

                performance_risk=0.5,
                security_risk=0.5,
                technical_debt_score=50.0,
                maintainability_prediction=50.0,
                confidence=0.0,  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿¡é ¼åº¦ã‚¼ãƒ­
                recommendations=["Error in prediction - manual review required"],
                risk_factors=[{"type": "prediction_error", "message": str(e)}],
                prediction_time=time.time() - start_time
            )
    
    def _extract_code_features(self, code: str) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        try:
            tree = ast.parse(code)
            
            features = {
                # åŸºæœ¬çµ±è¨ˆ
                "lines_of_code": len(code.split('\n')),
                "characters": len(code),
                "functions": len([n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)]),
                "classes": len([n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]),
                
                # è¤‡é›‘åº¦æŒ‡æ¨™
                "cyclomatic_complexity": self._calculate_complexity(tree),
                "nesting_depth": self._calculate_nesting_depth(tree),
                "conditional_statements": len(
                    [n for n in ast.walk(tree) if isinstance(n,
                    (ast.If,
                    ast.While,
                    ast.For))]
                ),
                
                # ã‚³ãƒ¼ãƒ‰å“è³ªæŒ‡æ¨™
                "comments_ratio": self._calculate_comments_ratio(code),
                "docstring_ratio": self._calculate_docstring_ratio(tree),
                "magic_numbers": self._count_magic_numbers(tree),
                "long_functions": self._count_long_functions(tree, code),
                
                # ãƒªã‚¹ã‚¯æŒ‡æ¨™
                "exception_handling": self._count_exception_handling(tree),
                "global_variables": self._count_global_variables(tree),
                "imports": len([n for n in ast.walk(tree) if isinstance(n, (ast.Import, ast.ImportFrom))]),
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
                "loops": len([n for n in ast.walk(tree) if isinstance(n, (ast.For, ast.While))]),
                "nested_loops": self._count_nested_loops(tree),
                "list_comprehensions": len([n for n in ast.walk(tree) if isinstance(n, ast.ListComp)]),
                
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æŒ‡æ¨™
                "eval_usage": len(re.findall(r'\beval\s*\(', code)),
                "exec_usage": len(re.findall(r'\bexec\s*\(', code)),
                "os_system_usage": len(re.findall(r'os\.system\s*\(', code)),
                "subprocess_usage": len(re.findall(r'subprocess\s*\.', code)),
            }
            
            return features
            
        except Exception as e:
            logging.warning(f"Feature extraction error: {e}")
            return self._get_default_features()

        """ãƒã‚°ç™ºç”Ÿç¢ºç‡ã®äºˆæ¸¬"""
        try:
            # ç°¡å˜ãªé‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«

            # è¤‡é›‘åº¦ã«ã‚ˆã‚‹å½±éŸ¿
            complexity = features.get("cyclomatic_complexity", 0)

            # ãƒã‚¹ãƒˆæ·±åº¦ã«ã‚ˆã‚‹å½±éŸ¿
            nesting = features.get("nesting_depth", 0)

            # é•·ã„é–¢æ•°ã«ã‚ˆã‚‹å½±éŸ¿
            long_funcs = features.get("long_functions", 0)

            # ä¾‹å¤–å‡¦ç†ã®ä¸è¶³ã«ã‚ˆã‚‹å½±éŸ¿
            exception_handling = features.get("exception_handling", 0)
            total_functions = features.get("functions", 1)
            if total_functions > 0 and exception_handling / total_functions < 0.3:

            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹å½±éŸ¿
            magic_numbers = features.get("magic_numbers", 0)

            # éå»ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°

        except Exception as e:

            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _predict_performance_risk(self, features: Dict[str, Any], code: str) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ãƒªã‚¹ã‚¯ã®äºˆæ¸¬"""
        try:
            perf_risk = 0.0
            
            # ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
            nested_loops = features.get("nested_loops", 0)
            perf_risk += min(nested_loops * 0.2, 0.4)  # O(nÂ²)ä»¥ä¸Šã®ãƒªã‚¹ã‚¯
            
            # ãƒ«ãƒ¼ãƒ—å†…ã§ã®éåŠ¹ç‡ãªæ“ä½œ
            loops = features.get("loops", 0)
            if loops > 0:
                # ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«I/Oã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡¦ç†ã‚’æ¤œå‡º
                if re.search(r'for.*open\s*\(|while.*open\s*\(', code):
                    perf_risk += 0.3
                if re.search(r'for.*requests\.|while.*requests\.', code):
                    perf_risk += 0.3
            
            # å¤§é‡ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
            if re.search(r'range\s*\(\s*\d{6,}', code):  # 100ä¸‡ä»¥ä¸Šã®range
                perf_risk += 0.2
            
            # éåŠ¹ç‡ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ä½¿ç”¨
            if 'list.append' in code and 'for' in code:
                perf_risk += 0.1  # ãƒªã‚¹ãƒˆappendãƒ«ãƒ¼ãƒ—
            
            # ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã®ä¸é©åˆ‡ãªä½¿ç”¨
            list_comps = features.get("list_comprehensions", 0)
            if list_comps > 5:  # å¤šæ•°ã®ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜
                perf_risk += 0.1
            
            return min(perf_risk, 1.0)
            
        except Exception as e:
            logging.warning(f"Performance prediction error: {e}")
            return 0.5
    
    def _predict_security_risk(self, features: Dict[str, Any], code: str) -> float:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®äºˆæ¸¬"""
        try:
            sec_risk = 0.0
            
            # å±é™ºãªé–¢æ•°ã®ä½¿ç”¨
            sec_risk += features.get("eval_usage", 0) * 0.4  # evalä½¿ç”¨
            sec_risk += features.get("exec_usage", 0) * 0.3  # execä½¿ç”¨
            sec_risk += features.get("os_system_usage", 0) * 0.5  # os.systemä½¿ç”¨
            sec_risk += features.get("subprocess_usage", 0) * 0.2  # subprocessä½¿ç”¨
            
            # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯
            if re.search(r'execute\s*\(\s*["\'].*%.*["\']', code):
                sec_risk += 0.3
            
            # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±
            if re.search(
                r'password\s*=\s*["\'][^"\']+["\']|api_key\s*=\s*["\'][^"\']+["\']',
                code,
                re.IGNORECASE
            ):
                sec_risk += 0.4
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ“ä½œã®ãƒªã‚¹ã‚¯
            if re.search(r'open\s*\([^)]*\+|\.\./|/etc/', code):
                sec_risk += 0.2
            
            # å…¥åŠ›æ¤œè¨¼ã®ä¸è¶³
            functions = features.get("functions", 0)
            if functions > 0 and not re.search(r'isinstance\s*\(|len\s*\(.*\)\s*[<>]|validate', code):
                sec_risk += 0.2
            
            return min(sec_risk, 1.0)
            
        except Exception as e:
            logging.warning(f"Security prediction error: {e}")
            return 0.5
    
    def _predict_technical_debt(self, features: Dict[str, Any], code: str) -> float:
        """æŠ€è¡“è² å‚µã®äºˆæ¸¬ï¼ˆ0-100ã‚¹ã‚³ã‚¢ï¼‰"""
        try:
            debt_score = 0.0

            # ã‚³ãƒ¡ãƒ³ãƒˆä¸è¶³ã«ã‚ˆã‚‹è² å‚µ
            comments_ratio = features.get("comments_ratio", 0)
            if comments_ratio < 0.1:  # ã‚³ãƒ¡ãƒ³ãƒˆç‡10%æœªæº€
                debt_score += 20
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³ã«ã‚ˆã‚‹è² å‚µ
            docstring_ratio = features.get("docstring_ratio", 0)
            if docstring_ratio < 0.5:  # é–¢æ•°ã®50%æœªæº€ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–
                debt_score += 15
            
            # è¤‡é›‘åº¦ã«ã‚ˆã‚‹è² å‚µ
            complexity = features.get("cyclomatic_complexity", 0)
            debt_score += min(complexity * 2, 25)
            
            # é•·ã„é–¢æ•°ã«ã‚ˆã‚‹è² å‚µ
            long_funcs = features.get("long_functions", 0)
            debt_score += min(long_funcs * 8, 20)
            
            return min(debt_score, 100.0)
            
        except Exception as e:
            logging.warning(f"Technical debt prediction error: {e}")
            return 50.0
    
    def _predict_maintainability(self, features: Dict[str, Any], code: str) -> float:
        """ä¿å®ˆæ€§ã®äºˆæ¸¬ï¼ˆ0-100ã‚¹ã‚³ã‚¢ï¼‰"""
        try:
            maintain_score = 100.0  # æœ€é«˜ã‚¹ã‚³ã‚¢ã‹ã‚‰æ¸›ç®—
            
            # è¤‡é›‘åº¦ã«ã‚ˆã‚‹ä¿å®ˆæ€§ä½ä¸‹
            complexity = features.get("cyclomatic_complexity", 0)
            maintain_score -= min(complexity * 3, 40)
            
            # ãƒã‚¹ãƒˆæ·±åº¦ã«ã‚ˆã‚‹ä¿å®ˆæ€§ä½ä¸‹
            nesting = features.get("nesting_depth", 0)
            maintain_score -= min(nesting * 5, 20)
            
            # é•·ã„é–¢æ•°ã«ã‚ˆã‚‹ä¿å®ˆæ€§ä½ä¸‹
            long_funcs = features.get("long_functions", 0)
            maintain_score -= min(long_funcs * 10, 25)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ã‚ˆã‚‹ä¿å®ˆæ€§ä½ä¸‹
            globals_count = features.get("global_variables", 0)
            maintain_score -= min(globals_count * 8, 15)
            
            # ã‚³ãƒ¡ãƒ³ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ä¿å®ˆæ€§å‘ä¸Š
            comments_ratio = features.get("comments_ratio", 0)
            docstring_ratio = features.get("docstring_ratio", 0)
            maintain_score += (comments_ratio + docstring_ratio) * 10
            
            return max(0.0, min(maintain_score, 100.0))
            
        except Exception as e:
            logging.warning(f"Maintainability prediction error: {e}")
            return 50.0
    
    def _calculate_prediction_confidence(self, features: Dict[str, Any]) -> float:
        """äºˆæ¸¬ä¿¡é ¼åº¦ã®è¨ˆç®—"""
        try:
            confidence = 0.5  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
            
            # ã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ä¿¡é ¼åº¦èª¿æ•´
            loc = features.get("lines_of_code", 0)
            if 10 <= loc <= 500:  # é©åˆ‡ãªã‚µã‚¤ã‚ºç¯„å›²
                confidence += 0.2
            elif loc < 10:  # å°ã•ã™ãã‚‹
                confidence -= 0.1
            elif loc > 1000:  # å¤§ãã™ãã‚‹
                confidence -= 0.2
            
            # ç‰¹å¾´é‡ã®å®Œå…¨æ€§
            feature_completeness = len(features) / 20  # æœŸå¾…ç‰¹å¾´é‡æ•°
            confidence += min(feature_completeness * 0.3, 0.3)
            
            return max(0.0, min(confidence, 1.0))
            
        except Exception:
            return 0.5
    
    def _identify_risk_factors(self, code: str, features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ãƒªã‚¹ã‚¯è¦å› ã®ç‰¹å®š"""
        risk_factors = []
        
        try:
            # é«˜ã„è¤‡é›‘åº¦
            complexity = features.get("cyclomatic_complexity", 0)
            if complexity > 10:
                risk_factors.append({
                    "type": "high_complexity",
                    "severity": "high" if complexity > 20 else "medium",
                    "description": f"High cyclomatic complexity: {complexity}",
                    "recommendation": "Consider refactoring into smaller functions"
                })
            
            # æ·±ã„ãƒã‚¹ãƒˆ
            nesting = features.get("nesting_depth", 0)
            if nesting > 4:
                risk_factors.append({
                    "type": "deep_nesting",
                    "severity": "medium",
                    "description": f"Deep nesting level: {nesting}",
                    "recommendation": "Extract nested logic into separate functions"
                })
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯
            if features.get("eval_usage", 0) > 0:
                risk_factors.append({
                    "type": "security_risk",
                    "severity": "critical",
                    "description": "Use of eval() function detected",
                    "recommendation": "Replace eval() with safer alternatives"
                })
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒªã‚¹ã‚¯
            nested_loops = features.get("nested_loops", 0)
            if nested_loops > 2:
                risk_factors.append({
                    "type": "performance_risk",
                    "severity": "high",
                    "description": f"Nested loops detected: depth {nested_loops}",
                    "recommendation": "Consider algorithmic optimization"
                })
            
            return risk_factors
            
        except Exception as e:
            logging.warning(f"Risk factor identification error: {e}")
            return [{"type": "analysis_error", "description": str(e)}]

                                 sec_risk: float, debt_score: float, maintain_pred: float) -> List[str]:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        recommendations = []

            recommendations.append("HIGH: Implement comprehensive unit tests")
            recommendations.append("HIGH: Add extensive error handling")

            recommendations.append("MEDIUM: Review function complexity")
            recommendations.append("MEDIUM: Add input validation")
        
        if perf_risk > 0.6:
            recommendations.append("HIGH: Optimize nested loops")
            recommendations.append("HIGH: Profile memory usage")
        elif perf_risk > 0.3:
            recommendations.append("MEDIUM: Review algorithm efficiency")
        
        if sec_risk > 0.6:
            recommendations.append("CRITICAL: Address security vulnerabilities immediately")
            recommendations.append("HIGH: Implement input sanitization")
        elif sec_risk > 0.3:
            recommendations.append("MEDIUM: Review security best practices")
        
        if debt_score > 70:
            recommendations.append("HIGH: Refactor code to reduce technical debt")
            recommendations.append("MEDIUM: Add comprehensive documentation")
        
        if maintain_pred < 40:
            recommendations.append("HIGH: Simplify complex functions")
            recommendations.append("MEDIUM: Improve code organization")
        
        if not recommendations:
            recommendations.append("Code quality appears acceptable - continue monitoring")
        
        return recommendations
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def _calculate_complexity(self, tree: ast.AST) -> int:
        """ã‚µã‚¤ã‚¯ãƒ­ãƒãƒ†ã‚£ãƒƒã‚¯è¤‡é›‘åº¦è¨ˆç®—"""
        complexity = 1  # ãƒ™ãƒ¼ã‚¹è¤‡é›‘åº¦
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        return complexity
    
    def _calculate_nesting_depth(self, tree: ast.AST) -> int:
        """ãƒã‚¹ãƒˆæ·±åº¦è¨ˆç®—"""
        max_depth = 0
        
        def get_depth(node, current_depth=0):
            """depthå–å¾—ãƒ¡ã‚½ãƒƒãƒ‰"""
            nonlocal max_depth
            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try, ast.With, ast.FunctionDef)):
                current_depth += 1
                max_depth = max(max_depth, current_depth)
            
            for child in ast.iter_child_nodes(node):
                get_depth(child, current_depth)
        
        get_depth(tree)
        return max_depth
    
    def _calculate_comments_ratio(self, code: str) -> float:
        """ã‚³ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—"""
        lines = code.split('\n')
        comment_lines = len([line for line in lines if line.strip().startswith('#')])
        total_lines = len([line for line in lines if line.strip()])
        return comment_lines / max(total_lines, 1)
    
    def _calculate_docstring_ratio(self, tree: ast.AST) -> float:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ç‡è¨ˆç®—"""
        functions = [n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)]
        if not functions:
            return 1.0  # é–¢æ•°ãŒãªã„å ´åˆã¯å®Œç’§ã¨ã™ã‚‹
        
        documented = 0
        for func in functions:
            # è¤‡é›‘ãªæ¡ä»¶åˆ¤å®š
            if (func.body and isinstance(func.body[0], ast.Expr) and 
                isinstance(func.body[0].value, ast.Constant) and 
                isinstance(func.body[0].value.value, str)):
                documented += 1
        
        return documented / len(functions)
    
    def _count_magic_numbers(self, tree: ast.AST) -> int:
        """ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        count = 0
        for node in ast.walk(tree):
            if isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):
                if node.value not in [0, 1, -1]:  # ä¸€èˆ¬çš„ãªå€¤ã¯é™¤å¤–
                    count += 1
        return count
    
    def _count_long_functions(self, tree: ast.AST, code: str) -> int:
        """é•·ã„é–¢æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        functions = [n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)]
        long_count = 0
        
        for func in functions:
            if hasattr(func, 'end_lineno') and func.end_lineno:
                func_length = func.end_lineno - func.lineno
                if func_length > 50:  # 50è¡Œä»¥ä¸Šã‚’é•·ã„é–¢æ•°ã¨ã™ã‚‹
                    long_count += 1
        
        return long_count
    
    def _count_exception_handling(self, tree: ast.AST) -> int:
        """ä¾‹å¤–å‡¦ç†ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        return len([n for n in ast.walk(tree) if isinstance(n, ast.Try)])
    
    def _count_global_variables(self, tree: ast.AST) -> int:
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ"""
        return len([n for n in ast.walk(tree) if isinstance(n, ast.Global)])
    
    def _count_nested_loops(self, tree: ast.AST) -> int:
        """ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®æœ€å¤§æ·±åº¦"""
        max_depth = 0
        
        def count_depth(node, current_depth=0):
            """count_depthãƒ¡ã‚½ãƒƒãƒ‰"""
            nonlocal max_depth
            if isinstance(node, (ast.For, ast.While)):
                current_depth += 1
                max_depth = max(max_depth, current_depth)
            
            for child in ast.iter_child_nodes(node):
                count_depth(child, current_depth)
        
        count_depth(tree)
        return max_depth

        """éå»ã®ãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã®ãƒãƒƒãƒãƒ³ã‚°"""
        # ç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ä¾‹
        pattern_score = 0.0
        
        # ä¸€èˆ¬çš„ãªãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³

            r'==\s*True',  # == True instead of is True
            r'==\s*False',  # == False instead of is False
            r'except:',  # bare except
            r'\.close\(\)',  # resource without try-finally
        ]

            matches = len(re.findall(pattern, code))
            pattern_score += matches * 0.05  # å„ãƒ‘ã‚¿ãƒ¼ãƒ³5%ã®ãƒªã‚¹ã‚¯
        
        return min(pattern_score, 0.3)  # æœ€å¤§30%
    
    def _get_default_features(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰¹å¾´é‡"""
        return {
            "lines_of_code": 0, "characters": 0, "functions": 0, "classes": 0,
            "cyclomatic_complexity": 1, "nesting_depth": 0, "conditional_statements": 0,
            "comments_ratio": 0, "docstring_ratio": 0, "magic_numbers": 0, "long_functions": 0,
            "exception_handling": 0, "global_variables": 0, "imports": 0,
            "loops": 0, "nested_loops": 0, "list_comprehensions": 0,
            "eval_usage": 0, "exec_usage": 0, "os_system_usage": 0, "subprocess_usage": 0,
        }
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå°†æ¥ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰

        """ãƒã‚°äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        return None  # ç¾åœ¨ã¯é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    
    def _initialize_performance_model(self):
        """æ€§èƒ½äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        return None
    
    def _initialize_security_model(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        return None
    
    def _load_historical_data(self) -> Dict[str, Any]:
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        return {}  # å°†æ¥å®Ÿè£…

        """ãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        return []  # å°†æ¥å®Ÿè£…
    
    def _load_performance_patterns(self) -> List[str]:
        """æ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        return []
    
    def _load_security_patterns(self) -> List[str]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        return []
    
    def get_prediction_statistics(self) -> Dict[str, Any]:
        """äºˆæ¸¬çµ±è¨ˆæƒ…å ±å–å¾—"""
        if not self.prediction_history:
            return {"message": "No prediction history available"}

        confidences = [p.confidence for p in self.prediction_history]
        
        return {
            "total_predictions": len(self.prediction_history),

            "average_confidence": statistics.mean(confidences),

        }

# ä¾¿åˆ©é–¢æ•°
def predict_quality(code: str, metadata: Optional[Dict] = None) -> PredictionResult:
    """å“è³ªäºˆæ¸¬ã®ä¾¿åˆ©é–¢æ•°"""
    engine = PredictiveQualityEngine()
    return engine.predict_quality_issues(code, metadata)

if __name__ == "__main__":
    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    sample_code = """
def risky_function(data):
    result = []
    for i in range(len(data)):
        for j in range(len(data)):
            if eval(f"data[{i}] > data[{j}]"):
                result.append(data[i])
    return result
"""
    
    engine = PredictiveQualityEngine()
    result = engine.predict_quality_issues(sample_code)

    print(f"Performance Risk: {result.performance_risk:0.2f}")
    print(f"Security Risk: {result.security_risk:0.2f}")
    print(f"Technical Debt: {result.technical_debt_score:0.2f}")
    print(f"Confidence: {result.confidence:0.2f}")
    print(f"Recommendations: {len(result.recommendations)}")