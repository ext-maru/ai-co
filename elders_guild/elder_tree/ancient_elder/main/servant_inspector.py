#!/usr/bin/env python3
"""
üõ°Ô∏è Servant Inspector Magic - „Çµ„Éº„Éê„É≥„ÉàÊüªÂØüÈ≠îÊ≥ï
==============================================

„Ç®„É´„ÉÄ„Éº„Çµ„Éº„Éê„É≥„Éà„ÅÆÂÆüË£ÖÂìÅË≥™„ÄÅÂΩπÂâ≤ÈÅµÂÆà„ÄÅÂ∞ÇÈñÄÊÄß„ÇíÁõ£Êüª„Åô„ÇãÂè§‰ª£È≠îÊ≥ï„Ç∑„Çπ„ÉÜ„É†
Issue #202ÂØæÂøú

Features:
- „Çπ„Çø„ÉñÂÆüË£Ö„ÉªÊâãÊäú„ÅçÊ§úÂá∫
- ÂΩπÂâ≤ÈÅµÂÆà„ÉªÂ∞ÇÈñÄÊÄßË©ï‰æ°
- „Çµ„Éº„Éê„É≥„ÉàÈñìÂçîË™øÊ§úË®º
- ÂÆüË£ÖË©êÁß∞„ÉªÂÅΩÊ©üËÉΩÊ§úÂá∫
- „Çµ„Éº„Éê„É≥„ÉàÂìÅË≥™„Çπ„Ç≥„Ç¢ÁÆóÂá∫
- Ëá™ÂãïÊîπÂñÑÊèêÊ°àÁîüÊàê

Author: Claude Elder
Created: 2025-07-21
"""

import ast
import asyncio
import json
import logging
import os
import re
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Set, Tuple
import xml.etree.ElementTree as ET

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Çí„Éë„Çπ„Å´ËøΩÂä†
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from elders_guild.elder_tree.ancient_elder.base import AncientElderBase, AuditResult, ViolationSeverity


class ServantType:
    """„Ç®„É´„ÉÄ„Éº„Çµ„Éº„Éê„É≥„Éà„ÅÆÁ®ÆÈ°û"""
    CODE_CRAFTSMAN = "code_craftsman"        # „Ç≥„Éº„ÉâËÅ∑‰∫∫
    TEST_GUARDIAN = "test_guardian"          # „ÉÜ„Çπ„ÉàÂÆàË≠∑ËÄÖ
    QUALITY_INSPECTOR = "quality_inspector" # ÂìÅË≥™Ê§úÊüªÂÆò
    DEPLOYMENT_MASTER = "deployment_master"  # „Éá„Éó„É≠„Ç§„É°„É≥„ÉàÂ∏´Âå†
    MONITOR_WATCHER = "monitor_watcher"      # Áõ£Ë¶ñÁï™‰∫∫
    DOC_SCRIBE = "doc_scribe"               # „Éâ„Ç≠„É•„É°„É≥„ÉàÊõ∏Ë®ò


class ServantViolationType:
    """„Çµ„Éº„Éê„É≥„ÉàÈÅïÂèç„ÅÆÁ®ÆÈ°û"""
    STUB_IMPLEMENTATION = "STUB_IMPLEMENTATION"              # „Çπ„Çø„ÉñÂÆüË£Ö
    LAZY_IMPLEMENTATION = "LAZY_IMPLEMENTATION"              # ÊâãÊäú„ÅçÂÆüË£Ö
    ROLE_VIOLATION = "ROLE_VIOLATION"                        # ÂΩπÂâ≤ÈÅïÂèç
    INSUFFICIENT_EXPERTISE = "INSUFFICIENT_EXPERTISE"        # Â∞ÇÈñÄÊÄß‰∏çË∂≥
    POOR_COLLABORATION = "POOR_COLLABORATION"                # ÂçîË™ø‰∏çË∂≥
    FAKE_FUNCTIONALITY = "FAKE_FUNCTIONALITY"                # ÂÅΩÊ©üËÉΩÂÆüË£Ö
    INCOMPLETE_TASK = "INCOMPLETE_TASK"                      # ‰∏çÂÆåÂÖ®„Çø„Çπ„ÇØ
    SERVANT_ABANDONMENT = "SERVANT_ABANDONMENT"              # „Çµ„Éº„Éê„É≥„ÉàÊîæÊ£Ñ


class ServantImplementationAnalyzer:
    """„Çµ„Éº„Éê„É≥„ÉàÂÆüË£ÖÂìÅË≥™ÂàÜÊûê„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self, project_root: Optional[Path] = None)self.project_root = project_root or Path.cwd()
    """ÂàùÊúüÂåñ„É°„ÇΩ„ÉÉ„Éâ"""
        self.logger = logging.getLogger("ServantImplementationAnalyzer")
        
        # „Çπ„Çø„ÉñÂÆüË£Ö„Éë„Çø„Éº„É≥
        self.stub_patterns = {
            "pass_only": re.compile(r'^\s*pass\s*$', re.MULTILINE),
            "todo_comment": re.compile(r'#\s*TODO|#\s*FIXME|#\s*XXX', re.IGNORECASE),
            "not_implemented": re.compile(
                r'raise\s+NotImplementedError|NotImplemented',
                re.IGNORECASE
            ),
            "placeholder": re.compile(r'placeholder|dummy|mock|fake', re.IGNORECASE),
            "empty_function": re.compile(r'def\s+\w+\([^)]*\):\s*pass', re.MULTILINE),
        }
        
        # ÊâãÊäú„ÅçÂÆüË£Ö„Éë„Çø„Éº„É≥
        self.lazy_patterns = {
            "hardcoded_values": " \
                "re.compile(r'return\s+["\'].*["\']|return\s+\d+|return\s+True|return\s+False', re.MULTILINE),
            "no_error_handling": re.compile(r'def\s+\w+.*?(?=def|\Z)', re.DOTALL),
            "copy_paste": re.compile(r'(.{20,})\s*\n.*?\1', re.MULTILINE),
            "minimal_logic": re.compile(r'def\s+\w+[^:]*:\s*return\s+[^;\n]*$', re.MULTILINE),
        }
        
        # „Çµ„Éº„Éê„É≥„ÉàÂΩπÂâ≤ÂÆöÁæ©
        self.servant_roles = {
            ServantType.CODE_CRAFTSMAN: {
                "keywords": ["craft", "code", "implement", "build", "create"],
                "required_methods": ["craft_code", "implement_feature", "build_component"],
                "file_patterns": ["*_craftsman.py", "*craftsman*", "*craft*"]
            },
            ServantType.TEST_GUARDIAN: {
                "keywords": ["test", "guard", "verify", "validate", "check"],
                "required_methods": ["guard_tests", "verify_quality", "validate_implementation"],
                "file_patterns": ["*_guardian.py", "*guardian*", "*test*"]
            },
            ServantType.QUALITY_INSPECTOR: {
                "keywords": ["quality", "inspect", "review", "audit", "analyze"],
                "required_methods": ["inspect_quality", "review_code", "audit_implementation"],
                "file_patterns": ["*_inspector.py", "*inspector*", "*quality*"]
            },
            ServantType.DEPLOYMENT_MASTER: {
                "keywords": ["deploy", "master", "release", "publish", "deliver"],
                "required_methods": ["master_deployment", "release_service", "deliver_product"],
                "file_patterns": ["*_master.py", "*master*", "*deploy*"]
            },
            ServantType.MONITOR_WATCHER: {
                "keywords": ["monitor", "watch", "observe", "track", "alert"],
                "required_methods": ["watch_system", "monitor_health", "track_metrics"],
                "file_patterns": ["*_watcher.py", "*watcher*", "*monitor*"]
            },
            ServantType.DOC_SCRIBE: {
                "keywords": ["doc", "scribe", "document", "write", "record"],
                "required_methods": ["scribe_documentation", "document_system", "record_knowledge"],
                "file_patterns": ["*_scribe.py", "*scribe*", "*doc*"]
            }
        }
        
    def analyze_servant_implementation(self, 
                                     file_path: str,
                                     servant_type: Optional[str] = None) -> Dict[str, Any]:
        """„Çµ„Éº„Éê„É≥„ÉàÂÆüË£Ö„ÇíÂàÜÊûê"""
        try:
            # „Éï„Ç°„Ç§„É´„Åã„Çâ„Çµ„Éº„Éê„É≥„Éà„Çø„Ç§„Éó„ÇíÊé®ÂÆö
            if not servant_type:
                servant_type = self._detect_servant_type(file_path)
                
            # „ÇΩ„Éº„Çπ„Ç≥„Éº„ÉâËß£Êûê
            source_analysis = self._analyze_source_code(file_path)
            
            # „Çπ„Çø„ÉñÂÆüË£ÖÊ§úÂá∫
            stub_violations = self._detect_stub_implementations(
                source_analysis["content"],
                file_path
            )
            
            # ÊâãÊäú„ÅçÂÆüË£ÖÊ§úÂá∫
            lazy_violations = self._detect_lazy_implementations(
                source_analysis["content"],
                file_path
            )
            
            # ÂΩπÂâ≤ÈÅµÂÆà„ÉÅ„Çß„ÉÉ„ÇØ
            role_compliance = self._check_role_compliance(source_analysis, servant_type, file_path)
            
            # Â∞ÇÈñÄÊÄßË©ï‰æ°
            expertise_score = self._evaluate_expertise(source_analysis, servant_type)
            
            return {
                "file_path": file_path,
                "servant_type": servant_type,
                "source_analysis": source_analysis,
                "stub_violations": stub_violations,
                "lazy_violations": lazy_violations,
                "role_compliance": role_compliance,
                "expertise_score": expertise_score,
                "overall_quality_score": self._calculate_servant_quality_score(
                    stub_violations, lazy_violations, role_compliance, expertise_score
                )
            }
            
        except Exception as e:
            self.logger.error(f"Servant implementation analysis failed for {file_path}: {e}")
            return {
                "file_path": file_path,
                "error": str(e),
                "servant_type": servant_type,
                "stub_violations": [],
                "lazy_violations": [],
                "role_compliance": {"compliant": False, "score": 0.0},
                "expertise_score": 0.0,
                "overall_quality_score": 0.0
            }
            
    def _detect_servant_type(self, file_path: str) -> strfile_name = Path(file_path).name.lower():
    """„Ç°„Ç§„É´„Éë„Çπ„Åã„Çâ„Çµ„Éº„Éê„É≥„Éà„Çø„Ç§„Éó„ÇíÊ§úÂá∫"""
        :
        for servant_type, role_info in self.servant_roles.items():
            # „Éï„Ç°„Ç§„É´Âêç„Éë„Çø„Éº„É≥„Éû„ÉÉ„ÉÅ„É≥„Ç∞
            for pattern in role_info["file_patterns"]:
                if any(keyword in file_name for keyword in role_info["keywords"]):
                    return servant_type
                    
        # „Éá„Éï„Ç©„É´„Éà„ÅØ„Ç≥„Éº„ÉâËÅ∑‰∫∫
        return ServantType.CODE_CRAFTSMAN
        
    def _analyze_source_code(self, file_path: str) -> Dict[str, Any]:
        """„ÇΩ„Éº„Çπ„Ç≥„Éº„ÉâËß£Êûê"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ASTËß£Êûê
            try:
                tree = ast.parse(content)
                ast_analysis = self._analyze_ast(tree)
            except SyntaxError:
                ast_analysis = {"functions": [], "classes": [], "imports": []}
                
            return {
                "content": content,
                "lines_of_code": len(content.split('\n')),
                "ast_analysis": ast_analysis,
                "file_size": len(content),
                "has_docstrings": '"""' in content or "'''" in content,
                "has_type_hints": ":" in content and "->" in content
            }
            
        except Exception as e:
            self.logger.error(f"Failed to analyze source code for {file_path}: {e}")
            return {
                "content": "",
                "lines_of_code": 0,
                "ast_analysis": {"functions": [], "classes": [], "imports": []},
                "file_size": 0,
                "has_docstrings": False,
                "has_type_hints": False
            }
            
    def _analyze_ast(self, tree: ast.AST) -> Dict[str, Any]:
        """ASTË©≥Á¥∞Ëß£Êûê"""
        functions = []
        classes = []
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append({
                    "name": node.name,
                    "line_number": node.lineno,
                    "args_count": len(node.args.args),
                    "has_docstring": ast.get_docstring(node) is not None,
                    "is_async": isinstance(node, ast.AsyncFunctionDef)
                })
            elif isinstance(node, ast.ClassDef):
                classes.append({
                    "name": node.name,
                    "line_number": node.lineno,
                    "methods_count": len([n for n in node.body if isinstance(n, ast.FunctionDef)]),
                    "has_docstring": ast.get_docstring(node) is not None
                })
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                else:
                    imports.append(node.module if node.module else "")
                    
        return {
            "functions": functions,
            "classes": classes,
            "imports": imports,
            "total_functions": len(functions),
            "total_classes": len(classes),
            "total_imports": len(imports)
        }
        
    def _detect_stub_implementations(self, content: str, file_path: str) -> List[Dict[str, Any]]:
        """„Çπ„Çø„ÉñÂÆüË£Ö„ÇíÊ§úÂá∫"""
        violations = []
        
        for pattern_name, pattern in self.stub_patterns.items():
            matches = pattern.finditer(content)
            
            for match in matches:
                line_number = content[:match.start()].count('\n') + 1
                
                violations.append({
                    "type": ServantViolationType.STUB_IMPLEMENTATION,
                    "severity": "HIGH",
                    "pattern": pattern_name,
                    "line_number": line_number,
                    "file_path": file_path,
                    "evidence": match.group().strip(),
                    "description": f"Stub implementation detected: {pattern_name}",
                    "suggestion": "Replace stub with actual implementation"
                })
                
        return violations
        
    def _detect_lazy_implementations(self, content: str, file_path: str) -> List[Dict[str, Any]]:
        """ÊâãÊäú„ÅçÂÆüË£Ö„ÇíÊ§úÂá∫"""
        violations = []
        
        for pattern_name, pattern in self.lazy_patterns.items():
            matches = pattern.finditer(content)
            
            for match in matches:
                line_number = content[:match.start()].count('\n') + 1
                
                # ÊâãÊäú„ÅçÂÆüË£Ö„ÅÆÂ∫¶Âêà„ÅÑ„ÇíË©ï‰æ°
                severity = self._evaluate_lazy_severity(pattern_name, match.group())
                
                violations.append({
                    "type": ServantViolationType.LAZY_IMPLEMENTATION,
                    "severity": severity,
                    "pattern": pattern_name,
                    "line_number": line_number,
                    "file_path": file_path,
                    "evidence": match.group().strip()[:100],  # ÊúÄÂàù„ÅÆ100ÊñáÂ≠ó
                    "description": f"Lazy implementation detected: {pattern_name}",
                    "suggestion": "Improve implementation quality and add proper logic"
                })
                
        return violations
        
    def _evaluate_lazy_severity(self, pattern_name: str, evidence: str) -> str:
        """ÊâãÊäú„ÅçÂÆüË£Ö„ÅÆÈáçË¶ÅÂ∫¶„ÇíË©ï‰æ°"""
        if pattern_name == "hardcoded_values":
            return "MEDIUM"
        elif pattern_name == "no_error_handling":
            return "HIGH"
        elif pattern_name == "copy_paste":
            return "MEDIUM"
        elif pattern_name == "minimal_logic":
            return "LOW"
        else:
            return "MEDIUM"
            
    def _check_role_compliance(self, 
                             source_analysis: Dict[str, Any], 
                             servant_type: str,
                             file_path: str) -> Dict[str, Any]:
        """ÂΩπÂâ≤ÈÅµÂÆà„Çí„ÉÅ„Çß„ÉÉ„ÇØ"""
        if servant_type not in self.servant_roles:
            return {"compliant": False, "score": 0.0, "violations": []}
            
        role_info = self.servant_roles[servant_type]
        violations = []
        compliance_score = 100.0
        
        # ÂøÖÈ†à„É°„ÇΩ„ÉÉ„Éâ„ÅÆÂ≠òÂú®„ÉÅ„Çß„ÉÉ„ÇØ
        functions = source_analysis["ast_analysis"]["functions"]
        function_names = [f["name"] for f in functions]
        
        missing_methods = []
        for required_method in role_info["required_methods"]:
            if not any(required_method in func_name for func_name in function_names):
                missing_methods.append(required_method)
                compliance_score -= 20.0
                
        if missing_methods:
            violations.append({
                "type": ServantViolationType.ROLE_VIOLATION,
                "severity": "HIGH",
                "file_path": file_path,
                "description": f"Missing required methods for {servant_type}",
                "missing_methods": missing_methods,
                "suggestion": f"Implement required methods: {', '.join(missing_methods)}"
            })
            
        # „Ç≠„Éº„ÉØ„Éº„ÉâÈñ¢ÈÄ£ÊÄß„ÉÅ„Çß„ÉÉ„ÇØ
        content_lower = source_analysis["content"].lower()
        keyword_matches = sum(1 for keyword in role_info["keywords"] if keyword in content_lower)
        keyword_score = (keyword_matches / len(role_info["keywords"])) * 100
        
        if keyword_score < 50:
            violations.append({
                "type": ServantViolationType.INSUFFICIENT_EXPERTISE,
                "severity": "MEDIUM",
                "file_path": file_path,
                "description": f"Insufficient {servant_type} related keywords",
                "keyword_score": keyword_score,
                "suggestion": f"Add more {servant_type} specific functionality"
            })
            compliance_score = min(compliance_score, keyword_score)
            
        return {
            "compliant": compliance_score >= 70.0,
            "score": max(compliance_score, 0.0),
            "violations": violations,
            "missing_methods": missing_methods,
            "keyword_score": keyword_score
        }
        
    def _evaluate_expertise(self, source_analysis: Dict[str, Any], servant_type: str) -> float:
        """Â∞ÇÈñÄÊÄß„ÇíË©ï‰æ°"""
        expertise_score = 0.0
        
        # „Ç≥„Éº„Éâ„ÅÆË§áÈõë„ÅïË©ï‰æ°
        functions = source_analysis["ast_analysis"]["functions"]
        if functions:
            avg_args = sum(f["args_count"] for f in functions) / len(functions)
            expertise_score += min(avg_args * 10, 30)  # ÊúÄÂ§ß30ÁÇπ
            
        # „Éâ„Ç≠„É•„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Ë©ï‰æ°
        if source_analysis["has_docstrings"]:
            expertise_score += 20
            
        # Âûã„Éí„É≥„ÉàË©ï‰æ°
        if source_analysis["has_type_hints"]:
            expertise_score += 15
            
        # „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫Ë©ï‰æ°ÔºàÈÅ©Â∫¶„Å™ÂÆüË£ÖÈáèÔºâ
        lines_of_code = source_analysis["lines_of_code"]
        if 50 <= lines_of_code <= 500:
            expertise_score += 20
        elif lines_of_code > 20:
            expertise_score += 10
            
        # „Ç§„É≥„Éù„Éº„ÉàË©ï‰æ°ÔºàÈÅ©Âàá„Å™‰æùÂ≠òÈñ¢‰øÇÔºâ
        imports_count = source_analysis["ast_analysis"]["total_imports"]
        if imports_count > 0:
            expertise_score += min(imports_count * 3, 15)  # ÊúÄÂ§ß15ÁÇπ
            
        return min(expertise_score, 100.0)
        
    def _calculate_servant_quality_score(self,
                                       stub_violations: List[Dict[str, Any]],
                                       lazy_violations: List[Dict[str, Any]],
                                       role_compliance: Dict[str, Any],
                                       expertise_score: float) -> float:
        """„Çµ„Éº„Éê„É≥„ÉàÂìÅË≥™„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó"""
        base_score = 100.0
        
        # „Çπ„Çø„ÉñÂÆüË£Ö„Å´„Çà„ÇãÊ∏õÁÇπ
        base_score -= len(stub_violations) * 25
        
        # ÊâãÊäú„ÅçÂÆüË£Ö„Å´„Çà„ÇãÊ∏õÁÇπ
        base_score -= len(lazy_violations) * 10
        
        # ÂΩπÂâ≤ÈÅµÂÆà„Çπ„Ç≥„Ç¢Ôºà30%Ôºâ
        role_score = role_compliance.get("score", 0) * 0.3
        
        # Â∞ÇÈñÄÊÄß„Çπ„Ç≥„Ç¢Ôºà20%Ôºâ
        expertise_contribution = expertise_score * 0.2
        
        # ÂÆüË£ÖÂìÅË≥™„Çπ„Ç≥„Ç¢Ôºà50%Ôºâ
        implementation_score = max(base_score, 0) * 0.5
        
        final_score = role_score + expertise_contribution + implementation_score
        return min(final_score, 100.0)


class ServantCollaborationAnalyzer:
    """„Çµ„Éº„Éê„É≥„ÉàÈñìÂçîË™øÂàÜÊûê„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self, project_root: Optional[Path] = None)self.project_root = project_root or Path.cwd()
    """ÂàùÊúüÂåñ„É°„ÇΩ„ÉÉ„Éâ"""
        self.logger = logging.getLogger("ServantCollaborationAnalyzer")
        
    def analyze_servant_collaboration(self, 
                                    servant_files: List[str],
                                    time_window: Optional[timedelta] = None) -> Dict[str, Any]:
        """„Çµ„Éº„Éê„É≥„ÉàÈñìÂçîË™ø„ÇíÂàÜÊûê"""
        if time_window is None:
            time_window = timedelta(days=30)
            
        try:
            # „Çµ„Éº„Éê„É≥„ÉàÈñì„ÅÆ‰æùÂ≠òÈñ¢‰øÇ„ÇíÂàÜÊûê
            dependency_analysis = self._analyze_dependencies(servant_files)
            
            # ÂçîË™ø„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫
            collaboration_patterns = self._detect_collaboration_patterns(servant_files)
            
            # ÂçîË™øÂìÅË≥™„ÇíË©ï‰æ°
            collaboration_quality = self._evaluate_collaboration_quality(
                dependency_analysis, collaboration_patterns
            )
            
            # ÂçîË™øÈÅïÂèç„ÇíÊ§úÂá∫
            collaboration_violations = self._detect_collaboration_violations(
                dependency_analysis, collaboration_patterns, servant_files
            )
            
            return {
                "servant_files": servant_files,
                "dependency_analysis": dependency_analysis,
                "collaboration_patterns": collaboration_patterns,
                "collaboration_quality": collaboration_quality,
                "collaboration_violations": collaboration_violations,
                "overall_collaboration_score": self._calculate_collaboration_score(
                    collaboration_quality, collaboration_violations
                )
            }
            
        except Exception as e:
            self.logger.error(f"Servant collaboration analysis failed: {e}")
            return {
                "servant_files": servant_files,
                "error": str(e),
                "collaboration_violations": [],
                "overall_collaboration_score": 0.0
            }
            
    def _analyze_dependencies(self, servant_files: List[str]) -> Dict[str, Any]:
        """„Çµ„Éº„Éê„É≥„ÉàÈñì‰æùÂ≠òÈñ¢‰øÇ„ÇíÂàÜÊûê"""
        dependencies = {}
        
        for file_path in servant_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # „Ç§„É≥„Éù„Éº„ÉàÊñá„Åã„Çâ‰æùÂ≠òÈñ¢‰øÇ„ÇíÊäΩÂá∫
                servant_imports = []
                for other_file in servant_files:
                    if other_file != file_path:
                        other_name = Path(other_file).stem
                        if other_name in content:
                            servant_imports.append(other_name)
                            
                dependencies[file_path] = {
                    "imports": servant_imports,
                    "import_count": len(servant_imports)
                }
                
            except Exception as e:
                self.logger.error(f"Failed to analyze dependencies for {file_path}: {e}")
                dependencies[file_path] = {"imports": [], "import_count": 0}
                
        return dependencies
        
    def _detect_collaboration_patterns(self, servant_files: List[str]) -> List[Dict[str, Any]]:
        """ÂçîË™ø„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫"""
        patterns = []
        
        # ÂÖ±ÈÄö„ÅÆ„Éë„Çø„Éº„É≥‰æã
        patterns.append({
            "pattern": "sequential_workflow",
            "description": "Sequential servant workflow pattern",
            "quality": "good",
            "frequency": len(servant_files)
        })
        
        return patterns
        
    def _evaluate_collaboration_quality(self,
                                      dependency_analysis: Dict[str, Any],
                                      collaboration_patterns: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ÂçîË™øÂìÅË≥™„ÇíË©ï‰æ°"""
        total_files = len(dependency_analysis)
        total_imports = sum(dep["import_count"] for dep in dependency_analysis.values())
        
        if total_files == 0:
            return {"quality_score": 0.0, "collaboration_ratio": 0.0}
            
        collaboration_ratio = total_imports / (total_files * (total_files - 1)) if total_files > 1 else 0.0
        
        quality_score = min(collaboration_ratio * 100, 100.0)
        
        return {
            "quality_score": quality_score,
            "collaboration_ratio": collaboration_ratio,
            "total_dependencies": total_imports
        }
        
    def _detect_collaboration_violations(self,
                                       dependency_analysis: Dict[str, Any],
                                       collaboration_patterns: List[Dict[str, Any]],
                                       servant_files: List[str]) -> List[Dict[str, Any]]:
        """ÂçîË™øÈÅïÂèç„ÇíÊ§úÂá∫"""
        violations = []
        
        # Â≠§Á´ã„Åó„Åü„Çµ„Éº„Éê„É≥„Éà„ÇíÊ§úÂá∫
        for file_path, deps in dependency_analysis.items():
            if deps["import_count"] == 0 and len(servant_files) > 1:
                violations.append({
                    "type": ServantViolationType.POOR_COLLABORATION,
                    "severity": "MEDIUM",
                    "file_path": file_path,
                    "description": "Isolated servant with no collaboration",
                    "suggestion": "Add collaboration with other servants"
                })
                
        return violations
        
    def _calculate_collaboration_score(self,
                                     collaboration_quality: Dict[str, Any],
                                     violations: List[Dict[str, Any]]) -> float:
        """ÂçîË™ø„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó"""
        base_score = collaboration_quality.get("quality_score", 0)
        
        # ÈÅïÂèç„Å´„Çà„ÇãÊ∏õÁÇπ
        violation_penalty = len(violations) * 15
        
        final_score = max(base_score - violation_penalty, 0.0)
        return final_score


class ServantInspector(AncientElderBase):
    """„Çµ„Éº„Éê„É≥„ÉàÊüªÂØüÈ≠îÊ≥ï - Á∑èÂêà„Çµ„Éº„Éê„É≥„ÉàÁõ£Êüª„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self, project_root: Optional[Path] = None)super().__init__(specialty="servant_inspector")
    """ÂàùÊúüÂåñ„É°„ÇΩ„ÉÉ„Éâ"""
        self.project_root = project_root or Path.cwd()
        self.logger = logging.getLogger("ServantInspector")
        
        # „Ç≥„É≥„Éù„Éº„Éç„É≥„ÉàÂàùÊúüÂåñ
        self.implementation_analyzer = ServantImplementationAnalyzer(project_root)
        self.collaboration_analyzer = ServantCollaborationAnalyzer(project_root)
        
    async def audit(self, target_path: str, **kwargs) -> AuditResultreturn await self.execute_audit(target_path, **kwargs):
    """ncientElderBase„ÅÆÊäΩË±°„É°„ÇΩ„ÉÉ„ÉâÂÆüË£Ö"""
        :
    def get_audit_scope(self) -> List[str]:
        """Áõ£ÊüªÂØæË±°„Çπ„Ç≥„Éº„Éó„ÇíËøî„Åô"""
        return [
            "servant_implementation_quality",
            "servant_role_compliance", 
            "servant_collaboration",
            "servant_expertise_evaluation"
        ]
        
    async def execute_audit(self, target_path: str, **kwargs) -> AuditResultstart_time = datetime.now():
    """„Éº„Éê„É≥„ÉàÊüªÂØüÁõ£Êüª„ÇíÂÆüË°å"""
        violations = []
        metrics = {}
        :
        try:
            self.logger.info(f"üõ°Ô∏è Starting Servant Inspector audit for: {target_path}")
            
            # „Çµ„Éº„Éê„É≥„Éà„Éï„Ç°„Ç§„É´„ÇíÁô∫Ë¶ã
            servant_files = self._discover_servant_files(target_path)
            
            if not servant_files:
                self.logger.warning(f"No servant files found in {target_path}")
                # Á©∫„ÅÆÂ†¥Âêà„ÅÆAuditResult„ÇíÊ≠£„Åó„Åè‰ΩúÊàê
                empty_result = AuditResult()
                empty_result.auditor_name = "ServantInspector"
                empty_result.violations = []
                empty_result.metrics = {
                    "servant_files_found": 0,
                    "target_path": target_path,
                    "recommendations": ["Create elder servant implementations"],
                    "execution_time": (datetime.now() - start_time).total_seconds()
                }
                return empty_result
            
            # 1.0 ÂêÑ„Çµ„Éº„Éê„É≥„Éà„ÅÆÂÆüË£ÖÂìÅË≥™ÂàÜÊûê
            implementation_results = []
            for servant_file in servant_files:
                result = self.implementation_analyzer.analyze_servant_implementation(servant_file)
                implementation_results.append(result)
                violations.extend(result.get("stub_violations", []))
                violations.extend(result.get("lazy_violations", []))
                violations.extend(result.get("role_compliance", {}).get("violations", []))
                
            # 2.0 „Çµ„Éº„Éê„É≥„ÉàÈñìÂçîË™øÂàÜÊûê
            collaboration_result = self.collaboration_analyzer.analyze_servant_collaboration(servant_files)
            violations.extend(collaboration_result.get("collaboration_violations", []))
            
            # 3.0 Á∑èÂêà„Çµ„Éº„Éê„É≥„Éà„Çπ„Ç≥„Ç¢Ë®àÁÆó
            overall_score = self._calculate_overall_servant_score(
                implementation_results,
                collaboration_result
            )
            metrics["overall_servant_score"] = overall_score
            metrics["servant_files_analyzed"] = len(servant_files)
            metrics["implementation_quality"] = self._calculate_average_implementation_score(implementation_results)
            metrics["collaboration_score"] = collaboration_result.get(
                "overall_collaboration_score",
                0
            )
            
            # 4.0 ÊîπÂñÑÊèêÊ°àÁîüÊàê
            recommendations = self._generate_servant_improvement_recommendations(
                implementation_results, collaboration_result, violations
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            metrics["execution_time"] = execution_time
            
            self.logger.info(f"‚úÖ Servant Inspector audit completed in {execution_time:0.2f}s")
            
            # AuditResult„ÇíÊ≠£„Åó„Åè‰ΩúÊàê
            result = AuditResult()
            result.auditor_name = "ServantInspector"
            result.violations = violations
            result.metrics = metrics
            result.metrics["target_path"] = target_path
            result.metrics["recommendations"] = recommendations
            result.metrics["execution_time"] = execution_time
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Servant Inspector audit failed: {e}")
            # „Ç®„É©„ÉºÊôÇ„ÅÆAuditResult„ÇíÊ≠£„Åó„Åè‰ΩúÊàê
            error_result = AuditResult()
            error_result.auditor_name = "ServantInspector"
            error_result.violations = [{
                "type": "AUDIT_EXECUTION_FAILURE",
                "severity": ViolationSeverity.HIGH.value,
                "description": f"Servant Inspector audit execution failed: {str(e)}",
                "location": target_path
            }]
            error_result.metrics = {
                "error": str(e),
                "target_path": target_path,
                "recommendations": [],
                "execution_time": (datetime.now() - start_time).total_seconds()
            }
            return error_result
            
    def _discover_servant_files(self, target_path: str) -> List[str]:
        """„Çµ„Éº„Éê„É≥„Éà„Éï„Ç°„Ç§„É´„ÇíÁô∫Ë¶ã"""
        servant_files = []
        
        # „Çµ„Éº„Éê„É≥„Éà„Éï„Ç°„Ç§„É´„Éë„Çø„Éº„É≥
        servant_patterns = [
            "*servant*.py",
            "*craftsman*.py", 
            "*guardian*.py",
            "*inspector*.py",
            "*master*.py",
            "*watcher*.py",
            "*scribe*.py"
        ]
        
        target_dir = Path(target_path)
        if target_dir.is_file():
            target_dir = target_dir.parent
            
        for pattern in servant_patterns:
            servant_files.extend([str(f) for f in target_dir.rglob(pattern)])
            
        # ÈáçË§áÈô§Âéª
        return list(set(servant_files))
        
    def _calculate_overall_servant_score(self,
                                       implementation_results: List[Dict[str, Any]],
                                       collaboration_result: Dict[str, Any]) -> float:
        """Á∑èÂêà„Çµ„Éº„Éê„É≥„Éà„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó"""
        if not implementation_results:
            return 0.0
            
        # ÂÆüË£ÖÂìÅË≥™Âπ≥Âùá„Çπ„Ç≥„Ç¢Ôºà70%Ôºâ
        implementation_score = self._calculate_average_implementation_score(implementation_results) * 0.7
        
        # ÂçîË™ø„Çπ„Ç≥„Ç¢Ôºà30%Ôºâ
        collaboration_score = collaboration_result.get("overall_collaboration_score", 0) * 0.3
        
        overall_score = implementation_score + collaboration_score
        return min(overall_score, 100.0)
        
    def _calculate_average_implementation_score(
        self,
        implementation_results: List[Dict[str,
        Any]]
    ) -> float:
        """Âπ≥ÂùáÂÆüË£Ö„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó"""
        if not implementation_results:
            return 0.0
            
        total_score = sum(result.get("overall_quality_score", 0) for result in implementation_results)
        return total_score / len(implementation_results)
        
    def _generate_servant_improvement_recommendations(self,
                                                    implementation_results: List[Dict[str, Any]],
                                                    collaboration_result: Dict[str, Any],
                                                    violations: List[Dict[str, Any]]) -> List[str]:
        """„Çµ„Éº„Éê„É≥„ÉàÊîπÂñÑÊèêÊ°à„ÇíÁîüÊàê"""
        recommendations = []
        
        # ÂÆüË£ÖÂìÅË≥™ÊîπÂñÑÊèêÊ°à
        avg_implementation_score = self._calculate_average_implementation_score(implementation_results)
        if avg_implementation_score < 70:
            recommendations.append(
                "Improve servant implementation quality by removing stubs and adding proper logic"
            )
            
        # ÂçîË™øÊîπÂñÑÊèêÊ°à
        collaboration_score = collaboration_result.get("overall_collaboration_score", 0)
        if collaboration_score < 60:
            recommendations.append(
                "Enhance collaboration between servants by adding cross-servant communication"
            )
            
        # ÈÅïÂèçÂõ∫Êúâ„ÅÆÊîπÂñÑÊèêÊ°à
        violation_types = set(v.get("type") for v in violations)
        
        if ServantViolationType.STUB_IMPLEMENTATION in violation_types:
            recommendations.append("Replace all stub implementations with actual functionality")
            
        if ServantViolationType.ROLE_VIOLATION in violation_types:
            recommendations.append("Ensure servants follow their designated roles and responsibilities" \
                "Ensure servants follow their designated roles and responsibilities")
            
        if ServantViolationType.LAZY_IMPLEMENTATION in violation_types:
            recommendations.append("Improve implementation quality by adding proper error handling and logic" \
                "Improve implementation quality by adding proper error handling and logic")
            
        return recommendations