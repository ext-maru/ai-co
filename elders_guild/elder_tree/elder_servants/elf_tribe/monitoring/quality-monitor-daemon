#!/usr/bin/env python3
"""
ğŸ“Š Elder Guild Quality Monitor Daemon
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰å“è³ªç›£è¦–ãƒ‡ãƒ¼ãƒ¢ãƒ³

Features:
- ç¶™ç¶šçš„ã‚³ãƒ¼ãƒ‰å“è³ªç›£è¦–
- æ—¥æ¬¡å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ  
- å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
- nWoè©•è­°ä¼šã¸ã®è‡ªå‹•å ±å‘Š
- 4è³¢è€…é€£æºã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import logging
import json
import sys
import signal
import os
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import time

# Add project root to path
sys.path.insert(0, '/home/aicompany/ai_co')

from libs.elders_code_quality_engine import EldersCodeQualityEngine
from libs.four_sages_quality_bridge import get_four_sages_quality_orchestrator

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/aicompany/ai_co/logs/quality_monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: datetime
    total_files: int
    analyzed_files: int
    average_quality_score: float
    iron_will_compliance_rate: float
    tdd_compatibility_rate: float
    security_issues_count: int
    critical_incidents: int
    improvement_tasks_pending: int
    quality_trend: str  # improving, stable, declining

@dataclass
class QualityAlert:
    """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ"""
    alert_id: str
    severity: str  # critical, warning, info
    message: str
    affected_files: List[str]
    recommended_actions: List[str]
    timestamp: datetime
    auto_escalated: bool

class QualityTrendAnalyzer:
    """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå™¨"""
    
    def __init__(self):
        self.history_file = "/home/aicompany/ai_co/data/quality_metrics_history.json"
        self.metrics_history = []
        self.load_history()
        
    def load_history(self):
        """å±¥æ­´èª­ã¿è¾¼ã¿"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r') as f:
                    data = json.load(f)
                    self.metrics_history = [
                        QualityMetrics(**item) for item in data
                    ]
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load metrics history: {e}")
            self.metrics_history = []
            
    def save_history(self):
        """å±¥æ­´ä¿å­˜"""
        try:
            os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
            with open(self.history_file, 'w') as f:
                json.dump([
                    asdict(metric) for metric in self.metrics_history
                ], f, indent=2, default=str)
        except Exception as e:
            logger.error(f"âŒ Failed to save metrics history: {e}")
            
    def add_metrics(self, metrics: QualityMetrics):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ """
        self.metrics_history.append(metrics)
        
        # æœ€å¤§100ä»¶ã¾ã§ä¿æŒ
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
            
        self.save_history()
        
    def analyze_trend(self, window_days: int = 7) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if len(self.metrics_history) < 2:
            return "insufficient_data"
            
        # æŒ‡å®šæœŸé–“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        cutoff_date = datetime.now() - timedelta(days=window_days)
        recent_metrics = [
            m for m in self.metrics_history 
            if m.timestamp >= cutoff_date
        ]
        
        if len(recent_metrics) < 2:
            return "insufficient_data"
            
        # å“è³ªã‚¹ã‚³ã‚¢ã®å¤‰åŒ–ã‚’åˆ†æ
        scores = [m.average_quality_score for m in recent_metrics]
        
        # ç·šå½¢å›å¸°ã§å‚¾å‘åˆ¤å®š
        x_values = list(range(len(scores)))
        if len(x_values) > 1:
            # ç°¡å˜ãªå‚¾ãè¨ˆç®—
            n = len(scores)
            sum_x = sum(x_values)
            sum_y = sum(scores)
            sum_xy = sum(x * y for x, y in zip(x_values, scores))
            sum_x2 = sum(x * x for x in x_values)
            
            slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
            
            if slope > 1.0:
                return "improving"
            elif slope < -1.0:
                return "declining"
            else:
                return "stable"
        
        return "stable"
        
    def get_quality_insights(self) -> Dict:
        """å“è³ªã‚¤ãƒ³ã‚µã‚¤ãƒˆå–å¾—"""
        if not self.metrics_history:
            return {'insights': [], 'recommendations': []}
            
        latest = self.metrics_history[-1]
        insights = []
        recommendations = []
        
        # å“è³ªã‚¹ã‚³ã‚¢åˆ†æ
        if latest.average_quality_score < 60:
            insights.append("Critical: Average quality score is below acceptable threshold")
            recommendations.append("Immediate code review and refactoring required")
        elif latest.average_quality_score < 75:
            insights.append("Warning: Quality score needs improvement")
            recommendations.append("Schedule quality improvement sprint")
            
        # Iron Willéµå®ˆç‡åˆ†æ
        if latest.iron_will_compliance_rate < 0.9:
            insights.append("Iron Will compliance rate is concerning")
            recommendations.append("Review and remove all workaround code")
            
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œåˆ†æ
        if latest.security_issues_count > 0:
            insights.append(f"Security issues detected: {latest.security_issues_count}")
            recommendations.append("Priority security review required")
            
        return {
            'insights': insights,
            'recommendations': recommendations,
            'trend': self.analyze_trend()
        }

class QualityMonitorDaemon:
    """å“è³ªç›£è¦–ãƒ‡ãƒ¼ãƒ¢ãƒ³"""
    
    def __init__(self):
        self.running = False
        self.quality_engine = None
        self.four_sages = None
        self.trend_analyzer = QualityTrendAnalyzer()
        self.alerts = []
        
        # è¨­å®š
        self.scan_interval = 3600  # 1 hour
        self.project_paths = [
            "/home/aicompany/ai_co/libs",
            "/home/aicompany/ai_co/scripts"
        ]
        self.quality_thresholds = {
            'minimum_score': 70.0,
            'iron_will_rate': 0.95,
            'security_issues': 0,
            'critical_incidents': 3
        }
        
    async def initialize(self):
        """åˆæœŸåŒ–"""
        # å“è³ªã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        db_params = {
            'host': 'localhost',
            'database': 'elders_guild_pgvector',
            'user': 'postgres',
            'password': ''
        }
        
        self.quality_engine = EldersCodeQualityEngine(db_params)
        await self.quality_engine.initialize()
        
        # 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.four_sages = await get_four_sages_quality_orchestrator()
        
        logger.info("ğŸ“Š Quality Monitor Daemon initialized")
        
    async def shutdown(self):
        """çµ‚äº†å‡¦ç†"""
        self.running = False
        
        if self.quality_engine:
            await self.quality_engine.shutdown()
            
        logger.info("ğŸ”’ Quality Monitor Daemon shutdown")
        
    def find_python_files(self) -> List[str]:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        python_files = []
        
        for base_path in self.project_paths:
            path = Path(base_path)
            if path.exists():
                for py_file in path.rglob('*.py'):
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if '__pycache__' not in str(py_file) and not py_file.name.startswith('test_'):
                        python_files.append(str(py_file))
                        
        return python_files[:50]  # æœ€å¤§50ãƒ•ã‚¡ã‚¤ãƒ«
        
    async def scan_project_quality(self) -> QualityMetrics:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªã‚¹ã‚­ãƒ£ãƒ³"""
        logger.info("ğŸ” Starting project quality scan...")
        
        python_files = self.find_python_files()
        
        if not python_files:
            logger.warning("âš ï¸ No Python files found for scanning")
            return QualityMetrics(
                timestamp=datetime.now(),
                total_files=0,
                analyzed_files=0,
                average_quality_score=0.0,
                iron_will_compliance_rate=0.0,
                tdd_compatibility_rate=0.0,
                security_issues_count=0,
                critical_incidents=0,
                improvement_tasks_pending=0,
                quality_trend="unknown"
            )
            
        # å“è³ªåˆ†æå®Ÿè¡Œ
        total_quality_score = 0.0
        iron_will_compliant = 0
        tdd_compatible = 0
        security_issues = 0
        analyzed_count = 0
        
        for file_path in python_files:
            try:
                result = await self.quality_engine.analyze_file(file_path)
                
                if 'error' not in result:
                    analysis = result.get('analysis', {})
                    
                    total_quality_score += analysis.get('quality_score', 0)
                    
                    if analysis.get('iron_will_compliance', False):
                        iron_will_compliant += 1
                        
                    if analysis.get('tdd_compatibility', False):
                        tdd_compatible += 1
                        
                    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚«ã‚¦ãƒ³ãƒˆ
                    bug_risks = analysis.get('bug_risks', [])
                    security_issues += len([risk for risk in bug_risks if risk.get('risk_level', 0) > 7])
                    
                    analyzed_count += 1
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to analyze {file_path}: {e}")
                
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        avg_quality = total_quality_score / analyzed_count if analyzed_count > 0 else 0.0
        iron_will_rate = iron_will_compliant / analyzed_count if analyzed_count > 0 else 0.0
        tdd_rate = tdd_compatible / analyzed_count if analyzed_count > 0 else 0.0
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trend = self.trend_analyzer.analyze_trend()
        
        metrics = QualityMetrics(
            timestamp=datetime.now(),
            total_files=len(python_files),
            analyzed_files=analyzed_count,
            average_quality_score=avg_quality,
            iron_will_compliance_rate=iron_will_rate,
            tdd_compatibility_rate=tdd_rate,
            security_issues_count=security_issues,
            critical_incidents=0,  # Will be updated by incident sage
            improvement_tasks_pending=0,  # Will be updated by task sage
            quality_trend=trend
        )
        
        logger.info(f"âœ… Quality scan completed: {analyzed_count} files, avg score: {avg_quality:.1f}")
        return metrics
        
    async def check_quality_thresholds(self, metrics: QualityMetrics) -> List[QualityAlert]:
        """å“è³ªé–¾å€¤ãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        # å“è³ªã‚¹ã‚³ã‚¢ã‚¢ãƒ©ãƒ¼ãƒˆ
        if metrics.average_quality_score < self.quality_thresholds['minimum_score']:
            alerts.append(QualityAlert(
                alert_id=f"QA_{datetime.now().strftime('%Y%m%d_%H%M%S')}_SCORE",
                severity='critical' if metrics.average_quality_score < 50 else 'warning',
                message=f"Average quality score ({metrics.average_quality_score:.1f}) below threshold ({self.quality_thresholds['minimum_score']})",
                affected_files=[],
                recommended_actions=[
                    "Review code quality standards",
                    "Schedule refactoring sprint",
                    "Increase code review rigor"
                ],
                timestamp=datetime.now(),
                auto_escalated=metrics.average_quality_score < 50
            ))
            
        # Iron Willéµå®ˆç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
        if metrics.iron_will_compliance_rate < self.quality_thresholds['iron_will_rate']:
            alerts.append(QualityAlert(
                alert_id=f"QA_{datetime.now().strftime('%Y%m%d_%H%M%S')}_IRON_WILL",
                severity='critical',
                message=f"Iron Will compliance rate ({metrics.iron_will_compliance_rate:.1%}) below threshold",
                affected_files=[],
                recommended_actions=[
                    "Remove all TODO/FIXME comments",
                    "Complete temporary implementations",
                    "Enforce Iron Will policy"
                ],
                timestamp=datetime.now(),
                auto_escalated=True
            ))
            
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚¢ãƒ©ãƒ¼ãƒˆ
        if metrics.security_issues_count > self.quality_thresholds['security_issues']:
            alerts.append(QualityAlert(
                alert_id=f"QA_{datetime.now().strftime('%Y%m%d_%H%M%S')}_SECURITY",
                severity='critical',
                message=f"Security issues detected: {metrics.security_issues_count}",
                affected_files=[],
                recommended_actions=[
                    "Immediate security review",
                    "Fix high-risk vulnerabilities",
                    "Update security guidelines"
                ],
                timestamp=datetime.now(),
                auto_escalated=True
            ))
            
        return alerts
        
    async def generate_daily_report(self, metrics: QualityMetrics, alerts: List[QualityAlert]):
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            'date': datetime.now().isoformat(),
            'metrics': asdict(metrics),
            'alerts': [asdict(alert) for alert in alerts],
            'insights': self.trend_analyzer.get_quality_insights(),
            'summary': {
                'overall_status': self._determine_overall_status(metrics, alerts),
                'priority_actions': self._generate_priority_actions(metrics, alerts),
                'trend_analysis': metrics.quality_trend
            }
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = f"/home/aicompany/ai_co/daily_reports/quality_report_{datetime.now().strftime('%Y%m%d')}.json"
        os.makedirs(os.path.dirname(report_file), exist_ok=True)
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, default=str)
            
        logger.info(f"ğŸ“„ Daily quality report saved: {report_file}")
        
        # nWoè©•è­°ä¼šå ±å‘Šï¼ˆé‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆï¼‰
        critical_alerts = [alert for alert in alerts if alert.severity == 'critical']
        if critical_alerts:
            await self._report_to_nwo_council(report)
            
    def _determine_overall_status(self, metrics: QualityMetrics, alerts: List[QualityAlert]) -> str:
        """å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š"""
        critical_alerts = [alert for alert in alerts if alert.severity == 'critical']
        
        if critical_alerts:
            return 'critical'
        elif metrics.average_quality_score < 60:
            return 'warning'
        elif metrics.quality_trend == 'declining':
            return 'caution'
        else:
            return 'healthy'
            
    def _generate_priority_actions(self, metrics: QualityMetrics, alerts: List[QualityAlert]) -> List[str]:
        """å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        actions = []
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        for alert in alerts:
            if alert.severity == 'critical':
                actions.extend(alert.recommended_actions)
                
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if metrics.average_quality_score < 70:
            actions.append("Schedule immediate code quality improvement")
            
        if metrics.iron_will_compliance_rate < 0.9:
            actions.append("Enforce Iron Will compliance")
            
        if metrics.tdd_compatibility_rate < 0.5:
            actions.append("Increase test coverage and TDD adoption")
            
        return list(set(actions))  # é‡è¤‡å‰Šé™¤
        
    async def _report_to_nwo_council(self, report: Dict):
        """nWoè©•è­°ä¼šå ±å‘Š"""
        try:
            # nWoè©•è­°ä¼šãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            nwo_report_file = f"/home/aicompany/ai_co/data/nwo_quality_alerts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            nwo_report = {
                'alert_type': 'quality_concern',
                'priority': 'high',
                'summary': report['summary'],
                'critical_alerts': [
                    alert for alert in report['alerts'] 
                    if alert['severity'] == 'critical'
                ],
                'recommended_council_actions': [
                    "Review quality standards enforcement",
                    "Consider emergency quality improvement sprint",
                    "Evaluate development process adherence"
                ]
            }
            
            with open(nwo_report_file, 'w') as f:
                json.dump(nwo_report, f, indent=2, default=str)
                
            logger.warning(f"ğŸ›ï¸ Critical quality issues reported to nWo Council: {nwo_report_file}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to report to nWo Council: {e}")
            
    async def monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        logger.info("ğŸ”„ Quality monitoring loop started")
        
        while self.running:
            try:
                # å“è³ªã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
                metrics = await self.scan_project_quality()
                
                # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«è¿½åŠ 
                self.trend_analyzer.add_metrics(metrics)
                
                # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                alerts = await self.check_quality_thresholds(metrics)
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆä¿å­˜
                self.alerts.extend(alerts)
                
                # é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆã¯ãƒ­ã‚°ã«è¨˜éŒ²
                for alert in alerts:
                    if alert.severity == 'critical':
                        logger.critical(f"ğŸš¨ Critical quality alert: {alert.message}")
                    elif alert.severity == 'warning':
                        logger.warning(f"âš ï¸ Quality warning: {alert.message}")
                        
                # æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆ1æ—¥1å›ï¼‰
                current_hour = datetime.now().hour
                if current_hour == 9:  # æœ9æ™‚ã«å®Ÿè¡Œ
                    await self.generate_daily_report(metrics, alerts)
                    
                # æ¬¡å›å®Ÿè¡Œã¾ã§å¾…æ©Ÿ
                await asyncio.sleep(self.scan_interval)
                
            except Exception as e:
                logger.error(f"âŒ Monitoring loop error: {e}")
                await asyncio.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾Œã«ãƒªãƒˆãƒ©ã‚¤
                
    async def start(self):
        """ãƒ‡ãƒ¼ãƒ¢ãƒ³é–‹å§‹"""
        await self.initialize()
        self.running = True
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
        def signal_handler(signum, frame):
            logger.info(f"ğŸ›‘ Received signal {signum}, shutting down...")
            self.running = False
            
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        logger.info("ğŸš€ Quality Monitor Daemon started")
        await self.monitoring_loop()
        await self.shutdown()

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    daemon = QualityMonitorDaemon()
    await daemon.start()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Quality monitoring interrupted")
    except Exception as e:
        logger.error(f"âŒ Quality monitoring failed: {e}")
        sys.exit(1)