#!/usr/bin/env python3
"""
ğŸ›ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ 
æ—¥æ¬¡è‡ªå‹•å­¦ç¿’ãƒ»æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import sqlite3
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging
import subprocess
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from libs.project_automation_engine import ProjectAutomationEngine

logger = logging.getLogger(__name__)

class ProjectIntelligenceSystem:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ  - è‡ªå‹•å­¦ç¿’ãƒ»æ”¹å–„"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""

        self.automation_engine = ProjectAutomationEngine()
        self.db_path = PROJECT_ROOT / "project_intelligence.db"
        self.reports_dir = PROJECT_ROOT / "reports" / "daily_intelligence"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self._init_database()

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS learning_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date DATE NOT NULL,
                project_id TEXT,

                phase_name TEXT,
                metric_type TEXT,
                metric_value REAL,
                improvement_suggestion TEXT,
                confidence_score REAL,
                applied BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # æ”¹å–„å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS improvement_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                improvement_type TEXT NOT NULL,
                old_value TEXT,
                new_value TEXT,
                effectiveness_score REAL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                validated_at TIMESTAMP,
                elder_approval TEXT
            )
        """
        )

        # ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šå ±å‘Šãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS elder_council_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_date DATE NOT NULL,
                report_type TEXT NOT NULL,
                content TEXT NOT NULL,
                elder_responses TEXT,
                approved BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        conn.commit()
        conn.close()

    async def daily_intelligence_cycle(self):
        """æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«"""
        today = datetime.now().date()

        logger.info(f"ğŸ§  æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹: {today}")

        # 1.0 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿åé›†
        project_data = await self._collect_project_data()

        # 2.0 ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = await self._analyze_patterns(project_data)

        # 3.0 æ”¹å–„ææ¡ˆç”Ÿæˆ
        improvements = await self._generate_improvements(patterns)

        # 4.0 ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šã¸ã®å ±å‘Š
        report = await self._generate_elder_council_report(improvements)

        # 5.0 æ‰¿èªã•ã‚ŒãŸæ”¹å–„ã®è‡ªå‹•é©ç”¨
        await self._apply_approved_improvements()

        # 6.0 æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        await self._generate_daily_report(today, project_data, patterns, improvements)

        logger.info("ğŸ§  æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«å®Œäº†")

        return {
            "success": True,
            "date": today,
            "projects_analyzed": len(project_data),
            "patterns_found": len(patterns),
            "improvements_suggested": len(improvements),
            "elder_council_report": report["id"] if report else None,
        }

    async def _collect_project_data(self) -> List[Dict[str, Any]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿åé›†"""
        project_data = []

        # æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ†æ
        projects_dir = PROJECT_ROOT / "projects"
        if projects_dir.exists():
            for project_dir in projects_dir.iterdir():
                if project_dir.is_dir() and project_dir.name.startswith("project_"):
                    try:

                            project_dir.name
                        )
                        if not (context):
                            continue  # Early return to reduce nesting
                        # Reduced nesting - original condition satisfied
                        if context:
                            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
                            metrics = await self._collect_project_metrics(project_dir)

                            project_data.append(
                                {
                                    "project_id": project_dir.name,
                                    "context": context,
                                    "metrics": metrics,
                                    "files": self._analyze_project_files(project_dir),
                                }
                            )
                    except Exception as e:
                        logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼ {project_dir.name}: {e}")

        return project_data

    async def _collect_project_metrics(self, project_dir: Path) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        metrics = {
            "file_count": 0,
            "code_lines": 0,
            "test_coverage": 0.0,
            "completion_rate": 0.0,
            "quality_score": 0.0,
            "automation_efficiency": 0.0,
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        for file_path in project_dir.rglob("*"):
            if file_path.is_file():
                metrics["file_count"] += 1

                # ã‚³ãƒ¼ãƒ‰è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
                if file_path.suffix in [".py", ".js", ".ts", ".sql"]:
                    try:
                        # Deep nesting detected (depth: 5) - consider refactoring
                        with open(file_path, "r", encoding="utf-8") as f:
                            metrics["code_lines"] += len(f.readlines())
                    except:
                        pass

        # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸æ¨å®š
        test_files = list(project_dir.glob("**/test_*.py"))
        if test_files:
            metrics["test_coverage"] = min(
                len(test_files) / max(1, metrics["file_count"] * 0.3), 1.0
            )

        # å®Œæˆåº¦æ¨å®š
        required_files = ["requirements.md", "architecture.md"]
        existing_files = [f for f in required_files if (project_dir / f).exists()]
        metrics["completion_rate"] = len(existing_files) / len(required_files)

        return metrics

    def _analyze_project_files(self, project_dir: Path) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ"""
        file_analysis = {
            "total_files": 0,
            "documentation_files": 0,
            "code_files": 0,
            "test_files": 0,
            "config_files": 0,
            "missing_files": [],
            "quality_issues": [],
        }

        for file_path in project_dir.rglob("*"):
            if file_path.is_file():
                file_analysis["total_files"] += 1

                if file_path.suffix in [".md", ".txt", ".rst"]:
                    file_analysis["documentation_files"] += 1
                elif file_path.suffix in [".py", ".js", ".ts", ".java", ".cpp"]:
                    file_analysis["code_files"] += 1
                elif file_path.name.startswith("test_"):
                    file_analysis["test_files"] += 1
                elif file_path.suffix in [".json", ".yaml", ".yml", ".ini"]:
                    file_analysis["config_files"] += 1

        # æ¬ è½ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
        expected_files = ["README.md", "requirements.md", ".gitignore"]
        for expected in expected_files:
            if not (project_dir / expected).exists():
                file_analysis["missing_files"].append(expected)

        return file_analysis

    async def _analyze_patterns(
        self, project_data: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        patterns = []

        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        successful_projects = [
            p for p in project_data if p["metrics"]["completion_rate"] > 0.7
        ]
        if successful_projects:
            patterns.append(
                {
                    "type": "success_pattern",
                    "description": "é«˜å®Œæˆåº¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…±é€šç‚¹",
                    "data": self._extract_common_patterns(successful_projects),
                    "confidence": 0.8,
                }
            )

        # åŠ¹ç‡æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        efficient_projects = [
            p for p in project_data if p["metrics"]["automation_efficiency"] > 0.6
        ]
        if efficient_projects:
            patterns.append(
                {
                    "type": "efficiency_pattern",
                    "description": "é«˜åŠ¹ç‡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç‰¹å¾´",
                    "data": self._extract_efficiency_patterns(efficient_projects),
                    "confidence": 0.7,
                }
            )

        # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        problematic_projects = [
            p for p in project_data if p["metrics"]["quality_score"] < 0.5
        ]
        if problematic_projects:
            patterns.append(
                {
                    "type": "problem_pattern",
                    "description": "å“è³ªå•é¡Œã®å…±é€šè¦å› ",
                    "data": self._extract_problem_patterns(problematic_projects),
                    "confidence": 0.6,
                }
            )

        return patterns

    def _extract_common_patterns(
        self, projects: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º"""

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨é »åº¦
        for project in projects:

            )

        # å…±é€šãƒ•ã‚¡ã‚¤ãƒ«
        all_files = set()
        for project in projects:
            files = project["files"]
            all_files.update(files.keys())

        for file_type in all_files:
            count = sum(1 for p in projects if file_type in p["files"])
            if count > len(projects) * 0.7:  # 70%ä»¥ä¸Šã§å…±é€š
                patterns["common_files"][file_type] = count / len(projects)

        return patterns

    def _extract_efficiency_patterns(
        self, projects: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åŠ¹ç‡æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º"""
        return {
            "average_file_count": sum(p["metrics"]["file_count"] for p in projects)
            / len(projects),
            "average_completion_time": "æ¨å®šå€¤",  # å®Ÿéš›ã®å®Œæˆæ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ç”¨
            "common_automation_rules": "åˆ†æçµæœ",
        }

    def _extract_problem_patterns(
        self, projects: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º"""
        return {
            "common_missing_files": {},
            "quality_issues": [],
            "completion_bottlenecks": [],
        }

    async def _generate_improvements(
        self, patterns: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        improvements = []

        for pattern in patterns:
            if pattern["type"] == "success_pattern":
                # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ”¹å–„ææ¡ˆ
                improvements.extend(self._generate_success_improvements(pattern))
            elif pattern["type"] == "efficiency_pattern":
                # åŠ¹ç‡æ€§æ”¹å–„ææ¡ˆ
                improvements.extend(self._generate_efficiency_improvements(pattern))
            elif pattern["type"] == "problem_pattern":
                # å•é¡Œè§£æ±ºææ¡ˆ
                improvements.extend(self._generate_problem_solutions(pattern))

        return improvements

    def _generate_success_improvements(
        self, pattern: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ”¹å–„ææ¡ˆ"""
        improvements = []

        # æˆåŠŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…±é€šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«è¿½åŠ 
        common_files = pattern["data"].get("common_files", {})
        for file_type, frequency in common_files.items():
            if frequency > 0.8:  # 80%ä»¥ä¸Šã§å…±é€š
                improvements.append(
                    {

                        "description": f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«{file_type}ã‚’è¿½åŠ ",

                        "confidence": frequency,
                        "priority": "medium",
                    }
                )

        return improvements

    def _generate_efficiency_improvements(
        self, pattern: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """åŠ¹ç‡æ€§æ”¹å–„ææ¡ˆ"""
        improvements = []

        # è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«ã®æ”¹å–„
        improvements.append(
            {
                "type": "automation_rule",
                "description": "è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«ã®æœ€é©åŒ–",
                "action": "optimize_automation_rules",
                "confidence": 0.7,
                "priority": "high",
            }
        )

        return improvements

    def _generate_problem_solutions(
        self, pattern: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """å•é¡Œè§£æ±ºææ¡ˆ"""
        improvements = []

        # å“è³ªãƒã‚§ãƒƒã‚¯å¼·åŒ–
        improvements.append(
            {
                "type": "quality_check",
                "description": "å“è³ªãƒã‚§ãƒƒã‚¯é …ç›®ã®è¿½åŠ ",
                "action": "add_quality_checks",
                "confidence": 0.6,
                "priority": "medium",
            }
        )

        return improvements

    async def _generate_elder_council_report(
        self, improvements: List[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not improvements:
            return None

        report_id = f"intelligence_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        report_content = {
            "report_id": report_id,
            "date": datetime.now().date().isoformat(),
            "summary": {
                "total_improvements": len(improvements),
                "high_priority": len(
                    [i for i in improvements if i["priority"] == "high"]
                ),
                "medium_priority": len(
                    [i for i in improvements if i["priority"] == "medium"]
                ),
                "low_priority": len(
                    [i for i in improvements if i["priority"] == "low"]
                ),
            },
            "improvements": improvements,
            "recommendations": [
                "é«˜å„ªå…ˆåº¦ã®æ”¹å–„ã‚’å„ªå…ˆå®Ÿè£…",
                "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç¶™ç¶šçš„æ”¹å–„",
                "è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«ã®æœ€é©åŒ–",
            ],
            "elder_consultation": {
                "knowledge_sage": "éå»ã®æˆåŠŸäº‹ä¾‹ã¨ã®æ¯”è¼ƒåˆ†æ",
                "task_sage": "å®Ÿè£…å„ªå…ˆé †ä½ã®æ±ºå®š",
                "incident_sage": "ãƒªã‚¹ã‚¯è©•ä¾¡ã¨äºˆé˜²ç­–",
                "rag_sage": "æœ€æ–°æŠ€è¡“å‹•å‘ã®èª¿æŸ»",
            },
        }

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO elder_council_reports (report_date, report_type, content)
            VALUES (?, ?, ?)
        """,
            (
                datetime.now().date(),
                "daily_intelligence",
                json.dumps(report_content, ensure_ascii=False),
            ),
        )

        conn.commit()
        conn.close()

        # ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        report_file = self.reports_dir / f"{report_id}.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report_content, f, indent=2, ensure_ascii=False)

        return {"id": report_id, "file": str(report_file)}

    async def _apply_approved_improvements(self):
        """æ‰¿èªã•ã‚ŒãŸæ”¹å–„ã®è‡ªå‹•é©ç”¨"""
        # æ‰¿èªæ¸ˆã¿æ”¹å–„ã®å–å¾—
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT * FROM elder_council_reports
            WHERE approved = TRUE AND report_type = 'daily_intelligence'
            ORDER BY created_at DESC LIMIT 5
        """
        )

        approved_reports = cursor.fetchall()
        conn.close()

        for report in approved_reports:
            try:
                content = json.loads(report[3])  # content column
                await self._apply_improvements(content["improvements"])
            except Exception as e:
                logger.error(f"æ”¹å–„é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")

    async def _apply_improvements(self, improvements: List[Dict[str, Any]]):
        """æ”¹å–„ã®é©ç”¨"""
        for improvement in improvements:
            try:

                elif improvement["type"] == "automation_rule":
                    await self._apply_automation_rule(improvement)
                elif improvement["type"] == "quality_check":
                    await self._apply_quality_check(improvement)

                # é©ç”¨å±¥æ­´è¨˜éŒ²
                conn = sqlite3connect(self.db_path)
                cursor = conn.cursor()

                cursor.execute(
                    """
                    INSERT INTO improvement_history
                    (improvement_type, old_value, new_value, applied_at)
                    VALUES (?, ?, ?, ?)
                """,
                    (improvement["type"], "æ—§å€¤", "æ–°å€¤", datetime.now()),
                )

                conn.commit()
                conn.close()

            except Exception as e:
                logger.error(f"æ”¹å–„é©ç”¨ã‚¨ãƒ©ãƒ¼ {improvement['type']}: {e}")

        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ”¹å–„ã®é©ç”¨"""
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°
        logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ”¹å–„é©ç”¨: {improvement['description']}")

    async def _apply_automation_rule(self, improvement: Dict[str, Any]):
        """è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«æ”¹å–„ã®é©ç”¨"""
        # è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«ã®æ›´æ–°
        logger.info(f"è‡ªå‹•åŒ–ãƒ«ãƒ¼ãƒ«æ”¹å–„é©ç”¨: {improvement['description']}")

    async def _apply_quality_check(self, improvement: Dict[str, Any]):
        """å“è³ªãƒã‚§ãƒƒã‚¯æ”¹å–„ã®é©ç”¨"""
        # å“è³ªãƒã‚§ãƒƒã‚¯ã®è¿½åŠ 
        logger.info(f"å“è³ªãƒã‚§ãƒƒã‚¯æ”¹å–„é©ç”¨: {improvement['description']}")

    async def _generate_daily_report(self, date, project_data, patterns, improvements):
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            "date": date.isoformat(),
            "summary": {
                "projects_analyzed": len(project_data),
                "patterns_identified": len(patterns),
                "improvements_suggested": len(improvements),
                "overall_health": self._calculate_overall_health(project_data),
            },
            "projects": [
                {
                    "id": p["project_id"],
                    "completion_rate": p["metrics"]["completion_rate"],
                    "quality_score": p["metrics"]["quality_score"],
                }
                for p in project_data
            ],
            "patterns": patterns,
            "improvements": improvements,
        }

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        report_file = self.reports_dir / f"daily_report_{date.strftime('%Y%m%d')}.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        return report_file

    def _calculate_overall_health(self, project_data: List[Dict[str, Any]]) -> float:
        """å…¨ä½“å¥åº·åº¦è¨ˆç®—"""
        if not project_data:
            return 0.0

        total_health = sum(
            p["metrics"]["completion_rate"] * 0.4
            + p["metrics"]["quality_score"] * 0.3
            + p["metrics"]["test_coverage"] * 0.3
            for p in project_data
        )

        return total_health / len(project_data)

class DailyIntelligenceScheduler:
    """æ—¥æ¬¡çŸ¥èƒ½ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.intelligence_system = ProjectIntelligenceSystem()

    async def start_daily_cycle(self):
        """æ—¥æ¬¡ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹"""
        while True:
            try:
                # æ¯æ—¥åˆå‰6æ™‚ã«å®Ÿè¡Œ
                now = datetime.now()
                next_run = now.replace(hour=6, minute=0, second=0, microsecond=0)

                if next_run <= now:
                    next_run += timedelta(days=1)

                # æ¬¡å›å®Ÿè¡Œã¾ã§ã®å¾…æ©Ÿæ™‚é–“è¨ˆç®—
                wait_seconds = (next_run - now).total_seconds()

                logger.info(f"ğŸ“… æ¬¡å›å®Ÿè¡Œäºˆå®š: {next_run}")
                await asyncio.sleep(wait_seconds)

                # æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
                result = await self.intelligence_system.daily_intelligence_cycle()
                logger.info(f"ğŸ“Š æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«çµæœ: {result}")

            except Exception as e:
                logger.error(f"æ—¥æ¬¡çŸ¥èƒ½ã‚µã‚¤ã‚¯ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(3600)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1æ™‚é–“å¾Œã«å†è©¦è¡Œ

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--daily", action="store_true", help="æ—¥æ¬¡ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ")
    parser.add_argument("--schedule", action="store_true", help="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
    parser.add_argument("--report", help="ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (æ—¥ä»˜: YYYY-MM-DD)")

    args = parser.parse_args()

    system = ProjectIntelligenceSystem()

    if args.daily:
        # æ—¥æ¬¡ã‚µã‚¤ã‚¯ãƒ«ã‚’å³åº§ã«å®Ÿè¡Œ
        asyncio.run(system.daily_intelligence_cycle())
    elif args.schedule:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹
        scheduler = DailyIntelligenceScheduler()
        asyncio.run(scheduler.start_daily_cycle())
    elif args.report:
        # æŒ‡å®šæ—¥ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print(f"æŒ‡å®šæ—¥ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {args.report}")
    else:
        parser.print_help()
