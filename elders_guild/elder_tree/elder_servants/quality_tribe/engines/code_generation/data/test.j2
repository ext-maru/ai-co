#!/usr/bin/env python3
"""
Test cases for Data Processing implementation - Issue #{{ issue_number }}
{{ issue_title }}

Generated by Elder Flow Auto Issue Processor with Jinja2 Templates
"""

import unittest
from unittest.mock import Mock, patch, MagicMock
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import shutil
from datetime import datetime

# Import the implementation
from {{ module_name }} import {{ class_name }}


class Test{{ class_name }}(unittest.TestCase):
    """Test cases for {{ class_name }}"""
    
    def setUp(self):
        """Set up test fixtures"""
        # Create temporary directories
        self.temp_dir = tempfile.mkdtemp()
        self.input_dir = Path(self.temp_dir) / "input"
        self.output_dir = Path(self.temp_dir) / "output"
        self.input_dir.mkdir()
        self.output_dir.mkdir()
        
        # Configuration
        self.config = {
            'input_path': str(self.input_dir),
            'output_path': str(self.output_dir),
            'chunk_size': 1000,
            'encoding': 'utf-8'
        }
        
        # Create test data
        self.test_data = pd.DataFrame({
            'id': range(1, 101),
            'name': [f'Item_{i}' for i in range(1, 101)],
            'value': np.random.rand(100) * 100,
            'category': np.random.choice(['A', 'B', 'C'], 100),
            'date': pd.date_range('2025-01-01', periods=100, freq='D')
        })
        
        # Save test data as CSV
        self.test_csv = self.input_dir / "test_data.csv"
        self.test_data.to_csv(self.test_csv, index=False)
        
        # Initialize test instance
        self.instance = {{ class_name }}(config=self.config)
    
    def tearDown(self):
        """Clean up after tests"""
        # Remove temporary directory
        shutil.rmtree(self.temp_dir)
    
    def test_initialization(self):
        """Test successful initialization"""
        self.assertIsNotNone(self.instance)
        self.assertEqual(self.instance.input_path, str(self.input_dir))
        self.assertEqual(self.instance.output_path, str(self.output_dir))
        self.assertEqual(self.instance.chunk_size, 1000)
        self.assertEqual(self.instance.encoding, 'utf-8')
    
    def test_initialization_creates_output_dir(self):
        """Test that initialization creates output directory"""
        # Remove output directory
        shutil.rmtree(self.output_dir)
        
        # Re-initialize
        instance = {{ class_name }}(config=self.config)
        
        # Check directory was created
        self.assertTrue(self.output_dir.exists())
    
    def test_validate_input_no_file_or_data(self):
        """Test input validation with no file or data"""
        result = self.instance._validate_input()
        self.assertFalse(result['valid'])
        self.assertIn('No input file', result['error'])
    
    def test_validate_input_file_not_found(self):
        """Test input validation with non-existent file"""
        result = self.instance._validate_input(input_file='nonexistent.csv')
        self.assertFalse(result['valid'])
        self.assertIn('not found', result['error'])
    
    def test_validate_input_valid_file(self):
        """Test input validation with valid file"""
        result = self.instance._validate_input(input_file='test_data.csv')
        self.assertTrue(result['valid'])
    
    def test_validate_input_with_data(self):
        """Test input validation with direct data"""
        result = self.instance._validate_input(data=[{'a': 1}, {'a': 2}])
        self.assertTrue(result['valid'])
    
    def test_load_data_from_csv(self):
        """Test loading data from CSV file"""
        data = self.instance._load_data('test_data.csv')
        
        self.assertIsNotNone(data)
        self.assertIsInstance(data, pd.DataFrame)
        self.assertEqual(len(data), 100)
        self.assertListEqual(list(data.columns), ['id', 'name', 'value', 'category', 'date'])
    
    def test_load_data_from_dict(self):
        """Test loading data from dictionary"""
        test_dict = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4}]
        data = self.instance._load_data(None, data=test_dict)
        
        self.assertIsNotNone(data)
        self.assertIsInstance(data, pd.DataFrame)
        self.assertEqual(len(data), 2)
    
    {% if 'json' in issue_body.lower() %}
    def test_load_data_from_json(self):
        """Test loading data from JSON file"""
        # Create test JSON file
        test_json = self.input_dir / "test_data.json"
        self.test_data.to_json(test_json, orient='records')
        
        data = self.instance._load_data('test_data.json')
        
        self.assertIsNotNone(data)
        self.assertIsInstance(data, pd.DataFrame)
        self.assertEqual(len(data), 100)
    {% endif %}
    
    {% if 'excel' in issue_body.lower() or 'xlsx' in issue_body.lower() %}
    def test_load_data_from_excel(self):
        """Test loading data from Excel file"""
        # Create test Excel file
        test_excel = self.input_dir / "test_data.xlsx"
        self.test_data.to_excel(test_excel, index=False)
        
        data = self.instance._load_data('test_data.xlsx')
        
        self.assertIsNotNone(data)
        self.assertIsInstance(data, pd.DataFrame)
        self.assertEqual(len(data), 100)
    {% endif %}
    
    def test_execute_success(self):
        """Test successful execution"""
        result = self.instance.execute(
            input_file='test_data.csv',
            output_file='processed_data.csv'
        )
        
        self.assertTrue(result['success'])
        self.assertEqual(result['issue_number'], {{ issue_number }})
        self.assertIn('result', result)
        self.assertIn('input_shape', result['result'])
        self.assertIn('output_shape', result['result'])
        self.assertIn('summary', result['result'])
        
        # Check output file exists
        output_file = Path(result['result']['output_file'])
        self.assertTrue(output_file.exists())
    
    def test_execute_validation_failure(self):
        """Test execution with validation failure"""
        result = self.instance.execute()
        
        self.assertFalse(result['success'])
        self.assertIn('No input file', result['error'])
    
    def test_execute_load_failure(self):
        """Test execution with data load failure"""
        result = self.instance.execute(input_file='nonexistent.csv')
        
        self.assertFalse(result['success'])
    
    {% if 'clean' in issue_body.lower() or 'missing' in issue_body.lower() %}
    def test_clean_data(self):
        """Test data cleaning functionality"""
        # Create data with missing values and duplicates
        dirty_data = pd.DataFrame({
            'a': [1, 2, None, 4, 4],
            'b': ['x', None, 'y', 'z', 'z'],
            'c': [10, 20, 30, 40, 40]
        })
        
        cleaned = self.instance._clean_data(dirty_data)
        
        # Check no missing values
        self.assertFalse(cleaned.isnull().any().any())
        
        # Check duplicates removed
        self.assertEqual(len(cleaned), 4)  # One duplicate removed
    {% endif %}
    
    {% if 'transform' in issue_body.lower() %}
    def test_transform_data(self):
        """Test data transformation"""
        data = pd.DataFrame({
            'value1': [1, 2, 3, 4, 5],
            'value2': [10, 20, 30, 40, 50]
        })
        
        transformed = self.instance._transform_data(data)
        
        # Check normalized columns were added
        self.assertIn('value1_normalized', transformed.columns)
        self.assertIn('value2_normalized', transformed.columns)
        
        # Check normalization (mean should be ~0, std should be ~1)
        self.assertAlmostEqual(transformed['value1_normalized'].mean(), 0, places=5)
        self.assertAlmostEqual(transformed['value1_normalized'].std(), 1, places=5)
    {% endif %}
    
    {% if 'aggregate' in issue_body.lower() or 'group' in issue_body.lower() %}
    def test_aggregate_data(self):
        """Test data aggregation"""
        aggregated = self.instance._aggregate_data(self.test_data, ['category'])
        
        # Check aggregation results
        self.assertIn('category', aggregated.columns)
        self.assertIn('value_mean', aggregated.columns)
        self.assertIn('value_sum', aggregated.columns)
        self.assertIn('value_count', aggregated.columns)
        
        # Should have 3 rows (categories A, B, C)
        self.assertEqual(len(aggregated), 3)
    {% endif %}
    
    {% if 'filter' in issue_body.lower() %}
    def test_filter_data_simple(self):
        """Test simple data filtering"""
        filtered = self.instance._filter_data(
            self.test_data,
            {'category': 'A'}
        )
        
        # Check all rows have category A
        self.assertTrue((filtered['category'] == 'A').all())
    
    def test_filter_data_complex(self):
        """Test complex data filtering"""
        filtered = self.instance._filter_data(
            self.test_data,
            {'value': {'gt': 50, 'lt': 80}}
        )
        
        # Check all values are in range
        self.assertTrue((filtered['value'] > 50).all())
        self.assertTrue((filtered['value'] < 80).all())
    {% endif %}
    
    {% if 'sort' in issue_body.lower() or 'order' in issue_body.lower() %}
    def test_process_data_with_sorting(self):
        """Test data processing with sorting"""
        result = self.instance.execute(
            input_file='test_data.csv',
            output_file='sorted_data.csv',
            sort_by=['value']
        )
        
        self.assertTrue(result['success'])
        
        # Load output and check it's sorted
        output_path = Path(result['result']['output_file'])
        sorted_data = pd.read_csv(output_path)
        
        # Check values are in ascending order
        values = sorted_data['value'].tolist()
        self.assertEqual(values, sorted(values))
    {% endif %}
    
    def test_save_data_csv(self):
        """Test saving data to CSV"""
        result = self.instance._save_data(self.test_data, 'output.csv')
        
        self.assertTrue(result['success'])
        self.assertTrue(Path(result['file_path']).exists())
        
        # Verify data integrity
        loaded = pd.read_csv(result['file_path'])
        self.assertEqual(len(loaded), len(self.test_data))
    
    {% if 'json' in issue_body.lower() %}
    def test_save_data_json(self):
        """Test saving data to JSON"""
        result = self.instance._save_data(self.test_data.head(10), 'output.json')
        
        self.assertTrue(result['success'])
        self.assertTrue(Path(result['file_path']).exists())
        
        # Verify data integrity
        loaded = pd.read_json(result['file_path'])
        self.assertEqual(len(loaded), 10)
    {% endif %}
    
    def test_generate_summary(self):
        """Test summary generation"""
        summary = self.instance._generate_summary(self.test_data)
        
        self.assertIn('total_rows', summary)
        self.assertIn('total_columns', summary)
        self.assertIn('column_types', summary)
        self.assertIn('numeric_summary', summary)
        self.assertIn('categorical_summary', summary)
        
        # Check numeric summary
        self.assertIn('value', summary['numeric_summary'])
        self.assertIn('mean', summary['numeric_summary']['value'])
        self.assertIn('std', summary['numeric_summary']['value'])
        
        # Check categorical summary
        self.assertIn('category', summary['categorical_summary'])
        self.assertIn('unique_values', summary['categorical_summary']['category'])
    
    def test_add_pipeline_step(self):
        """Test adding custom pipeline steps"""
        def custom_step(data):
            data['custom_column'] = 'processed'
            return data
        
        self.instance.add_pipeline_step(custom_step)
        
        result = self.instance.execute(
            input_file='test_data.csv',
            output_file='pipeline_output.csv'
        )
        
        self.assertTrue(result['success'])
        
        # Check custom column was added
        output_path = Path(result['result']['output_file'])
        processed_data = pd.read_csv(output_path)
        self.assertIn('custom_column', processed_data.columns)
        self.assertTrue((processed_data['custom_column'] == 'processed').all())
    
    def test_get_status(self):
        """Test status retrieval"""
        status = self.instance.get_status()
        
        self.assertTrue(status['initialized'])
        self.assertEqual(status['input_path'], str(self.input_dir))
        self.assertEqual(status['output_path'], str(self.output_dir))
        self.assertEqual(status['issue_number'], {{ issue_number }})
        self.assertIn('pipeline_steps', status)
        self.assertIn('configuration', status)


if __name__ == '__main__':
    unittest.main()