"""
ğŸ§ª ã‚¨ãƒ«ãƒ€ãƒ¼ã‚µãƒ¼ãƒãƒ³ãƒˆ EldersLegacyçµ±åˆãƒ†ã‚¹ãƒˆ

Issue #69: åŸºç›¤ä¿®æ­£ - EldersLegacyå¯¾å¿œã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
TDDåŸå‰‡ã«å¾“ã„ã€EldersServiceLegacyç¶™æ‰¿ã¨Iron Willå“è³ªåŸºæº–ã®æ¤œè¨¼ã‚’è¡Œã„ã¾ã™ã€‚
"""

import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime
from typing import Dict, Any, List

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from elders_guild.elder_tree.elder_servants.base.elder_servant import (
    ElderServant,
    ServantCategory,
    ServantCapability,
    ServantRequest,
    ServantResponse,
    TaskStatus,
    TaskPriority,
    TaskResult
)
from elders_guild.elder_tree.core.elders_legacy import (
    EldersServiceLegacy,
    IronWillCriteria,
    EldersLegacyDomain
)


class TestElderServantImplementation(ElderServant):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¨ãƒ«ãƒ€ãƒ¼ã‚µãƒ¼ãƒãƒ³ãƒˆå®Ÿè£…"""
    
    def __init__(self):
        capabilities = [
            ServantCapability(
                "test_capability",
                "ãƒ†ã‚¹ãƒˆèƒ½åŠ›",
                ["test_input"],
                ["test_output"],
                1
            )
        ]
        super().__init__(
            servant_id="test_servant_001",
            servant_name="TestServant",
            category=ServantCategory.DWARF,
            specialization="testing",
            capabilities=capabilities
        )
        self.should_fail = False
        self.execution_delay = 0.0
    
    async def execute_task(self, task: Dict[str, Any]) -> TaskResult:
        """ãƒ†ã‚¹ãƒˆç”¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        if self.execution_delay > 0:
            await asyncio.sleep(self.execution_delay)
        
        if self.should_fail:
            return TaskResult(
                task_id=task.get("task_id", "unknown"),
                servant_id=self.servant_id,
                status=TaskStatus.FAILED,
                error_message="Test failure",
                execution_time_ms=100.0,
                quality_score=0.0
            )
        
        # æˆåŠŸã‚±ãƒ¼ã‚¹
        result_data = {
            "success": True,
            "status": "completed",
            "data": {"test": "result"},
            "execution_time_ms": 100.0
        }
        
        quality_score = await self.validate_iron_will_quality(result_data)
        
        return TaskResult(
            task_id=task.get("task_id", "test_001"),
            servant_id=self.servant_id,
            status=TaskStatus.COMPLETED,
            result_data=result_data,
            execution_time_ms=100.0,
            quality_score=quality_score
        )
    
    def get_specialized_capabilities(self) -> List[ServantCapability]:
        """å°‚é–€èƒ½åŠ›å–å¾—"""
        return [
            ServantCapability(
                "test_specialized",
                "ãƒ†ã‚¹ãƒˆå°‚é–€èƒ½åŠ›",
                ["test_spec_input"],
                ["test_spec_output"],
                2
            )
        ]


class TestElderServantLegacyIntegration:
    """ã‚¨ãƒ«ãƒ€ãƒ¼ã‚µãƒ¼ãƒãƒ³ãƒˆ EldersLegacyçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    @pytest.fixture
    def servant(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ¼ãƒãƒ³ãƒˆã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        return TestElderServantImplementation()
    
    @pytest.fixture
    def sample_request(self):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        return ServantRequest(
            task_id="test_001",
            task_type="test_task",
            priority=TaskPriority.HIGH,
            payload={"test_data": "sample"},
            context={"user": "test_user"}
        )
    
    # ========== EldersLegacyç¶™æ‰¿ã®æ¤œè¨¼ ==========
    
    def test_elders_legacy_inheritance(self, servant):
        """EldersServiceLegacyã‹ã‚‰ã®ç¶™æ‰¿ã‚’æ¤œè¨¼"""
        assert isinstance(servant, EldersServiceLegacy)
        assert hasattr(servant, 'process_request')
        assert hasattr(servant, 'validate_request')
        assert hasattr(servant, 'get_capabilities')
        assert hasattr(servant, 'execute_with_quality_gate')
    
    def test_enforce_boundary_decorator(self, servant):
        """@enforce_boundary ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãŒé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ¤œè¨¼"""
        execute_task_method = getattr(servant, 'execute_task')
        assert hasattr(execute_task_method, '_boundary_enforced')
        assert execute_task_method._boundary_enforced == "servant"
    
    def test_elders_legacy_domain(self, servant):
        """EldersLegacyãƒ‰ãƒ¡ã‚¤ãƒ³ãŒEXECUTIONã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ¤œè¨¼"""
        assert servant.domain == EldersLegacyDomain.EXECUTION
        assert servant.component_id == "test_servant_001"
    
    # ========== Iron Willå“è³ªåŸºæº–ã®ãƒ†ã‚¹ãƒˆ ==========
    
    @pytest.mark.asyncio
    async def test_iron_will_quality_validation_perfect_score(self, servant):
        """Iron Willå“è³ªåŸºæº–ã®æ¤œè¨¼ï¼ˆå®Œç’§ãªã‚¹ã‚³ã‚¢ï¼‰"""
        result_data = {
            "success": True,         # 30ç‚¹
            "status": "completed",   # 25ç‚¹
            "data": {"result": "ok"}, # 25ç‚¹  
            "execution_time_ms": 100  # 25ç‚¹
        }
        
        score = await servant.validate_iron_will_quality(result_data)
        assert score == 100.0  # æº€ç‚¹
        
        # Iron WillåŸºæº–ï¼ˆ95%ä»¥ä¸Šï¼‰ã‚’ã‚¯ãƒªã‚¢
        assert score >= 95.0
    
    @pytest.mark.asyncio
    async def test_iron_will_quality_validation_failing_score(self, servant):
        """Iron Willå“è³ªåŸºæº–ã®æ¤œè¨¼ï¼ˆå¤±æ•—ã‚±ãƒ¼ã‚¹ï¼‰"""
        result_data = {
            "success": False,        # 0ç‚¹
            "error": "Test error",   # 0ç‚¹
            "execution_time_ms": 6000  # 0ç‚¹ï¼ˆ5ç§’è¶…éï¼‰
        }
        
        score = await servant.validate_iron_will_quality(result_data)
        assert score < 95.0  # Iron WillåŸºæº–æœªé”
        assert score == 0.0  # æœ€ä½ã‚¹ã‚³ã‚¢
    
    @pytest.mark.asyncio
    async def test_iron_will_95_percent_threshold(self, servant):
        """Iron Will 95%é–¾å€¤ã®æ­£ç¢ºãªæ¤œè¨¼"""
        # 95%ã¡ã‚‡ã†ã©ã®ã‚±ãƒ¼ã‚¹
        result_data = {
            "success": True,         # 30ç‚¹
            "status": "completed",   # 25ç‚¹
            "data": {"result": "ok"}, # 25ç‚¹  
            "execution_time_ms": 4000  # 15ç‚¹ï¼ˆ5ç§’æœªæº€ã ãŒé…ã„ï¼‰
        }
        
        score = await servant.validate_iron_will_quality(result_data)
        assert score == 95.0  # ã¡ã‚‡ã†ã©95%
    
    # ========== EldersServiceLegacyçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ==========
    
    @pytest.mark.asyncio
    async def test_process_request_success(self, servant, sample_request):
        """process_requestãƒ¡ã‚½ãƒƒãƒ‰ã®æ­£å¸¸å‹•ä½œã‚’æ¤œè¨¼"""
        response = await servant.process_request(sample_request)
        
        assert isinstance(response, ServantResponse)
        assert response.task_id == "test_001"
        assert response.servant_id == "test_servant_001"
        assert response.status == TaskStatus.COMPLETED
        assert response.result_data["success"] is True
        assert response.execution_time_ms > 0
        assert response.quality_score >= 95.0  # Iron WillåŸºæº–
    
    @pytest.mark.asyncio
    async def test_process_request_failure(self, servant, sample_request):
        """process_requestãƒ¡ã‚½ãƒƒãƒ‰ã®å¤±æ•—å‡¦ç†ã‚’æ¤œè¨¼"""
        servant.should_fail = True
        
        response = await servant.process_request(sample_request)
        
        assert isinstance(response, ServantResponse)
        assert response.status == TaskStatus.FAILED
        assert response.error_message == "Test failure"
        assert response.quality_score == 0.0
    
    def test_validate_request_valid(self, servant, sample_request):
        """æœ‰åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ¤œè¨¼"""
        assert servant.validate_request(sample_request) is True
    
    def test_validate_request_invalid_no_task_id(self, servant):
        """ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆtask_idä¸è¶³ï¼‰ã®æ¤œè¨¼"""
        invalid_request = ServantRequest(
            task_id="",  # ç©ºã®ã‚¿ã‚¹ã‚¯ID
            task_type="test_task",
            priority=TaskPriority.HIGH,
            payload={"test": "data"}
        )
        
        assert servant.validate_request(invalid_request) is False
    
    def test_validate_request_invalid_payload(self, servant):
        """ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆpayloadå½¢å¼ä¸æ­£ï¼‰ã®æ¤œè¨¼"""
        invalid_request = ServantRequest(
            task_id="test_001",
            task_type="test_task",
            priority=TaskPriority.HIGH,
            payload="invalid_payload"  # dictä»¥å¤–
        )
        
        assert servant.validate_request(invalid_request) is False
    
    def test_get_capabilities_format(self, servant):
        """get_capabilitiesãƒ¡ã‚½ãƒƒãƒ‰ã®å½¢å¼ã‚’æ¤œè¨¼"""
        capabilities = servant.get_capabilities()
        
        assert isinstance(capabilities, list)
        assert all(isinstance(cap, str) for cap in capabilities)
        assert "test_capability" in capabilities
        assert "test_specialized" in capabilities
    
    # ========== çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆexecute_with_quality_gateï¼‰ ==========
    
    @pytest.mark.asyncio
    async def test_execute_with_quality_gate_success(self, servant, sample_request):
        """å“è³ªã‚²ãƒ¼ãƒˆä»˜ãå®Ÿè¡Œã®æˆåŠŸã‚±ãƒ¼ã‚¹"""
        response = await servant.execute_with_quality_gate(sample_request)
        
        assert isinstance(response, ServantResponse)
        assert response.status == TaskStatus.COMPLETED
        assert response.quality_score >= 95.0
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ç¢ºèª
        metrics = servant.get_metrics()
        assert metrics["execution_stats"]["requests_processed"] == 1
        assert metrics["execution_stats"]["requests_succeeded"] == 1
        assert metrics["iron_will_compliant"] is True
    
    @pytest.mark.asyncio
    async def test_execute_with_quality_gate_failure(self, servant, sample_request):
        """å“è³ªã‚²ãƒ¼ãƒˆä»˜ãå®Ÿè¡Œã®å¤±æ•—ã‚±ãƒ¼ã‚¹"""
        servant.should_fail = True
        
        with pytest.raises(Exception):
            await servant.execute_with_quality_gate(sample_request)
        
        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆæ›´æ–°ç¢ºèª
        metrics = servant.get_metrics()
        assert metrics["execution_stats"]["requests_failed"] == 1
    
    @pytest.mark.asyncio
    async def test_execute_with_quality_gate_validation_error(self, servant):
        """å“è³ªã‚²ãƒ¼ãƒˆä»˜ãå®Ÿè¡Œã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"""
        invalid_request = ServantRequest(
            task_id="",  # ç„¡åŠ¹
            task_type="test_task",
            priority=TaskPriority.HIGH,
            payload={}
        )
        
        with pytest.raises(ValueError, match="Invalid request"):
            await servant.execute_with_quality_gate(invalid_request)
    
    # ========== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ==========
    
    @pytest.mark.asyncio
    async def test_performance_under_200ms(self, servant, sample_request):
        """200msæœªæº€ã§ã®å®Ÿè¡Œã‚’æ¤œè¨¼"""
        import time
        
        start_time = time.time()
        response = await servant.execute_with_quality_gate(sample_request)
        execution_time = (time.time() - start_time) * 1000
        
        assert execution_time < 200  # 200msæœªæº€
        assert response.execution_time_ms < 200
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ãŒæœ€é«˜å€¤ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        assert servant.quality_scores[IronWillCriteria.PERFORMANCE_SCORE] == 100.0
    
    @pytest.mark.asyncio
    async def test_performance_timeout_handling(self, servant, sample_request):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
        servant.execution_delay = 2.0  # 2ç§’é…å»¶
        
        response = await servant.execute_with_quality_gate(sample_request)
        
        # é…å»¶ãŒã‚ã£ã¦ã‚‚ã‚¿ã‚¹ã‚¯ã¯å®Œäº†ã™ã‚‹
        assert response.status == TaskStatus.COMPLETED
        assert response.execution_time_ms > 2000
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ãŒä¸‹ãŒã‚‹ã“ã¨ã‚’ç¢ºèª
        assert servant.quality_scores[IronWillCriteria.PERFORMANCE_SCORE] == 85.0  # 1ç§’ä»¥ä¸Š5ç§’æœªæº€
    
    # ========== ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ ==========
    
    @pytest.mark.asyncio
    async def test_metrics_tracking(self, servant, sample_request):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡ã®æ¤œè¨¼"""
        initial_metrics = servant.get_metrics()
        assert initial_metrics["execution_stats"]["requests_processed"] == 0
        
        # è¤‡æ•°å›å®Ÿè¡Œ
        for i in range(3):
            await servant.execute_with_quality_gate(sample_request)
        
        updated_metrics = servant.get_metrics()
        assert updated_metrics["execution_stats"]["requests_processed"] == 3
        assert updated_metrics["execution_stats"]["requests_succeeded"] == 3
        assert updated_metrics["execution_stats"]["average_quality_score"] >= 95.0
    
    @pytest.mark.asyncio
    async def test_health_check_healthy(self, servant, sample_request):
        """æ­£å¸¸ãªå¥åº·çŠ¶æ…‹ã®ãƒã‚§ãƒƒã‚¯"""
        # æˆåŠŸå®Ÿè¡Œã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‘ä¸Š
        await servant.execute_with_quality_gate(sample_request)
        
        health = await servant.health_check()
        
        assert health["status"] == "healthy"
        assert health["component_id"] == "test_servant_001"
        assert health["domain"] == "execution"
        assert health["iron_will_compliant"] is True
        assert health["quality_score"] >= 95.0
    
    @pytest.mark.asyncio
    async def test_health_check_degraded(self, servant):
        """åŠ£åŒ–çŠ¶æ…‹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        # å“è³ªã‚¹ã‚³ã‚¢ã‚’äººå·¥çš„ã«ä¸‹ã’ã‚‹
        for criteria in servant.quality_scores:
            servant.quality_scores[criteria] = 50.0  # åŸºæº–æœªæº€
        
        health = await servant.health_check()
        
        assert health["status"] == "degraded"
        assert health["iron_will_compliant"] is False
    
    # ========== å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ ==========
    
    @pytest.mark.asyncio
    async def test_backward_compatibility_dict_request(self, servant):
        """æ—§å½¢å¼ã®dictå‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã®å¾Œæ–¹äº’æ›æ€§"""
        # æ—§å½¢å¼ã®process_requestï¼ˆè¾æ›¸å‹ï¼‰ã‚‚å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        old_request = {
            "type": "execute_task",
            "task": {
                "task_id": "old_001",
                "task_type": "old_test",
                "priority": "high",
                "payload": {"old": "data"}
            }
        }
        
        # æ—§å½¢å¼process_requestãŒå­˜åœ¨ã—å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        # ï¼ˆå®Ÿè£…ã§ã¯æ–°å½¢å¼process_requestã«çµ±åˆã•ã‚Œã¦ã„ã‚‹ãŒã€
        # ã€€execute_taskã¯å¼•ãç¶šãå‹•ä½œã™ã‚‹ï¼‰
        task = old_request["task"]
        result = await servant.execute_task(task)
        
        assert result.task_id == "old_001"
        assert result.status == TaskStatus.COMPLETED


class TestServantRequestResponse:
    """ServantRequest/Response ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_servant_request_creation(self):
        """ServantRequestä½œæˆã®ãƒ†ã‚¹ãƒˆ"""
        request = ServantRequest(
            task_id="req_001",
            task_type="test_request",
            priority=TaskPriority.MEDIUM,
            payload={"key": "value"},
            context={"user": "tester"}
        )
        
        assert request.task_id == "req_001"
        assert request.task_type == "test_request"
        assert request.priority == TaskPriority.MEDIUM
        assert request.payload == {"key": "value"}
        assert request.context == {"user": "tester"}
        assert isinstance(request.created_at, datetime)
    
    def test_servant_response_creation(self):
        """ServantResponseä½œæˆã®ãƒ†ã‚¹ãƒˆ"""
        response = ServantResponse(
            task_id="resp_001",
            servant_id="test_servant",
            status=TaskStatus.COMPLETED,
            result_data={"result": "success"},
            execution_time_ms=150.0,
            quality_score=97.5
        )
        
        assert response.task_id == "resp_001"
        assert response.servant_id == "test_servant"
        assert response.status == TaskStatus.COMPLETED
        assert response.result_data == {"result": "success"}
        assert response.execution_time_ms == 150.0
        assert response.quality_score == 97.5
        assert isinstance(response.completed_at, datetime)


# ========== ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ ==========

@pytest.mark.benchmark
class TestElderServantPerformance:
    """ã‚¨ãƒ«ãƒ€ãƒ¼ã‚µãƒ¼ãƒãƒ³ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
        servant = TestElderServantImplementation()
        
        requests = [
            ServantRequest(
                task_id=f"concurrent_{i}",
                task_type="performance_test",
                priority=TaskPriority.HIGH,
                payload={"index": i}
            )
            for i in range(10)
        ]
        
        import time
        start_time = time.time()
        
        # ä¸¦è¡Œå®Ÿè¡Œ
        responses = await asyncio.gather(*[
            servant.execute_with_quality_gate(req) for req in requests
        ])
        
        total_time = time.time() - start_time
        
        # å…¨ã¦æˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(responses) == 10
        assert all(resp.status == TaskStatus.COMPLETED for resp in responses)
        assert all(resp.quality_score >= 95.0 for resp in responses)
        
        # ä¸¦è¡Œå®Ÿè¡Œã«ã‚ˆã‚ŠåŠ¹ç‡çš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆç›®å®‰ï¼‰
        assert total_time < 2.0  # 10å€‹ã®ã‚¿ã‚¹ã‚¯ãŒ2ç§’ä»¥å†…
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
        metrics = servant.get_metrics()
        assert metrics["execution_stats"]["requests_processed"] == 10
        assert metrics["execution_stats"]["requests_succeeded"] == 10