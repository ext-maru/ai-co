#!/usr/bin/env python3
"""
Search Quality Enhancer - æ¤œç´¢å“è³ªå‘ä¸Šã‚·ã‚¹ãƒ†ãƒ 
Created: 2025-07-19
Author: Claude Elder
"""

import asyncio
import json
import logging
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from core.elders_legacy import DomainBoundary, EldersServiceLegacy, enforce_boundary
from core.lightweight_logger import get_logger
from elders_guild.elder_tree.tracking.unified_tracking_db import UnifiedTrackingDB

logger = get_logger("search_quality_enhancer")


@dataclass
class QueryExpansion:
    """ã‚¯ã‚¨ãƒªæ‹¡å¼µãƒ‡ãƒ¼ã‚¿"""

    original_query: str
    expanded_terms: List[str] = field(default_factory=list)
    synonyms: List[str] = field(default_factory=list)
    related_concepts: List[str] = field(default_factory=list)
    expansion_score: float = 0.0


@dataclass
class RelevanceScore:
    """é–¢é€£æ€§ã‚¹ã‚³ã‚¢"""

    document_id: str
    original_score: float
    enhanced_score: float
    boost_factors: Dict[str, float] = field(default_factory=dict)
    feedback_weight: float = 0.0


@dataclass
class SearchQualityMetrics:
    """æ¤œç´¢å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    query_id: str
    relevance_improvement: float = 0.0
    user_satisfaction: float = 0.0
    click_through_rate: float = 0.0
    dwell_time: float = 0.0
    feedback_score: float = 0.0


class SearchQualityEnhancer(EldersServiceLegacy):
    """æ¤œç´¢å“è³ªå‘ä¸Šã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        super().__init__(name="SearchQualityEnhancer")
        self.tracking_db = UnifiedTrackingDB()
        self.query_history = {}
        self.feedback_cache = {}
        self.learning_model = None
        self._initialize_components()

    def _initialize_components(self):
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        self.synonym_dict = self._load_synonym_dictionary()
        self.concept_graph = self._load_concept_graph()
        self.feedback_weights = self._load_feedback_weights()
        logger.info("ğŸ” Search Quality EnhanceråˆæœŸåŒ–å®Œäº†")

    @enforce_boundary(DomainBoundary.EXECUTION, "enhance_search_quality")
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """æ¤œç´¢å“è³ªå‘ä¸Šå‡¦ç†"""
        try:
            action = request.get("action", "enhance")

            if action == "enhance":
                return await self._enhance_search_quality(request)
            elif action == "analyze":
                return await self._analyze_search_performance(request)
            elif action == "learn":
                return await self._learn_from_feedback(request)
            elif action == "rerank":
                return await self._rerank_results(request)
            else:
                return {"error": f"Unknown action: {action}"}

        except Exception as e:
            logger.error(f"æ¤œç´¢å“è³ªå‘ä¸Šã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _enhance_search_quality(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """æ¤œç´¢å“è³ªå‘ä¸Šå®Ÿè¡Œ"""
        query = request.get("query", "")
        search_results = request.get("search_results", [])
        context = request.get("context", {})

        if not query:
            return {"error": "ã‚¯ã‚¨ãƒªãŒå¿…è¦ã§ã™"}

        logger.info(f"ğŸ” æ¤œç´¢å“è³ªå‘ä¸Šé–‹å§‹: {query}")

        # 1.0 ã‚¯ã‚¨ãƒªæ‹¡å¼µ
        expanded_query = await self._expand_query(query, context)

        # 2.0 çµæœãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        reranked_results = await self._rerank_results(
            {
                "query": query,
                "expanded_query": expanded_query,
                "results": search_results,
                "context": context,
            }
        )

        # 3.0 å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        quality_metrics = await self._calculate_quality_metrics(
            query, expanded_query, reranked_results
        )

        # 4.0 ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨˜éŒ²
        await self._record_enhancement_metrics(
            query, expanded_query, reranked_results, quality_metrics
        )

        return {
            "original_query": query,
            "expanded_query": expanded_query,
            "enhanced_results": reranked_results,
            "quality_metrics": quality_metrics,
            "enhancement_score": quality_metrics.relevance_improvement,
        }

    async def _expand_query(
        self, query: str, context: Dict[str, Any]
    ) -> QueryExpansion:
        """ã‚¯ã‚¨ãƒªæ‹¡å¼µå®Ÿè¡Œ"""
        logger.info(f"ğŸ” ã‚¯ã‚¨ãƒªæ‹¡å¼µå®Ÿè¡Œ: {query}")

        # åŸºæœ¬çš„ãªå‰å‡¦ç†
        query_tokens = query.lower().split()

        # ã‚·ãƒãƒ‹ãƒ å±•é–‹
        synonyms = []
        for token in query_tokens:
            if token in self.synonym_dict:
                synonyms.extend(self.synonym_dict[token])

        # é–¢é€£æ¦‚å¿µæŠ½å‡º
        related_concepts = []
        for token in query_tokens:
            if token in self.concept_graph:
                related_concepts.extend(self.concept_graph[token])

        # æ‹¡å¼µé …ç›®é¸æŠ
        expanded_terms = []

        # éå»ã®æ¤œç´¢å±¥æ­´ã‹ã‚‰å­¦ç¿’
        if query in self.query_history:
            history = self.query_history[query]
            successful_terms = [
                term for term, success in history.items() if success > 0.7
            ]
            expanded_terms.extend(successful_terms)

        # æ‹¡å¼µã‚¹ã‚³ã‚¢è¨ˆç®—
        expansion_score = self._calculate_expansion_score(
            query, synonyms, related_concepts, expanded_terms
        )

        expansion = QueryExpansion(
            original_query=query,
            expanded_terms=expanded_terms,
            synonyms=synonyms[:5],  # ä¸Šä½5å€‹
            related_concepts=related_concepts[:5],  # ä¸Šä½5å€‹
            expansion_score=expansion_score,
        )

        logger.info(f"ğŸ” ã‚¯ã‚¨ãƒªæ‹¡å¼µå®Œäº†: ã‚¹ã‚³ã‚¢={expansion_score:0.2f}")
        return expansion

    async def _rerank_results(self, request: Dict[str, Any]) -> List[Dict[str, Any]]:
        """çµæœãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
        query = request.get("query", "")
        expanded_query = request.get("expanded_query")
        results = request.get("results", [])
        context = request.get("context", {})

        if not results:
            return []

        logger.info(f"ğŸ“Š çµæœãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°é–‹å§‹: {len(results)}ä»¶")

        # å„çµæœã®é–¢é€£æ€§ã‚¹ã‚³ã‚¢å†è¨ˆç®—
        relevance_scores = []

        for result in results:
            doc_id = result.get("id", "")
            original_score = result.get("score", 0.0)

            # æ‹¡å¼µã‚¯ã‚¨ãƒªã«åŸºã¥ãé–¢é€£æ€§ã‚¹ã‚³ã‚¢
            enhanced_score = await self._calculate_enhanced_relevance(
                query, expanded_query, result, context
            )

            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é‡ã¿é©ç”¨
            feedback_weight = self._get_feedback_weight(doc_id, query)

            # æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—
            final_score = self._combine_scores(
                original_score, enhanced_score, feedback_weight
            )

            relevance_scores.append(
                RelevanceScore(
                    document_id=doc_id,
                    original_score=original_score,
                    enhanced_score=enhanced_score,
                    boost_factors={
                        "query_expansion": enhanced_score - original_score,
                        "user_feedback": feedback_weight,
                    },
                    feedback_weight=feedback_weight,
                )
            )

            # çµæœã«æœ€çµ‚ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
            result["enhanced_score"] = final_score
            result["boost_factors"] = relevance_scores[-1].boost_factors

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        reranked_results = sorted(
            results, key=lambda x: x.get("enhanced_score", 0), reverse=True
        )

        logger.info(
            f"ğŸ“Š çµæœãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Œäº†: ä¸Šä½ã‚¹ã‚³ã‚¢={reranked_results[0].get('enhanced_score', 0):0.2f}"
        )
        return reranked_results

    async def _calculate_enhanced_relevance(
        self,
        query: str,
        expanded_query: QueryExpansion,
        result: Dict[str, Any],
        context: Dict[str, Any],
    ) -> float:
        """æ‹¡å¼µã•ã‚ŒãŸé–¢é€£æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        base_score = result.get("score", 0.0)
        content = result.get("content", "").lower()
        title = result.get("title", "").lower()

        enhancement_factors = []

        # æ‹¡å¼µèªå½™ãƒãƒƒãƒãƒ³ã‚°
        if expanded_query:
            for term in expanded_query.expanded_terms:
                if term.lower() in content:
                    enhancement_factors.append(0.1)
                if term.lower() in title:
                    enhancement_factors.append(0.2)

            # ã‚·ãƒãƒ‹ãƒ ãƒãƒƒãƒãƒ³ã‚°
            for synonym in expanded_query.synonyms:
                if synonym.lower() in content:
                    enhancement_factors.append(0.05)

            # é–¢é€£æ¦‚å¿µãƒãƒƒãƒãƒ³ã‚°
            for concept in expanded_query.related_concepts:
                if concept.lower() in content:
                    enhancement_factors.append(0.08)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°
        if context:
            domain = context.get("domain", "")
            if domain and domain.lower() in content:
                enhancement_factors.append(0.15)

        # æ‹¡å¼µã‚¹ã‚³ã‚¢è¨ˆç®—
        enhancement_boost = min(sum(enhancement_factors), 0.5)  # æœ€å¤§50%ãƒ–ãƒ¼ã‚¹ãƒˆ
        enhanced_score = base_score * (1 + enhancement_boost)

        return enhanced_score

    def _get_feedback_weight(self, doc_id: str, query: str) -> float:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é‡ã¿å–å¾—"""
        feedback_key = f"{query}:{doc_id}"

        if feedback_key in self.feedback_cache:
            feedback_data = self.feedback_cache[feedback_key]
            positive_feedback = feedback_data.get("positive", 0)
            negative_feedback = feedback_data.get("negative", 0)
            total_feedback = positive_feedback + negative_feedback

            if total_feedback > 0:
                feedback_ratio = positive_feedback / total_feedback
                return (feedback_ratio - 0.5) * 0.2  # -0.1 to +0.1 ã®é‡ã¿

        return 0.0

    def _combine_scores(
        self, original: float, enhanced: float, feedback: float
    ) -> float:
        """ã‚¹ã‚³ã‚¢çµ±åˆ"""
        # é‡ã¿ä»˜ãå¹³å‡
        base_weight = 0.4
        enhanced_weight = 0.5
        feedback_weight = 0.1

        combined = (
            original * base_weight
            + enhanced * enhanced_weight
            + feedback * feedback_weight
        )

        return max(0.0, min(1.0, combined))

    async def _calculate_quality_metrics(
        self, query: str, expanded_query: QueryExpansion, results: List[Dict[str, Any]]
    ) -> SearchQualityMetrics:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        query_id = f"{query}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # é–¢é€£æ€§æ”¹å–„åº¦è¨ˆç®—
        if results:
            original_scores = [r.get("score", 0) for r in results]
            enhanced_scores = [r.get("enhanced_score", 0) for r in results]

            original_avg = np.mean(original_scores) if original_scores else 0
            enhanced_avg = np.mean(enhanced_scores) if enhanced_scores else 0

            relevance_improvement = (
                (enhanced_avg - original_avg) / original_avg if original_avg > 0 else 0
            )
        else:
            relevance_improvement = 0.0

        # ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å®Ÿæ¸¬å€¤ã‹ã‚‰å–å¾—ï¼ˆç¾åœ¨ã¯æ¨å®šå€¤ï¼‰
        metrics = SearchQualityMetrics(
            query_id=query_id,
            relevance_improvement=relevance_improvement,
            user_satisfaction=0.8,  # æ¨å®šå€¤
            click_through_rate=0.3,  # æ¨å®šå€¤
            dwell_time=120.0,  # æ¨å®šå€¤ï¼ˆç§’ï¼‰
            feedback_score=0.7,  # æ¨å®šå€¤
        )

        return metrics

    async def _record_enhancement_metrics(
        self,
        query: str,
        expanded_query: QueryExpansion,
        results: List[Dict[str, Any]],
        metrics: SearchQualityMetrics,
    ):
        """å‘ä¸Šãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        record = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "expanded_query": expanded_query.__dict__,
            "results_count": len(results),
            "metrics": metrics.__dict__,
            "enhancement_type": "search_quality",
        }

        await self.tracking_db.save_search_record(record)

    def _load_synonym_dictionary(self) -> Dict[str, List[str]]:
        """ã‚·ãƒãƒ‹ãƒ è¾æ›¸èª­ã¿è¾¼ã¿"""
        # åŸºæœ¬çš„ãªã‚·ãƒãƒ‹ãƒ è¾æ›¸
        return {
            "implement": ["develop", "create", "build", "code"],
            "error": ["bug", "issue", "problem", "fault"],
            "optimize": ["improve", "enhance", "refine", "upgrade"],
            "analyze": ["examine", "study", "review", "investigate"],
            "design": ["architect", "plan", "structure", "blueprint"],
        }

    def _load_concept_graph(self) -> Dict[str, List[str]]:
        """æ¦‚å¿µã‚°ãƒ©ãƒ•èª­ã¿è¾¼ã¿"""
        return {
            "database": ["sql", "nosql", "storage", "query", "index"],
            "security": ["authentication", "authorization", "encryption", "ssl"],
            "api": ["rest", "graphql", "endpoint", "request", "response"],
            "performance": ["latency", "throughput", "scalability", "optimization"],
            "testing": ["unit", "integration", "e2e", "mock", "coverage"],
        }

    def _load_feedback_weights(self) -> Dict[str, float]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é‡ã¿èª­ã¿è¾¼ã¿"""
        return {}

    def _calculate_expansion_score(
        self,
        query: str,
        synonyms: List[str],
        concepts: List[str],
        expanded_terms: List[str],
    ) -> float:
        """æ‹¡å¼µã‚¹ã‚³ã‚¢è¨ˆç®—"""
        base_score = 0.5

        # æ‹¡å¼µèªå½™ã®è³ªã¨é‡ã«åŸºã¥ãã‚¹ã‚³ã‚¢
        synonym_score = min(len(synonyms) * 0.05, 0.2)
        concept_score = min(len(concepts) * 0.08, 0.3)
        history_score = min(len(expanded_terms) * 0.1, 0.3)

        total_score = base_score + synonym_score + concept_score + history_score
        return min(1.0, total_score)

    async def _analyze_search_performance(
        self, request: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        # åˆ†æå®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        return {
            "analysis": "search_performance_analysis",
            "metrics": {
                "average_improvement": 0.25,
                "success_rate": 0.85,
                "user_satisfaction": 0.8,
            },
        }

    async def _learn_from_feedback(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å­¦ç¿’"""
        query = request.get("query", "")
        doc_id = request.get("doc_id", "")
        feedback_type = request.get("feedback_type", "positive")

        feedback_key = f"{query}:{doc_id}"

        if feedback_key not in self.feedback_cache:
            self.feedback_cache[feedback_key] = {"positive": 0, "negative": 0}

        self.feedback_cache[feedback_key][feedback_type] += 1

        return {
            "learned": True,
            "feedback_key": feedback_key,
            "total_feedback": sum(self.feedback_cache[feedback_key].values()),
        }

    def validate_request(self, request: Dict[str, Any]) -> bool:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ¤œè¨¼"""
        return isinstance(request, dict) and "action" in request

    def get_capabilities(self) -> List[str]:
        """æ©Ÿèƒ½ä¸€è¦§"""
        return [
            "query_expansion",
            "result_reranking",
            "relevance_enhancement",
            "feedback_learning",
            "quality_metrics",
            "performance_analysis",
        ]


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
def create_search_quality_enhancer() -> SearchQualityEnhancer:
    """Search Quality Enhancerä½œæˆ"""
    return SearchQualityEnhancer()


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    async def test_enhancer():
        """test_enhancerãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰"""
        enhancer = create_search_quality_enhancer()

        # ãƒ†ã‚¹ãƒˆæ¤œç´¢å“è³ªå‘ä¸Š
        result = await enhancer.process_request(
            {
                "action": "enhance",
                "query": "implement database optimization",
                "search_results": [
                    {
                        "id": "doc1",
                        "title": "Database Performance Tuning",
                        "content": "Guide to optimize database queries and indexes",
                        "score": 0.7,
                    },
                    {
                        "id": "doc2",
                        "title": "SQL Query Optimization",
                        "content": "Advanced techniques for SQL performance improvement",
                        "score": 0.6,
                    },
                ],
            }
        )

        print(f"æ¤œç´¢å“è³ªå‘ä¸Šçµæœ: {result}")

    asyncio.run(test_enhancer())
