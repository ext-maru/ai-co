#!/usr/bin/env python3
"""
ğŸ›¡ï¸ Deployment Safeguard System
ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚»ãƒ¼ãƒ•ã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ  - é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¶ˆå¤±é˜²æ­¢

ãƒ‡ãƒ—ãƒ­ã‚¤ã‚„ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œæ™‚ã«é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿è­·:
1.0 Pre-deployment validation
2.0 Critical file locking
3.0 Rollback preparation
4.0 Post-deployment verification
"""

import contextlib
import json
import logging
import shutil
import subprocess
import sys

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set

logger = logging.getLogger(__name__)

class DeploymentSafeguard:
    """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚»ãƒ¼ãƒ•ã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_root: Path = None):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.project_root = project_root or Path.cwd()
        self.safeguard_dir = self.project_root / ".deployment_safeguard"
        self.safeguard_dir.mkdir(exist_ok=True)

        # çµ¶å¯¾ã«æ¶ˆã—ã¦ã¯ã„ã‘ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        self.critical_files = {
            ".env",
            "CLAUDE.md",
            "config/slack_config.json",
            "config/slack_pm_config.json",
            "config/database.conf",
            "config/worker_config.json",
            "config/async_workers_config.yaml",
            "config/config.json",
            "config/system.json",
            "knowledge_base/README.md",
        }

        # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³
        self.dangerous_patterns = [
            r"rm\s+-rf?\s+config/",
            r"rm\s+-rf?\s+\.env",
            r"rm\s+-rf?\s+\*\.json",
            r"rm\s+-rf?\s+knowledge_base/",
            r"find.*-delete",
            r"git\s+clean\s+-fd",
            r"docker\s+system\s+prune\s+-af",
            r">\s*config/.*\.json",
            r"mv\s+config/.*\s+/tmp",
            r"cp\s+/dev/null",
        ]

        self.deployment_log = []

    @contextlib.contextmanager
    def deployment_protection(self, operation_name: str = "deployment"):
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä¿è­·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        logger.info(f"ğŸ›¡ï¸ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä¿è­·é–‹å§‹: {operation_name}")

        # 1.0 Pre-deployment checks
        self._pre_deployment_checks()

        # 2.0 Create safety snapshot
        snapshot_id = self._create_safety_snapshot(operation_name)

        # 3.0 Lock critical files
        self._lock_critical_files()

        try:
            yield self

            # 4.0 Post-deployment verification
            self._post_deployment_verification()

            logger.info(f"âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä¿è­·å®Œäº†: {operation_name}")

        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            # 5.0 Emergency rollback
            self._emergency_rollback(snapshot_id)
            raise

        finally:
            # 6.0 Unlock files
            self._unlock_critical_files()

    def _pre_deployment_checks(self):
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå‰ãƒã‚§ãƒƒã‚¯"""
        checks = []

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            if not file_path.exists():
                checks.append(f"âŒ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨: {rel_path}")
            else:
                checks.append(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {rel_path}")

        # Gitä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çŠ¶æ…‹ç¢ºèª
        try:
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )

            if result.stdout.strip():
                checks.append("âš ï¸ æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ã‚ã‚Š")
                # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›´ãŒã‚ã‚‹å ´åˆã¯è­¦å‘Š
                for line in result.stdout.strip().split("\n"):
                    if len(line) > 3:
                        file_path = line[3:]
                        if file_path in self.critical_files:
                            checks.append(
                                f"ğŸš¨ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã«æœªã‚³ãƒŸãƒƒãƒˆå¤‰æ›´: {file_path}"
                            )
            else:
                checks.append("âœ… Gitä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³")

        except Exception as e:
            checks.append(f"âš ï¸ GitçŠ¶æ…‹ç¢ºèªå¤±æ•—: {e}")

        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèª
        try:
            disk_usage = shutil.disk_usage(self.project_root)
            free_gb = disk_usage.free / (1024**3)
            if free_gb < 1.0:
                checks.append(f"ğŸš¨ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³: {free_gb:0.1f}GB")
            else:
                checks.append(f"âœ… ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡: {free_gb:0.1f}GBåˆ©ç”¨å¯èƒ½")

        except Exception as e:
            checks.append(f"âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèªå¤±æ•—: {e}")

        # ãƒã‚§ãƒƒã‚¯çµæœã‚’ãƒ­ã‚°
        for check in checks:
            logger.info(check)

        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ä¾‹å¤–ç™ºç”Ÿ
        error_checks = [c for c in checks if c.startswith("âŒ") or c.startswith("ğŸš¨")]
        if error_checks:
            raise RuntimeError(
                f"Pre-deployment checks failed: {'; '.join(error_checks)}"
            )

    def _create_safety_snapshot(self, operation_name: str) -> str:
        """å®‰å…¨æ€§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        snapshot_id = f"{operation_name}_{timestamp}"
        snapshot_dir = self.safeguard_dir / "snapshots" / snapshot_id
        snapshot_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ“¸ å®‰å…¨æ€§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ: {snapshot_id}")

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            if file_path.exists():
                backup_path = snapshot_dir / rel_path
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, backup_path)

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±ã‚’è¨˜éŒ²
        snapshot_info = {
            "snapshot_id": snapshot_id,
            "operation_name": operation_name,
            "timestamp": timestamp,
            "files_backed_up": list(self.critical_files),
            "git_commit": self._get_current_git_commit(),
        }

        with open(snapshot_dir / "snapshot_info.json", "w") as f:
            json.dump(snapshot_info, f, indent=2)

        return snapshot_id

    def _lock_critical_files(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒƒã‚¯"""
        logger.info("ğŸ”’ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ä¸­...")

        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            if file_path.exists():
                try:
                    # Linux: chattr +i ã§ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«åŒ–
                    subprocess.run(
                        ["chattr", "+i", str(file_path)],
                        capture_output=True,
                        check=False,
                    )

                except FileNotFoundError:
                    # chattrã‚³ãƒãƒ³ãƒ‰ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                    # ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚’èª­ã¿å–ã‚Šå°‚ç”¨ã«å¤‰æ›´
                    file_path.chmod(0o444)

    def _unlock_critical_files(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒƒã‚¯è§£é™¤"""
        logger.info("ğŸ”“ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯è§£é™¤ä¸­...")

        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            if file_path.exists():
                try:
                    # Linux: chattr -i ã§ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«è§£é™¤
                    subprocess.run(
                        ["chattr", "-i", str(file_path)],
                        capture_output=True,
                        check=False,
                    )

                except FileNotFoundError:
                    # æ¨©é™ã‚’å…ƒã«æˆ»ã™
                    file_path.chmod(0o644)

    def _post_deployment_verification(self):
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œæ¤œè¨¼"""
        logger.info("ğŸ” ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œæ¤œè¨¼ä¸­...")

        verification_results = []

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            if file_path.exists():
                verification_results.append(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {rel_path}")
            else:
                verification_results.append(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ¶ˆå¤±: {rel_path}")

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹æ¤œè¨¼
        try:
            from .unified_config_manager import health_check

            health_results = health_check()

            for namespace, result in health_results.items():
                if result["status"] == "healthy":
                    verification_results.append(f"âœ… è¨­å®šæ­£å¸¸: {namespace}")
                else:
                    verification_results.append(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {namespace}")

        except Exception as e:
            verification_results.append(f"âš ï¸ è¨­å®šæ¤œè¨¼å¤±æ•—: {e}")

        # æ¤œè¨¼çµæœã‚’ãƒ­ã‚°
        for result in verification_results:
            logger.info(result)

        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ä¾‹å¤–ç™ºç”Ÿ
        error_results = [r for r in verification_results if r.startswith("âŒ")]
        if error_results:
            raise RuntimeError(
                f"Post-deployment verification failed: {'; '.join(error_results)}"
            )

    def _emergency_rollback(self, snapshot_id: str):
        """ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        logger.critical(f"ğŸš¨ ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ: {snapshot_id}")

        snapshot_dir = self.safeguard_dir / "snapshots" / snapshot_id
        if not snapshot_dir.exists():
            logger.error(f"âŒ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¸åœ¨: {snapshot_id}")
            return False

        rollback_success = True

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒ
        for rel_path in self.critical_files:
            backup_path = snapshot_dir / rel_path
            if backup_path.exists():
                file_path = self.project_root / rel_path
                try:
                    # ãƒ­ãƒƒã‚¯è§£é™¤
                    self._unlock_single_file(file_path)

                    # å¾©å…ƒ
                    shutil.copy2(backup_path, file_path)
                    logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ: {rel_path}")

                except Exception as e:
                    logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒå¤±æ•—: {rel_path} - {e}")
                    rollback_success = False

        if rollback_success:
            logger.info("âœ… ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
        else:
            logger.error("âŒ ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯éƒ¨åˆ†å¤±æ•—")

        return rollback_success

    def _unlock_single_file(self, file_path: Path):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒƒã‚¯è§£é™¤"""
        try:
            subprocess.run(
                ["chattr", "-i", str(file_path)], capture_output=True, check=False
            )
        except FileNotFoundError:
            try:
                file_path.chmod(0o644)
            except Exception:
                pass

    def _get_current_git_commit(self) -> str:
        """ç¾åœ¨ã®Gitã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )
            return result.stdout.strip()
        except Exception:
            return "unknown"

    def validate_command(self, command: str) -> bool:
        """ã‚³ãƒãƒ³ãƒ‰ã®å®‰å…¨æ€§æ¤œè¨¼"""
        import re

        # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern in self.dangerous_patterns:
            if re.search(pattern, command, re.IGNORECASE):
                logger.warning(f"ğŸš¨ å±é™ºãªã‚³ãƒãƒ³ãƒ‰æ¤œå‡º: {command}")
                logger.warning(f"   ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}")
                return False

        return True

    def safe_execute(
        self, command: str, operation_name: str = "command_execution"
    ) -> subprocess.CompletedProcess:
        """å®‰å…¨ãªã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
        # ã‚³ãƒãƒ³ãƒ‰æ¤œè¨¼
        if not self.validate_command(command):
            raise ValueError(f"Dangerous command blocked: {command}")

        # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä¿è­·ä¸‹ã§å®Ÿè¡Œ
        with self.deployment_protection(operation_name):
            logger.info(f"ğŸ›¡ï¸ ä¿è­·ä¸‹ã§ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ: {command}")

            result = subprocess.run(
                command,
                shell=True,
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )

            if result.returncode != 0:
                logger.warning(
                    f"âš ï¸ ã‚³ãƒãƒ³ãƒ‰ã‚¨ãƒ©ãƒ¼ (code {result.returncode}): {result.stderr}"
                )
            else:
                logger.info(f"âœ… ã‚³ãƒãƒ³ãƒ‰æˆåŠŸ: {command}")

            return result

    def get_safeguard_status(self) -> Dict:
        """ã‚»ãƒ¼ãƒ•ã‚¬ãƒ¼ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
        status = {
            "timestamp": datetime.now().isoformat(),
            "critical_files_count": len(self.critical_files),
            "snapshots_count": 0,
            "recent_operations": [],
        }

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°ã‚’è¨ˆç®—
        snapshots_dir = self.safeguard_dir / "snapshots"
        if snapshots_dir.exists():
            status["snapshots_count"] = len(list(snapshots_dir.iterdir()))

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ…‹
        status["critical_files_status"] = {}
        for rel_path in self.critical_files:
            file_path = self.project_root / rel_path
            status["critical_files_status"][rel_path] = {
                "exists": file_path.exists(),
                "size": file_path.stat().st_size if file_path.exists() else 0,
                "writable": (
                    file_path.is_file() and os.access(file_path, os.W_OK)
                    if file_path.exists()
                    else False
                ),
            }

        return status

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
deployment_safeguard = DeploymentSafeguard()

def safe_deployment(operation_name: str = "deployment"):
    """å®‰å…¨ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    return deployment_safeguard.deployment_protection(operation_name)

def safe_execute_command(command: str, operation_name: str = "command_execution"):
    """å®‰å…¨ãªã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
    return deployment_safeguard.safe_execute(command, operation_name)

def validate_command_safety(command: str) -> bool:
    """ã‚³ãƒãƒ³ãƒ‰ã®å®‰å…¨æ€§æ¤œè¨¼"""
    return deployment_safeguard.validate_command(command)

if __name__ == "__main__":
    import os

    logging.basicConfig(level=logging.INFO)

    # ãƒ†ã‚¹ãƒˆ
    print("ğŸ›¡ï¸ Deployment Safeguard Test")

    # å±é™ºãªã‚³ãƒãƒ³ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
    dangerous_commands = [
        "rm -rf config/",
        "rm .env",
        "mv config/slack_config.json /tmp/",
        "echo '' > config/config.json",
    ]

    for cmd in dangerous_commands:
        is_safe = validate_command_safety(cmd)
        status = "âœ… SAFE" if is_safe else "ğŸš¨ BLOCKED"
        print(f"{status}: {cmd}")

    # å®‰å…¨ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
    with safe_deployment("test_deployment"):
        print("âœ… Safe deployment context test completed")
