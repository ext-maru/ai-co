#!/usr/bin/env python3
"""
Worker Load Balancer - Dynamic Process Optimization
51å€‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’åŠ¹ç‡çš„ã«ç®¡ç†ãƒ»è² è·åˆ†æ•£
"""

import json
import logging
import queue
import threading
import time
from collections import defaultdict, deque
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import psutil

logger = logging.getLogger(__name__)

@dataclass(frozen=True)
class WorkerProcess:
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±"""

    pid: int
    name: str
    cpu_percent: float
    memory_mb: float
    status: str
    start_time: datetime
    task_count: int = 0
    last_activity: Optional[datetime] = None

@dataclass
class LoadMetrics:
    """è² è·ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    total_workers: int
    active_workers: int
    idle_workers: int
    avg_cpu: float
    avg_memory: float
    total_tasks: int
    system_load: float

class WorkerLoadBalancer:
    """ãƒ¯ãƒ¼ã‚«ãƒ¼è² è·åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, max_workers: int = 20, target_cpu: float = 70.0):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.max_workers = max_workers
        self.target_cpu = target_cpu
        self.workers: Dict[int, WorkerProcess] = {}
        self.task_queue = queue.Queue()
        self.metrics_history = deque(maxlen=100)
        self.running = False
        self.monitor_thread = None

    def scan_workers(self) -> List[WorkerProcess]:
        """ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        workers = []

        for proc in psutil.process_iter(
            ["pid", "name", "cpu_percent", "memory_info", "status", "create_time"]
        ):
            try:
                info = proc.info

                # AIé–¢é€£ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç‰¹å®š
                cmdline = " ".join(proc.cmdline()) if proc.cmdline() else ""
                if any(
                    keyword in info["name"].lower() for keyword in ["python", "python3"]
                ):
                    if any(
                        pattern in cmdline
                        for pattern in ["worker", "claude", "ai_co", "dashboard"]
                    ):
                        worker = WorkerProcess(
                            pid=info["pid"],
                            name=info["name"],
                            cpu_percent=info["cpu_percent"] or 0.0,
                            memory_mb=(
                                info["memory_info"].rss / 1024 / 1024
                                if info["memory_info"]
                                else 0.0
                            ),
                            status=info["status"],
                            start_time=datetime.fromtimestamp(info["create_time"]),
                        )
                        workers.append(worker)

            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue

        return workers

    def analyze_load_distribution(self, workers: List[WorkerProcess]) -> LoadMetrics:
        """è² è·åˆ†æ•£çŠ¶æ³ã‚’åˆ†æ"""
        if not workers:
            return LoadMetrics(0, 0, 0, 0.0, 0.0, 0, 0.0)

        active_workers = [w for w in workers if w.cpu_percent > 1.0]
        idle_workers = [w for w in workers if w.cpu_percent <= 1.0]

        avg_cpu = sum(w.cpu_percent for w in workers) / len(workers)
        avg_memory = sum(w.memory_mb for w in workers) / len(workers)
        total_tasks = sum(w.task_count for w in workers)

        # ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è² è·
        system_load = psutil.cpu_percent()

        return LoadMetrics(
            total_workers=len(workers),
            active_workers=len(active_workers),
            idle_workers=len(idle_workers),
            avg_cpu=avg_cpu,
            avg_memory=avg_memory,
            total_tasks=total_tasks,
            system_load=system_load,
        )

    def identify_optimization_targets(
        self, workers: List[WorkerProcess]
    ) -> Dict[str, List[WorkerProcess]]:
        """æœ€é©åŒ–å¯¾è±¡ã‚’ç‰¹å®š"""
        targets = {
            "high_cpu": [],
            "high_memory": [],
            "idle_long": [],
            "redundant": [],
            "candidates_for_termination": [],
        }

        now = datetime.now()

        for worker in workers:
            # é«˜CPUä½¿ç”¨ç‡
            if worker.cpu_percent > 80.0:
                targets["high_cpu"].append(worker)

            # é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            if worker.memory_mb > 500.0:
                targets["high_memory"].append(worker)

            # é•·æ™‚é–“ã‚¢ã‚¤ãƒ‰ãƒ«
            idle_time = (now - worker.start_time).total_seconds()
            if worker.cpu_percent < 0.5 and idle_time > 1800:  # 30åˆ†ä»¥ä¸Šã‚¢ã‚¤ãƒ‰ãƒ«
                targets["idle_long"].append(worker)

            # é‡è¤‡ãƒ—ãƒ­ã‚»ã‚¹
            similar_workers = [
                w for w in workers if w.name == worker.name and w.pid != worker.pid
            ]
            if len(similar_workers) > 2:  # åŒåãƒ—ãƒ­ã‚»ã‚¹ãŒ3å€‹ä»¥ä¸Š
                targets["redundant"].append(worker)

        # çµ‚äº†å€™è£œï¼ˆã‚¢ã‚¤ãƒ‰ãƒ« + é‡è¤‡ï¼‰
        targets["candidates_for_termination"] = list(
            set(targets["idle_long"] + targets["redundant"])
        )

        return targets

    def calculate_optimal_worker_count(self, metrics: LoadMetrics) -> int:
        """æœ€é©ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’è¨ˆç®—"""
        # ã‚·ã‚¹ãƒ†ãƒ è² è·ã«åŸºã¥ãå‹•çš„èª¿æ•´
        if metrics.system_load > 90:
            return max(1, metrics.total_workers - 5)  # å¤§å¹…å‰Šæ¸›
        elif metrics.system_load > 80:
            return max(5, metrics.total_workers - 3)  # ä¸­ç¨‹åº¦å‰Šæ¸›
        elif metrics.system_load < 30:
            return min(self.max_workers, metrics.total_workers + 2)  # å¢—åŠ 
        else:
            return min(self.max_workers, max(8, metrics.total_workers))  # ç¶­æŒ

    def terminate_worker(self, worker: WorkerProcess, force: bool = False) -> bool:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’å®‰å…¨ã«çµ‚äº†"""
        try:
            proc = psutil.Process(worker.pid)

            # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒã‚§ãƒƒã‚¯ (claudeã€dashboard_serverã¯ä¿è­·)
            cmdline = " ".join(proc.cmdline()) if proc.cmdline() else ""
            if not force and any(
                critical in cmdline for critical in ["claude", "dashboard_server"]
            ):
                logger.info(
                    f"Skipping critical process {worker.name} (PID: {worker.pid})"
                )
                return False

            # å…ˆã«SIGTERMã§ç©ã‚„ã‹ã«çµ‚äº†ã‚’è©¦è¡Œ
            proc.terminate()
            time.sleep(2)

            # ã¾ã ç”Ÿãã¦ã„ã‚Œã°SIGKILL
            if proc.is_running():
                proc.kill()
                time.sleep(1)

            logger.info(f"Terminated worker {worker.name} (PID: {worker.pid})")
            return True

        except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
            logger.warning(f"Could not terminate worker {worker.pid}: {e}")
            return False

    def optimize_worker_distribution(self) -> Dict[str, any]:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ†æ•£ã‚’æœ€é©åŒ–"""
        workers = self.scan_workers()
        metrics = self.analyze_load_distribution(workers)
        targets = self.identify_optimization_targets(workers)
        optimal_count = self.calculate_optimal_worker_count(metrics)

        optimization_result = {
            "timestamp": datetime.now().isoformat(),
            "before": {
                "worker_count": metrics.total_workers,
                "avg_cpu": metrics.avg_cpu,
                "avg_memory": metrics.avg_memory,
                "system_load": metrics.system_load,
            },
            "optimization_actions": [],
            "terminated_workers": [],
            "after": {},
        }

        # éå‰°ãªãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†
        if metrics.total_workers > optimal_count:
            workers_to_terminate = targets["candidates_for_termination"][
                : metrics.total_workers - optimal_count
            ]

            for worker in workers_to_terminate:
                if self.terminate_worker(worker):
                    optimization_result["terminated_workers"].append(
                        {
                            "pid": worker.pid,
                            "name": worker.name,
                            "reason": "idle_or_redundant",
                        }
                    )
                    optimization_result["optimization_actions"].append(
                        f"Terminated {worker.name} (PID: {worker.pid})"
                    )

        # æœ€é©åŒ–å¾Œã®çŠ¶æ…‹ã‚’æ¸¬å®š
        time.sleep(3)  # ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ã®åæ˜ ã‚’å¾…ã¤
        updated_workers = self.scan_workers()
        updated_metrics = self.analyze_load_distribution(updated_workers)

        optimization_result["after"] = {
            "worker_count": updated_metrics.total_workers,
            "avg_cpu": updated_metrics.avg_cpu,
            "avg_memory": updated_metrics.avg_memory,
            "system_load": updated_metrics.system_load,
            "reduction": metrics.total_workers - updated_metrics.total_workers,
        }

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã«è¿½åŠ 
        self.metrics_history.append(updated_metrics)

        return optimization_result

    def start_monitoring(self):
        """è² è·ç›£è¦–ã‚’é–‹å§‹"""
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("Worker load balancer monitoring started")

    def stop_monitoring(self):
        """è² è·ç›£è¦–ã‚’åœæ­¢"""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join()
        logger.info("Worker load balancer monitoring stopped")

    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                workers = self.scan_workers()
                metrics = self.analyze_load_distribution(workers)

                # è‡ªå‹•æœ€é©åŒ–ã®é–¾å€¤ãƒã‚§ãƒƒã‚¯
                if metrics.total_workers > self.max_workers or metrics.system_load > 85:
                    logger.info(
                        f"Auto-optimization triggered: {metrics.total_workers} workers, " \
                            "{metrics.system_load}% system load"
                    )
                    self.optimize_worker_distribution()

                self.metrics_history.append(metrics)
                time.sleep(30)  # 30ç§’é–“éš”ã§ç›£è¦–

            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

    def get_current_status(self) -> Dict[str, any]:
        """ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—"""
        workers = self.scan_workers()
        metrics = self.analyze_load_distribution(workers)
        targets = self.identify_optimization_targets(workers)

        return {
            "timestamp": datetime.now().isoformat(),
            "metrics": {
                "total_workers": metrics.total_workers,
                "active_workers": metrics.active_workers,
                "idle_workers": metrics.idle_workers,
                "avg_cpu": metrics.avg_cpu,
                "avg_memory": metrics.avg_memory,
                "system_load": metrics.system_load,
            },
            "optimization_targets": {
                "high_cpu_count": len(targets["high_cpu"]),
                "high_memory_count": len(targets["high_memory"]),
                "idle_long_count": len(targets["idle_long"]),
                "redundant_count": len(targets["redundant"]),
                "termination_candidates": len(targets["candidates_for_termination"]),
            },
            "recommendations": self._generate_recommendations(metrics, targets),
        }

    def _generate_recommendations(
        self, metrics: LoadMetrics, targets: Dict[str, List[WorkerProcess]]
    ) -> List[str]:
        """æœ€é©åŒ–æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []

        if metrics.total_workers > self.max_workers:
            recommendations.append(
                f"{metrics.total_workers - self.max_workers}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’å‰Šæ¸›æ¨å¥¨"
            )

        if metrics.system_load > 80:
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒé«˜ã„ãŸã‚ã€ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®å‰Šæ¸›ãŒå¿…è¦")

        if len(targets["idle_long"]) > 0:
            recommendations.append(
                f"{len(targets['idle_long'])}å€‹ã®é•·æ™‚é–“ã‚¢ã‚¤ãƒ‰ãƒ«ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµ‚äº†æ¨å¥¨"
            )

        if len(targets["redundant"]) > 0:
            recommendations.append(
                f"{len(targets['redundant'])}å€‹ã®é‡è¤‡ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµ±åˆæ¨å¥¨"
            )

        if metrics.avg_cpu < 20 and metrics.total_workers > 10:
            recommendations.append("ä½CPUä½¿ç”¨ç‡ã®ãŸã‚ã€ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®æœ€é©åŒ–æ¨å¥¨")

        return recommendations

    def export_metrics_report(self, output_path: str):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        report_data = {
            "export_timestamp": datetime.now().isoformat(),
            "current_status": self.get_current_status(),
            "metrics_history": [
                {
                    "total_workers": m.total_workers,
                    "active_workers": m.active_workers,
                    "avg_cpu": m.avg_cpu,
                    "avg_memory": m.avg_memory,
                    "system_load": m.system_load,
                }
                for m in list(self.metrics_history)
            ],
            "optimization_summary": {
                "max_workers_limit": self.max_workers,
                "target_cpu_threshold": self.target_cpu,
                "monitoring_active": self.running,
            },
        }

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        logger.info(f"Metrics report exported to {output_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”§ Worker Load Balancer - è² è·åˆ†æ•£æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)

    balancer = WorkerLoadBalancer(max_workers=20, target_cpu=70.0)

    # ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
    print("ğŸ“Š ç¾åœ¨ã®çŠ¶æ…‹åˆ†æä¸­...")
    status = balancer.get_current_status()

    print(f"\nğŸ“ˆ ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ³:")
    print(f"   ç·ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {status['metrics']['total_workers']}")
    print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {status['metrics']['active_workers']}")
    print(f"   ã‚¢ã‚¤ãƒ‰ãƒ«: {status['metrics']['idle_workers']}")
    print(f"   å¹³å‡CPU: {status['metrics']['avg_cpu']:0.1f}%")
    print(f"   å¹³å‡ãƒ¡ãƒ¢ãƒª: {status['metrics']['avg_memory']:0.1f}MB")
    print(f"   ã‚·ã‚¹ãƒ†ãƒ è² è·: {status['metrics']['system_load']:0.1f}%")

    print(f"\nğŸ¯ æœ€é©åŒ–å¯¾è±¡:")
    for key, count in status["optimization_targets"].items():
        if count > 0:
            print(f"   {key}: {count}å€‹")

    print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
    for rec in status["recommendations"]:
        print(f"   â€¢ {rec}")

    # æœ€é©åŒ–å®Ÿè¡Œ
    if status["optimization_targets"]["termination_candidates"] > 0:
        print(f"\nâš¡ æœ€é©åŒ–å®Ÿè¡Œä¸­...")
        result = balancer.optimize_worker_distribution()

        print(f"âœ… æœ€é©åŒ–å®Œäº†:")
        print(
            f"   ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {result['before']['worker_count']} â†’ {result['after']['worker_count']}"
        )
        print(
            f"   ã‚·ã‚¹ãƒ†ãƒ è² è·: {result['before']['system_load']:0.1f}% â†’ {result['after']['system_load']:0.1f}%"
        )
        print(f"   çµ‚äº†ã—ãŸãƒ¯ãƒ¼ã‚«ãƒ¼: {len(result['terminated_workers'])}å€‹")

        if result["terminated_workers"]:
            print(f"\nğŸ—‘ï¸ çµ‚äº†ã—ãŸãƒ¯ãƒ¼ã‚«ãƒ¼:")
            for worker in result["terminated_workers"]:
                print(
                    f"   â€¢ {worker['name']} (PID: {worker['pid']}) - {worker['reason']}"
                )

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    balancer.export_metrics_report(

    )
    print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    print(f"\nğŸ‰ Worker Load Balancer æœ€é©åŒ–å®Œäº†ï¼")

if __name__ == "__main__":
    main()
