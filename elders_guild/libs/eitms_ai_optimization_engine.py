#!/usr/bin/env python3
"""
EITMS AIæœ€é©åŒ–ãƒ»å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³

AIé§†å‹•ã«ã‚ˆã‚‹ã‚¿ã‚¹ã‚¯ç®¡ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
- å„ªå…ˆåº¦è‡ªå‹•èª¿æ•´
- å·¥æ•°è¦‹ç©ã‚‚ã‚Šå­¦ç¿’
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
- 4è³¢è€…é€£æºAIæœ€é©åŒ–

Author: ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ï¼ˆClaude Elderï¼‰  
Created: 2025/07/21
Version: 1.0.0
"""

import asyncio
import json
import logging
import math
import statistics
from dataclasses import dataclass, field
from datetime import datetime, timezone, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple
import pickle
import numpy as np
from collections import defaultdict, deque
import uuid

# å†…éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†
import sys
import os
sys.path.append(os.path.dirname(__file__))

# çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
if os.path.exists(os.path.join(os.path.dirname(__file__), 'eitms_unified_data_model.py')):
    from eitms_unified_data_model import (
        UnifiedTask, TaskType, TaskStatus, Priority,
        EitmsUnifiedManager
    )
else:
    # ãƒ¢ãƒƒã‚¯å®šç¾©
    from enum import Enum
    from dataclasses import dataclass
    
    class TaskType(Enum):
        """TaskTypeã‚¯ãƒ©ã‚¹"""

        PROJECT_TASK = "project_task" 
        ISSUE = "issue"
        PLANNING = "planning"
    
    class TaskStatus(Enum):
        """TaskStatusã‚¯ãƒ©ã‚¹"""
        CREATED = "created"
        IN_PROGRESS = "in_progress"
        COMPLETED = "completed"
        BLOCKED = "blocked"
    
    class Priority(Enum):
        """Priorityã‚¯ãƒ©ã‚¹"""
        HIGH = "high"
        MEDIUM = "medium"
        LOW = "low"
        CRITICAL = "critical"
    
    @dataclass
    class UnifiedTask:
        """UnifiedTaskã‚¯ãƒ©ã‚¹"""
        id: str = "mock-id"
        title: str = ""

        status: TaskStatus = TaskStatus.CREATED
        priority: Priority = Priority.MEDIUM
        context: Dict = field(default_factory=dict)
        time_estimated: Optional[int] = None
        time_spent: Optional[int] = None

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OptimizationStrategy(Enum):
    """æœ€é©åŒ–æˆ¦ç•¥"""
    PRIORITY_BOOST = "priority_boost"
    EFFORT_BALANCE = "effort_balance"
    DEADLINE_DRIVEN = "deadline_driven"
    SKILL_MATCHING = "skill_matching"
    DEPENDENCY_AWARE = "dependency_aware"

@dataclass
class TaskMetrics:
    """ã‚¿ã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    
    task_id: str = ""
    complexity_score: float = 0.0
    estimated_hours: float = 0.0
    actual_hours: Optional[float] = None
    completion_probability: float = 0.5
    priority_score: float = 0.0
    dependency_impact: float = 0.0
    skills_required: List[str] = field(default_factory=list)
    historical_accuracy: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """to_dictãƒ¡ã‚½ãƒƒãƒ‰"""
        return {
            'task_id': self.task_id,
            'complexity_score': self.complexity_score,
            'estimated_hours': self.estimated_hours,
            'actual_hours': self.actual_hours,
            'completion_probability': self.completion_probability,
            'priority_score': self.priority_score,
            'dependency_impact': self.dependency_impact,
            'skills_required': self.skills_required,
            'historical_accuracy': self.historical_accuracy
        }

@dataclass
class AIRecommendation:
    """AIæ¨å¥¨äº‹é …"""
    
    task_id: str = ""
    recommendation_type: str = ""
    current_value: Any = None
    recommended_value: Any = None
    confidence: float = 0.0
    reasoning: str = ""
    impact_score: float = 0.0
    generated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    
    def to_dict(self) -> Dict[str, Any]:
        """to_dictãƒ¡ã‚½ãƒƒãƒ‰"""
        return {
            'task_id': self.task_id,
            'recommendation_type': self.recommendation_type,
            'current_value': self.current_value,
            'recommended_value': self.recommended_value,
            'confidence': self.confidence,
            'reasoning': self.reasoning,
            'impact_score': self.impact_score,
            'generated_at': self.generated_at.isoformat()
        }

class ComplexityAnalyzer:
    """è¤‡é›‘åº¦åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.keywords_weights = {
            # é«˜è¤‡é›‘åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            'system': 1.5, 'architecture': 2.0, 'integration': 1.8, 'optimization': 1.6,
            'algorithm': 1.7, 'performance': 1.4, 'security': 1.9, 'migration': 2.1,
            'refactor': 1.3, 'database': 1.5, 'api': 1.2, 'framework': 1.4,
            
            # ä¸­è¤‡é›‘åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰  
            'feature': 1.0, 'function': 0.9, 'component': 1.1, 'module': 1.0,
            'test': 0.8, 'documentation': 0.6, 'ui': 0.9, 'frontend': 1.0,
            
            # ä½è¤‡é›‘åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            'fix': 0.7, 'update': 0.5, 'config': 0.6, 'style': 0.4,
            'typo': 0.2, 'text': 0.3, 'comment': 0.3
        }
        
        self.type_multipliers = {
            TaskType.PLANNING: 1.8,
            TaskType.ISSUE: 1.4,
            TaskType.PROJECT_TASK: 1.2,

        }
    
    def analyze_complexity(self, task: UnifiedTask) -> float:
        """ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦åˆ†æ"""
        text = f"{task.title} {task.description}".lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è¤‡é›‘åº¦
        keyword_score = 1.0
        for keyword, weight in self.keywords_weights.items():
            if keyword in text:
                keyword_score *= weight
        
        # ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ã‚ˆã‚‹èª¿æ•´
        length_factor = min(len(text) / 200, 2.0)  # æœ€å¤§2å€ã¾ã§
        
        # ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ã«ã‚ˆã‚‹èª¿æ•´
        type_multiplier = self.type_multipliers.get(task.task_type, 1.0)
        
        # ä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹èª¿æ•´
        dependency_factor = 1.0
        if hasattr(task, 'dependencies') and task.dependencies:
            dependency_factor = 1 + (len(task.dependencies) * 0.1)
        
        complexity = keyword_score * length_factor * type_multiplier * dependency_factor
        
        # 0.1ã€œ5.0ã®ç¯„å›²ã«æ­£è¦åŒ–
        return max(0.1, min(5.0, complexity))

class EffortEstimator:
    """å·¥æ•°è¦‹ç©ã‚‚ã‚Šã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.historical_data = defaultdict(list)
        self.base_estimates = {

            TaskType.PROJECT_TASK: 4.0,  # 4æ™‚é–“
            TaskType.ISSUE: 8.0,     # 8æ™‚é–“
            TaskType.PLANNING: 2.0   # 2æ™‚é–“
        }
        
        self.complexity_multipliers = {
            'very_low': 0.5,
            'low': 0.8,
            'medium': 1.0,
            'high': 1.5,
            'very_high': 2.5
        }
    
    def estimate_effort(self, task: UnifiedTask, complexity_score: float) -> float:
        """å·¥æ•°è¦‹ç©ã‚‚ã‚Š"""
        # ãƒ™ãƒ¼ã‚¹è¦‹ç©ã‚‚ã‚Š
        base_hours = self.base_estimates.get(task.task_type, 2.0)
        
        # è¤‡é›‘åº¦ã«ã‚ˆã‚‹èª¿æ•´
        complexity_category = self._categorize_complexity(complexity_score)
        complexity_multiplier = self.complexity_multipliers[complexity_category]
        
        # éå»ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹èª¿æ•´
        historical_adjustment = self._get_historical_adjustment(task)
        
        # å„ªå…ˆåº¦ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé«˜å„ªå…ˆåº¦ã¯ã‚ˆã‚Šæ…é‡ã«è¦‹ç©ã‚‚ã‚Šï¼‰
        priority_adjustment = {
            Priority.CRITICAL: 1.3,
            Priority.HIGH: 1.2,
            Priority.MEDIUM: 1.0,
            Priority.LOW: 0.9
        }.get(task.priority, 1.0)
        
        estimated_hours = (base_hours * complexity_multiplier * 
                         historical_adjustment * priority_adjustment)
        
        return round(max(0.25, estimated_hours), 2)  # æœ€ä½15åˆ†
    
    def _categorize_complexity(self, score: float) -> str:
        """è¤‡é›‘åº¦ã‚«ãƒ†ã‚´ãƒªåŒ–"""
        if score <= 0.5:
            return 'very_low'
        elif score <= 1.0:
            return 'low'
        elif score <= 2.0:
            return 'medium'
        elif score <= 3.5:
            return 'high'
        else:
            return 'very_high'
    
    def _get_historical_adjustment(self, task: UnifiedTask) -> float:
        """éå»ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹èª¿æ•´ä¿‚æ•°"""
        task_type_data = self.historical_data.get(task.task_type.value, [])
        
        if len(task_type_data) < 3:
            return 1.0  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # éå»ã®è¦‹ç©ã‚‚ã‚Šç²¾åº¦ã‹ã‚‰èª¿æ•´
        accuracies = [data['accuracy'] for data in task_type_data[-10:]]  # æœ€æ–°10ä»¶
        avg_accuracy = statistics.mean(accuracies)
        
        # ç²¾åº¦ãŒä½ã„å ´åˆã¯è¦‹ç©ã‚‚ã‚Šã‚’ä¸Šã’ã‚‹
        if avg_accuracy < 0.8:
            return 1.2
        elif avg_accuracy > 1.2:
            return 0.9
        else:
            return 1.0
    
    def learn_from_completion(self, task: UnifiedTask, actual_hours: float, estimated_hours: float):
        """å®Œäº†ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å­¦ç¿’"""
        accuracy = actual_hours / max(estimated_hours, 0.1)
        
        self.historical_data[task.task_type.value].append({
            'task_id': task.id,
            'estimated': estimated_hours,
            'actual': actual_hours,
            'accuracy': accuracy,
            'complexity_indicators': self._extract_complexity_indicators(task),
            'timestamp': datetime.now(timezone.utc)
        })
        
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ï¼ˆæœ€å¤§100ä»¶ä¿æŒï¼‰
        if len(self.historical_data[task.task_type.value]) > 100:
            self.historical_data[task.task_type.value] = \
                self.historical_data[task.task_type.value][-100:]
    
    def _extract_complexity_indicators(self, task: UnifiedTask) -> Dict[str, Any]:
        """è¤‡é›‘åº¦æŒ‡æ¨™æŠ½å‡º"""
        return {
            'title_length': len(task.title),
            'description_length': len(task.description or ''),
            'has_dependencies': bool(getattr(task, 'dependencies', [])),
            'priority': task.priority.value
        }

class PriorityOptimizer:
    """å„ªå…ˆåº¦æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.urgency_factors = {
            'deadline': 2.0,
            'blocking': 1.8,
            'critical_path': 1.6,
            'stakeholder_priority': 1.4,
            'business_value': 1.3
        }
        
        self.priority_scores = {
            Priority.CRITICAL: 100,
            Priority.HIGH: 75,
            Priority.MEDIUM: 50,
            Priority.LOW: 25
        }
    
    def optimize_priority(
        self,
        task: UnifiedTask,
        context: Dict[str,
        Any]
    ) -> Tuple[Priority, float]:
        """å„ªå…ˆåº¦æœ€é©åŒ–"""
        current_score = self.priority_scores[task.priority]
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦å› ã«ã‚ˆã‚‹èª¿æ•´
        urgency_boost = self._calculate_urgency_boost(context)
        impact_multiplier = self._calculate_impact_multiplier(task, context)
        effort_factor = self._calculate_effort_factor(context.get('estimated_hours', 2.0))
        
        # æœ€é©åŒ–ã‚¹ã‚³ã‚¢è¨ˆç®—
        optimized_score = current_score * urgency_boost * impact_multiplier * effort_factor
        
        # æ–°ã—ã„å„ªå…ˆåº¦æ±ºå®š
        new_priority = self._score_to_priority(optimized_score)
        confidence = self._calculate_confidence(current_score, optimized_score)
        
        return new_priority, confidence
    
    def _calculate_urgency_boost(self, context: Dict[str, Any]) -> float:
        """ç·Šæ€¥åº¦ãƒ–ãƒ¼ã‚¹ãƒˆè¨ˆç®—"""
        boost = 1.0
        
        # æœŸé™ã«ã‚ˆã‚‹ç·Šæ€¥åº¦
        if 'due_date' in context and context['due_date']:
            try:
                due_date = datetime.fromisoformat(context['due_date'])
                days_until_due = (due_date - datetime.now(timezone.utc)).days
                
                if days_until_due <= 1:
                    boost *= 2.0
                elif days_until_due <= 3:
                    boost *= 1.5
                elif days_until_due <= 7:
                    boost *= 1.2
            except:
                pass
        
        # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°è¦å› 
        if context.get('blocking_tasks', 0) > 0:
            boost *= (1 + context['blocking_tasks'] * 0.2)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼è¦æ±‚
        if context.get('stakeholder_urgency', 'normal') == 'high':
            boost *= 1.3
        
        return min(boost, 3.0)  # æœ€å¤§3å€ã¾ã§
    
    def _calculate_impact_multiplier(self, task: UnifiedTask, context: Dict[str, Any]) -> float:
        """å½±éŸ¿åº¦ä¹—æ•°è¨ˆç®—"""
        multiplier = 1.0
        
        # ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤
        business_value = context.get('business_value', 'medium')
        value_multipliers = {'critical': 1.5, 'high': 1.3, 'medium': 1.0, 'low': 0.8}
        multiplier *= value_multipliers.get(business_value, 1.0)
        
        # ä¾å­˜é–¢ä¿‚å½±éŸ¿
        dependent_tasks = context.get('dependent_tasks', 0)
        if dependent_tasks > 0:
            multiplier *= (1 + dependent_tasks * 0.1)
        
        # ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿åº¦
        system_impact = context.get('system_impact', 'low')
        impact_multipliers = {'high': 1.4, 'medium': 1.1, 'low': 1.0}
        multiplier *= impact_multipliers.get(system_impact, 1.0)
        
        return multiplier
    
    def _calculate_effort_factor(self, estimated_hours: float) -> float:
        """å·¥æ•°è¦å› è¨ˆç®—"""
        # çŸ­æ™‚é–“ã§é«˜ä¾¡å€¤ãªã‚¿ã‚¹ã‚¯ã‚’å„ªå…ˆ
        if estimated_hours <= 0.5:
            return 1.2  # ã‚¯ã‚¤ãƒƒã‚¯ã‚¦ã‚£ãƒ³
        elif estimated_hours <= 2.0:
            return 1.1
        elif estimated_hours >= 8.0:
            return 0.9  # å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯ã¯è‹¥å¹²å„ªå…ˆåº¦ä¸‹ã’
        else:
            return 1.0
    
    def _score_to_priority(self, score: float) -> Priority:
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰å„ªå…ˆåº¦å¤‰æ›"""
        if score >= 120:
            return Priority.CRITICAL
        elif score >= 85:
            return Priority.HIGH
        elif score >= 40:
            return Priority.MEDIUM
        else:
            return Priority.LOW
    
    def _calculate_confidence(self, original_score: float, optimized_score: float) -> float:
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        difference = abs(optimized_score - original_score)
        max_difference = max(original_score, optimized_score)
        
        if max_difference == 0:
            return 1.0
        
        # å¤‰æ›´å¹…ãŒå¤§ãã„ã»ã©ä¿¡é ¼åº¦ã¯ä¸‹ãŒã‚‹
        confidence = 1.0 - (difference / max_difference * 0.5)
        return max(0.1, min(1.0, confidence))

class EitmsAiEngine:
    """EITMS AIæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ - ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, unified_manager):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.unified_manager = unified_manager
        self.complexity_analyzer = ComplexityAnalyzer()
        self.effort_estimator = EffortEstimator()
        self.priority_optimizer = PriorityOptimizer()
        
        self.learning_enabled = True
        self.auto_optimization = True
        self.optimization_history = deque(maxlen=1000)
        
        self.ai_stats = {
            'recommendations_generated': 0,
            'recommendations_applied': 0,
            'learning_sessions': 0,
            'optimization_accuracy': 0.0
        }
    
    async def analyze_task(self, task_id: str) -> TaskMetrics:
        """ã‚¿ã‚¹ã‚¯ç·åˆåˆ†æ"""
        task = await self.unified_manager.db.get_task(task_id)
        if not task:
            raise ValueError(f"Task not found: {task_id}")
        
        # è¤‡é›‘åº¦åˆ†æ
        complexity_score = self.complexity_analyzer.analyze_complexity(task)
        
        # å·¥æ•°è¦‹ç©ã‚‚ã‚Š
        estimated_hours = self.effort_estimator.estimate_effort(task, complexity_score)
        
        # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        priority_scores = {
            Priority.CRITICAL: 100,
            Priority.HIGH: 75, 
            Priority.MEDIUM: 50,
            Priority.LOW: 25
        }
        priority_score = priority_scores[task.priority]
        
        # ä¾å­˜é–¢ä¿‚å½±éŸ¿åº¦
        dependency_impact = self._calculate_dependency_impact(task)
        
        # å®Œäº†ç¢ºç‡äºˆæ¸¬
        completion_probability = self._predict_completion_probability(
            task, complexity_score, estimated_hours
        )
        
        metrics = TaskMetrics(
            task_id=task_id,
            complexity_score=complexity_score,
            estimated_hours=estimated_hours,
            completion_probability=completion_probability,
            priority_score=priority_score,
            dependency_impact=dependency_impact,
            skills_required=self._extract_required_skills(task)
        )
        
        logger.info(f"ğŸ§  AIåˆ†æå®Œäº†: {task.title} (è¤‡é›‘åº¦: {complexity_score:0.2f}, å·¥æ•°: {estimated_hours:0.1f}h)" \
            "ğŸ§  AIåˆ†æå®Œäº†: {task.title} (è¤‡é›‘åº¦: {complexity_score:0.2f}, å·¥æ•°: {estimated_hours:0.1f}h)")
        return metrics
    
    async def generate_recommendations(self, task_id: str) -> List[AIRecommendation]:
        """AIæ¨å¥¨äº‹é …ç”Ÿæˆ"""
        task = await self.unified_manager.db.get_task(task_id)
        if not task:
            return []
        
        recommendations = []
        
        # è¤‡é›‘åº¦åˆ†æ
        complexity_score = self.complexity_analyzer.analyze_complexity(task)
        
        # 1.0 å„ªå…ˆåº¦æœ€é©åŒ–æ¨å¥¨
        context = self._build_task_context(task)
        new_priority, confidence = self.priority_optimizer.optimize_priority(task, context)
        
        if new_priority != task.priority and confidence > 0.7:
            recommendations.append(AIRecommendation(
                task_id=task_id,
                recommendation_type='priority_adjustment',
                current_value=task.priority.value,
                recommended_value=new_priority.value,
                confidence=confidence,
                reasoning=f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã«ã‚ˆã‚Šå„ªå…ˆåº¦èª¿æ•´ã‚’æ¨å¥¨ (ä¿¡é ¼åº¦: {confidence:0.2f})",
                impact_score=self._calculate_priority_impact(task.priority, new_priority)
            ))
        
        # 2.0 å·¥æ•°è¦‹ç©ã‚‚ã‚Šæ¨å¥¨
        estimated_hours = self.effort_estimator.estimate_effort(task, complexity_score)
        current_estimate = task.time_estimated or 0
        
        if abs(estimated_hours - current_estimate) > 0.5:  # 30åˆ†ä»¥ä¸Šã®å·®
            recommendations.append(AIRecommendation(
                task_id=task_id,
                recommendation_type='effort_estimation',
                current_value=current_estimate,
                recommended_value=estimated_hours,
                confidence=0.8,
                reasoning=f"è¤‡é›‘åº¦åˆ†æã«åŸºã¥ãå·¥æ•°è¦‹ç©ã‚‚ã‚Šèª¿æ•´ (è¤‡é›‘åº¦: {complexity_score:0.2f})",
                impact_score=abs(estimated_hours - current_estimate) / max(estimated_hours, 1)
            ))
        
        # 3.0 åˆ†è§£æ¨å¥¨ (å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯ç”¨)
        if complexity_score > 3.0 and estimated_hours > 6.0:
            recommendations.append(AIRecommendation(
                task_id=task_id,
                recommendation_type='task_breakdown',
                current_value='single_task',
                recommended_value='multiple_subtasks',
                confidence=0.85,
                reasoning=f"é«˜è¤‡é›‘åº¦ãƒ»å¤§å·¥æ•°ã‚¿ã‚¹ã‚¯ã®åˆ†è§£ã‚’æ¨å¥¨ (è¤‡é›‘åº¦: {complexity_score:0.2f}, å·¥æ•°: {estimated_hours:0.1f}h)",
                impact_score=complexity_score / 5.0
            ))
        
        # 4.0 ã‚¹ã‚­ãƒ«ãƒãƒƒãƒãƒ³ã‚°æ¨å¥¨
        required_skills = self._extract_required_skills(task)
        if required_skills:
            recommendations.append(AIRecommendation(
                task_id=task_id,
                recommendation_type='skill_matching',
                current_value=[],
                recommended_value=required_skills,
                confidence=0.75,
                reasoning=f"å¿…è¦ã‚¹ã‚­ãƒ«: {', '.join(required_skills)}",
                impact_score=len(required_skills) / 10.0
            ))
        
        self.ai_stats['recommendations_generated'] += len(recommendations)
        logger.info(f"ğŸ¤– AIæ¨å¥¨ç”Ÿæˆ: {task.title} â†’ {len(recommendations)}ä»¶")
        
        return recommendations
    
    async def apply_recommendation(self, recommendation: AIRecommendation) -> bool:
        """AIæ¨å¥¨äº‹é …é©ç”¨"""
        try:
            task = await self.unified_manager.db.get_task(recommendation.task_id)
            if not task:
                return False
            
            if recommendation.recommendation_type == 'priority_adjustment':
                new_priority = Priority(recommendation.recommended_value)
                await self.unified_manager.update_task_status(task.id, task.status)
                # å®Ÿéš›ã®å„ªå…ˆåº¦æ›´æ–°ã¯ unified_manager ã®æ©Ÿèƒ½æ‹¡å¼µãŒå¿…è¦
                
            elif recommendation.recommendation_type == 'effort_estimation':
                # å·¥æ•°è¦‹ç©ã‚‚ã‚Šæ›´æ–°ï¼ˆå®Ÿè£…ã¯ unified_manager æ‹¡å¼µãŒå¿…è¦ï¼‰
                pass
            
            self.ai_stats['recommendations_applied'] += 1
            self.optimization_history.append({
                'task_id': recommendation.task_id,
                'type': recommendation.recommendation_type,
                'applied_at': datetime.now(timezone.utc),
                'confidence': recommendation.confidence
            })
            
            logger.info(f"âœ… AIæ¨å¥¨é©ç”¨: {recommendation.recommendation_type} â†’ {task.title}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨å¥¨é©ç”¨å¤±æ•—: {e}")
            return False
    
    async def learn_from_completion(self, task_id: str, actual_hours: float):
        """å®Œäº†ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å­¦ç¿’"""
        if not self.learning_enabled:
            return
        
        try:
            task = await self.unified_manager.db.get_task(task_id)
            if not task:
                return
            
            # å·¥æ•°è¦‹ç©ã‚‚ã‚Šå­¦ç¿’
            estimated_hours = task.time_estimated or 0
            self.effort_estimator.learn_from_completion(task, actual_hours, estimated_hours)
            
            # å­¦ç¿’çµ±è¨ˆæ›´æ–°
            self.ai_stats['learning_sessions'] += 1
            
            # ç²¾åº¦è¨ˆç®—
            if estimated_hours > 0:
                accuracy = min(actual_hours, estimated_hours) / max(actual_hours, estimated_hours)
                current_accuracy = self.ai_stats['optimization_accuracy']
                sessions = self.ai_stats['learning_sessions']
                
                # ç§»å‹•å¹³å‡ã§ç²¾åº¦æ›´æ–°
                self.ai_stats['optimization_accuracy'] = (
                    (current_accuracy * (sessions - 1) + accuracy) / sessions
                )
            
            logger.info(f"ğŸ§  AIå­¦ç¿’å®Œäº†: {task.title} (å®Ÿç¸¾: {actual_hours}h, è¦‹ç©: {estimated_hours}h)")
            
        except Exception as e:
            logger.error(f"âŒ AIå­¦ç¿’å¤±æ•—: {e}")
    
    async def optimize_task_batch(self, task_ids: List[str]) -> Dict[str, List[AIRecommendation]]:
        """ã‚¿ã‚¹ã‚¯ä¸€æ‹¬æœ€é©åŒ–"""
        results = {}
        
        for task_id in task_ids:
            try:
                recommendations = await self.generate_recommendations(task_id)
                results[task_id] = recommendations
            except Exception as e:
                logger.error(f"âŒ ãƒãƒƒãƒæœ€é©åŒ–å¤±æ•— {task_id}: {e}")
                results[task_id] = []
        
        return results
    
    def _calculate_dependency_impact(self, task: UnifiedTask) -> float:
        """ä¾å­˜é–¢ä¿‚å½±éŸ¿åº¦è¨ˆç®—"""
        # å®Ÿè£…æ™‚ã¯ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•åˆ†æ
        dependencies = getattr(task, 'dependencies', [])
        sub_tasks = getattr(task, 'sub_tasks', [])
        
        impact = len(dependencies) * 0.1 + len(sub_tasks) * 0.2
        return min(impact, 1.0)
    
    def _predict_completion_probability(
        self,
        task: UnifiedTask,
        complexity: float,
        effort: float
    ) -> float:
        """å®Œäº†ç¢ºç‡äºˆæ¸¬"""
        base_probability = 0.8
        
        # è¤‡é›‘åº¦ã«ã‚ˆã‚‹èª¿æ•´
        complexity_factor = max(0.3, 1.0 - (complexity - 1.0) * 0.15)
        
        # å·¥æ•°ã«ã‚ˆã‚‹èª¿æ•´
        if effort > 8.0:
            effort_factor = 0.8
        elif effort < 1.0:
            effort_factor = 0.95
        else:
            effort_factor = 0.9
        
        # å„ªå…ˆåº¦ã«ã‚ˆã‚‹èª¿æ•´
        priority_factor = {
            Priority.CRITICAL: 0.95,
            Priority.HIGH: 0.9,
            Priority.MEDIUM: 0.85,
            Priority.LOW: 0.7
        }[task.priority]
        
        probability = base_probability * complexity_factor * effort_factor * priority_factor
        return max(0.1, min(0.99, probability))
    
    def _extract_required_skills(self, task: UnifiedTask) -> List[str]:
        """å¿…è¦ã‚¹ã‚­ãƒ«æŠ½å‡º"""
        text = f"{task.title} {task.description}".lower()
        
        skill_keywords = {
            'python': ['python', 'django', 'flask', 'fastapi'],
            'javascript': ['javascript', 'js', 'node', 'react', 'vue'],
            'database': ['database', 'sql', 'mysql', 'postgresql', 'mongodb'],
            'devops': ['docker', 'kubernetes', 'aws', 'ci/cd', 'deployment'],
            'frontend': ['frontend', 'ui', 'css', 'html', 'design'],
            'backend': ['backend', 'api', 'server', 'microservice'],
            'testing': ['test', 'testing', 'pytest', 'unittest'],
            'security': ['security', 'auth', 'encryption', 'vulnerability']
        }
        
        skills = [skill for skill, keywords in skill_keywords.items() 
                 if any(keyword in text for keyword in keywords)]
        
        return skills[:5]  # æœ€å¤§5ã¤ã¾ã§
    
    def _build_task_context(self, task: UnifiedTask) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰"""
        return {
            'due_date': task.context.get('due_date'),
            'blocking_tasks': len(getattr(task, 'sub_tasks', [])),
            'dependent_tasks': len(getattr(task, 'dependencies', [])),
            'business_value': task.context.get('business_value', 'medium'),
            'system_impact': task.context.get('system_impact', 'low'),
            'stakeholder_urgency': task.context.get('stakeholder_urgency', 'normal'),
            'estimated_hours': task.time_estimated
        }
    
    def _calculate_priority_impact(self, current: Priority, new: Priority) -> float:
        """å„ªå…ˆåº¦å¤‰æ›´å½±éŸ¿åº¦è¨ˆç®—"""
        priority_values = {Priority.LOW: 1, Priority.MEDIUM: 2, Priority.HIGH: 3, Priority.CRITICAL: 4}
        current_val = priority_values[current]
        new_val = priority_values[new]
        
        return abs(new_val - current_val) / 4.0
    
    def get_ai_statistics(self) -> Dict[str, Any]:
        """AIçµ±è¨ˆå–å¾—"""
        recent_optimizations = list(self.optimization_history)[-10:]
        
        return {
            **self.ai_stats,
            'learning_enabled': self.learning_enabled,
            'auto_optimization': self.auto_optimization,
            'recent_optimizations': len(recent_optimizations),
            'average_confidence': statistics.mean([opt['confidence'] for opt in recent_optimizations]) \
                if recent_optimizations \
                else 0.0,
            'generated_at': datetime.now(timezone.utc).isoformat()
        }
    
    def enable_learning(self):
        """å­¦ç¿’æ©Ÿèƒ½æœ‰åŠ¹åŒ–"""
        self.learning_enabled = True
        logger.info("ğŸ§  AIå­¦ç¿’æ©Ÿèƒ½æœ‰åŠ¹åŒ–")
    
    def disable_learning(self):
        """å­¦ç¿’æ©Ÿèƒ½ç„¡åŠ¹åŒ–"""
        self.learning_enabled = False
        logger.info("â¸ï¸ AIå­¦ç¿’æ©Ÿèƒ½ç„¡åŠ¹åŒ–")

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
async def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    # ãƒ¢ãƒƒã‚¯çµ±ä¸€ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    class MockUnifiedManager:
        """MockUnifiedManager - ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
        def __init__(self):
            """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
            self.tasks = {}
        
        async def create_task(self, **kwargs):
            """taskä½œæˆãƒ¡ã‚½ãƒƒãƒ‰"""
            return "ai-test-task"
        
        @property
        def db(self):
            """dbãƒ¡ã‚½ãƒƒãƒ‰"""
            return type('MockDB', (), {
                'get_task': lambda self, task_id: UnifiedTask(
                    id=task_id,
                    title="AIæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯",
                    description="è¤‡é›‘ãªã‚·ã‚¹ãƒ†ãƒ çµ±åˆã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆãŒå¿…è¦ãªå¤§è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
                    task_type=TaskType.PROJECT_TASK,
                    priority=Priority.MEDIUM,
                    time_estimated=4.0,
                    context={'business_value': 'high', 'system_impact': 'medium'}
                )
            })()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    manager = MockUnifiedManager()
    ai_engine = EitmsAiEngine(manager)
    
    # ã‚¿ã‚¹ã‚¯åˆ†æ
    task_id = "ai-test-task"
    metrics = await ai_engine.analyze_task(task_id)
    logger.info(f"ğŸ¯ åˆ†æçµæœ: è¤‡é›‘åº¦={metrics.complexity_score:0.2f}, å·¥æ•°={metrics.estimated_hours:0.1f}h")
    
    # AIæ¨å¥¨ç”Ÿæˆ
    recommendations = await ai_engine.generate_recommendations(task_id)
    logger.info(f"ğŸ¤– AIæ¨å¥¨: {len(recommendations)}ä»¶ç”Ÿæˆ")
    
    for rec in recommendations:
        logger.info(f"  - {rec.recommendation_type}: {rec.reasoning}")
    
    # çµ±è¨ˆç¢ºèª
    stats = ai_engine.get_ai_statistics()
    logger.info(f"ğŸ“Š AIçµ±è¨ˆ: {stats['recommendations_generated']}ä»¶æ¨å¥¨ç”Ÿæˆ")

if __name__ == "__main__":
    asyncio.run(main())