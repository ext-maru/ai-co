#!/usr/bin/env python3
"""
Elder Flow Core Enhancement
ã‚¨ãƒ«ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚³ã‚¢å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ  - è¨˜éŒ²ãƒ»ç›£è¦–ãƒ»å“è³ªä¿è¨¼ã®çµ±åˆ

ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰è©•è­°ä¼šæ‰¿èª - 2025å¹´7æœˆ11æ—¥
"""

import asyncio
import json
import logging
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib
import subprocess


class FlowPhase(Enum):
    """Elder Flowãƒ•ã‚§ãƒ¼ã‚º"""

    SAGE_CONSULTATION = "sage_consultation"  # 4è³¢è€…ç›¸è«‡
    SERVANT_EXECUTION = "servant_execution"  # ã‚µãƒ¼ãƒãƒ³ãƒˆå®Ÿè¡Œ
    QUALITY_GATE = "quality_gate"  # å“è³ªã‚²ãƒ¼ãƒˆ
    COUNCIL_REPORT = "council_report"  # è©•è­°ä¼šå ±å‘Š
    GIT_AUTOMATION = "git_automation"  # Gitè‡ªå‹•åŒ–


class FlowStatus(Enum):
    """ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹"""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class FlowExecution:
    """ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œè¨˜éŒ²"""

    execution_id: str
    task_name: str
    priority: str
    phase: FlowPhase
    status: FlowStatus
    start_time: datetime
    end_time: Optional[datetime]
    duration_seconds: Optional[float]
    quality_score: Optional[float]
    violations_found: int
    violations_fixed: int
    sage_recommendations: List[Dict[str, Any]]
    servant_results: List[Dict[str, Any]]
    git_commits: List[str]
    error_log: List[str]
    metadata: Dict[str, Any]


class ElderFlowCoreEnhancement:
    """Elder Flowã‚³ã‚¢å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.logger = self._setup_logger()
        self.db_path = Path("data/elder_flow_core.db")
        self.flow_log = Path("logs/elder_flow_executions.log")
        self.metrics_file = Path("data/elder_flow_metrics.json")
        self._init_database()
        self._init_metrics()

    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼è¨­å®š"""
        logger = logging.getLogger("elder_flow_core_enhancement")
        logger.setLevel(logging.INFO)

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            "%(asctime)s - Elder Flow Core - %(levelname)s - %(message)s"
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        self.flow_log.parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(self.flow_log, mode="a")
        file_handler.setFormatter(console_formatter)
        logger.addHandler(file_handler)

        return logger

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS flow_executions (
                execution_id TEXT PRIMARY KEY,
                task_name TEXT NOT NULL,
                priority TEXT NOT NULL,
                phase TEXT NOT NULL,
                status TEXT NOT NULL,
                start_time TEXT NOT NULL,
                end_time TEXT,
                duration_seconds REAL,
                quality_score REAL,
                violations_found INTEGER DEFAULT 0,
                violations_fixed INTEGER DEFAULT 0,
                sage_recommendations TEXT,
                servant_results TEXT,
                git_commits TEXT,
                error_log TEXT,
                metadata TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # ãƒ•ã‚§ãƒ¼ã‚ºå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS phase_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                phase TEXT NOT NULL,
                status TEXT NOT NULL,
                start_time TEXT NOT NULL,
                end_time TEXT,
                details TEXT,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                threshold REAL,
                passed BOOLEAN,
                recorded_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        # é•åè¨˜éŒ²ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS violation_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                violation_type TEXT NOT NULL,
                severity TEXT NOT NULL,
                location TEXT,
                description TEXT,
                fixed BOOLEAN DEFAULT FALSE,
                fix_details TEXT,
                detected_at TEXT DEFAULT CURRENT_TIMESTAMP,
                fixed_at TEXT,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        conn.commit()
        conn.close()

        self.logger.info("âœ… Elder Flow Core ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")

    def _init_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–"""
        if not self.metrics_file.exists():
            initial_metrics = {
                "total_executions": 0,
                "successful_executions": 0,
                "failed_executions": 0,
                "average_quality_score": 0.0,
                "total_violations_found": 0,
                "total_violations_fixed": 0,
                "average_execution_time": 0.0,
                "phase_success_rates": {phase.value: 0.0 for phase in FlowPhase},
                "last_updated": datetime.now().isoformat(),
            }

            self.metrics_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.metrics_file, "w") as f:
                json.dump(initial_metrics, f, indent=2)

    def generate_execution_id(self, task_name: str) -> str:
        """å®Ÿè¡ŒIDç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        hash_input = f"{task_name}_{timestamp}".encode()
        hash_value = hashlib.md5(hash_input).hexdigest()[:8]
        return f"EF_{timestamp}_{hash_value}"

    async def start_flow_execution(
        self, task_name: str, priority: str = "normal"
    ) -> str:
        """ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹"""
        execution_id = self.generate_execution_id(task_name)

        self.logger.info(f"ğŸš€ Elder Flowå®Ÿè¡Œé–‹å§‹: {execution_id} - {task_name}")

        # å®Ÿè¡Œè¨˜éŒ²ä½œæˆ
        execution = FlowExecution(
            execution_id=execution_id,
            task_name=task_name,
            priority=priority,
            phase=FlowPhase.SAGE_CONSULTATION,
            status=FlowStatus.IN_PROGRESS,
            start_time=datetime.now(),
            end_time=None,
            duration_seconds=None,
            quality_score=None,
            violations_found=0,
            violations_fixed=0,
            sage_recommendations=[],
            servant_results=[],
            git_commits=[],
            error_log=[],
            metadata={"priority": priority},
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
        await self._record_execution_start(execution)

        return execution_id

    async def _record_execution_start(self, execution: FlowExecution):
        """å®Ÿè¡Œé–‹å§‹è¨˜éŒ²"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO flow_executions (
                execution_id, task_name, priority, phase, status,
                start_time, sage_recommendations, servant_results,
                git_commits, error_log, metadata
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                execution.execution_id,
                execution.task_name,
                execution.priority,
                execution.phase.value,
                execution.status.value,
                execution.start_time.isoformat(),
                json.dumps(execution.sage_recommendations),
                json.dumps(execution.servant_results),
                json.dumps(execution.git_commits),
                json.dumps(execution.error_log),
                json.dumps(execution.metadata),
            ),
        )

        conn.commit()
        conn.close()

    async def record_phase_transition(
        self,
        execution_id: str,
        from_phase: FlowPhase,
        to_phase: FlowPhase,
        details: Dict[str, Any] = None,
    ):
        """ãƒ•ã‚§ãƒ¼ã‚ºé·ç§»è¨˜éŒ²"""
        self.logger.info(f"ğŸ”„ ãƒ•ã‚§ãƒ¼ã‚ºé·ç§»: {from_phase.value} â†’ {to_phase.value}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # å‰ãƒ•ã‚§ãƒ¼ã‚ºçµ‚äº†
        cursor.execute(
            """
            UPDATE phase_history
            SET end_time = ?, status = 'completed'
            WHERE execution_id = ? AND phase = ? AND end_time IS NULL
        """,
            (datetime.now().isoformat(), execution_id, from_phase.value),
        )

        # æ–°ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹
        cursor.execute(
            """
            INSERT INTO phase_history (execution_id, phase, status, start_time, details)
            VALUES (?, ?, ?, ?, ?)
        """,
            (
                execution_id,
                to_phase.value,
                FlowStatus.IN_PROGRESS.value,
                datetime.now().isoformat(),
                json.dumps(details) if details else None,
            ),
        )

        # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œè¨˜éŒ²æ›´æ–°
        cursor.execute(
            """
            UPDATE flow_executions
            SET phase = ?
            WHERE execution_id = ?
        """,
            (to_phase.value, execution_id),
        )

        conn.commit()
        conn.close()

    async def record_sage_recommendation(
        self, execution_id: str, sage_name: str, recommendation: Dict[str, Any]
    ):
        """è³¢è€…æ¨å¥¨è¨˜éŒ²"""
        self.logger.info(f"ğŸ§™â€â™‚ï¸ {sage_name}ã‹ã‚‰ã®æ¨å¥¨è¨˜éŒ²")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # ç¾åœ¨ã®æ¨å¥¨ã‚’å–å¾—
        cursor.execute(
            """
            SELECT sage_recommendations FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        result = cursor.fetchone()
        if result:
            recommendations = json.loads(result[0]) if result[0] else []
            recommendations.append(
                {
                    "sage": sage_name,
                    "recommendation": recommendation,
                    "timestamp": datetime.now().isoformat(),
                }
            )

            cursor.execute(
                """
                UPDATE flow_executions
                SET sage_recommendations = ?
                WHERE execution_id = ?
            """,
                (json.dumps(recommendations), execution_id),
            )

            conn.commit()

        conn.close()

    async def record_violation(
        self,
        execution_id: str,
        violation_type: str,
        severity: str,
        location: str,
        description: str,
    ):
        """é•åè¨˜éŒ²"""
        self.logger.warning(f"âš ï¸ é•åæ¤œå‡º: {violation_type} ({severity})")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO violation_records (
                execution_id, violation_type, severity, location, description
            ) VALUES (?, ?, ?, ?, ?)
        """,
            (execution_id, violation_type, severity, location, description),
        )

        # é•åæ•°æ›´æ–°
        cursor.execute(
            """
            UPDATE flow_executions
            SET violations_found = violations_found + 1
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        conn.commit()
        conn.close()

    async def record_violation_fix(
        self, execution_id: str, violation_id: int, fix_details: str
    ):
        """é•åä¿®æ­£è¨˜éŒ²"""
        self.logger.info(f"âœ… é•åä¿®æ­£: ID {violation_id}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            UPDATE violation_records
            SET fixed = TRUE, fix_details = ?, fixed_at = ?
            WHERE id = ? AND execution_id = ?
        """,
            (fix_details, datetime.now().isoformat(), violation_id, execution_id),
        )

        # ä¿®æ­£æ•°æ›´æ–°
        cursor.execute(
            """
            UPDATE flow_executions
            SET violations_fixed = violations_fixed + 1
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        conn.commit()
        conn.close()

    async def record_quality_metric(
        self,
        execution_id: str,
        metric_name: str,
        metric_value: float,
        threshold: float = None,
    ):
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        passed = metric_value >= threshold if threshold else True

        self.logger.info(
            f"ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹: {metric_name} = {metric_value} "
            f"({'PASS' if passed else 'FAIL'})"
        )

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO quality_metrics (
                execution_id, metric_name, metric_value, threshold, passed
            ) VALUES (?, ?, ?, ?, ?)
        """,
            (execution_id, metric_name, metric_value, threshold, passed),
        )

        conn.commit()
        conn.close()

    async def complete_flow_execution(
        self,
        execution_id: str,
        status: FlowStatus,
        quality_score: float,
        git_commits: List[str] = None,
    ):
        """ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†"""
        end_time = datetime.now()

        self.logger.info(f"ğŸ Elder Flowå®Ÿè¡Œå®Œäº†: {execution_id} - {status.value}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # é–‹å§‹æ™‚åˆ»å–å¾—
        cursor.execute(
            """
            SELECT start_time FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        result = cursor.fetchone()
        if result:
            start_time = datetime.fromisoformat(result[0])
            duration = (end_time - start_time).total_seconds()

            cursor.execute(
                """
                UPDATE flow_executions
                SET status = ?, end_time = ?, duration_seconds = ?,
                    quality_score = ?, git_commits = ?
                WHERE execution_id = ?
            """,
                (
                    status.value,
                    end_time.isoformat(),
                    duration,
                    quality_score,
                    json.dumps(git_commits) if git_commits else None,
                    execution_id,
                ),
            )

            conn.commit()

        conn.close()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        await self._update_global_metrics()

    async def _update_global_metrics(self):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # çµ±è¨ˆå–å¾—
        cursor.execute(
            """
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as successful,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed,
                AVG(quality_score) as avg_quality,
                SUM(violations_found) as total_violations_found,
                SUM(violations_fixed) as total_violations_fixed,
                AVG(duration_seconds) as avg_duration
            FROM flow_executions
            WHERE end_time IS NOT NULL
        """
        )

        stats = cursor.fetchone()

        if stats:
            metrics = {
                "total_executions": stats[0] or 0,
                "successful_executions": stats[1] or 0,
                "failed_executions": stats[2] or 0,
                "average_quality_score": round(stats[3] or 0, 2),
                "total_violations_found": stats[4] or 0,
                "total_violations_fixed": stats[5] or 0,
                "average_execution_time": round(stats[6] or 0, 2),
                "phase_success_rates": await self._calculate_phase_success_rates(
                    cursor
                ),
                "last_updated": datetime.now().isoformat(),
            }

            with open(self.metrics_file, "w") as f:
                json.dump(metrics, f, indent=2)

        conn.close()

    async def _calculate_phase_success_rates(self, cursor) -> Dict[str, float]:
        """ãƒ•ã‚§ãƒ¼ã‚ºæˆåŠŸç‡è¨ˆç®—"""
        rates = {}

        for phase in FlowPhase:
            cursor.execute(
                """
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as successful
                FROM phase_history
                WHERE phase = ?
            """,
                (phase.value,),
            )

            result = cursor.fetchone()
            if result and result[0] > 0:
                rates[phase.value] = round((result[1] / result[0]) * 100, 2)
            else:
                rates[phase.value] = 0.0

        return rates

    async def generate_execution_report(self, execution_id: str) -> str:
        """å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # å®Ÿè¡Œæƒ…å ±å–å¾—
        cursor.execute(
            """
            SELECT * FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        execution = cursor.fetchone()
        if not execution:
            return "å®Ÿè¡Œè¨˜éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        # ãƒ•ã‚§ãƒ¼ã‚ºå±¥æ­´å–å¾—
        cursor.execute(
            """
            SELECT phase, status, start_time, end_time
            FROM phase_history
            WHERE execution_id = ?
            ORDER BY start_time
        """,
            (execution_id,),
        )

        phases = cursor.fetchall()

        # é•åè¨˜éŒ²å–å¾—
        cursor.execute(
            """
            SELECT violation_type, severity, fixed
            FROM violation_records
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        violations = cursor.fetchall()

        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        cursor.execute(
            """
            SELECT metric_name, metric_value, threshold, passed
            FROM quality_metrics
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        metrics = cursor.fetchall()

        conn.close()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = f"""
# Elder Flowå®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
## å®Ÿè¡ŒID: {execution_id}

### ğŸ“‹ åŸºæœ¬æƒ…å ±
- **ã‚¿ã‚¹ã‚¯å**: {execution[1]}
- **å„ªå…ˆåº¦**: {execution[2]}
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {execution[4]}
- **é–‹å§‹æ™‚åˆ»**: {execution[5]}
- **çµ‚äº†æ™‚åˆ»**: {execution[6] or 'N/A'}
- **å®Ÿè¡Œæ™‚é–“**: {execution[7] or 0:0.2f}ç§’
- **å“è³ªã‚¹ã‚³ã‚¢**: {execution[8] or 0:0.2f}/100

### ğŸ”„ ãƒ•ã‚§ãƒ¼ã‚ºé€²è¡Œ
"""

        for phase in phases:
            report += (
                f"- **{phase[0]}**: {phase[1]} ({phase[2]} â†’ {phase[3] or 'é€²è¡Œä¸­'})\n"
            )

        report += f"""
### âš ï¸ é•åè¨˜éŒ²
- **ç™ºè¦‹æ•°**: {execution[9]}
- **ä¿®æ­£æ•°**: {execution[10]}

é•åè©³ç´°:
"""

        for violation in violations:
            status = "âœ… ä¿®æ­£æ¸ˆ" if violation[2] else "âŒ æœªä¿®æ­£"
            report += f"- {violation[0]} ({violation[1]}): {status}\n"

        report += "\n### ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹\n"

        for metric in metrics:
            status = "âœ…" if metric[3] else "âŒ"
            report += (
                f"- **{metric[0]}**: {metric[1]} / {metric[2] or 'N/A'} {status}\n"
            )

        # è³¢è€…æ¨å¥¨
        if execution[11]:
            recommendations = json.loads(execution[11])
            report += f"\n### ğŸ§™â€â™‚ï¸ è³¢è€…æ¨å¥¨ ({len(recommendations)}ä»¶)\n"
            for rec in recommendations:
                report += f"- **{rec['sage']}**: {rec['recommendation'].get('summary', 'N/A')}\n"

        # Gitã‚³ãƒŸãƒƒãƒˆ
        if execution[13]:
            commits = json.loads(execution[13])
            report += f"\n### ğŸ“¤ Gitã‚³ãƒŸãƒƒãƒˆ ({len(commits)}ä»¶)\n"
            for commit in commits:
                report += f"- {commit}\n"

        return report

    async def get_execution_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """å®Ÿè¡Œå±¥æ­´å–å¾—"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT execution_id, task_name, status, quality_score,
                   start_time, end_time, duration_seconds
            FROM flow_executions
            ORDER BY start_time DESC
            LIMIT ?
        """,
            (limit,),
        )

        history = []
        for row in cursor.fetchall():
            history.append(
                {
                    "execution_id": row[0],
                    "task_name": row[1],
                    "status": row[2],
                    "quality_score": row[3],
                    "start_time": row[4],
                    "end_time": row[5],
                    "duration": row[6],
                }
            )

        conn.close()
        return history

    async def monitor_active_flows(self) -> List[Dict[str, Any]]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ãƒ­ãƒ¼ç›£è¦–"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT execution_id, task_name, phase, start_time
            FROM flow_executions
            WHERE status = 'in_progress'
            ORDER BY start_time DESC
        """
        )

        active_flows = []
        for row in cursor.fetchall():
            duration = (datetime.now() - datetime.fromisoformat(row[3])).total_seconds()
            active_flows.append(
                {
                    "execution_id": row[0],
                    "task_name": row[1],
                    "current_phase": row[2],
                    "duration_seconds": duration,
                }
            )

        conn.close()
        return active_flows


# CLIå®Ÿè¡Œ
async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    system = ElderFlowCoreEnhancement()

    print("ğŸŒŠ Elder Flow Core Enhancement System")
    print("=" * 50)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    execution_id = await system.start_flow_execution("Test Task", "high")
    print(f"âœ… å®Ÿè¡Œé–‹å§‹: {execution_id}")

    # ãƒ•ã‚§ãƒ¼ã‚ºé·ç§»
    await system.record_phase_transition(
        execution_id, FlowPhase.SAGE_CONSULTATION, FlowPhase.SERVANT_EXECUTION
    )

    # è³¢è€…æ¨å¥¨è¨˜éŒ²
    await system.record_sage_recommendation(
        execution_id,
        "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…",
        {"summary": "TDDå®Ÿè£…æ¨å¥¨", "details": "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆé–‹ç™º"},
    )

    # é•åè¨˜éŒ²
    await system.record_violation(
        execution_id,
        "abstract_method",
        "critical",
        "workers/test_worker.py",
        "validate_configæœªå®Ÿè£…",
    )

    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    await system.record_quality_metric(execution_id, "coverage", 85.5, 80.0)
    await system.record_quality_metric(execution_id, "complexity", 15.2, 20.0)

    # å®Ÿè¡Œå®Œäº†
    await system.complete_flow_execution(
        execution_id, FlowStatus.COMPLETED, 85.5, ["feat: test implementation"]
    )

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = await system.generate_execution_report(execution_id)
    print("\n" + report)

    # å±¥æ­´è¡¨ç¤º
    print("\nğŸ“Š å®Ÿè¡Œå±¥æ­´:")
    history = await system.get_execution_history(5)
    for h in history:
        print(f"- {h['execution_id']}: {h['task_name']} ({h['status']})")


if __name__ == "__main__":
    asyncio.run(main())
