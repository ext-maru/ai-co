#!/usr/bin/env python3
"""
Elders Guild ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’è‡ªå‹•å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
"""
import hashlib
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


class KnowledgeBaseManager:
    """ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… (Knowledge Sage) - 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ

    Elders Guildã®4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€ç¿¼ã‚’æ‹…ã†ã€éå»ã®è‹±æ™ºã‚’è“„ç©ãƒ»ç¶™æ‰¿ã™ã‚‹è³¢è€…ã€‚
    å­¦ç¿’ã«ã‚ˆã‚‹çŸ¥æµã®é€²åŒ–ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹çŸ¥è­˜ç®¡ç†ã€è‹±æ™ºã®ç¶™æ‰¿ã‚’è¡Œã†ã€‚
    """

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.project_root = Path("/home/aicompany/ai_co")
        self.knowledge_dir = self.project_root / "docs"
        self.index_file = self.knowledge_dir / "KNOWLEDGE_INDEX.md"
        self.cache_file = self.project_root / "db" / "knowledge_cache.json"
        self._cache = self._load_cache()

        # 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
        self.sage_type = "Knowledge Sage"
        self.wisdom_level = "knowledge_inheritance"
        self.collaboration_mode = True
        self.knowledge_evolution_active = True

        import logging

        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ“š {self.sage_type} åˆæœŸåŒ–å®Œäº† - çŸ¥è­˜ç¶™æ‰¿ã‚·ã‚¹ãƒ†ãƒ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")

    def _load_cache(self) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.cache_file.exists():
            with open(self.cache_file, "r") as f:
                return json.load(f)
        return {}

    def _save_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜"""
        self.cache_file.parent.mkdir(exist_ok=True)
        with open(self.cache_file, "w") as f:
            json.dump(self._cache, f, indent=2)

    def get_knowledge(self, topic: str) -> Optional[str]:
        """ãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã‚’å–å¾—"""
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        keyword_map = {
            "test": ["TEST_FRAMEWORK_KNOWLEDGE.md", "TEST_GUIDELINES.md"],
            "ãƒ†ã‚¹ãƒˆ": ["TEST_FRAMEWORK_KNOWLEDGE.md", "TEST_GUIDELINES.md"],
            "ai_command": ["AI_COMMAND_EXECUTOR_KNOWLEDGE.md"],
            "æ–°æ©Ÿèƒ½": ["AI_COMPANY_NEW_FEATURES.md"],
            "core": ["AI_COMPANY_CORE_KNOWLEDGE.md"],
            "é–‹ç™º": ["DEVELOPER_PERSONALITY.md", "PROJECT_INSTRUCTIONS.md"],
        }

        # ãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        relevant_files = []
        for keyword, files in keyword_map.items():
            if keyword in topic.lower():
                relevant_files.extend(files)

        # ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã¿
        knowledge_content = []
        for filename in set(relevant_files):
            filepath = self.knowledge_dir / filename
            if filepath.exists():
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()
                    knowledge_content.append(f"## ğŸ“š {filename}\n\n{content}")

        return "\n\n---\n\n".join(knowledge_content) if knowledge_content else None

    def get_all_knowledge_files(self) -> List[Dict]:
        """å…¨ã¦ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—"""
        knowledge_files = []

        for md_file in self.knowledge_dir.glob("*.md"):
            stat = md_file.stat()
            knowledge_files.append(
                {
                    "filename": md_file.name,
                    "path": str(md_file),
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "hash": self._get_file_hash(md_file),
                }
            )

        return knowledge_files

    def _get_file_hash(self, filepath: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        with open(filepath, "rb") as f:
            return hashlib.md5(f.read()).hexdigest()

    def check_updates(self) -> Dict[str, List[str]]:
        """æ›´æ–°ã•ã‚ŒãŸãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯"""
        current_files = self.get_all_knowledge_files()
        updates = {"new": [], "modified": [], "deleted": []}

        current_hashes = {f["filename"]: f["hash"] for f in current_files}
        cached_hashes = self._cache.get("file_hashes", {})

        # æ–°è¦ãƒ»æ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        for filename, hash_val in current_hashes.items():
            if filename not in cached_hashes:
                updates["new"].append(filename)
            elif cached_hashes[filename] != hash_val:
                updates["modified"].append(filename)

        # å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        for filename in cached_hashes:
            if filename not in current_hashes:
                updates["deleted"].append(filename)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        self._cache["file_hashes"] = current_hashes
        self._cache["last_check"] = datetime.now().isoformat()
        self._save_cache()

        return updates

    def search_knowledge(self, query: str) -> List[Dict]:
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹å†…ã‚’æ¤œç´¢"""
        results = []

        # ç¹°ã‚Šè¿”ã—å‡¦ç†
        for md_file in self.knowledge_dir.glob("*.md"):
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

                for i, line in enumerate(lines):
                    if query.lower() in line.lower():
                        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã¦çµæœã‚’ä¿å­˜
                        context_start = max(0, i - 2)
                        context_end = min(len(lines), i + 3)
                        context = "\n".join(lines[context_start:context_end])

                        results.append(
                            {
                                "file": md_file.name,
                                "line": i + 1,
                                "context": context,
                                "match": line.strip(),
                            }
                        )

        return results


# ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³
class KnowledgeAwareMixin:
    """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’å‚ç…§ã§ãã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³"""

    def __init__(self, *args, **kwargs):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        super().__init__(*args, **kwargs)
        self.knowledge_manager = KnowledgeBaseManager()

    def consult_knowledge(self, topic: str) -> Optional[str]:
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’å‚ç…§"""
        self.logger.info(f"Consulting knowledge base for: {topic}")
        knowledge = self.knowledge_manager.get_knowledge(topic)

        if knowledge:
            self.logger.info(f"Found relevant knowledge for: {topic}")
            return knowledge
        else:
            self.logger.warning(f"No knowledge found for: {topic}")
            return None

    def check_knowledge_updates(self):
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯"""
        updates = self.knowledge_manager.check_updates()

        if any(updates.values()):
            self.logger.info("Knowledge base updates detected:")
            for update_type, files in updates.items():
                if files:
                    self.logger.info(f"  {update_type}: {', '.join(files)}")

        return updates


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    manager = KnowledgeBaseManager()

    print("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
    print("\nğŸ“š ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«:")
    for file_info in manager.get_all_knowledge_files():
        print(f"  - {file_info['filename']} ({file_info['size']} bytes)")

    # ãƒ†ã‚¹ãƒˆæ¤œç´¢
    print("\nğŸ” 'test'ã«é–¢ã™ã‚‹ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢:")
    test_knowledge = manager.get_knowledge("test")
    if test_knowledge:
        print(f"  è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ï¼ˆ{len(test_knowledge)} æ–‡å­—ï¼‰")

    # æ›´æ–°ãƒã‚§ãƒƒã‚¯
    print("\nğŸ“Š æ›´æ–°ãƒã‚§ãƒƒã‚¯:")
    updates = manager.check_updates()
    print(f"  æ–°è¦: {len(updates['new'])}")
    print(f"  æ›´æ–°: {len(updates['modified'])}")
    print(f"  å‰Šé™¤: {len(updates['deleted'])}")
