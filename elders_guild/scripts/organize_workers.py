#!/usr/bin/env python3
# é‡è¤‡ãƒ¯ãƒ¼ã‚«ãƒ¼æ•´ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

import json
import os
import shutil
from datetime import datetime
from pathlib import Path


class WorkerOrganizer:
    def __init__(self):
        self.workers_dir = Path("/home/aicompany/ai_co/workers")
        self.archive_dir = (
    """WorkerOrganizerãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¯ãƒ©ã‚¹"""
            self.workers_dir / "_archived" / datetime.now().strftime("%Y%m%d")
        )
        self.worker_mapping = {}

    def organize(self):
        print("ğŸ”§ ãƒ¯ãƒ¼ã‚«ãƒ¼æ•´ç†ã‚’é–‹å§‹ã—ã¾ã™...")

        """organizeãƒ¡ã‚½ãƒƒãƒ‰"""
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.archive_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ•´ç†è¨ˆç”»
        self.analyze_workers()
        self.archive_duplicates()
        self.update_imports()
        self.generate_report()

        print("âœ… ãƒ¯ãƒ¼ã‚«ãƒ¼æ•´ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")

    def analyze_workers(self)print("\nğŸ“Š ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­...")
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""

        # é‡è¤‡åˆ¤å®šãƒãƒƒãƒ—
        worker_groups = {
            "pm_worker": {
                "primary": "pm_worker_enhanced.py",  # æœ€æ–°ç‰ˆã‚’ä½¿ç”¨
                "duplicates": [
                    "pm_worker.py",
                    "pm_worker_v2.0py",
                    "enhanced_pm_worker.py",
                    "pm_worker_gitflow.py",
                    "quality_pm_worker.py",
                ],
            },
            "task_worker": {
                "primary": "task_worker.py",
                "duplicates": [
                    "enhanced_task_worker.py",
                    "quality_task_worker.py",
                    "dialog_task_worker.py",
                ],
            },
            "result_worker": {
                "primary": "result_worker.py",
                "duplicates": ["result_worker_simple.py"],
            },
            "command_executor": {
                "primary": "command_executor_worker.py",
                "duplicates": ["command_executor_worker_backup_*.py"],
            },
        }

        self.worker_mapping = worker_groups

        # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        all_files = list(self.workers_dir.glob("*.py"))
        print(f"  ç·ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_files)}")

    def archive_duplicates(self)print("\nğŸ“¦ é‡è¤‡ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸­...")
    """é‡è¤‡ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""

        archived_count = 0

        for group_name, group_info in self.worker_mapping.items():
        # ç¹°ã‚Šè¿”ã—å‡¦ç†
            primary = group_info["primary"]

            for duplicate in group_info["duplicates"]:
                # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¯¾å¿œ
                if "*" in duplicate:
                    files = self.workers_dir.glob(duplicate)
                else:
                    files = [self.workers_dir / duplicate]

                for file_path in files:
                    if file_path.exists() and file_path.name != primary:
                        dest = self.archive_dir / file_path.name
                        shutil.move(str(file_path), str(dest))
                        print(f"  ğŸ“ {file_path.name} â†’ _archived/")
                        archived_count += 1

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç§»å‹•
        for backup_file in self.workers_dir.glob("*.bak"):
            dest = self.archive_dir / backup_file.name
            shutil.move(str(backup_file), str(dest))
            archived_count += 1

        print(f"  âœ“ {archived_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã—ãŸ")

    def update_imports(self)print("\nğŸ” ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®ç¢ºèª...")
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æ›´æ–°ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º"""

        # ã‚³ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‚‚ã®ã‚’æ¤œç´¢
        core_files = [
            "/home/aicompany/ai_co/commands/ai-start",
            "/home/aicompany/ai_co/libs/worker_controller.py",
        ]

        updates_needed = []

        # ç¹°ã‚Šè¿”ã—å‡¦ç†
        for core_file in core_files:
            if Path(core_file).exists():
                with open(core_file, "r") as f:
                    content = f.read()

                # æ—§ãƒ¯ãƒ¼ã‚«ãƒ¼åã‚’ãƒã‚§ãƒƒã‚¯
                for group in self.worker_mapping.values():
                    for duplicate in group["duplicates"]:
                        if duplicate.replace(".py", "") in content:
                            updates_needed.append(core_file)
                            break

        if updates_needed:
            print(f"  âš ï¸  ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°ãŒå¿…è¦:")
            for file in updates_needed:
                print(f"    - {file}")
        else:
            print("  âœ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æ›´æ–°ã¯ä¸è¦ã§ã™")

    def generate_report(self):
        """æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_path = self.workers_dir / "worker_organization_report.json"

        report = {
            "timestamp": datetime.now().isoformat(),
            "archive_location": str(self.archive_dir),
            "worker_mapping": self.worker_mapping,
            "summary": {
                "total_workers_before": len(list(self.workers_dir.glob("*.py"))),
                "active_workers": [v["primary"] for v in self.worker_mapping.values()],
                "archived_count": (
                    len(list(self.archive_dir.glob("*.py")))
                    if self.archive_dir.exists()
                    else 0
                ),
            },
        }

        with open(report_path, "w") as f:
            json.dump(report, f, indent=2)

        print(f"\nğŸ“‹ æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_path}")


if __name__ == "__main__":
    organizer = WorkerOrganizer()
    organizer.organize()
