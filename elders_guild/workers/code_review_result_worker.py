#!/usr/bin/env python3
"""
ğŸŒ³ Elder Tree Integrated CodeReviewResultWorker
ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ä»˜ãResultWorker - Elders Guildçµ±åˆç‰ˆ

Elders Guild Integration:
- ğŸŒŸ Grand Elder maru oversight
- ğŸ¤– Claude Elder execution guidance
- ğŸ§™â€â™‚ï¸ Four Sages wisdom consultation
- ğŸ›ï¸ Elder Council decision support
- âš”ï¸ Elder Servants coordination

Part of the Elder Tree Hierarchy for code review result generation
"""

import asyncio
import datetime
import difflib
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.async_base_worker_v2 import AsyncBaseWorkerV2

# Elder Tree Integration imports
try:
    from libs.elder_council_summoner import ElderCouncilSummoner
    from libs.elder_tree_hierarchy import ElderMessage, ElderRank, get_elder_tree
    from libs.four_sages_integration import FourSagesIntegration

    ELDER_TREE_AVAILABLE = True
except ImportError as e:
    # Handle specific exception case
    logging.warning(f"Elder Tree integration not available: {e}")
    FourSagesIntegration = None
    ElderCouncilSummoner = None
    get_elder_tree = None
    ElderMessage = None
    ElderRank = None
    ELDER_TREE_AVAILABLE = False

class CodeReviewResultWorker(AsyncBaseWorkerV2):
    """ğŸŒ³ Elder Treeçµ±åˆã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¯ãƒ¼ã‚«ãƒ¼"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__(
            worker_name="code_review_result_worker",
            config=config,
            input_queues=["ai_results"],
            output_queues=["ai_final"],
        )

        self.output_formats = config.get("output_formats", ["json", "markdown", "html"])

        )
        self.output_dir = config.get("output_dir", "output/reports")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)

        # Elder Tree Integration
        self.elder_tree = None
        self.four_sages = None
        self.elder_council_summoner = None
        self.elder_integration_enabled = False
        self._initialize_elder_systems()

    def _initialize_elder_systems(self):
        """Elder Tree ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†ä»˜ãï¼‰"""
        try:
            if get_elder_tree:
                self.elder_tree = get_elder_tree()
                self.logger.info("ğŸŒ³ Elder Tree Hierarchy connected")

            if FourSagesIntegration:
                self.four_sages = FourSagesIntegration()
                self.logger.info("ğŸ§™â€â™‚ï¸ Four Sages Integration activated")

            if ElderCouncilSummoner:
                self.elder_council_summoner = ElderCouncilSummoner()
                self.logger.info("ğŸ›ï¸ Elder Council Summoner initialized")

            if all([self.elder_tree, self.four_sages, self.elder_council_summoner]):
                self.elder_integration_enabled = True
                self.logger.info("âœ… Full Elder Tree Integration enabled")
            else:
                self.logger.warning(
                    "âš ï¸ Partial Elder Tree Integration - some systems unavailable"
                )

        except Exception as e:
            # Handle specific exception case
            self.logger.error(f"Elder Tree initialization failed: {e}")
            self.elder_integration_enabled = False

    async def process_message(self, message: Dict[str, Any]) -> Dict[str, Any]message_type = message.get("message_type"):
    """ Elder Treeçµ±åˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç† - ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†"""

        # Elder Treeãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ :
        if self.elder_integration_enabled:
            message["elder_metadata"] = {
                "processed_by": "CodeReviewResultWorker",
                "elder_rank": ElderRank.ELDER_SERVANT.value
                if ElderRank
                else "elder_servant",
                "wisdom_consulted": False,
                "council_escalated": False,
            }

        try:
            if message_type == "review_completion":
                return await self._generate_review_result(message)
            else:
                # Elder Council ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                if self.elder_integration_enabled and self.elder_council_summoner:
                    # Complex condition - consider breaking down
                    await self._escalate_to_elder_council(
                        {
                            "issue_type": "unsupported_message",
                            "message_type": message_type,
                            "worker": "code_review_result_worker",
                        }
                    )
                raise ValueError(f"Unsupported message type: {message_type}")
        except Exception as e:
            # Handle specific exception case
            if self.elder_integration_enabled:
                await self._handle_elder_error(e, message)
            raise

    async def _escalate_to_elder_council(self, issue: Dict[str, Any]):
        """Elder Council ã¸ã®å•é¡Œã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        try:
            if self.elder_council_summoner:
                await self.elder_council_summoner.escalate_issue(
                    issue_type=issue["issue_type"],
                    details=issue,
                    requester="CodeReviewResultWorker",
                )
                self.logger.info(
                    f"ğŸ›ï¸ Issue escalated to Elder Council: {issue['issue_type']}"
                )
        except Exception as e:
            # Handle specific exception case
            self.logger.error(f"Failed to escalate to Elder Council: {e}")

    async def _handle_elder_error(self, error: Exception, context: Dict[str, Any]):
        """Elder Tree ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        try:
            await self._escalate_to_elder_council(
                {
                    "issue_type": "worker_error",
                    "error": str(error),
                    "context": context,
                    "worker": "code_review_result_worker",
                }
            )
        except Exception as escalation_error:
            # Handle specific exception case
            self.logger.error(f"Failed to handle elder error: {escalation_error}")

    async def _consult_four_sages(
        self, consultation_type: str, data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Four Sages ã¸ã®çŸ¥æµã®ç›¸è«‡"""
        if not self.four_sages:
            return {"consulted": False, "wisdom": None}

        try:
            wisdom = await self.four_sages.consult(
                sage_type=consultation_type, query_data=data
            )
            return {"consulted": True, "wisdom": wisdom}
        except Exception as e:
            # Handle specific exception case
            self.logger.error(f"Four Sages consultation failed: {e}")
            return {"consulted": False, "wisdom": None, "error": str(e)}

    async def _generate_review_result(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸŒ³ Elder Treeçµ±åˆãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã®ç”Ÿæˆ"""
        task_id = message["task_id"]
        payload = message["payload"]

        # Four Sages çŸ¥æµã®ç›¸è«‡
        sages_wisdom = await self._consult_four_sages(
            "rag",
            {
                "task_type": "review_result_generation",
                "task_id": task_id,
                "payload": payload,
            },
        )

        # åŸºæœ¬æƒ…å ±ã®å–å¾—
        final_quality_score = payload["final_quality_score"]
        total_iterations = payload["total_iterations"]
        improvement_summary = payload["improvement_summary"]
        review_report = payload.get(
            "review_report",
            {
                "syntax_score": 90,
                "logic_score": 85,
                "performance_score": 88,
                "security_score": 87,
            },
        )

        # å“è³ªæ”¹å–„æƒ…å ±ã®è¨ˆç®—
        quality_improvement = await self._calculate_quality_improvement(
            improvement_summary
        )

        # ã‚³ãƒ¼ãƒ‰æ¯”è¼ƒæƒ…å ±ã®ç”Ÿæˆ
        code_comparison = await self._generate_code_comparison(payload)

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        detailed_report = await self._generate_detailed_report(
            payload, quality_improvement
        )

        # å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ
        quality_trends = await self._analyze_quality_trends(payload)

        # å„å½¢å¼ã§ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        output_formats = await self._generate_output_formats(task_id, payload)

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å‡¦ç†

        result = {
            "message_id": f"result_{task_id}",
            "task_id": task_id,
            "worker_source": "result_worker",
            "worker_target": "final",
            "message_type": "review_result",
            "payload": {
                "status": "completed",
                "quality_improvement": quality_improvement,
                "code_comparison": code_comparison,
                "detailed_report": detailed_report,
                "quality_trends": quality_trends,
                "output_formats": output_formats,

            },
        }

        # Elder Tree ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        if self.elder_integration_enabled:
            result["elder_metadata"] = {
                "processed_by": "CodeReviewResultWorker",
                "elder_rank": ElderRank.ELDER_SERVANT.value
                if ElderRank
                else "elder_servant",
                "wisdom_consulted": sages_wisdom.get("consulted", False),
                "sages_wisdom": sages_wisdom,
                "processing_timestamp": datetime.datetime.now().isoformat(),
                "elder_tree_version": "1.0",
            }

        return result

    async def _calculate_quality_improvement(
        self, improvement_summary: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å“è³ªæ”¹å–„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        initial_score = improvement_summary.get("initial_score", 0)
        final_score = improvement_summary.get("final_score", 0)

        # æ”¹å–„ç‡ã®è¨ˆç®—
        if initial_score > 0:
            improvement_percentage = (
                (final_score - initial_score) / initial_score
            ) * 100
        else:
            improvement_percentage = 0

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ”¹å–„æƒ…å ±ï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰
        category_improvements = {
            "syntax": {"before": 70, "after": 90, "improvement": 20},
            "logic": {"before": 80, "after": 85, "improvement": 5},
            "performance": {"before": 75, "after": 88, "improvement": 13},
            "security": {"before": 85, "after": 87, "improvement": 2},
        }

        return {
            "before": initial_score,
            "after": final_score,
            "improvement_percentage": improvement_percentage,
            "category_improvements": category_improvements,
        }

    async def _generate_code_comparison(
        self, payload: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰æ¯”è¼ƒæƒ…å ±ã®ç”Ÿæˆ"""
        original_code = payload.get("original_code", "# Original code")
        final_code = payload.get("final_code", "# Final code")

        # å·®åˆ†ã®è¨ˆç®—
        diff_lines = list(
            difflib.unified_diff(
                original_code.splitlines(keepends=True),
                final_code.splitlines(keepends=True),
                fromfile="Before",
                tofile="After",
            )
        )

        # å·®åˆ†çµ±è¨ˆã®è¨ˆç®—
        lines_added = sum(
            1
            for line in diff_lines
            if line.startswith("+") and not line.startswith("+++")
        )
        lines_removed = sum(
            1
            for line in diff_lines
            if line.startswith("-") and not line.startswith("---")
        )
        lines_modified = max(lines_added, lines_removed)  # ç°¡æ˜“è¨ˆç®—

        return {
            "before": original_code,
            "after": final_code,
            "diff_summary": {
                "lines_added": lines_added,
                "lines_removed": lines_removed,
                "lines_modified": lines_modified,
            },
        }

    async def _generate_detailed_report(
        self, payload: Dict[str, Any], quality_improvement: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        # ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ
        summary = f"Code review completed with quality score improvement from {quality_improvement[" \
            "Code review completed with quality score improvement from {quality_improvement[" \
            "Code review completed with quality score improvement from " \
                "{quality_improvement["before']:0.1f} to {quality_improvement['after']:0.1f}"

        # æ”¹å–„ç‚¹ã®æ•´ç†
        improvements = payload.get("improvement_summary", {}).get(
            "improvements_made", []
        )

        # æœ€çµ‚æ¨å¥¨äº‹é …
        final_recommendations = [
            "Continue following established coding standards",
            "Regular code reviews to maintain quality",
            "Consider automated testing integration",
        ]

        # ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
        executive_summary = {
            "overall_assessment": "Successful code review completion",
            "key_achievements": improvements,
            "recommendations": final_recommendations,
            "next_steps": [
                "Deploy to production",
                "Monitor performance",
                "Schedule follow-up review",
            ],
        }

        return {
            "summary": summary,
            "improvements": improvements,
            "final_recommendations": final_recommendations,
            "executive_summary": executive_summary,
        }

    async def _analyze_quality_trends(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ"""
        # åå¾©å±¥æ­´ã®å–å¾—
        iteration_history = payload.get("iteration_history", [])

        if not iteration_history:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åå¾©ãƒ‡ãƒ¼ã‚¿
            iteration_history = [
                {"iteration": 1, "quality_score": 65.5},
                {"iteration": 2, "quality_score": 87.5},
            ]

        # åå¾©ã‚¹ã‚³ã‚¢ã®æŠ½å‡º
        iteration_scores = [item["quality_score"] for item in iteration_history]

        # æ”¹å–„ç‡ã®è¨ˆç®—
        if len(iteration_scores) > 1:
            improvement_rate = (iteration_scores[-1] - iteration_scores[0]) / len(
                iteration_scores
            )
        else:
            improvement_rate = 0

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if improvement_rate > 5:
            trend_analysis = "improving"
        elif improvement_rate < -5:
            trend_analysis = "declining"
        else:
            trend_analysis = "stable"

        return {
            "iteration_scores": iteration_scores,
            "improvement_rate": improvement_rate,
            "trend_analysis": trend_analysis,
        }

    async def _generate_output_formats(
        self, task_id: str, payload: Dict[str, Any]
    ) -> Dict[str, str]:
        """å„å½¢å¼ã§ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        output_formats = {}

        # JSONå½¢å¼
        if "json" in self.output_formats:
            json_path = os.path.join(self.output_dir, f"{task_id}_report.json")
            output_formats["json"] = json_path

            # JSONãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            json_report = {
                "task_id": task_id,
                "timestamp": datetime.datetime.now().isoformat(),
                "quality_score": payload.get("final_quality_score", 0),
                "details": payload,
            }

            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(json_report, f, indent=2, ensure_ascii=False)

        # Markdownå½¢å¼
        if "markdown" in self.output_formats:
            markdown_path = os.path.join(self.output_dir, f"{task_id}_report.md")
            output_formats["markdown"] = markdown_path

            # Markdownãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            markdown_content = f"""# Code Review Report

## Task: {task_id}

## Quality Score: {payload.get('final_quality_score', 0):0.1f}/100

## Summary
Code review completed successfully with quality improvements.

## Improvements Made
- Code quality enhanced through iterative review process
- Various issues identified and resolved

## Final Recommendations
- Continue following established coding standards
- Regular code reviews to maintain quality
"""

            with open(markdown_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)

        # HTMLå½¢å¼
        if "html" in self.output_formats:
            html_path = os.path.join(self.output_dir, f"{task_id}_report.html")
            output_formats["html"] = html_path

            # HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>Code Review Report - {task_id}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ color: #333; }}
        .score {{ color: #4CAF50; font-size: 24px; font-weight: bold; }}
    </style>
</head>
<body>
    <h1 class="header">Code Review Report</h1>
    <h2>Task: {task_id}</h2>
    <p class="score">Quality Score: {payload.get('final_quality_score', 0):0.1f}/100</p>

    <h3>Summary</h3>
    <p>Code review completed successfully with quality improvements.</p>

    <h3>Improvements Made</h3>
    <ul>
        <li>Code quality enhanced through iterative review process</li>
        <li>Various issues identified and resolved</li>
    </ul>
</body>
</html>"""

            with open(html_path, "w", encoding="utf-8") as f:
                f.write(html_content)

        return output_formats

        self, detailed_report: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é©ç”¨"""
        # ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘ã®è¿½åŠ é …ç›®
        detailed_report["compliance_check"] = {
            "status": "passed",
            "standards": ["PEP8", "Security Guidelines", "Company Standards"],
            "violations": [],
        }

        detailed_report["risk_assessment"] = {
            "overall_risk": "low",
            "security_risk": "minimal",
            "performance_risk": "low",
            "maintenance_risk": "low",
        }

        detailed_report["cost_benefit_analysis"] = {
            "development_cost": "2 hours",
            "maintenance_cost_reduction": "20%",
            "quality_improvement_value": "high",
        }

        return detailed_report

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
async def main():
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    config = {
        "output_formats": ["json", "markdown", "html"],

        "output_dir": "output/reports",
    }

    worker = CodeReviewResultWorker(config)

    print("ğŸš€ CodeReviewResultWorker started")

    try:
        while True:
            await asyncio.sleep(10)
            print("ğŸ’“ CodeReview ResultWorker heartbeat")
    except KeyboardInterrupt:
        # Handle specific exception case
        print("\nğŸ›‘ CodeReview ResultWorker stopping...")
        await worker.shutdown()
        print("âœ… CodeReview ResultWorker stopped")

if __name__ == "__main__":
    asyncio.run(main())
