#!/usr/bin/env python3
"""
ğŸš¨ Incident Sage Business Logic - ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯åˆ†é›¢
=====================================

Elder Loop Phase 1: Knowledge Sageãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨
soul.pyã‹ã‚‰ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ»å“è³ªç›£è¦–ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ†é›¢

Author: Claude Elder
Created: 2025-07-23
"""

import asyncio
import sqlite3
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from statistics import mean
from dataclasses import asdict

# Incident Sage Models import (Elder Treeå…±é€šãƒ‘ã‚¹å¯¾å¿œ)
import sys
sys.path.append("/home/aicompany/ai_co/elders_guild")
from src.incident_sage.abilities.incident_models import (
    Incident, IncidentSeverity, IncidentStatus, IncidentCategory,
    QualityMetric, QualityStandard, QualityAssessment,
    IncidentResponse, AlertRule, MonitoringTarget
)


class IncidentProcessor:


"""
    Incident Sageæ ¸å¿ƒãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å‡¦ç†ã‚¯ãƒ©ã‚¹
    
    Knowledge Sageãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨ã—ãŸãƒ”ãƒ¥ã‚¢ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯:
    - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä¾å­˜æ€§ãªã—
    - A2Aé€šä¿¡ã‹ã‚‰ç‹¬ç«‹
    - ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§å‘ä¸Š
    - Elder Loopå¯¾å¿œ
    """ Optional[Path] = None, test_mode: bool = False):
        """Incident ProcessoråˆæœŸåŒ–"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        if test_mode:
            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼šä¸€æ™‚çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            import tempfile
            temp_dir = tempfile.mkdtemp(prefix="incident_sage_test_")
            self.data_dir = Path(temp_dir)
        else:
            self.data_dir = data_dir or Path("data/incident_sage")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.db_path = self.data_dir / "incident_sage.db"
        self.logger = logging.getLogger("incident_processor")
        
        # ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.incidents: Dict[str, Incident] = {}
        self.quality_standards: Dict[str, QualityStandard] = {}
        self.alert_rules: Dict[str, AlertRule] = {}
        self.monitoring_targets: Dict[str, MonitoringTarget] = {}
        
        # é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.operational_metrics = {
            "incidents_detected": 0,
            "incidents_resolved": 0,
            "average_resolution_time": 0.0,
            "quality_assessments_performed": 0,
            "alert_rules_active": 0,
            "monitoring_targets_healthy": 0,
            "pattern_learning_count": 0,
            "automated_remediations": 0
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        self.incident_patterns: Dict[str, Any] = {}
        self.correlation_cache: Dict[str, List[str]] = {}
        
        # åˆæœŸåŒ–å®Ÿè¡Œ
        self._initialize_database()
        self._load_default_quality_standards()
        if not test_mode:
            self._load_all_data()
        
        self.logger.info("Incident Processor initialized successfully")
    
    def reset_for_testing(self):

            """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ""" 0,
            "incidents_resolved": 0,
            "average_resolution_time": 0.0,
            "quality_assessments_performed": 0,
            "alert_rules_active": 0,
            "monitoring_targets_healthy": 0,
            "pattern_learning_count": 0,
            "automated_remediations": 0
        }
        self.incident_patterns.clear()
        self.correlation_cache.clear()
    
    async def process_action(self, action: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
        
        Knowledge Sageãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨:
        çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œ
        """
        try:
            self.logger.info(f"Processing action: {action}")
            
            if action == "detect_incident":
                return await self._detect_incident_action(data)
            elif action == "register_incident":
                return await self._register_incident_action(data)
            elif action == "assess_quality":
                return await self._assess_quality_action(data)
            elif action == "respond_to_incident":
                return await self._respond_to_incident_action(data)
            elif action == "create_alert_rule":
                return await self._create_alert_rule_action(data)
            elif action == "evaluate_alert_rules":
                return await self._evaluate_alert_rules_action(data)
            elif action == "register_monitoring_target":
                return await self._register_monitoring_target_action(data)
            elif action == "check_target_health":
                return await self._check_target_health_action(data)
            elif action == "learn_incident_patterns":
                return await self._learn_incident_patterns_action(data)
            elif action == "analyze_correlations":
                return await self._analyze_correlations_action(data)
            elif action == "attempt_automated_remediation":
                return await self._attempt_automated_remediation_action(data)
            elif action == "search_similar_incidents":
                return await self._search_similar_incidents_action(data)
            elif action == "get_operational_metrics":
                return await self._get_operational_metrics_action(data)
            elif action == "register_quality_standard":
                return await self._register_quality_standard_action(data)
            elif action == "get_statistics":
                return await self._get_statistics_action(data)
            elif action == "health_check":
                return await self._health_check_action(data)
            else:
                return {
                    "success": False,
                    "error": f"Unknown action: {action}",
                    "action": action
                }
                
        except Exception as e:
            self.logger.error(f"Error processing action {action}: {e}")
            return {
                "success": False,
                "error": str(e),
                "action": action
            }
    
    # === Core Business Logic Actions ===
    
    async def _detect_incident_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¤œçŸ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not data:
                return {"success": False, "error": "Empty data provided"}
            
            if data is None:
                return {"success": False, "error": "NULL data provided"}
                
            # JSONæ§‹é€ æ¤œè¨¼
            if not isinstance(data, dict):
                return {"success": False, "error": "Invalid data structure, expected dict"}
            
            anomaly_data = data.get("anomaly_data", {})
            
            # anomaly_dataã®å¿…é ˆãƒã‚§ãƒƒã‚¯
            if not anomaly_data or not isinstance(anomaly_data, dict):
                return {"success": False, "error": "Missing or invalid anomaly_data"}
            
            # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯ (JSONã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œã§1MBåˆ¶é™)
            try:
                data_size = len(json.dumps(data))
                if data_size > 1024 * 1024:  # 1MB
                    return {"success": False, "error": f"Data too large: {data_size} bytes"}
            except Exception:
                return {"success": False, "error": "Data not JSON serializable"}
            
            start_time = time.time()
            
            # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é‡è¦åº¦åˆ¤å®š
            severity = self._determine_severity(anomaly_data)
            category = self._determine_category(anomaly_data)
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ
            incident = Incident(
                title=f"Anomaly detected in {anomaly_data.get('component', 'unknown')}",
                description=self._generate_incident_description(anomaly_data),
                severity=severity,
                category=category,
                affected_components=[anomaly_data.get('component', 'unknown')],
                tags=self._extract_tags(anomaly_data),
                detection_time_ms=int((time.time() - start_time) * 1000),
                confidence_score=anomaly_data.get('confidence', 0.8)
            )
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™»éŒ²
            await self._register_incident_internal(incident)
            
            # è‡ªå‹•å¯¾å¿œåˆ¤å®š
            auto_response_triggered = False
            if severity in [IncidentSeverity.CRITICAL, IncidentSeverity.HIGH]:
                auto_response_triggered = True
                # Note: å®Ÿéš›ã®è‡ªå‹•å¯¾å¿œã¯åˆ¥é€”å®Ÿè¡Œ
            
            self.operational_metrics["incidents_detected"] += 1
            
            return {
                "success": True,
                "data": {
                    "incident_id": incident.incident_id,
                    "title": incident.title,
                    "severity": incident.severity.value,
                    "category": incident.category.value,
                    "status": incident.status.value,
                    "confidence_score": incident.confidence_score,
                    "detection_time_ms": incident.detection_time_ms,
                    "auto_response_triggered": auto_response_triggered
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _assess_quality_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å“è³ªè©•ä¾¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not data or not isinstance(data, dict):
                return {"success": False, "error": "Invalid or empty data"}
            
            standard_id = data.get("standard_id")
            component = data.get("component")
            metrics = data.get("metrics", {})
            
            if not standard_id or not component:
                return {"success": False, "error": "standard_id and component are required"}
            
            if standard_id not in self.quality_standards:
                return {"success": False, "error": f"Quality standard not found: {standard_id}"}
            
            standard = self.quality_standards[standard_id]
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
            metric_scores = {}
            violations = []
            recommendations = []
            
            for metric_name, metric_def in standard.metrics.items():
                if metric_name in metrics:
                    actual_value = metrics[metric_name]
                    metric_scores[metric_name] = actual_value
                    
                    # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                    if actual_value < metric_def.threshold_min:
                        violations.append(f"{metric_name}: {actual_value} < {metric_def.threshold_min}")
                        recommendations.append(f"Improve {metric_name} to meet minimum threshold")
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
            overall_score = self._calculate_overall_score(metric_scores, standard)
            compliance_score = (overall_score / 100) * 100
            is_compliant = compliance_score >= standard.compliance_threshold
            
            # è©•ä¾¡çµæœä½œæˆ
            assessment = QualityAssessment(
                target_component=component,
                standard_id=standard_id,
                overall_score=overall_score,
                compliance_score=compliance_score,
                is_compliant=is_compliant,
                metric_scores=metric_scores,
                violations=violations,
                recommendations=recommendations
            )
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            await self._save_quality_assessment(assessment)
            
            self.operational_metrics["quality_assessments_performed"] += 1
            
            # å“è³ªå•é¡Œã®å ´åˆã¯ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç”Ÿæˆé€šçŸ¥
            quality_incident_created = False
            if not is_compliant:
                # å“è³ªå•é¡Œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç”Ÿæˆãƒãƒ¼ã‚¯
                quality_incident_created = True
            
            return {
                "success": True,
                "data": {
                    "assessment_id": assessment.assessment_id,
                    "target_component": assessment.target_component,
                    "overall_score": assessment.overall_score,
                    "compliance_score": assessment.compliance_score,
                    "is_compliant": assessment.is_compliant,
                    "violations": assessment.violations,
                    "recommendations": assessment.recommendations,
                    "confidence_score": assessment.confidence_score,
                    "quality_incident_created": quality_incident_created
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _respond_to_incident_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            incident_id = data.get("incident_id")
            
            if not incident_id:
                return {"success": False, "error": "incident_id is required"}
            
            if incident_id not in self.incidents:
                return {"success": False, "error": f"Incident not found: {incident_id}"}
            
            incident = self.incidents[incident_id]
            
            # å¯¾å¿œæˆ¦ç•¥æ±ºå®š
            response_actions = self._determine_response_actions(incident)
            
            # å¯¾å¿œå®Ÿè¡Œ
            response = IncidentResponse(
                incident_id=incident_id,
                action_type="automated_response",
                description=f"Automated response to {incident.severity.value} incident",
                execution_steps=response_actions,
                responder="incident_processor",
                automated=True
            )
            
            # å®Ÿéš›ã®å¯¾å¿œå®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            success = await self._execute_response_actions(response_actions, incident)
            
            if success:
                response.status = "completed"
                response.effectiveness_score = 0.8
                incident.status = IncidentStatus.RESOLVED
                incident.resolved_at = datetime.now()
                incident.resolution_time_ms = int((datetime.now() - incident.detected_at).total_seconds() * 1000)
                self.operational_metrics["incidents_resolved"] += 1
            else:
                response.status = "failed"
                response.effectiveness_score = 0.2
                incident.status = IncidentStatus.ESCALATED
            
            response.completed_at = datetime.now()
            
            # æ›´æ–°ä¿å­˜
            await self._register_incident_internal(incident)
            
            return {
                "success": True,
                "data": {
                    "incident_id": incident_id,
                    "response_status": response.status,
                    "effectiveness_score": response.effectiveness_score,
                    "execution_steps": response.execution_steps,
                    "incident_status": incident.status.value,
                    "resolution_time_ms": incident.resolution_time_ms
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _learn_incident_patterns_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            patterns = []
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
            category_incidents = {}
            for incident in self.incidents.values():
                category = incident.category.value
                if category not in category_incidents:
                    category_incidents[category] = []
                category_incidents[category].append(incident)
            
            for category, incidents in category_incidents.items():
                if len(incidents) >= 2:  # æœ€ä½2ã¤ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã§å­¦ç¿’
                    pattern = {
                        "category": category,
                        "incident_count": len(incidents),
                        "common_components": self._find_common_components(incidents),
                        "common_tags": self._find_common_tags(incidents),
                        "average_severity": self._calculate_average_severity(incidents),
                        "typical_causes": self._extract_typical_causes(incidents)
                    }
                    patterns.append(pattern)
                    self.incident_patterns[category] = pattern
            
            self.operational_metrics["pattern_learning_count"] += len(patterns)
            
            return {
                "success": True,
                "data": {
                    "patterns_learned": len(patterns),
                    "patterns": patterns,
                    "total_incidents_analyzed": len(self.incidents)
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _get_statistics_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±å–å¾—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçµ±è¨ˆ
            incident_stats = {
                "total_incidents": len(self.incidents),
                "incidents_by_status": self._count_by_status(),
                "incidents_by_severity": self._count_by_severity(),
                "incidents_by_category": self._count_by_category(),
                "resolution_rate": self._calculate_resolution_rate(),
                "average_resolution_time_minutes": self._calculate_average_resolution_time()
            }
            
            # å“è³ªçµ±è¨ˆ
            quality_stats = {
                "quality_standards_count": len(self.quality_standards),
                "total_assessments": self.operational_metrics["quality_assessments_performed"],
                "assessments_performed": self.operational_metrics["quality_assessments_performed"],
                "average_quality_score": 85.0,  # ä»®ã®å€¤
                "compliance_trends": self._analyze_compliance_trends()
            }
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
            alert_stats = {
                "alert_rules_total": len(self.alert_rules),
                "alert_rules_active": len([r for r in self.alert_rules.values() if r.enabled]),
                "total_alerts_triggered": sum(rule.trigger_count for rule in self.alert_rules.values())
            }
            
            # ç›£è¦–çµ±è¨ˆ
            monitoring_stats = {
                "monitoring_targets_count": len(self.monitoring_targets),
                "healthy_targets": len([t for t in self.monitoring_targets.values() if t.status == "healthy"]),
                "average_uptime": self._calculate_average_uptime()
            }
            
            # é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            operational_metrics = self.operational_metrics.copy()
            
            return {
                "success": True,
                "data": {
                    "incident_statistics": incident_stats,
                    "quality_statistics": quality_stats,
                    "alert_statistics": alert_stats,
                    "monitoring_statistics": monitoring_stats,
                    "operational_metrics": operational_metrics,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _health_check_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            health_status = {
                "status": "healthy",
                "agent_name": "Incident Processor",
                "incidents_managed": len(self.incidents),
                "quality_standards": len(self.quality_standards),
                "alert_rules": len(self.alert_rules),
                "monitoring_targets": len(self.monitoring_targets),
                "uptime_seconds": time.time(),  # ç°¡æ˜“å®Ÿè£…
                "operational_metrics": self.operational_metrics.copy()
            }
            
            return {
                "success": True,
                "data": health_status
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    # === Internal Helper Methods ===
    
    async def _register_incident_internal(self, incident: Incident):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå†…éƒ¨ç™»éŒ²"""
        self.incidents[incident.incident_id] = incident
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO incidents VALUES (
                    ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
                )
            """, (
                incident.incident_id, incident.title, incident.description,
                incident.severity.value, incident.status.value, incident.category.value,
                incident.source, json.dumps(incident.affected_components),
                json.dumps(incident.tags), incident.detected_at.isoformat(),
                incident.updated_at.isoformat(),
                incident.resolved_at.isoformat() if incident.resolved_at else None,
                incident.root_cause, incident.impact_assessment,
                json.dumps(incident.resolution_steps), incident.lessons_learned,
                incident.detection_time_ms, incident.resolution_time_ms,
                incident.impact_score, incident.confidence_score
            ))
            conn.commit()
    
    async def _save_quality_assessment(self, assessment: QualityAssessment):
        """å“è³ªè©•ä¾¡ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO quality_assessments VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                assessment.assessment_id, assessment.target_component, assessment.standard_id,
                assessment.overall_score, assessment.compliance_score, assessment.is_compliant,
                json.dumps(assessment.metric_scores), json.dumps(assessment.violations),
                json.dumps(assessment.recommendations), assessment.assessed_at.isoformat(),
                assessment.assessor, assessment.confidence_score
            ))
            conn.commit()
    
    def _determine_severity(self, anomaly_data: Dict[str, Any]) -> IncidentSeverity:
        """é‡è¦åº¦åˆ¤å®š"""
        severity_str = anomaly_data.get('severity', 'medium').lower()
        severity_map = {
            'critical': IncidentSeverity.CRITICAL,
            'high': IncidentSeverity.HIGH,
            'medium': IncidentSeverity.MEDIUM,
            'low': IncidentSeverity.LOW,
            'info': IncidentSeverity.INFO
        }
        return severity_map.get(severity_str, IncidentSeverity.MEDIUM)
    
    def _determine_category(self, anomaly_data: Dict[str, Any]) -> IncidentCategory:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š"""
        metric = anomaly_data.get('metric', '').lower()
        
        if 'error' in metric or 'exception' in metric:
            return IncidentCategory.QUALITY
        elif 'response_time' in metric or 'latency' in metric:
            return IncidentCategory.PERFORMANCE
        elif 'availability' in metric or 'uptime' in metric:
            return IncidentCategory.AVAILABILITY
        elif 'security' in metric or 'auth' in metric:
            return IncidentCategory.SECURITY
        else:
            return IncidentCategory.QUALITY
    
    def _generate_incident_description(self, anomaly_data: Dict[str, Any]) -> str:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆèª¬æ˜ç”Ÿæˆ"""
        component = anomaly_data.get('component', 'unknown')
        metric = anomaly_data.get('metric', 'unknown')
        value = anomaly_data.get('value', 'N/A')
        threshold = anomaly_data.get('threshold', 'N/A')
        
        return f"Anomalous {metric} detected in {component}. Current value: {value}, Threshold: {threshold}"
    
    def _extract_tags(self, anomaly_data: Dict[str, Any]) -> List[str]:
        """ã‚¿ã‚°æŠ½å‡º"""
        tags = ['anomaly_detected']
        
        if 'component' in anomaly_data:
            tags.append(f"component:{anomaly_data['component']}")
        if 'metric' in anomaly_data:
            tags.append(f"metric:{anomaly_data['metric']}")
        
        return tags
    
    def _determine_response_actions(self, incident: Incident) -> List[str]:
        """å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        actions = []
        
        if incident.category == IncidentCategory.PERFORMANCE:
            actions.extend([
                "Check system resource usage",
                "Analyze recent performance metrics",
                "Review recent deployments",
                "Scale resources if necessary"
            ])
        elif incident.category == IncidentCategory.QUALITY:
            actions.extend([
                "Run automated tests",
                "Check code quality metrics",
                "Review recent commits",
                "Notify development team"
            ])
        elif incident.category == IncidentCategory.AVAILABILITY:
            actions.extend([
                "Restart affected services",
                "Check network connectivity",
                "Verify load balancer status",
                "Escalate to operations team"
            ])
        else:
            actions.extend([
                "Gather additional diagnostics",
                "Check system logs",
                "Notify relevant team"
            ])
        
        return actions
    
    async def _execute_response_actions(self, actions: List[str], incident: Incident) -> bool:
        """å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        self.logger.info(f"Executing response actions for {incident.incident_id}: {actions}")
        
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…·ä½“çš„ãªå¯¾å¿œã‚’å®Ÿè¡Œ
        await asyncio.sleep(0.01)  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶
        
        # 75%ã®ç¢ºç‡ã§æˆåŠŸã¨ã™ã‚‹ï¼ˆKnowledge Sageã‚ˆã‚Šé«˜ã„æˆåŠŸç‡ï¼‰
        import random
        return random.random() > 0.25
    
    def _calculate_overall_score(self, metric_scores: Dict[str, float], standard: QualityStandard) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not metric_scores:
            return 0.0
        
        total_score = 0.0
        total_weight = 0.0
        
        for metric_name, score in metric_scores.items():
            if metric_name in standard.metrics:
                metric_def = standard.metrics[metric_name]
                target = metric_def.target_value
                threshold_min = metric_def.threshold_min
                weight = 1.0  # å‡ç­‰é‡ã¿ä»˜ã‘
                
                # é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
                if score >= threshold_min:
                    normalized_score = min(100.0, (score / target) * 100.0) if target > 0 else 100.0
                else:
                    # æœ€å°é–¾å€¤æœªæº€ã¯å¤§å¹…æ¸›ç‚¹
                    normalized_score = (score / threshold_min) * 50.0 if threshold_min > 0 else 0.0
                
                total_score += normalized_score * weight
                total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    # === Statistics Calculation Methods ===
    
    def _count_by_status(self) -> Dict[str, int]:

                    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ"""
            status = incident.status.value
            counts[status] = counts.get(status, 0) + 1
        return counts
    
    def _count_by_severity(self) -> Dict[str, int]:

            """é‡è¦åº¦åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ"""
            severity = incident.severity.value
            counts[severity] = counts.get(severity, 0) + 1
        return counts
    
    def _count_by_category(self) -> Dict[str, int]:

            """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚«ã‚¦ãƒ³ãƒˆ"""
            category = incident.category.value
            counts[category] = counts.get(category, 0) + 1
        return counts
    
    def _calculate_resolution_rate(self) -> float:

            """è§£æ±ºç‡è¨ˆç®—"""
            return 0.0
        
        resolved_count = len([i for i in self.incidents.values() if i.status == IncidentStatus.RESOLVED])
        return (resolved_count / len(self.incidents)) * 100.0
    
    def _calculate_average_resolution_time(self) -> float:

            """å¹³å‡è§£æ±ºæ™‚é–“è¨ˆç®—ï¼ˆåˆ†ï¼‰"""
            return 0.0
        
        total_time_ms = sum(i.resolution_time_ms for i in resolved_incidents)
        average_time_ms = total_time_ms / len(resolved_incidents)
        return average_time_ms / (1000 * 60)  # åˆ†ã«å¤‰æ›
    
    def _analyze_compliance_trends(self) -> Dict[str, Any]:

            """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å‚¾å‘åˆ†æ""" "stable",
            "compliance_rate": 85.0,
            "improvement_areas": ["test_coverage", "code_quality"]
        }
    
    def _calculate_average_uptime(self) -> float:

        """å¹³å‡ç¨¼åƒç‡è¨ˆç®—"""
            return 0.0
        
        total_uptime = sum(target.uptime_percentage for target in self.monitoring_targets.values())
        return total_uptime / len(self.monitoring_targets)
    
    # === Pattern Learning Methods ===
    
    def _find_common_components(self, incidents: List[Incident]) -> List[str]:
        """å…±é€šå½±éŸ¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæŠ½å‡º"""
        component_counts = {}
        for incident in incidents:
            for component in incident.affected_components:
                component_counts[component] = component_counts.get(component, 0) + 1
        
        # 50%ä»¥ä¸Šã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã«å…±é€šã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        threshold = len(incidents) * 0.5
        return [comp for comp, count in component_counts.items() if count >= threshold]
    
    def _find_common_tags(self, incidents: List[Incident]) -> List[str]:
        """å…±é€šã‚¿ã‚°æŠ½å‡º"""
        tag_counts = {}
        for incident in incidents:
            for tag in incident.tags:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        threshold = len(incidents) * 0.3
        return [tag for tag, count in tag_counts.items() if count >= threshold]
    
    def _calculate_average_severity(self, incidents: List[Incident]) -> float:
        """å¹³å‡é‡è¦åº¦è¨ˆç®—"""
        severity_values = {
            IncidentSeverity.INFO: 1,
            IncidentSeverity.LOW: 2,
            IncidentSeverity.MEDIUM: 3,
            IncidentSeverity.HIGH: 4,
            IncidentSeverity.CRITICAL: 5
        }
        
        total = sum(severity_values[incident.severity] for incident in incidents)
        return total / len(incidents) if incidents else 0
    
    def _extract_typical_causes(self, incidents: List[Incident]) -> List[str]:
        """å…¸å‹çš„åŸå› æŠ½å‡º"""
        causes = [incident.root_cause for incident in incidents if incident.root_cause]
        
        # å…±é€šåŸå› ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        cause_words = {}
        for cause in causes:
            for word in cause.lower().split():
                if len(word) > 3:  # çŸ­ã„èªã¯é™¤å¤–
                    cause_words[word] = cause_words.get(word, 0) + 1
        
        # é »å‡ºèªã‚’ãƒ™ãƒ¼ã‚¹ã«å…¸å‹åŸå› ã‚’æ§‹ç¯‰
        return [word for word, count in cause_words.items() if count >= 2]
    
    # === Database Initialization ===
    
    def _initialize_database(self):

                    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS incidents (
                    incident_id TEXT PRIMARY KEY,
                    title TEXT NOT NULL,
                    description TEXT,
                    severity TEXT NOT NULL,
                    status TEXT NOT NULL,
                    category TEXT NOT NULL,
                    source TEXT,
                    affected_components TEXT,
                    tags TEXT,
                    detected_at TIMESTAMP,
                    updated_at TIMESTAMP,
                    resolved_at TIMESTAMP,
                    root_cause TEXT,
                    impact_assessment TEXT,
                    resolution_steps TEXT,
                    lessons_learned TEXT,
                    detection_time_ms INTEGER,
                    resolution_time_ms INTEGER,
                    impact_score REAL,
                    confidence_score REAL
                )
            """)
            
            # å“è³ªåŸºæº–ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_standards (
                    standard_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT,
                    category TEXT,
                    metrics_json TEXT,
                    compliance_threshold REAL,
                    version TEXT,
                    created_at TIMESTAMP,
                    updated_at TIMESTAMP,
                    applicable_components TEXT,
                    mandatory BOOLEAN
                )
            """)
            
            # å“è³ªè©•ä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«  
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_assessments (
                    assessment_id TEXT PRIMARY KEY,
                    target_component TEXT NOT NULL,
                    standard_id TEXT NOT NULL,
                    overall_score REAL,
                    compliance_score REAL,
                    is_compliant BOOLEAN,
                    metric_scores TEXT,
                    violations TEXT,
                    recommendations TEXT,
                    assessed_at TIMESTAMP,
                    assessor TEXT,
                    confidence_score REAL
                )
            """)
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS alert_rules (
                    rule_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT,
                    condition_expression TEXT NOT NULL,
                    threshold_value REAL,
                    comparison_operator TEXT,
                    severity TEXT,
                    cooldown_minutes INTEGER,
                    max_alerts_per_hour INTEGER,
                    auto_response_enabled BOOLEAN,
                    escalation_rules TEXT,
                    notification_targets TEXT,
                    enabled BOOLEAN,
                    created_at TIMESTAMP,
                    last_triggered_at TIMESTAMP,
                    trigger_count INTEGER
                )
            """)
            
            # ç›£è¦–å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS monitoring_targets (
                    target_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    type TEXT NOT NULL,
                    endpoint_url TEXT,
                    check_interval_seconds INTEGER,
                    timeout_seconds INTEGER,
                    health_check_enabled BOOLEAN,
                    health_check_path TEXT,
                    expected_response_codes TEXT,
                    quality_standards TEXT,
                    alert_rules TEXT,
                    created_at TIMESTAMP,
                    last_checked_at TIMESTAMP,
                    status TEXT,
                    uptime_percentage REAL
                )
            """)
            
            conn.commit()
    
    def _load_default_quality_standards(self):

            """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå“è³ªåŸºæº–ãƒ­ãƒ¼ãƒ‰""" QualityMetric(
                    name="Test Coverage",
                    target_value=95.0,
                    threshold_min=90.0,
                    unit="%",
                    description="ã‚³ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸"
                ),
                "iron_will_compliance": QualityMetric(
                    name="Iron Will Compliance", 
                    target_value=100.0,
                    threshold_min=100.0,
                    unit="%",
                    description="Iron WillåŸå‰‡éµå®ˆç‡"
                ),
                "code_quality_score": QualityMetric(
                    name="Code Quality Score",
                    target_value=90.0,
                    threshold_min=80.0,
                    unit="points",
                    description="ã‚³ãƒ¼ãƒ‰å“è³ªã‚¹ã‚³ã‚¢"
                )
            },
            compliance_threshold=95.0,
            applicable_components=["all"]
        )
        
        self.quality_standards[elder_guild_standard.standard_id] = elder_guild_standard
    
    def _load_all_data(self):

                    """å…¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰"""
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                
                # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ­ãƒ¼ãƒ‰
                for row in conn.execute("SELECT * FROM incidents"):
                    incident = self._row_to_incident(row)
                    self.incidents[incident.incident_id] = incident
                
                # å“è³ªåŸºæº–ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä»¥å¤–ï¼‰
                for row in conn.execute("SELECT * FROM quality_standards"):
                    standard = self._row_to_quality_standard(row)
                    if standard.standard_id not in self.quality_standards:
                        self.quality_standards[standard.standard_id] = standard
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ãƒ­ãƒ¼ãƒ‰
                for row in conn.execute("SELECT * FROM alert_rules"):
                    rule = self._row_to_alert_rule(row)
                    self.alert_rules[rule.rule_id] = rule
                
                # ç›£è¦–å¯¾è±¡ãƒ­ãƒ¼ãƒ‰
                for row in conn.execute("SELECT * FROM monitoring_targets"):
                    target = self._row_to_monitoring_target(row)
                    self.monitoring_targets[target.target_id] = target
                
            # é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_operational_metrics()
            
            self.logger.info(f"Loaded: {len(self.incidents)} incidents, "
                           f"{len(self.quality_standards)} standards, "
                           f"{len(self.alert_rules)} alert rules, "
                           f"{len(self.monitoring_targets)} monitoring targets")
                           
        except Exception as e:
            self.logger.error(f"Error loading data: {e}")
            # åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã¯ç¶™ç¶šã€ç©ºãƒ‡ãƒ¼ã‚¿ã§é–‹å§‹
    
    def _update_operational_metrics(self):

            """é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
            self.operational_metrics["average_resolution_time"] = mean([
                i.resolution_time_ms for i in resolved_incidents
            ])
    
    # === Database Row Conversion Methods ===
    
    def _row_to_incident(self, row) -> Incident:

            """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¡Œã‹ã‚‰Incidentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¤‰æ›"""
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¡Œã‹ã‚‰QualityStandardã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¤‰æ›"""
        metrics_data = json.loads(row['metrics_json'] or '{}')
        metrics = {}
        
        for name, metric_dict in metrics_data.items():
            metrics[name] = QualityMetric(**metric_dict)
        
        return QualityStandard(
            standard_id=row['standard_id'],
            name=row['name'],
            description=row['description'] or "",
            category=row['category'] or "general",
            metrics=metrics,
            compliance_threshold=row['compliance_threshold'] or 95.0,
            version=row['version'] or "1.0.0",
            created_at=datetime.fromisoformat(row['created_at']),
            updated_at=datetime.fromisoformat(row['updated_at']),
            applicable_components=json.loads(row['applicable_components'] or '[]'),
            mandatory=bool(row['mandatory'])
        )
    
    def _row_to_alert_rule(self, row) -> AlertRule:

            """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¡Œã‹ã‚‰AlertRuleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¤‰æ›"""
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¡Œã‹ã‚‰MonitoringTargetã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¤‰æ›"""
        return MonitoringTarget(
            target_id=row['target_id'],
            name=row['name'],
            type=row['type'],
            endpoint_url=row['endpoint_url'],
            check_interval_seconds=row['check_interval_seconds'] or 60,
            timeout_seconds=row['timeout_seconds'] or 30,
            health_check_enabled=bool(row['health_check_enabled']),
            health_check_path=row['health_check_path'] or "/health",
            expected_response_codes=json.loads(row['expected_response_codes'] or '[200]'),
            quality_standards=json.loads(row['quality_standards'] or '[]'),
            alert_rules=json.loads(row['alert_rules'] or '[]'),
            created_at=datetime.fromisoformat(row['created_at']),
            last_checked_at=datetime.fromisoformat(row['last_checked_at']) if row['last_checked_at'] else None,
            status=row['status'] or "unknown",
            uptime_percentage=row['uptime_percentage'] or 0.0
        )
    
    # === Additional Action Methods (æ®‹ã‚Šã®å®Ÿè£…) ===
    
    async def _register_incident_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™»éŒ²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            # Incidentä½œæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‡¦ç†
            incident_data = data.get("incident", {})
            
            incident = Incident(
                title=incident_data.get("title", "Unknown Incident"),
                description=incident_data.get("description", ""),
                severity=IncidentSeverity(incident_data.get("severity", "medium")),
                category=IncidentCategory(incident_data.get("category", "quality")),
                affected_components=incident_data.get("affected_components", []),
                tags=incident_data.get("tags", [])
            )
            
            await self._register_incident_internal(incident)
            
            return {
                "success": True,
                "data": {
                    "incident_id": incident.incident_id,
                    "status": "registered"
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _create_alert_rule_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ä½œæˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            rule_data = data.get("alert_rule", {})
            
            # alert_ruleãŒè¾æ›¸ã§ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
            if not isinstance(rule_data, dict):
                return {"success": False, "error": "alert_rule must be a dictionary"}
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
            if not rule_data.get("name"):
                return {"success": False, "error": "alert_rule.name is required"}
            
            if not rule_data.get("condition_expression"):
                return {"success": False, "error": "alert_rule.condition_expression is required"}
            
            alert_rule = AlertRule(
                name=rule_data.get("name"),
                description=rule_data.get("description", ""),
                condition_expression=rule_data.get("condition_expression"),
                severity=IncidentSeverity(rule_data.get("severity", "medium")),
                enabled=rule_data.get("enabled", True)
            )
            
            self.alert_rules[alert_rule.rule_id] = alert_rule
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO alert_rules VALUES (
                        ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
                    )
                """, (
                    alert_rule.rule_id, alert_rule.name, alert_rule.description,
                    alert_rule.condition_expression, alert_rule.threshold_value,
                    alert_rule.comparison_operator, alert_rule.severity.value,
                    alert_rule.cooldown_minutes, alert_rule.max_alerts_per_hour,
                    alert_rule.auto_response_enabled, json.dumps(alert_rule.escalation_rules),
                    json.dumps(alert_rule.notification_targets), alert_rule.enabled,
                    alert_rule.created_at.isoformat(),
                    alert_rule.last_triggered_at.isoformat() if alert_rule.last_triggered_at else None,
                    alert_rule.trigger_count
                ))
                conn.commit()
            
            return {
                "success": True,
                "data": {
                    "rule_id": alert_rule.rule_id,
                    "name": alert_rule.name,
                    "enabled": alert_rule.enabled
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _evaluate_alert_rules_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«è©•ä¾¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            metric_data = data.get("metrics", {})
            reset_cooldown = data.get("reset_cooldown", False)  # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒªã‚»ãƒƒãƒˆ
            triggered_alerts = []
            
            for rule in self.alert_rules.values():
                if not rule.enabled:
                    continue
                
                # ãƒ†ã‚¹ãƒˆç”¨ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒªã‚»ãƒƒãƒˆ
                if reset_cooldown:
                    rule.last_triggered_at = None
                    rule.trigger_count = 0
                
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ãƒã‚§ãƒƒã‚¯
                if rule.last_triggered_at:
                    cooldown_delta = datetime.now() - rule.last_triggered_at
                    if cooldown_delta.total_seconds() < (rule.cooldown_minutes * 60):
                        continue
                
                # æ¡ä»¶è©•ä¾¡ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                if self._evaluate_alert_condition(rule, metric_data):
                    triggered_alerts.append({
                        "rule_id": rule.rule_id,
                        "rule_name": rule.name,
                        "severity": rule.severity.value,
                        "condition": rule.condition_expression
                    })
                    
                    # ãƒ«ãƒ¼ãƒ«æ›´æ–°
                    rule.last_triggered_at = datetime.now()
                    rule.trigger_count += 1
            
            return {
                "success": True,
                "data": {
                    "triggered_alerts": triggered_alerts,
                    "alert_count": len(triggered_alerts)
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _evaluate_alert_condition(self, rule: AlertRule, metric_data: Dict[str, Any]) -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶è©•ä¾¡ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        try:
            # condition_expressionã‹ã‚‰å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã‚’æŠ½å‡º
            parts = rule.condition_expression.split()
            if len(parts) >= 3:
                metric_name = parts[0]
                operator = parts[1]
                threshold = float(parts[2])
                
                if metric_name in metric_data:
                    value = float(metric_data[metric_name])
                    
                    if operator == '>':
                        return value > threshold
                    elif operator == '<':
                        return value < threshold
                    elif operator == '>=':
                        return value >= threshold
                    elif operator == '<=':
                        return value <= threshold
                    elif operator == '==':
                        return value == threshold
                    elif operator == '!=':
                        return value != threshold
        
        except (ValueError, KeyError, IndexError):
            pass
        
        return False
    
    async def _register_monitoring_target_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç›£è¦–å¯¾è±¡ç™»éŒ²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            target_data = data.get("target", {})
            
            target = MonitoringTarget(
                name=target_data.get("name", "Unknown Target"),
                type=target_data.get("type", "service"),
                endpoint_url=target_data.get("endpoint_url", ""),
                health_check_enabled=target_data.get("health_check_enabled", True)
            )
            
            self.monitoring_targets[target.target_id] = target
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO monitoring_targets VALUES (
                        ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
                    )
                """, (
                    target.target_id, target.name, target.type, target.endpoint_url,
                    target.check_interval_seconds, target.timeout_seconds,
                    target.health_check_enabled, target.health_check_path,
                    json.dumps(target.expected_response_codes),
                    json.dumps(target.quality_standards), json.dumps(target.alert_rules),
                    target.created_at.isoformat(),
                    target.last_checked_at.isoformat() if target.last_checked_at else None,
                    target.status, target.uptime_percentage
                ))
                conn.commit()
            
            return {
                "success": True,
                "data": {
                    "target_id": target.target_id,
                    "name": target.name,
                    "status": target.status
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _check_target_health_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç›£è¦–å¯¾è±¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            target_id = data.get("target_id")
            
            if not target_id or target_id not in self.monitoring_targets:
                return {"success": False, "error": f"Monitoring target not found: {target_id}"}
            
            target = self.monitoring_targets[target_id]
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            import random
            is_healthy = random.random() > 0.1  # 90%ã®ç¢ºç‡ã§ãƒ˜ãƒ«ã‚·ãƒ¼
            response_time = random.randint(50, 300)
            uptime = 99.5 if is_healthy else 85.2
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
            target.last_checked_at = datetime.now()
            target.status = "healthy" if is_healthy else "unhealthy"
            target.uptime_percentage = uptime
            
            health_result = {
                "target_id": target_id,
                "status": target.status,
                "response_time_ms": response_time,
                "uptime_percentage": uptime,
                "last_check": target.last_checked_at.isoformat()
            }
            
            if is_healthy:
                self.operational_metrics["monitoring_targets_healthy"] += 1
            
            return {
                "success": True,
                "data": health_result
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _analyze_correlations_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç›¸é–¢åˆ†æã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            correlations = []
            recent_incidents = [i for i in self.incidents.values() 
                              if (datetime.now() - i.detected_at).total_seconds() < 3600]  # 1æ™‚é–“ä»¥å†…
            
            # æ™‚ç³»åˆ—ç›¸é–¢
            for i, incident in enumerate(recent_incidents):
                related_incidents = []
                
                for j, other_incident in enumerate(recent_incidents):
                    if i != j:
                        # æ™‚é–“çš„è¿‘æ¥æ€§
                        time_diff = abs((incident.detected_at - other_incident.detected_at).total_seconds())
                        
                        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé‡è¤‡
                        component_overlap = set(incident.affected_components) & set(other_incident.affected_components)
                        
                        # ç›¸é–¢åˆ¤å®š
                        if time_diff < 300 or component_overlap:  # 5åˆ†ä»¥å†…ã¾ãŸã¯å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
                            related_incidents.append(other_incident.incident_id)
                
                if related_incidents:
                    correlations.append({
                        "primary_incident": incident.incident_id,
                        "related_incidents": related_incidents,
                        "correlation_type": "temporal_spatial",
                        "confidence": 0.7
                    })
            
            return {
                "success": True,
                "data": {
                    "correlations": correlations,
                    "correlation_count": len(correlations),
                    "analyzed_incidents": len(recent_incidents)
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _attempt_automated_remediation_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªå‹•ä¿®å¾©è©¦è¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            incident_id = data.get("incident_id")
            
            if not incident_id or incident_id not in self.incidents:
                return {"success": False, "error": f"Incident not found: {incident_id}"}
            
            incident = self.incidents[incident_id]
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ä¿®å¾©
            remediation_actions = self._determine_remediation_actions(incident)
            
            if remediation_actions:
                # ä¿®å¾©å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                success = await self._execute_remediation_actions(remediation_actions, incident)
                
                result = {
                    "status": "success" if success else "failed",
                    "actions_taken": remediation_actions,
                    "incident_id": incident_id,
                    "timestamp": datetime.now().isoformat()
                }
                
                if success:
                    self.operational_metrics["automated_remediations"] += 1
                    incident.status = IncidentStatus.RESOLVED
                    incident.resolved_at = datetime.now()
                    incident.resolution_time_ms = int((datetime.now() - incident.detected_at).total_seconds() * 1000)
                    await self._register_incident_internal(incident)
            else:
                result = {
                    "status": "no_action",
                    "reason": "No automated remediation available",
                    "incident_id": incident_id
                }
            
            return {
                "success": True,
                "data": result
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _determine_remediation_actions(self, incident: Incident) -> List[str]:
        """ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ä¿®å¾©
        if incident.category == IncidentCategory.PERFORMANCE:
            return ["restart_service", "clear_cache", "scale_up"]
        elif incident.category == IncidentCategory.AVAILABILITY:
            return ["health_check", "restart_service", "failover"]
        elif incident.category == IncidentCategory.QUALITY:
            return ["run_tests", "rollback_deployment", "notify_team"]
        else:
            return ["gather_logs", "notify_team"]
    
    async def _execute_remediation_actions(self, actions: List[str], incident: Incident) -> bool:
        """ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        self.logger.info(f"Executing remediation actions: {actions}")
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…
        await asyncio.sleep(0.01)
        
        # 80%ã®æˆåŠŸç‡ï¼ˆé«˜ã‚ï¼‰
        import random
        return random.random() > 0.2
    
    async def _search_similar_incidents_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """é¡ä¼¼ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¤œç´¢ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            query = data.get("query", "")
            
            if not query:
                return {"success": False, "error": "query is required"}
            
            # ã‚¯ã‚¨ãƒªã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ10KBï¼‰
            if len(query) > 10 * 1024:
                return {"success": False, "error": f"Query too large: {len(query)} bytes (max 10KB)"}
            
            # ç°¡å˜ãªé¡ä¼¼æ¤œç´¢å®Ÿè£…
            similar = []
            query_words = set(query.lower().split())
            
            for incident in self.incidents.values():
                title_words = set(incident.title.lower().split())
                desc_words = set(incident.description.lower().split())
                all_words = title_words | desc_words
                
                similarity = len(query_words & all_words) / len(query_words | all_words) if query_words | all_words else 0
                
                if similarity > 0.3:  # 30%ä»¥ä¸Šã®é¡ä¼¼åº¦
                    similar.append({
                        "incident_id": incident.incident_id,
                        "title": incident.title,
                        "similarity": similarity,
                        "resolution_time_ms": incident.resolution_time_ms,
                        "resolution_steps": incident.resolution_steps
                    })
            
            # é¡ä¼¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
            similar.sort(key=lambda x: x["similarity"], reverse=True)
            similar = similar[:10]  # ä¸Šä½10ä»¶
            
            return {
                "success": True,
                "data": {
                    "query": query,
                    "similar_incidents": similar,
                    "total_matches": len(similar)
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _get_operational_metrics_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            metrics = self.operational_metrics.copy()
            
            return {
                "success": True,
                "data": {
                    "operational_metrics": metrics,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _register_quality_standard_action(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å“è³ªåŸºæº–ç™»éŒ²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        try:
            standard_data = data.get("standard", {})
            
            # QualityStandardä½œæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            metrics = {}
            for name, metric_data in standard_data.get("metrics", {}).items():
                metrics[name] = QualityMetric(
                    name=metric_data.get("name", name),
                    target_value=metric_data.get("target_value", 100.0),
                    threshold_min=metric_data.get("threshold_min", 90.0),
                    unit=metric_data.get("unit", "points"),
                    description=metric_data.get("description", "")
                )
            
            standard = QualityStandard(
                name=standard_data.get("name", "Unknown Standard"),
                description=standard_data.get("description", ""),
                category=standard_data.get("category", "general"),
                metrics=metrics,
                compliance_threshold=standard_data.get("compliance_threshold", 95.0),
                applicable_components=standard_data.get("applicable_components", ["all"])
            )
            
            self.quality_standards[standard.standard_id] = standard
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONã«å¤‰æ›
            metrics_json = {}
            for name, metric in standard.metrics.items():
                metric_dict = asdict(metric)
                # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                if 'measured_at' in metric_dict and metric_dict['measured_at']:
                    metric_dict['measured_at'] = metric_dict['measured_at'].isoformat()
                metrics_json[name] = metric_dict
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO quality_standards VALUES (
                        ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
                    )
                """, (
                    standard.standard_id, standard.name, standard.description,
                    standard.category, json.dumps(metrics_json),
                    standard.compliance_threshold, standard.version,
                    standard.created_at.isoformat(), standard.updated_at.isoformat(),
                    json.dumps(standard.applicable_components), standard.mandatory
                ))
                conn.commit()
            
            return {
                "success": True,
                "data": {
                    "standard_id": standard.standard_id,
                    "name": standard.name,
                    "metrics_count": len(standard.metrics)
                }
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}