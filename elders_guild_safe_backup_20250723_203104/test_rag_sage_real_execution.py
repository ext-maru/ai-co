#!/usr/bin/env python3
"""
ğŸ” RAG Sage A2A Agent - å®Ÿå‹•ä½œæ¤œè¨¼
=================================

Elder Loop Phase 5: å®Ÿå‹•ä½œæ¤œè¨¼
ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ç›´æ¥å®Ÿè¡Œã«ã‚ˆã‚‹å‹•ä½œç¢ºèª

Author: Claude Elder
Created: 2025-07-23
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Dict, Any, List
import sys
from pathlib import Path

# Elders Guildãƒ‘ã‚¹è¨­å®š
sys.path.append(str(Path(__file__).parent))
from rag_sage.business_logic import RAGProcessor


class RAGSageRealExecution:


"""RAG Sageå®Ÿå‹•ä½œæ¤œè¨¼"""
        self.processor = None
        self.test_results = []
        self.indexed_documents = []
    
    async def initialize(self):

        """åˆæœŸåŒ–""" Elder Loopå®Ÿå‹•ä½œç¢ºèª")
        print("ğŸ¯ ç›®æ¨™: 12ã‚¹ã‚­ãƒ«å€‹åˆ¥å‹•ä½œãƒ»çµ±åˆãƒ•ãƒ­ãƒ¼æ¤œè¨¼")
        print()
        
        print("ğŸ”§ ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–...")
        self.processor = RAGProcessor()
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±å–å¾—
        info_result = await self.processor.process_action("get_index_info", {})
        if info_result["success"]:
            info = info_result["data"]
            print(f"âœ… ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–å®Œäº†")
            print(f"   - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {info['document_count']}å€‹")
            print(f"   - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º: {info['size_bytes'] / 1024:.1f}KB")
        print()
    
    async def test_document_management_flow(self):

        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ãƒ•ãƒ­ãƒ¼æ¤œè¨¼""" "elder_loop_guide",
                "content": "Elder Loopé–‹ç™ºæ‰‹æ³•ã¯ã€å³å¯†ãªå“è³ªãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£ã®å®Œç’§ã«ãªã‚‹ã¾ã§ã®ãƒ«ãƒ¼ãƒ—ã‚’ç‰¹å¾´ã¨ã™ã‚‹é–‹ç™ºæ‰‹æ³•ã§ã™ã€‚",
                "source": "elders_guild_docs",
                "title": "Elder Loopé–‹ç™ºæ‰‹æ³•ã‚¬ã‚¤ãƒ‰",
                "category": "development",
                "tags": ["elder-loop", "quality", "methodology"],
                "author": "Claude Elder",
                "relevance_boost": 2.0
            },
            {
                "id": "four_sages_architecture",
                "content": "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¯ã€Knowledge Sageã€Task Sageã€Incident Sageã€RAG Sageã®4ã¤ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚",
                "source": "elders_guild_docs",
                "title": "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£",
                "category": "architecture",
                "tags": ["4-sages", "ai-agents", "architecture"],
                "author": "Grand Elder maru",
                "relevance_boost": 1.5
            },
            {
                "id": "a2a_protocol_guide",
                "content": "Google A2A Protocolã¯åˆ†æ•£AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®æ¨™æº–é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚",
                "source": "technical_docs",
                "title": "A2A Protocolå®Ÿè£…ã‚¬ã‚¤ãƒ‰",
                "category": "technical",
                "tags": ["a2a", "protocol", "distributed"],
                "author": "Technical Team"
            }
        ]
        
        # å€‹åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        for doc in test_documents:
            start_time = time.time()
            result = await self.processor.process_action("index_document", {"document": doc})
            end_time = time.time()
            
            if result.get("success"):
                self.indexed_documents.append(doc["id"])
                print(f"   âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆåŠŸ: {doc['id']}")
                print(f"      - ã‚¿ã‚¤ãƒˆãƒ«: {doc['title']}")
                print(f"      - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 2. ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        print("\n2ï¸âƒ£ ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ")
        batch_docs = [
            {
                "id": f"batch_doc_{i}",
                "content": f"ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i}ã€‚ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®å“è³ªåŸºæº–ã«æº–æ‹ ã€‚",
                "source": "batch_test",
                "title": f"ãƒãƒƒãƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i}",
                "category": "test",
                "tags": ["batch", f"test-{i}"]
            }
            for i in range(5)
        ]
        
        start_time = time.time()
        result = await self.processor.process_action("batch_index_documents", {
            "documents": batch_docs
        })
        end_time = time.time()
        
        if result.get("success"):
            for doc in batch_docs:
                self.indexed_documents.append(doc["id"])
            print(f"   âœ… ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆåŠŸ")
            print(f"      - ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {result['data']['total_documents']}")
            print(f"      - æˆåŠŸæ•°: {result['data']['successful_count']}")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ–ãƒ¼ã‚¹ãƒˆæ›´æ–°
        print("\n3ï¸âƒ£ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ–ãƒ¼ã‚¹ãƒˆæ›´æ–°ãƒ†ã‚¹ãƒˆ")
        
        start_time = time.time()
        result = await self.processor.process_action("update_document_boost", {
            "document_id": "elder_loop_guide",
            "boost_value": 3.0
        })
        end_time = time.time()
        
        if result.get("success"):
            print(f"   âœ… ãƒ–ãƒ¼ã‚¹ãƒˆæ›´æ–°æˆåŠŸ")
            print(f"      - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID: {result['data']['document_id']}")
            print(f"      - æ–°ãƒ–ãƒ¼ã‚¹ãƒˆå€¤: {result['data']['boost_value']}")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
    
    async def test_search_flow(self):

    
    """æ¤œç´¢ãƒ•ãƒ­ãƒ¼æ¤œè¨¼"""
            start_time = time.time()
            result = await self.processor.process_action("search_knowledge", {
                "query": query,
                "search_type": "full_text",
                "limit": 5
            })
            end_time = time.time()
            
            if result.get("success"):
                print(f"\n   ğŸ” ã‚¯ã‚¨ãƒª: '{query}'")
                print(f"   âœ… æ¤œç´¢æˆåŠŸ - {result['data']['total_count']}ä»¶ãƒ’ãƒƒãƒˆ")
                print(f"      - æ¤œç´¢æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
                
                # ä¸Šä½çµæœè¡¨ç¤º
                for i, doc in enumerate(result['data']['results'][:3]):
                    print(f"      {i+1}. [{doc['score']:.2f}] {doc['title']}")
        
        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œç´¢
        print("\n2ï¸âƒ£ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
        filter_tests = [
            {"filters": {"category": "development"}, "description": "é–‹ç™ºã‚«ãƒ†ã‚´ãƒª"},
            {"filters": {"tags": ["elder-loop"]}, "description": "elder-loopã‚¿ã‚°"},
            {"filters": {"source": "elders_guild_docs"}, "description": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"}
        ]
        
        for test in filter_tests:
            start_time = time.time()
            result = await self.processor.process_action("search_knowledge", {
                "query": "",
                "filters": test["filters"],
                "limit": 10
            })
            end_time = time.time()
            
            if result.get("success"):
                print(f"\n   ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {test['description']}")
                print(f"   âœ… æ¤œç´¢æˆåŠŸ - {result['data']['total_count']}ä»¶ãƒ’ãƒƒãƒˆ")
                print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 3. é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢
        print("\n3ï¸âƒ£ é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ãƒ†ã‚¹ãƒˆ")
        
        start_time = time.time()
        result = await self.processor.process_action("get_similar_documents", {
            "document_id": "elder_loop_guide",
            "limit": 5
        })
        end_time = time.time()
        
        if result.get("success"):
            print(f"   âœ… é¡ä¼¼æ¤œç´¢æˆåŠŸ")
            print(f"      - åŸºæº–ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: Elder Loopé–‹ç™ºæ‰‹æ³•ã‚¬ã‚¤ãƒ‰")
            print(f"      - é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(result['data']['similar_documents'])}")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
            
            for doc in result['data']['similar_documents'][:3]:
                print(f"      - [{doc['similarity_score']:.2f}] {doc['title']}")
    
    async def test_analysis_flow(self):

    
    """åˆ†æãƒ»æ´å¯Ÿãƒ•ãƒ­ãƒ¼æ¤œè¨¼"""
            start_time = time.time()
            result = await self.processor.process_action("analyze_query_intent", {
                "query": query
            })
            end_time = time.time()
            
            if result.get("success"):
                intent = result['data']
                print(f"\n   ğŸ“ ã‚¯ã‚¨ãƒª: '{query}'")
                print(f"   âœ… æ„å›³åˆ†ææˆåŠŸ")
                print(f"      - æ„å›³ã‚¿ã‚¤ãƒ—: {intent['intent_type']}")
                print(f"      - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(intent['keywords'])}")
                print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 2. æ´å¯Ÿç”Ÿæˆ
        print("\n2ï¸âƒ£ æ´å¯Ÿç”Ÿæˆãƒ†ã‚¹ãƒˆ")
        
        # ã¾ãšæ¤œç´¢å®Ÿè¡Œ
        search_result = await self.processor.process_action("search_knowledge", {
            "query": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰",
            "limit": 10
        })
        
        if search_result.get("success"):
            start_time = time.time()
            result = await self.processor.process_action("generate_insights", {
                "search_results": search_result["data"]["results"],
                "query": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰"
            })
            end_time = time.time()
            
            if result.get("success"):
                insights = result['data']
                print(f"   âœ… æ´å¯Ÿç”ŸæˆæˆåŠŸ")
                print(f"      - ã‚µãƒãƒªãƒ¼: {insights['summary']}")
                print(f"      - ä¸»è¦ãƒ†ãƒ¼ãƒæ•°: {len(insights['key_themes'])}")
                if insights['key_themes']:
                    print(f"      - ãƒˆãƒƒãƒ—ãƒ†ãƒ¼ãƒ: {insights['key_themes'][0]['theme']} ({insights['key_themes'][0]['count']}ä»¶)")
                print(f"      - æ¨å¥¨äº‹é …: {len(insights['recommendations'])}ä»¶")
                print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
    
    async def test_system_management_flow(self):

    
    """ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ãƒ•ãƒ­ãƒ¼æ¤œè¨¼"""
            info = result['data']
            print(f"   âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±å–å¾—æˆåŠŸ")
            print(f"      - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å: {info['index_name']}")
            print(f"      - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {info['document_count']}")
            print(f"      - ã‚µã‚¤ã‚º: {info['size_bytes'] / 1024:.1f}KB")
            print(f"      - ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: {len(info['category_distribution'])}ç¨®é¡")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 2. æ¤œç´¢çµ±è¨ˆå–å¾—
        print("\n2ï¸âƒ£ æ¤œç´¢çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ")
        
        start_time = time.time()
        result = await self.processor.process_action("get_search_statistics", {})
        end_time = time.time()
        
        if result.get("success"):
            stats = result['data']
            print(f"   âœ… æ¤œç´¢çµ±è¨ˆå–å¾—æˆåŠŸ")
            print(f"      - ç·æ¤œç´¢æ•°: {stats['total_searches']}å›")
            print(f"      - å¹³å‡æ¤œç´¢æ™‚é–“: {stats['average_search_time_ms']:.1f}ms")
            print(f"      - äººæ°—ã‚¯ã‚¨ãƒªæ•°: {len(stats['popular_queries'])}å€‹")
            if stats['popular_queries']:
                print(f"      - ãƒˆãƒƒãƒ—ã‚¯ã‚¨ãƒª: '{stats['popular_queries'][0]['query']}' ({stats['popular_queries'][0]['count']}å›)")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
        
        # 3. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
        print("\n3ï¸âƒ£ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
        
        start_time = time.time()
        result = await self.processor.process_action("optimize_index", {})
        end_time = time.time()
        
        if result.get("success"):
            print(f"   âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–æˆåŠŸ")
            print(f"      - æœ€é©åŒ–æ™‚é–“: {result['data']['optimization_time_ms']:.1f}ms")
            print(f"      - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {result['data']['message']}")
        
        # 4. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        print("\n4ï¸âƒ£ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
        
        start_time = time.time()
        result = await self.processor.process_action("health_check", {})
        end_time = time.time()
        
        if result.get("success"):
            health = result['data']
            print(f"   âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ")
            print(f"      - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {health['status']}")
            print(f"      - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {health['agent_name']}")
            print(f"      - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {health['cache_size']}")
            print(f"      - DBæ¥ç¶š: {'âœ…' if health['db_accessible'] else 'âŒ'}")
            print(f"      - æ¤œç´¢æ©Ÿèƒ½: {'âœ…' if health['search_functional'] else 'âŒ'}")
            print(f"      - å‡¦ç†æ™‚é–“: {(end_time - start_time) * 1000:.1f}ms")
    
    async def test_cleanup_flow(self):

    
    """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ•ãƒ­ãƒ¼"""
            if doc_id in self.indexed_documents:
                result = await self.processor.process_action("delete_document", {
                    "document_id": doc_id
                })
                
                if result.get("success"):
                    print(f"   âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤æˆåŠŸ: {doc_id}")
    
    async def run_all_tests(self):

    
    """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ""" {len(self.indexed_documents)}å€‹")
        print(f"\nğŸ›ï¸ Elder Loop Phase 5å®Œäº† - å®Ÿæˆ¦ãƒ¬ãƒ™ãƒ«å‹•ä½œç¢ºèªé”æˆï¼")


async def main():

        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    asyncio.run(main())