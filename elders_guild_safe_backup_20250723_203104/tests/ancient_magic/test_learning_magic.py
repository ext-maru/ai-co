#!/usr/bin/env python3
"""
ðŸ§  Learning Magic ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
===============================

Learning Magicï¼ˆå­¦ç¿’é­”æ³•ï¼‰ã®åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã€‚
è‡ªå·±é€²åŒ–ã€ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã€çŸ¥è­˜çµ±åˆã‚’ãƒ†ã‚¹ãƒˆã€‚

Author: Claude Elder
Created: 2025-07-23
"""

import pytest
import asyncio
from typing import Dict, Any, List
import json
import tempfile
from pathlib import Path
from datetime import datetime

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from ancient_magic.learning_magic.learning_magic import LearningMagic


class TestLearningMagic:


"""Learning Magic ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
        """Learning Magic ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
        return LearningMagic()
        
    @pytest.fixture
    def sample_knowledge_base(self):

        """ãƒ†ã‚¹ãƒˆç”¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹""" [
                {
                    "pattern": "TDD Implementation",
                    "success_rate": 0.95,
                    "usage_count": 150,
                    "feedback_score": 4.8
                },
                {
                    "pattern": "Microservices Architecture", 
                    "success_rate": 0.87,
                    "usage_count": 89,
                    "feedback_score": 4.2
                }
            ],
            "failure_cases": [
                {
                    "case": "Memory leak in batch processing",
                    "frequency": 12,
                    "resolution_time": "2 hours",
                    "learned_fix": "Use context managers for resource cleanup"
                }
            ],
            "optimization_history": [
                {
                    "component": "database_queries",
                    "before_performance": 500,  # ms
                    "after_performance": 50,   # ms  
                    "optimization": "Added indexes and query optimization"
                }
            ]
        }
        
    @pytest.fixture
    def mock_sage_responses(self):

                """ãƒ¢ãƒƒã‚¯è³¢è€…å¿œç­”""" {
                "patterns_identified": 15,
                "knowledge_gaps": ["advanced_security", "performance_tuning"],
                "confidence": 0.85
            },
            "task": {
                "completed_tasks": 240,
                "success_rate": 0.92,
                "bottlenecks": ["code_review", "testing"]
            },
            "incident": {
                "incidents_resolved": 45,
                "resolution_time_avg": "1.5 hours",
                "preventable_incidents": 0.30
            },
            "rag": {
                "search_accuracy": 0.88,
                "knowledge_coverage": 0.75,
                "response_time": "200ms"
            }
        }
        
    # Phase 1: åŸºæœ¬çš„ãªå­¦ç¿’æ©Ÿèƒ½ï¼ˆBasic Learningï¼‰
    async def test_learn_from_success_pattern(self, learning_magic):

    """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ""" "API endpoint optimization",
            "method": "Caching strategy implementation",
            "result": {
                "performance_improvement": 0.70,
                "resource_reduction": 0.45,
                "user_satisfaction": 0.95
            },
            "context": {
                "technology": "FastAPI",
                "data_size": "medium",
                "user_load": "high"
            }
        }
        
        result = await learning_magic.learn_from_success(success_case)
        
        assert result["success"] is True
        assert "learned_pattern" in result
        pattern = result["learned_pattern"]
        assert pattern["pattern_type"] == "optimization"
        assert pattern["confidence_score"] >= 0.7
        assert "replication_guide" in pattern
        assert "applicable_contexts" in pattern
        
    async def test_learn_from_failure_case(self, learning_magic):

            """å¤±æ•—ã‚±ãƒ¼ã‚¹ã‹ã‚‰ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ""" "Database connection pool exhaustion",
            "root_cause": "Unclosed connections in error handling paths",
            "impact": {
                "downtime": "15 minutes",
                "affected_users": 1500,
                "revenue_loss": 5000
            },
            "resolution": {
                "immediate_fix": "Restart service with increased pool size",
                "permanent_fix": "Add connection cleanup in finally blocks",
                "prevention": "Add connection monitoring alerts"
            }
        }
        
        result = await learning_magic.learn_from_failure(failure_case)
        
        assert result["success"] is True
        assert "learned_lesson" in result
        lesson = result["learned_lesson"]
        assert lesson["lesson_type"] == "prevention"
        assert lesson["criticality"] == "high"
        assert "prevention_strategies" in lesson
        assert "early_warning_signs" in lesson
        assert "automated_checks" in lesson
        
    async def test_identify_learning_opportunities(self, learning_magic, sample_knowledge_base):

            """å­¦ç¿’æ©Ÿä¼šã®ç‰¹å®šãƒ†ã‚¹ãƒˆ"""
            assert "domain" in opportunity
            assert "learning_type" in opportunity
            assert "expected_benefit" in opportunity
            assert "effort_estimate" in opportunity
            
    # Phase 2: çŸ¥è­˜çµ±åˆï¼ˆKnowledge Integrationï¼‰
    async def test_integrate_sage_knowledge(self, learning_magic, mock_sage_responses):

    """4è³¢è€…çŸ¥è­˜çµ±åˆãƒ†ã‚¹ãƒˆ"""
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆæˆãƒ†ã‚¹ãƒˆ"""
        individual_patterns = [
            {
                "domain": "backend",
                "pattern": "Database connection pooling",
                "effectiveness": 0.85
            },
            {
                "domain": "frontend", 
                "pattern": "Component lazy loading",
                "effectiveness": 0.78
            },
            {
                "domain": "infrastructure",
                "pattern": "Auto-scaling based on metrics",
                "effectiveness": 0.92
            }
        ]
        
        result = await learning_magic.synthesize_patterns(individual_patterns)
        
        assert result["success"] is True
        synthesized = result["synthesized_patterns"]
        
        # åˆæˆãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        assert "universal_patterns" in synthesized
        assert "domain_specific_adaptations" in synthesized
        
        # æ±Žç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å“è³ªç¢ºèª
        universal = synthesized["universal_patterns"]
        for pattern in universal:
            assert "core_principle" in pattern
            assert "adaptability_score" in pattern
            assert pattern["adaptability_score"] >= 0.6
            
    # Phase 3: è‡ªå·±é€²åŒ–ï¼ˆSelf Evolutionï¼‰
    async def test_evolve_system_capabilities(self, learning_magic):

    """ã‚·ã‚¹ãƒ†ãƒ èƒ½åŠ›é€²åŒ–ãƒ†ã‚¹ãƒˆ""" {
                "knowledge": {"accuracy": 0.85, "response_time": 0.3},
                "task": {"completion_rate": 0.90, "efficiency": 0.75},
                "incident": {"resolution_time": 0.8, "prevention_rate": 0.65},
                "rag": {"search_precision": 0.88, "relevance": 0.82}
            },
            "elder_servants_status": {
                "implemented": 19,
                "total": 32,
                "average_performance": 0.78
            },
            "overall_metrics": {
                "system_reliability": 0.92,
                "user_satisfaction": 0.85,
                "development_speed": 0.70
            }
        }
        
        result = await learning_magic.evolve_system_capabilities(current_state)
        
        assert result["success"] is True
        evolution = result["evolution_plan"]
        
        # é€²åŒ–è¨ˆç”»ã®è¦ç´ ç¢ºèª
        assert "capability_enhancements" in evolution
        assert "new_features" in evolution
        assert "optimization_targets" in evolution
        assert "implementation_roadmap" in evolution
        
        # å„é …ç›®ã®è©³ç´°ç¢ºèª
        enhancements = evolution["capability_enhancements"]
        for enhancement in enhancements:
            assert "target_component" in enhancement
            assert "current_level" in enhancement
            assert "target_level" in enhancement
            assert "improvement_method" in enhancement
            
    async def test_predict_system_growth(self, learning_magic):

            """ã‚·ã‚¹ãƒ†ãƒ æˆé•·äºˆæ¸¬ãƒ†ã‚¹ãƒˆ""" [
                {"date": "2025-01-01", "metric": "response_time", "value": 0.5},
                {"date": "2025-02-01", "metric": "response_time", "value": 0.4},
                {"date": "2025-03-01", "metric": "response_time", "value": 0.35}
            ],
            "feature_adoption": [
                {"feature": "TDD_workflow", "adoption_rate": 0.8, "month": 1},
                {"feature": "TDD_workflow", "adoption_rate": 0.9, "month": 2},
                {"feature": "TDD_workflow", "adoption_rate": 0.95, "month": 3}
            ],
            "user_feedback": [
                {"period": "Q1", "satisfaction": 0.75, "usage": 1000},
                {"period": "Q2", "satisfaction": 0.82, "usage": 1200},
                {"period": "Q3", "satisfaction": 0.85, "usage": 1400}
            ]
        }
        
        result = await learning_magic.predict_system_growth(historical_data, months_ahead=6)
        
        assert result["success"] is True
        predictions = result["predictions"]
        
        # äºˆæ¸¬ã®æ§‹é€ ç¢ºèª
        assert "performance_forecast" in predictions
        assert "feature_evolution" in predictions
        assert "capacity_requirements" in predictions
        assert "risk_factors" in predictions
        
        # äºˆæ¸¬ç²¾åº¦ã®ç¢ºèª
        forecast = predictions["performance_forecast"]
        for metric in forecast:
            assert "confidence_interval" in metric
            assert metric["confidence"] >= 0.6
            
    # Phase 4: ãƒ¡ã‚¿å­¦ç¿’ï¼ˆMeta Learningï¼‰
    async def test_learn_how_to_learn(self, learning_magic):

    """å­¦ç¿’æ–¹æ³•ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ""" [
                {
                    "method": "pattern_recognition",
                    "data_size": 1000,
                    "learning_time": 30,  # minutes
                    "accuracy_improvement": 0.15,
                    "retention_rate": 0.90
                },
                {
                    "method": "failure_analysis",
                    "data_size": 50,
                    "learning_time": 60,
                    "accuracy_improvement": 0.25,
                    "retention_rate": 0.95
                }
            ],
            "learning_failures": [
                {
                    "method": "brute_force_memorization",
                    "reason": "low_retention",
                    "retention_rate": 0.40
                }
            ]
        }
        
        result = await learning_magic.learn_how_to_learn(learning_history)
        
        assert result["success"] is True
        meta_learning = result["meta_learning"]
        
        # ãƒ¡ã‚¿å­¦ç¿’çµæžœã®ç¢ºèª
        assert "optimal_methods" in meta_learning
        assert "method_selection_rules" in meta_learning
        assert "learning_efficiency_predictors" in meta_learning
        
        # æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’æˆ¦ç•¥ã®ç¢ºèª
        optimal_methods = meta_learning["optimal_methods"]
        for method in optimal_methods:
            assert "method_name" in method
            assert "effectiveness_score" in method
            assert "recommended_contexts" in method
            
    # Phase 5: å”èª¿å­¦ç¿’ï¼ˆCollaborative Learningï¼‰
    async def test_learn_from_servant_interactions(self, learning_magic):

    """ã‚µãƒ¼ãƒãƒ³ãƒˆé–“ç›¸äº’ä½œç”¨ã‹ã‚‰ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ""" [
                {
                    "servants": ["CodeCrafter", "QualityGuardian"],
                    "task": "API endpoint implementation",
                    "interaction_pattern": "sequential_handoff",
                    "success_metrics": {
                        "quality_score": 0.92,
                        "completion_time": 45,  # minutes
                        "error_rate": 0.02
                    }
                },
                {
                    "servants": ["SecurityGuard", "PerformanceTuner"],
                    "task": "system_optimization",
                    "interaction_pattern": "parallel_validation",
                    "success_metrics": {
                        "security_score": 0.95,
                        "performance_gain": 0.35,
                        "coordination_overhead": 0.10
                    }
                }
            ],
            "failed_collaborations": [
                {
                    "servants": ["DocForge", "TestForge"],
                    "task": "documentation_generation",
                    "failure_reason": "conflicting_output_formats",
                    "resolution": "standardized_interface_definition"
                }
            ]
        }
        
        result = await learning_magic.learn_from_servant_interactions(servant_interactions)
        
        assert result["success"] is True
        collaboration_insights = result["collaboration_insights"]
        
        # å”èª¿å­¦ç¿’çµæžœã®ç¢ºèª
        assert "optimal_collaboration_patterns" in collaboration_insights
        assert "servant_compatibility_matrix" in collaboration_insights
        assert "coordination_best_practices" in collaboration_insights
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å“è³ªç¢ºèª
        patterns = collaboration_insights["optimal_collaboration_patterns"]
        for pattern in patterns:
            assert "pattern_name" in pattern
            assert "success_rate" in pattern
            assert "recommended_use_cases" in pattern
            assert pattern["success_rate"] >= 0.75
            
    # Phase 6: ç¶™ç¶šå­¦ç¿’ï¼ˆContinuous Learningï¼‰
    async def test_continuous_learning_cycle(self, learning_magic):

    """ç¶™ç¶šå­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«ãƒ†ã‚¹ãƒˆ""" "daily",
            "data_sources": ["sage_interactions", "servant_performance", "user_feedback"],
            "learning_targets": ["pattern_recognition", "performance_optimization"],
            "retention_period": "90_days"
        }
        
        result = await learning_magic.start_continuous_learning(cycle_config)
        
        assert result["success"] is True
        cycle_status = result["cycle_status"]
        
        # ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª
        assert cycle_status["status"] == "active"
        assert "next_learning_session" in cycle_status
        assert "learning_queue" in cycle_status
        assert "performance_metrics" in cycle_status
        
        # å­¦ç¿’ã‚­ãƒ¥ãƒ¼ã®å†…å®¹ç¢ºèª
        queue = cycle_status["learning_queue"]
        assert len(queue) > 0
        for item in queue:
            assert "data_source" in item
            assert "learning_type" in item
            assert "priority" in item
            assert "estimated_duration" in item
            
    async def test_measure_learning_effectiveness(self, learning_magic):

            """å­¦ç¿’åŠ¹æžœæ¸¬å®šãƒ†ã‚¹ãƒˆ""" "learning_session_001",
            "start_time": "2025-01-01T10:00:00",
            "end_time": "2025-01-01T10:30:00",
            "learning_type": "pattern_recognition",
            "data_processed": 500,
            "patterns_discovered": 12,
            "pre_test_score": 0.70,
            "post_test_score": 0.85,
            "retention_test_score": 0.82  # 1é€±é–“å¾Œ
        }
        
        result = await learning_magic.measure_learning_effectiveness(learning_session_data)
        
        assert result["success"] is True
        effectiveness = result["effectiveness_metrics"]
        
        # åŠ¹æžœæ¸¬å®šæŒ‡æ¨™ã®ç¢ºèª
        assert "learning_gain" in effectiveness
        assert "retention_rate" in effectiveness
        assert "knowledge_transfer_score" in effectiveness
        assert "learning_efficiency" in effectiveness
        
        # å­¦ç¿’åŠ¹æžœã®å“è³ªç¢ºèª
        assert effectiveness["learning_gain"] > 0
        assert effectiveness["retention_rate"] >= 0.8
        assert effectiveness["learning_efficiency"] > 0
        
    # Phase 7: Elder Treeçµ±åˆãƒ†ã‚¹ãƒˆ
    async def test_elder_tree_learning_integration(self, learning_magic):

    """Elder Treeå­¦ç¿’çµ±åˆãƒ†ã‚¹ãƒˆ""" {
                "4_sages_metrics": {
                    "knowledge_sage": {"query_accuracy": 0.87, "response_time": 0.25},
                    "task_sage": {"task_completion": 0.93, "resource_efficiency": 0.81},
                    "incident_sage": {"resolution_speed": 0.78, "prevention_rate": 0.65},
                    "rag_sage": {"search_precision": 0.89, "context_relevance": 0.84}
                },
                "servant_performance": {
                    "active_servants": 19,
                    "average_quality_score": 0.82,
                    "collaboration_efficiency": 0.76
                }
            },
            "user_interactions": {
                "session_count": 1250,
                "satisfaction_score": 0.86,
                "feature_usage": {
                    "tdd_workflow": 0.92,
                    "code_review": 0.78,
                    "automated_testing": 0.85
                }
            }
        }
        
        result = await learning_magic.integrate_with_elder_tree(elder_tree_data)
        
        assert result["success"] is True
        integration = result["integration_result"]
        
        # Elder Treeçµ±åˆçµæžœã®ç¢ºèª
        assert "system_improvements" in integration
        assert "sage_enhancements" in integration  
        assert "servant_optimizations" in integration
        assert "user_experience_upgrades" in integration
        
        # æ”¹å–„ææ¡ˆã®å“è³ªç¢ºèª
        improvements = integration["system_improvements"]
        for improvement in improvements:
            assert "component" in improvement
            assert "current_performance" in improvement
            assert "target_performance" in improvement
            assert "implementation_plan" in improvement


@pytest.mark.asyncio
class TestLearningMagicIntegration:

            """Learning Magicçµ±åˆãƒ†ã‚¹ãƒˆ"""
        """4è³¢è€…å­¦ç¿’å”èª¿ãƒ†ã‚¹ãƒˆ"""
        learning_magic = LearningMagic()
        
        # 4è³¢è€…ã‹ã‚‰ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡æ“¬
        sage_learning_data = {
            "knowledge_sage": {
                "new_patterns": 5,
                "knowledge_quality_improvement": 0.12,
                "learning_session_duration": 20
            },
            "task_sage": {
                "workflow_optimizations": 3,
                "efficiency_gain": 0.18,
                "automation_opportunities": 7
            },
            "incident_sage": {
                "prevention_strategies": 4,
                "resolution_time_improvement": 0.25,
                "false_positive_reduction": 0.15
            },
            "rag_sage": {
                "search_accuracy_improvement": 0.08,
                "context_understanding_gain": 0.20,
                "response_relevance_boost": 0.13
            }
        }
        
        result = await learning_magic.coordinate_sage_learning(sage_learning_data)
        
        assert result["success"] is True
        assert "learning_synthesis" in result
        assert "cross_sage_insights" in result
        assert result["overall_system_improvement"] > 0


if __name__ == "__main__":
    pytest.main(["-v", __file__])