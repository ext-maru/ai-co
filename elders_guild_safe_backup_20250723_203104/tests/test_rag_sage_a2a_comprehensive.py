#!/usr/bin/env python3
"""
ğŸ” RAG Sage A2A Agent - åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
========================================

Elder Loop Phase 4: å³å¯†æ¤œè¨¼ãƒ«ãƒ¼ãƒ—
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ä¸¦è¡Œæ€§ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»çµ±åˆãƒ†ã‚¹ãƒˆ

Author: Claude Elder
Created: 2025-07-23
"""

import asyncio
import json
import time
import logging
from datetime import datetime
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor
import threading
import random
import gc

# RAG Sage imports
import sys
sys.path.append("/home/aicompany/ai_co/elders_guild")
from rag_sage.business_logic import RAGProcessor


class TestRAGSageA2AComprehensive:


"""RAG Sage A2A AgentåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        self.test_results = {}
        self.performance_metrics = {}
        self.logger = logging.getLogger("rag_sage_comprehensive_test")
    
    async def run_all_tests(self) -> Dict[str, Any]:

        """å…¨åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
            print(f"\nğŸ§ª {test_name.replace('_', ' ').title()} å®Ÿè¡Œä¸­...")
            try:
                start_time = time.time()
                result = await test_method()
                end_time = time.time()
                
                self.test_results[test_name] = {
                    "passed": result,
                    "duration": end_time - start_time
                }
                
                if result:
                    passed_tests += 1
                    print(f"   âœ… {test_name} æˆåŠŸ ({self.test_results[test_name]['duration']:.3f}s)")
                else:
                    print(f"   âŒ {test_name} å¤±æ•—")
                    
            except Exception as e:
                print(f"   ğŸ’¥ {test_name} ã‚¨ãƒ©ãƒ¼: {e}")
                self.test_results[test_name] = {
                    "passed": False,
                    "error": str(e),
                    "duration": 0
                }
        
        # ç·åˆçµæœ
        success_rate = (passed_tests / total_tests) * 100
        total_duration = sum(r.get("duration", 0) for r in self.test_results.values())
        
        print(f"\nğŸ“Š åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 70)
        print(f"åˆæ ¼ãƒ†ã‚¹ãƒˆ: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {total_duration:.3f}ç§’")
        print(f"å¹³å‡ãƒ†ã‚¹ãƒˆæ™‚é–“: {total_duration/total_tests:.3f}ç§’")
        
        return {
            "total": total_tests,
            "passed": passed_tests,
            "failed": total_tests - passed_tests,
            "success_rate": success_rate,
            "total_duration": total_duration,
            "performance_metrics": self.performance_metrics,
            "details": self.test_results
        }
    
    async def test_performance(self) -> bool:

        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
            documents.append({
                "id": f"perf_doc_{i}",
                "content": f"ã“ã‚Œã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i}ã§ã™ã€‚" * 10,
                "source": "performance_test",
                "title": f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ {i}",
                "category": random.choice(["tech", "docs", "test"]),
                "tags": [f"tag{j}" for j in range(random.randint(1, 5))]
            })
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ™‚é–“æ¸¬å®š
        index_start = time.time()
        result = await processor.process_action("batch_index_documents", {
            "documents": documents
        })
        index_time = time.time() - index_start
        
        # æ¤œç´¢æ™‚é–“æ¸¬å®š
        search_times = []
        queries = ["ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "ãƒ†ã‚¹ãƒˆ", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", "ã“ã‚Œã¯"]
        
        for query in queries:
            search_start = time.time()
            result = await processor.process_action("search_knowledge", {
                "query": query,
                "limit": 20
            })
            search_time = time.time() - search_start
            search_times.append(search_time)
        
        avg_search_time = sum(search_times) / len(search_times)
        
        self.performance_metrics["indexing"] = {
            "documents": len(documents),
            "total_time": index_time,
            "docs_per_second": len(documents) / index_time
        }
        
        self.performance_metrics["search"] = {
            "queries": len(queries),
            "avg_time": avg_search_time,
            "queries_per_second": 1 / avg_search_time if avg_search_time > 0 else 0
        }
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ï¼ˆ50 docs/sec ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€8 queries/sec æ¤œç´¢ï¼‰
        # æ¤œç´¢ã¯SQLiteãƒ™ãƒ¼ã‚¹ãªã®ã§åŸºæº–ã‚’ç¾å®Ÿçš„ã«èª¿æ•´
        return (self.performance_metrics["indexing"]["docs_per_second"] > 50 and
                self.performance_metrics["search"]["queries_per_second"] > 8)
    
    async def test_concurrency(self) -> bool:

        """ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
            await processor.process_action("index_document", {
                "document": {
                    "id": f"concurrent_doc_{i}",
                    "content": f"ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i}",
                    "source": "concurrent_test",
                    "title": f"ä¸¦è¡Œãƒ†ã‚¹ãƒˆ {i}"
                }
            })
        
        # ä¸¦è¡Œæ¤œç´¢ã‚¿ã‚¹ã‚¯
        async def concurrent_search(query: str, task_id: int):
            result = await processor.process_action("search_knowledge", {
                "query": query,
                "limit": 10
            })
            return task_id, result["success"]
        
        # 20ä¸¦è¡Œã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
        tasks = []
        for i in range(20):
            query = random.choice(["ä¸¦è¡Œ", "ãƒ†ã‚¹ãƒˆ", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", f"{i}"])
            tasks.append(concurrent_search(query, i))
        
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        # çµæœæ¤œè¨¼
        successful_tasks = sum(1 for _, success in results if isinstance(success, bool) and success)
        
        self.performance_metrics["concurrency"] = {
            "total_tasks": len(tasks),
            "successful_tasks": successful_tasks,
            "total_time": end_time - start_time,
            "tasks_per_second": len(tasks) / (end_time - start_time)
        }
        
        return successful_tasks == len(tasks)
    
    async def test_error_handling(self) -> bool:

        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ""" "index_document",
                "data": {"document": {"content": ""}},  # IDãªã—
                "should_fail": True
            },
            # å­˜åœ¨ã—ãªã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤
            {
                "action": "delete_document",
                "data": {"document_id": "non_existent_doc"},
                "should_fail": True
            },
            # ä¸æ­£ãªæ¤œç´¢ã‚¿ã‚¤ãƒ—
            {
                "action": "search_knowledge",
                "data": {"query": "test", "search_type": "invalid_type"},
                "should_fail": True
            },
            # ç©ºã®ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            {
                "action": "batch_index_documents",
                "data": {"documents": []},
                "should_fail": False  # ç©ºã§ã‚‚æˆåŠŸã™ã‚‹ã¹ã
            },
            # æ¥µç«¯ãªãƒ–ãƒ¼ã‚¹ãƒˆå€¤ï¼ˆå­˜åœ¨ã—ãªã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰
            {
                "action": "update_document_boost",
                "data": {"document_id": "non_existent_doc", "boost_value": 100.0},
                "should_fail": True  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„ãŸã‚å¤±æ•—ã™ã¹ã
            }
        ]
        
        all_passed = True
        for case in error_cases:
            try:
                result = await processor.process_action(case["action"], case["data"])
                if case["should_fail"]:
                    # ã‚¨ãƒ©ãƒ¼ãŒæœŸå¾…ã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹
                    if result.get("success", True):
                        print(f"   âš ï¸ Expected failure but succeeded: {case['action']}")
                        all_passed = False
                else:
                    # æˆåŠŸãŒæœŸå¾…ã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹
                    if not result.get("success", False):
                        print(f"   âš ï¸ Expected success but failed: {case['action']}")
                        all_passed = False
            except Exception as e:
                if not case["should_fail"]:
                    print(f"   âš ï¸ Unexpected exception: {e}")
                    all_passed = False
        
        return all_passed
    
    async def test_data_integrity(self) -> bool:

                    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ""" "integrity_test_doc",
            "content": "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
            "source": "integrity_test",
            "title": "æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ",
            "category": "test",
            "tags": ["integrity", "test"],
            "author": "Test Author",
            "relevance_boost": 1.5
        }
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        await processor.process_action("index_document", {"document": test_doc})
        
        # æ¤œç´¢ã—ã¦ç¢ºèª
        result = await processor.process_action("search_knowledge", {
            "query": test_doc["content"],
            "limit": 1
        })
        
        if not result["success"] or len(result["data"]["results"]) == 0:
            return False
        
        retrieved_doc = result["data"]["results"][0]
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
        checks = [
            retrieved_doc["content"] == test_doc["content"],
            retrieved_doc["source"] == test_doc["source"],
            retrieved_doc["title"] == test_doc["title"],
            retrieved_doc["category"] == test_doc["category"],
            set(retrieved_doc["tags"]) == set(test_doc["tags"])
        ]
        
        return all(checks)
    
    async def test_complex_queries(self) -> bool:

            """è¤‡é›‘ãªã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"""
            await processor.process_action("index_document", {
                "document": {
                    "id": f"complex_doc_{i}",
                    "content": f"è¤‡é›‘ãªã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i}ã€‚ã‚«ãƒ†ã‚´ãƒªã¯{categories[i % 4]}ã§ã™ã€‚",
                    "source": f"source_{i % 3}",
                    "title": f"è¤‡é›‘ãƒ†ã‚¹ãƒˆ {i}",
                    "category": categories[i % 4],
                    "tags": [f"tag{j}" for j in range(i % 5)]
                }
            })
        
        # è¤‡é›‘ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ„ã¿åˆã‚ã›
        complex_queries = [
            {
                "query": "è¤‡é›‘",
                "filters": {"category": "tech"},
                "expected_category": "tech"
            },
            {
                "query": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                "filters": {"tags": ["tag1", "tag2"]},
                "expected_tags": True
            },
            {
                "query": "",
                "filters": {"source": "source_0"},
                "expected_source": "source_0"
            }
        ]
        
        all_passed = True
        for cq in complex_queries:
            result = await processor.process_action("search_knowledge", cq)
            
            if not result["success"]:
                all_passed = False
                continue
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœæ¤œè¨¼
            for doc in result["data"]["results"]:
                if "expected_category" in cq and doc["category"] != cq["expected_category"]:
                    all_passed = False
                if "expected_source" in cq and doc["source"] != cq["expected_source"]:
                    all_passed = False
        
        return all_passed
    
    async def test_memory_efficiency(self) -> bool:

                    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
            documents = []
            for i in range(batch_size):
                doc_id = batch * batch_size + i
                documents.append({
                    "id": f"memory_doc_{doc_id}",
                    "content": f"ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆç”¨ã®é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ " * 20,
                    "source": "memory_test",
                    "title": f"ãƒ¡ãƒ¢ãƒªãƒ†ã‚¹ãƒˆ {doc_id}"
                })
            
            await processor.process_action("batch_index_documents", {
                "documents": documents
            })
            
            # å®šæœŸçš„ã«GCå®Ÿè¡Œ
            if batch % 5 == 0:
                gc.collect()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç¢ºèª
        cache_size = len(processor.cache)
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŸºæº–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒ1000ä»¥ä¸‹ã«ä¿ãŸã‚Œã¦ã„ã‚‹ï¼‰
        return cache_size <= 1000
    
    async def test_search_accuracy(self) -> bool:

                """æ¤œç´¢ç²¾åº¦ãƒ†ã‚¹ãƒˆ""" {
                    "id": "exact_match",
                    "content": "Elder Loopé–‹ç™ºæ‰‹æ³•ã®å®Œå…¨ãªèª¬æ˜",
                    "title": "Elder Loop Guide"
                },
                "query": "Elder Loopé–‹ç™ºæ‰‹æ³•ã®å®Œå…¨ãªèª¬æ˜",
                "should_find": True,
                "expected_rank": 1
            },
            {
                "doc": {
                    "id": "partial_match",
                    "content": "éƒ¨åˆ†çš„ã«ãƒãƒƒãƒã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ with Elder",
                    "title": "Partial Match"
                },
                "query": "Elder",
                "should_find": True,
                "expected_rank": 2
            },
            {
                "doc": {
                    "id": "no_match",
                    "content": "å…¨ãé–¢ä¿‚ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    "title": "Unrelated"
                },
                "query": "Elder Loop",
                "should_find": False,
                "expected_rank": None
            }
        ]
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        for tc in test_cases:
            await processor.process_action("index_document", {"document": tc["doc"]})
        
        # æ¤œç´¢ç²¾åº¦ç¢ºèª
        all_passed = True
        for tc in test_cases:
            result = await processor.process_action("search_knowledge", {
                "query": tc["query"],
                "limit": 10
            })
            
            found = any(r["document_id"] == tc["doc"]["id"] 
                       for r in result["data"]["results"])
            
            if tc["should_find"] != found:
                all_passed = False
        
        return all_passed
    
    async def test_indexing_performance(self) -> bool:

                """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
            await processor.process_action("index_document", {
                "document": {
                    "id": f"individual_{i}",
                    "content": f"å€‹åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ {i}",
                    "source": "individual"
                }
            })
        individual_time = time.time() - individual_start
        
        # ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ™‚é–“
        batch_docs = [
            {
                "id": f"batch_{i}",
                "content": f"ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ {i}",
                "source": "batch"
            }
            for i in range(num_docs)
        ]
        
        batch_start = time.time()
        await processor.process_action("batch_index_documents", {
            "documents": batch_docs
        })
        batch_time = time.time() - batch_start
        
        self.performance_metrics["indexing_comparison"] = {
            "individual_time": individual_time,
            "batch_time": batch_time,
            "speedup": individual_time / batch_time if batch_time > 0 else 0
        }
        
        # ãƒãƒƒãƒãŒå€‹åˆ¥ã‚ˆã‚Šé«˜é€Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        # ãŸã ã—ã€ã‚ãšã‹ãªå·®ã¯è¨±å®¹ï¼ˆ1.2å€ä»¥å†…ãªã‚‰åŒç­‰ã¨ã¿ãªã™ï¼‰
        if batch_time < individual_time:
            return True
        elif individual_time * 1.2 >= batch_time:
            # ã»ã¼åŒç­‰ã®æ€§èƒ½ã§ã‚‚æˆåŠŸã¨ã™ã‚‹
            return True
        else:
            print(f"   âš ï¸ ãƒãƒƒãƒãŒé…ã„: å€‹åˆ¥{individual_time:.2f}s vs ãƒãƒƒãƒ{batch_time:.2f}s")
            return False
    
    async def test_cache_effectiveness(self) -> bool:

            """ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœãƒ†ã‚¹ãƒˆ"""
            await processor.process_action("index_document", {
                "document": {
                    "id": f"cache_doc_{i}",
                    "content": f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i}",
                    "source": "cache_test"
                }
            })
        
        # åŒã˜ã‚¯ã‚¨ãƒªã‚’è¤‡æ•°å›å®Ÿè¡Œ
        query = "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ"
        
        # åˆå›æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—ï¼‰
        first_start = time.time()
        result1 = await processor.process_action("search_knowledge", {
            "query": query,
            "limit": 5
        })
        first_time = time.time() - first_start
        
        # 2å›ç›®æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰
        second_start = time.time()
        result2 = await processor.process_action("search_knowledge", {
            "query": query,
            "limit": 5
        })
        second_time = time.time() - second_start
        
        self.performance_metrics["cache"] = {
            "first_search": first_time,
            "cached_search": second_time,
            "speedup": first_time / second_time if second_time > 0 else 0
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåŠ¹ã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆ2å›ç›®ãŒé«˜é€Ÿï¼‰
        return second_time < first_time * 0.5  # 50%ä»¥ä¸Šé«˜é€ŸåŒ–
    
    async def test_filter_combinations(self) -> bool:

        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ""" "tech", "tags": ["a", "b"], "source": "blog"},
            {"category": "tech", "tags": ["b", "c"], "source": "docs"},
            {"category": "guide", "tags": ["a", "c"], "source": "blog"},
            {"category": "guide", "tags": ["b"], "source": "wiki"}
        ]
        
        for i, attrs in enumerate(docs):
            doc = {
                "id": f"filter_doc_{i}",
                "content": f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ {i}",
                "title": f"Filter Test {i}",
                **attrs
            }
            await processor.process_action("index_document", {"document": doc})
        
        # è¤‡æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ
        filter_tests = [
            ({"category": "tech"}, 2),  # tech ã‚«ãƒ†ã‚´ãƒªã¯2ä»¶
            ({"tags": ["a"]}, 2),        # tag "a" ã¯2ä»¶
            ({"category": "tech", "tags": ["b"]}, 2),  # tech ã‹ã¤ tag "b"
            ({"source": "blog"}, 2)      # blog ã‚½ãƒ¼ã‚¹ã¯2ä»¶
        ]
        
        all_passed = True
        for filters, expected_count in filter_tests:
            result = await processor.process_action("search_knowledge", {
                "query": "",
                "filters": filters,
                "limit": 10
            })
            
            if len(result["data"]["results"]) != expected_count:
                all_passed = False
        
        return all_passed
    
    async def test_large_result_sets(self) -> bool:

                """å¤§é‡çµæœã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
            await processor.process_action("index_document", {
                "document": {
                    "id": f"large_set_{i}",
                    "content": "å¤§é‡çµæœã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆå…±é€šã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    "source": "large_test",
                    "relevance_boost": random.uniform(0.5, 2.0)
                }
            })
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
        page_size = 20
        total_pages = 3
        all_ids = set()
        
        for page in range(total_pages):
            result = await processor.process_action("search_knowledge", {
                "query": "å¤§é‡çµæœã‚»ãƒƒãƒˆ",
                "limit": page_size,
                "offset": page * page_size
            })
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            page_ids = {r["document_id"] for r in result["data"]["results"]}
            if page_ids & all_ids:  # é‡è¤‡ãŒã‚ã‚Œã°å¤±æ•—
                return False
            all_ids.update(page_ids)
        
        return len(all_ids) == page_size * total_pages
    
    async def test_concurrent_indexing(self) -> bool:

                """ä¸¦è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ""" int):
            docs = []
            for i in range(10):
                docs.append({
                    "id": f"concurrent_idx_{task_id}_{i}",
                    "content": f"ä¸¦è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ ã‚¿ã‚¹ã‚¯{task_id} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i}",
                    "source": f"task_{task_id}"
                })
            
            result = await processor.process_action("batch_index_documents", {
                "documents": docs
            })
            return result["success"]
        
        # 10ã‚¿ã‚¹ã‚¯ä¸¦è¡Œå®Ÿè¡Œ
        tasks = [index_task(i) for i in range(10)]
        results = await asyncio.gather(*tasks)
        
        # å…¨ã‚¿ã‚¹ã‚¯æˆåŠŸç¢ºèª
        return all(results)
    
    async def test_stress_load(self) -> bool:

            """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
            operation = random.choice(["search", "index", "delete"])
            
            try:
                if operation == "search":
                    await processor.process_action("search_knowledge", {
                        "query": f"stress {random.randint(1, 100)}",
                        "limit": 5
                    })
                elif operation == "index":
                    await processor.process_action("index_document", {
                        "document": {
                            "id": f"stress_{operations}",
                            "content": f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ {operations}",
                            "source": "stress"
                        }
                    })
                else:  # delete
                    await processor.process_action("delete_document", {
                        "document_id": f"stress_{random.randint(0, operations)}"
                    })
                
                operations += 1
            except Exception:
                errors += 1
        
        self.performance_metrics["stress"] = {
            "total_operations": operations,
            "errors": errors,
            "ops_per_second": operations / stress_duration,
            "error_rate": errors / operations if operations > 0 else 0
        }
        
        # ã‚¨ãƒ©ãƒ¼ç‡ãŒ5%æœªæº€ã§ã‚ã‚‹ã“ã¨
        return self.performance_metrics["stress"]["error_rate"] < 0.05
    
    async def test_edge_cases(self) -> bool:

        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ""" {
                "id": "test",
                "content": "ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                "source": "edge_test",
                "title": "Edge Test Document"
            }
        })
        
        edge_cases = [
            # ç©ºæ–‡å­—åˆ—æ¤œç´¢
            {"action": "search_knowledge", "data": {"query": ""}, "should_succeed": True},
            # è¶…é•·æ–‡ã‚¯ã‚¨ãƒª
            {"action": "search_knowledge", "data": {"query": "x" * 1000}, "should_succeed": True},
            # ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ã‚¯ã‚¨ãƒª
            {"action": "search_knowledge", "data": {"query": "!@#$%^&*()"}, "should_succeed": True},
            # æ—¥æœ¬èªã¨è‹±èªã®æ··åœ¨
            {"action": "search_knowledge", "data": {"query": "Elder Loopé–‹ç™º"}, "should_succeed": True},
            # Unicodeæ–‡å­—
            {"action": "search_knowledge", "data": {"query": "ğŸ”æ¤œç´¢ãƒ†ã‚¹ãƒˆğŸ§ª"}, "should_succeed": True},
            # æ¥µå°ãƒ–ãƒ¼ã‚¹ãƒˆå€¤
            {"action": "update_document_boost", "data": {"document_id": "test", "boost_value": 0.001}, "should_succeed": True},
            # æ¥µå¤§ãƒ–ãƒ¼ã‚¹ãƒˆå€¤
            {"action": "update_document_boost", "data": {"document_id": "test", "boost_value": 1000}, "should_succeed": True}
        ]
        
        all_passed = True
        for case in edge_cases:
            try:
                result = await processor.process_action(case["action"], case["data"])
                if case["should_succeed"] and not result.get("success", False):
                    all_passed = False
            except Exception as e:
                if case["should_succeed"]:
                    all_passed = False
        
        return all_passed
    
    async def test_integration_scenarios(self) -> bool:

                    """çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ""" ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ãƒ•ãƒ­ãƒ¼
        # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
        doc_id = "integration_doc_1"
        await processor.process_action("index_document", {
            "document": {
                "id": doc_id,
                "content": "çµ±åˆãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                "source": "integration",
                "title": "Integration Test",
                "relevance_boost": 1.0
            }
        })
        
        # 2. æ¤œç´¢ã§ç¢ºèª
        result = await processor.process_action("search_knowledge", {
            "query": "çµ±åˆãƒ†ã‚¹ãƒˆ",
            "limit": 1
        })
        
        if not result["success"] or len(result["data"]["results"]) == 0:
            return False
        
        # 3. ãƒ–ãƒ¼ã‚¹ãƒˆæ›´æ–°
        await processor.process_action("update_document_boost", {
            "document_id": doc_id,
            "boost_value": 2.0
        })
        
        # 4. é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢
        result = await processor.process_action("get_similar_documents", {
            "document_id": doc_id,
            "limit": 5
        })
        
        if not result["success"]:
            return False
        
        # 5. çµ±è¨ˆç¢ºèª
        result = await processor.process_action("get_index_info", {})
        
        if not result["success"] or result["data"]["document_count"] == 0:
            return False
        
        # 6. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤
        result = await processor.process_action("delete_document", {
            "document_id": doc_id
        })
        
        return result["success"] and result["data"]["deleted"]


async def main():

        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        print(f"\nğŸ‰ Elder Loop Quality Gate PASSED! ({results['success_rate']:.1f}%)")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        print("\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        if "indexing" in results["performance_metrics"]:
            metrics = results["performance_metrics"]["indexing"]
            print(f"   - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é€Ÿåº¦: {metrics['docs_per_second']:.1f} docs/sec")
        if "search" in results["performance_metrics"]:
            metrics = results["performance_metrics"]["search"]
            print(f"   - æ¤œç´¢é€Ÿåº¦: {metrics['queries_per_second']:.1f} queries/sec")
        if "concurrency" in results["performance_metrics"]:
            metrics = results["performance_metrics"]["concurrency"]
            print(f"   - ä¸¦è¡Œå‡¦ç†: {metrics['successful_tasks']}/{metrics['total_tasks']} tasks")
        if "cache" in results["performance_metrics"]:
            metrics = results["performance_metrics"]["cache"]
            print(f"   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ: {metrics['speedup']:.1f}x speedup")
    else:
        print(f"\nâŒ Elder Loop Quality Gate FAILED! ({results['success_rate']:.1f}% < 80%)")


if __name__ == "__main__":
    logging.basicConfig(level=logging.WARNING)
    asyncio.run(main())