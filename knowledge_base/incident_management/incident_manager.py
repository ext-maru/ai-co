#!/usr/bin/env python3
"""
Elders Guild ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼
æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ç®¡ç†æ©Ÿèƒ½ã‚’æ‹¡å¼µã—ãŸåŒ…æ‹¬çš„ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import sys
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Literal, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ ï¼ˆElders Guildæ¨™æº–ï¼‰
PROJECT_ROOT = Path(__file__).parent.parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚«ãƒ†ã‚´ãƒªã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å®šç¾©
IncidentCategory = Literal[
    "error", "failure", "request", "change", "security", "performance"
]
IncidentPriority = Literal["critical", "high", "medium", "low"]
IncidentStatus = Literal["open", "in_progress", "resolved", "closed"]


class IncidentManager:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ã‚¢ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.base_path = Path(__file__).parent
        self.history_file = self.base_path / "incident_history.json"
        self.patterns_file = self.base_path / "INCIDENT_PATTERNS_KB.md"
        self.error_handling_path = self.base_path.parent / "error_handling"

        # æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ç®¡ç†ã¨ã®é€£æº
        self.error_history_file = self.error_handling_path / "error_history.json"

        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰
        self.load_history()

    def load_history(self):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.history_file.exists():
            with open(self.history_file, "r", encoding="utf-8") as f:
                self.history = json.load(f)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ 
            self.history = {
                "metadata": {
                    "version": "1.0",
                    "created": datetime.now(timezone.utc).isoformat(),
                    "last_updated": datetime.now(timezone.utc).isoformat(),
                    "total_incidents": 0,
                    "open_incidents": 0,
                    "resolved_incidents": 0,
                    "categories": {
                        "error": "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãƒ»ä¾‹å¤–",
                        "failure": "ã‚µãƒ¼ãƒ“ã‚¹éšœå®³ãƒ»æ©Ÿèƒ½ä¸å…¨",
                        "request": "æ©Ÿèƒ½è¦æ±‚ãƒ»ã‚µãƒ¼ãƒ“ã‚¹è¦æ±‚",
                        "change": "å¤‰æ›´è¦æ±‚ãƒ»è¨­å®šå¤‰æ›´",
                        "security": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ",
                        "performance": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ",
                    },
                },
                "incidents": [],
                "category_statistics": {
                    cat: {"count": 0, "open": 0, "avg_resolution_time": None}
                    for cat in [
                        "error",
                        "failure",
                        "request",
                        "change",
                        "security",
                        "performance",
                    ]
                },
                "priority_statistics": {
                    pri: {"count": 0, "open": 0, "avg_resolution_time": None}
                    for pri in ["critical", "high", "medium", "low"]
                },
                "recurring_patterns": [],
                "preventive_actions": [],
                "knowledge_base_updates": [],
            }

    def save_history(self):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ã‚’ä¿å­˜"""
        self.history["metadata"]["last_updated"] = datetime.now(
            timezone.utc
        ).isoformat()
        with open(self.history_file, "w", encoding="utf-8") as f:
            json.dump(self.history, f, indent=2, ensure_ascii=False)

    def create_incident(
        self,
        category: IncidentCategory,
        priority: IncidentPriority,
        title: str,
        description: str,
        affected_components: List[str],
        impact: str,
        assignee: str = "ai_system",
    ) -> str:
        """æ–°è¦ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’ä½œæˆ"""
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆIDç”Ÿæˆ
        date_part = datetime.now().strftime("%Y%m%d")
        count = (
            len(
                [
                    i
                    for i in self.history["incidents"]
                    if i["incident_id"].startswith(f"INC-{date_part}")
                ]
            )
            + 1
        )
        incident_id = f"INC-{date_part}-{count:04d}"

        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        incident = {
            "incident_id": incident_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "category": category,
            "priority": priority,
            "title": title,
            "description": description,
            "affected_components": affected_components,
            "impact": impact,
            "status": "open",
            "assignee": assignee,
            "resolution": None,
            "timeline": [
                {
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "action": "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ",
                    "details": f"ã‚«ãƒ†ã‚´ãƒª: {category}, å„ªå…ˆåº¦: {priority}",
                }
            ],
        }

        # å±¥æ­´ã«è¿½åŠ 
        self.history["incidents"].append(incident)
        self.history["metadata"]["total_incidents"] += 1
        self.history["metadata"]["open_incidents"] += 1
        self.history["category_statistics"][category]["count"] += 1
        self.history["category_statistics"][category]["open"] += 1
        self.history["priority_statistics"][priority]["count"] += 1
        self.history["priority_statistics"][priority]["open"] += 1

        # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®å ´åˆã¯æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ç®¡ç†ã¨é€£æº
        if category == "error" and self.error_history_file.exists():
            self._sync_with_error_handling(incident)

        self.save_history()
        return incident_id

    def update_incident(self, incident_id: str, updates: Dict) -> bool:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’æ›´æ–°"""
        for incident in self.history["incidents"]:
            if incident["incident_id"] == incident_id:
                # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«æ›´æ–°ã‚’è¨˜éŒ²
                incident["timeline"].append(
                    {
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "action": "æ›´æ–°",
                        "details": f"æ›´æ–°é …ç›®: {list(updates.keys())}",
                    }
                )

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´ã®å‡¦ç†
                if "status" in updates:
                    old_status = incident["status"]
                    new_status = updates["status"]

                    if old_status in ["open", "in_progress"] and new_status in [
                        "resolved",
                        "closed",
                    ]:
                        self.history["metadata"]["open_incidents"] -= 1
                        self.history["metadata"]["resolved_incidents"] += 1
                        self.history["category_statistics"][incident["category"]][
                            "open"
                        ] -= 1
                        self.history["priority_statistics"][incident["priority"]][
                            "open"
                        ] -= 1

                # æ›´æ–°ã‚’é©ç”¨
                incident.update(updates)
                self.save_history()
                return True
        return False

    def resolve_incident(
        self,
        incident_id: str,
        actions_taken: List[str],
        root_cause: str,
        preventive_measures: List[str] = None,
        knowledge_updates: List[str] = None,
    ) -> bool:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’è§£æ±º"""
        resolution = {
            "actions_taken": actions_taken,
            "root_cause": root_cause,
            "preventive_measures": preventive_measures or [],
            "knowledge_updates": knowledge_updates or [],
            "resolved_at": datetime.now(timezone.utc).isoformat(),
        }

        updates = {"status": "resolved", "resolution": resolution}

        # è§£æ±ºæ™‚é–“ã‚’è¨ˆç®—ã—ã¦çµ±è¨ˆã‚’æ›´æ–°
        for incident in self.history["incidents"]:
            if incident["incident_id"] == incident_id:
                created_time = datetime.fromisoformat(
                    incident["timestamp"].replace("Z", "+00:00")
                )
                resolved_time = datetime.now(timezone.utc)
                resolution_time = (
                    resolved_time - created_time
                ).total_seconds() / 3600  # æ™‚é–“å˜ä½

                # çµ±è¨ˆæ›´æ–°
                self._update_resolution_statistics(
                    incident["category"], incident["priority"], resolution_time
                )

                # äºˆé˜²ç­–ãŒã‚ã‚Œã°è¨˜éŒ²
                if preventive_measures:
                    self.history["preventive_actions"].extend(preventive_measures)

                # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ›´æ–°ãŒã‚ã‚Œã°è¨˜éŒ²
                if knowledge_updates:
                    self.history["knowledge_base_updates"].extend(knowledge_updates)

                break

        return self.update_incident(incident_id, updates)

    def get_open_incidents(
        self, category: Optional[IncidentCategory] = None
    ) -> List[Dict]:
        """ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’å–å¾—"""
        incidents = [
            i
            for i in self.history["incidents"]
            if i["status"] in ["open", "in_progress"]
        ]
        if category:
            incidents = [i for i in incidents if i["category"] == category]
        return incidents

    def get_incident_by_id(self, incident_id: str) -> Optional[Dict]:
        """IDã§ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’å–å¾—"""
        for incident in self.history["incidents"]:
            if incident["incident_id"] == incident_id:
                return incident
        return None

    def analyze_patterns(self) -> Dict:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        analysis = {
            "most_common_category": None,
            "most_common_components": [],
            "recurring_issues": [],
            "avg_resolution_times": {},
            "recommendations": [],
        }

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é »åº¦
        category_counts = {
            cat: data["count"]
            for cat, data in self.history["category_statistics"].items()
        }
        if category_counts:
            analysis["most_common_category"] = max(
                category_counts, key=category_counts.get
            )

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆ¥ã®é »åº¦
        component_counts = {}
        for incident in self.history["incidents"]:
            for component in incident.get("affected_components", []):
                component_counts[component] = component_counts.get(component, 0) + 1

        if component_counts:
            sorted_components = sorted(
                component_counts.items(), key=lambda x: x[1], reverse=True
            )
            analysis["most_common_components"] = sorted_components[:5]

        # å†ç™ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        title_counts = {}
        for incident in self.history["incidents"]:
            title = incident["title"]
            title_counts[title] = title_counts.get(title, 0) + 1

        analysis["recurring_issues"] = [
            (title, count) for title, count in title_counts.items() if count > 1
        ]

        # å¹³å‡è§£æ±ºæ™‚é–“
        for cat, data in self.history["category_statistics"].items():
            if data["avg_resolution_time"]:
                analysis["avg_resolution_times"][
                    cat
                ] = f"{data['avg_resolution_time']:.1f}æ™‚é–“"

        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        if analysis["most_common_category"]:
            analysis["recommendations"].append(
                f"{analysis['most_common_category']}ã‚«ãƒ†ã‚´ãƒªã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãŒæœ€å¤šã€‚äºˆé˜²ç­–ã®å¼·åŒ–ã‚’æ¨å¥¨"
            )

        if analysis["recurring_issues"]:
            analysis["recommendations"].append(
                f"å†ç™ºã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãŒ{len(analysis['recurring_issues'])}ä»¶ã€‚æ ¹æœ¬åŸå› åˆ†æã®å®Ÿæ–½ã‚’æ¨å¥¨"
            )

        return analysis

    def generate_report(self) -> str:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = []
        report.append("# ğŸ“Š Elders Guild ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ãƒ¬ãƒãƒ¼ãƒˆ")
        report.append(f"\nç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # ã‚µãƒãƒªãƒ¼
        report.append("\n## ğŸ“ˆ ã‚µãƒãƒªãƒ¼")
        meta = self.history["metadata"]
        report.append(f"- ç·ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•°: {meta['total_incidents']}")
        report.append(f"- ã‚ªãƒ¼ãƒ—ãƒ³: {meta['open_incidents']}")
        report.append(f"- è§£æ±ºæ¸ˆã¿: {meta['resolved_incidents']}")

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        report.append("\n## ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")
        report.append("| ã‚«ãƒ†ã‚´ãƒª | ä»¶æ•° | ã‚ªãƒ¼ãƒ—ãƒ³ | å¹³å‡è§£æ±ºæ™‚é–“ |")
        report.append("|----------|------|----------|--------------|")
        for cat, data in self.history["category_statistics"].items():
            avg_time = (
                f"{data['avg_resolution_time']:.1f}h"
                if data["avg_resolution_time"]
                else "N/A"
            )
            report.append(f"| {cat} | {data['count']} | {data['open']} | {avg_time} |")

        # å„ªå…ˆåº¦åˆ¥çµ±è¨ˆ
        report.append("\n## ğŸš¨ å„ªå…ˆåº¦åˆ¥çµ±è¨ˆ")
        report.append("| å„ªå…ˆåº¦ | ä»¶æ•° | ã‚ªãƒ¼ãƒ—ãƒ³ | å¹³å‡è§£æ±ºæ™‚é–“ |")
        report.append("|--------|------|----------|--------------|")
        for pri, data in self.history["priority_statistics"].items():
            avg_time = (
                f"{data['avg_resolution_time']:.1f}h"
                if data["avg_resolution_time"]
                else "N/A"
            )
            report.append(f"| {pri} | {data['count']} | {data['open']} | {avg_time} |")

        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        report.append("\n## ğŸ” ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        analysis = self.analyze_patterns()
        if analysis["most_common_category"]:
            report.append(f"- æœ€å¤šã‚«ãƒ†ã‚´ãƒª: {analysis['most_common_category']}")
        if analysis["most_common_components"]:
            report.append("- å½±éŸ¿é »åº¦ã®é«˜ã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:")
            for comp, count in analysis["most_common_components"]:
                report.append(f"  - {comp}: {count}ä»¶")
        if analysis["recurring_issues"]:
            report.append("- å†ç™ºã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ:")
            for title, count in analysis["recurring_issues"]:
                report.append(f"  - ã€Œ{title}ã€: {count}å›")

        # æ¨å¥¨äº‹é …
        if analysis["recommendations"]:
            report.append("\n## ğŸ’¡ æ¨å¥¨äº‹é …")
            for rec in analysis["recommendations"]:
                report.append(f"- {rec}")

        return "\n".join(report)

    def _sync_with_error_handling(self, incident: Dict):
        """æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã¨åŒæœŸ"""
        try:
            with open(self.error_history_file, "r", encoding="utf-8") as f:
                error_history = json.load(f)

            # ã‚¨ãƒ©ãƒ¼å±¥æ­´ã«è¿½åŠ 
            error_entry = {
                "timestamp": incident["timestamp"],
                "error_type": "IncidentTracked",
                "file": ",".join(incident["affected_components"]),
                "error_message": incident["description"],
                "pattern_id": f"INCIDENT_{incident['incident_id']}",
                "fix_applied": "pending",
                "success": False,
                "incident_id": incident["incident_id"],
            }

            error_history["error_history"].append(error_entry)
            error_history["metadata"]["total_errors"] += 1

            with open(self.error_history_file, "w", encoding="utf-8") as f:
                json.dump(error_history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"Warning: ã‚¨ãƒ©ãƒ¼ç®¡ç†ã¨ã®åŒæœŸã«å¤±æ•—: {e}")

    def _update_resolution_statistics(
        self, category: str, priority: str, resolution_time: float
    ):
        """è§£æ±ºæ™‚é–“çµ±è¨ˆã‚’æ›´æ–°"""
        # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
        cat_stats = self.history["category_statistics"][category]
        if cat_stats["avg_resolution_time"] is None:
            cat_stats["avg_resolution_time"] = resolution_time
        else:
            # ç§»å‹•å¹³å‡ã§æ›´æ–°
            count = cat_stats["count"] - cat_stats["open"]
            cat_stats["avg_resolution_time"] = (
                cat_stats["avg_resolution_time"] * (count - 1) + resolution_time
            ) / count

        # å„ªå…ˆåº¦çµ±è¨ˆ
        pri_stats = self.history["priority_statistics"][priority]
        if pri_stats["avg_resolution_time"] is None:
            pri_stats["avg_resolution_time"] = resolution_time
        else:
            # ç§»å‹•å¹³å‡ã§æ›´æ–°
            count = pri_stats["count"] - pri_stats["open"]
            pri_stats["avg_resolution_time"] = (
                pri_stats["avg_resolution_time"] * (count - 1) + resolution_time
            ) / count


# CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Elders Guild ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument(
        "action",
        choices=["create", "update", "resolve", "list", "show", "report", "analyze"],
        help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
    )
    parser.add_argument(
        "--category",
        choices=["error", "failure", "request", "change", "security", "performance"],
        help="ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚«ãƒ†ã‚´ãƒª",
    )
    parser.add_argument(
        "--priority", choices=["critical", "high", "medium", "low"], help="å„ªå…ˆåº¦"
    )
    parser.add_argument("--title", help="ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«")
    parser.add_argument("--description", help="è©³ç´°èª¬æ˜")
    parser.add_argument("--components", nargs="+", help="å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ")
    parser.add_argument("--impact", help="å½±éŸ¿ç¯„å›²")
    parser.add_argument("--id", help="ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆID")
    parser.add_argument(
        "--status", choices=["open", "in_progress", "resolved", "closed"], help="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"
    )
    parser.add_argument("--actions", nargs="+", help="å®Ÿæ–½ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    parser.add_argument("--root-cause", help="æ ¹æœ¬åŸå› ")
    parser.add_argument("--preventive", nargs="+", help="äºˆé˜²ç­–")

    args = parser.parse_args()

    manager = IncidentManager()

    if args.action == "create":
        if not all(
            [
                args.category,
                args.priority,
                args.title,
                args.description,
                args.components,
                args.impact,
            ]
        ):
            print(
                "ã‚¨ãƒ©ãƒ¼: create ã«ã¯ --category, --priority, --title, --description, " \
                    "--components, --impact ãŒå¿…è¦ã§ã™"
            )
            sys.exit(1)

        incident_id = manager.create_incident(
            category=args.category,
            priority=args.priority,
            title=args.title,
            description=args.description,
            affected_components=args.components,
            impact=args.impact,
        )
        print(f"âœ… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆå®Œäº†: {incident_id}")

    elif args.action == "update":
        if not args.id:
            print("ã‚¨ãƒ©ãƒ¼: update ã«ã¯ --id ãŒå¿…è¦ã§ã™")
            sys.exit(1)

        updates = {}
        if args.status:
            updates["status"] = args.status
        if args.description:
            updates["description"] = args.description

        if manager.update_incident(args.id, updates):
            print(f"âœ… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ›´æ–°å®Œäº†: {args.id}")
        else:
            print(f"âŒ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.id}")

    elif args.action == "resolve":
        if all([args.id, args.actions, args.root_cause]):
            continue  # Early return to reduce nesting
        # Reduced nesting - original condition satisfied
        if not all([args.id, args.actions, args.root_cause]):
            print("ã‚¨ãƒ©ãƒ¼: resolve ã«ã¯ --id, --actions, --root-cause ãŒå¿…è¦ã§ã™")
            sys.exit(1)

        if not (manager.resolve_incident():
            continue  # Early return to reduce nesting
        # Reduced nesting - original condition satisfied
        if manager.resolve_incident(
            incident_id=args.id,
            actions_taken=args.actions,
            root_cause=args.root_cause,
            preventive_measures=args.preventive,
        ):
            print(f"âœ… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè§£æ±ºå®Œäº†: {args.id}")
        else:
            print(f"âŒ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.id}")

    elif args.action == "list":
        incidents = manager.get_open_incidents(category=args.category)
        if not (incidents):
            continue  # Early return to reduce nesting
        # Reduced nesting - original condition satisfied
        if incidents:
            print(f"\nğŸ“‹ ã‚ªãƒ¼ãƒ—ãƒ³ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä¸€è¦§ ({len(incidents)}ä»¶)")
            print("-" * 80)
            # TODO: Extract this complex nested logic into a separate method
            for inc in incidents:
                print(
                    f"ID: {inc['incident_id']} | {inc['priority'].upper()} | {inc['category']}"
                )
                print(f"   {inc['title']}")
                print(f"   æ‹…å½“: {inc['assignee']} | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {inc['status']}")
                print("-" * 80)
        else:
            print("âœ¨ ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“")

    elif args.action == "show":
        if args.id:
            continue  # Early return to reduce nesting
        # Reduced nesting - original condition satisfied
        if not args.id:
            print("ã‚¨ãƒ©ãƒ¼: show ã«ã¯ --id ãŒå¿…è¦ã§ã™")
            sys.exit(1)

        incident = manager.get_incident_by_id(args.id)
        if not (incident):
            continue  # Early return to reduce nesting
        # Reduced nesting - original condition satisfied
        if incident:
            print(json.dumps(incident, indent=2, ensure_ascii=False))
        else:
            print(f"âŒ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.id}")

    elif args.action == "report":
        report = manager.generate_report()
        print(report)

    elif args.action == "analyze":
        analysis = manager.analyze_patterns()
        print("\nğŸ” ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        print(json.dumps(analysis, indent=2, ensure_ascii=False))
