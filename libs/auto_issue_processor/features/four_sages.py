#!/usr/bin/env python3
"""
4è³¢è€…çµ±åˆæ©Ÿèƒ½
ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã¨ã®é€£æº
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
from pathlib import Path

from github.Issue import Issue

from ..core.config import ProcessorConfig

logger = logging.getLogger(__name__)


class KnowledgeSage:
    """ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… - éå»ã®çŸ¥è­˜ã¨çµŒé¨“ã‚’ç®¡ç†"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base"):
        self.knowledge_base = Path(knowledge_base_path)
        self.patterns_file = self.knowledge_base / "issue_patterns.json"
        self.solutions_file = self.knowledge_base / "known_solutions.json"
        self._load_knowledge()
    
    def _load_knowledge(self):
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
        self.patterns = {}
        self.solutions = {}
        
        if self.patterns_file.exists():
            with open(self.patterns_file, 'r') as f:
                self.patterns = json.load(f)
        
        if self.solutions_file.exists():
            with open(self.solutions_file, 'r') as f:
                self.solutions = json.load(f)
    
    async def analyze_issue(self, issue: Issue) -> Dict[str, Any]:
        """Issueã‚’åˆ†æã—ã¦æ—¢çŸ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç…§åˆ"""
        analysis = {
            "known_pattern": False,
            "pattern_match": None,
            "suggested_solution": None,
            "confidence": 0.0
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒœãƒ‡ã‚£ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keywords = self._extract_keywords(issue)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern_id, pattern in self.patterns.items():
            match_score = self._calculate_match_score(keywords, pattern["keywords"])
            if match_score > 0.7:
                analysis["known_pattern"] = True
                analysis["pattern_match"] = pattern_id
                analysis["confidence"] = match_score
                
                # æ—¢çŸ¥ã®è§£æ±ºç­–ã‚’æ¤œç´¢
                if pattern_id in self.solutions:
                    analysis["suggested_solution"] = self.solutions[pattern_id]
                
                break
        
        return analysis
    
    def _extract_keywords(self, issue: Issue) -> List[str]:
        """Issueã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        text = f"{issue.title} {issue.body or ''}"
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªå‡¦ç†ãŒå¿…è¦ï¼‰
        words = text.lower().split()
        return [w for w in words if len(w) > 3]
    
    def _calculate_match_score(self, keywords1: List[str], keywords2: List[str]) -> float:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´åº¦ã‚’è¨ˆç®—"""
        if not keywords1 or not keywords2:
            return 0.0
        
        common = set(keywords1) & set(keywords2)
        return len(common) / max(len(keywords1), len(keywords2))
    
    async def learn_from_result(self, issue: Issue, result: Dict[str, Any]):
        """å‡¦ç†çµæœã‹ã‚‰å­¦ç¿’"""
        if result.get("success"):
            # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
            pattern_id = f"pattern_{issue.number}"
            self.patterns[pattern_id] = {
                "keywords": self._extract_keywords(issue),
                "issue_type": self._classify_issue_type(issue),
                "success_rate": 1.0,
                "last_seen": datetime.now().isoformat()
            }
            
            # è§£æ±ºç­–ã‚’ä¿å­˜
            if "artifacts" in result:
                self.solutions[pattern_id] = {
                    "approach": "auto_generated",
                    "artifacts": list(result["artifacts"].keys()),
                    "metrics": result.get("_metrics", {})
                }
            
            self._save_knowledge()


class TaskSage:
    """ã‚¿ã‚¹ã‚¯è³¢è€… - ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆé †ä½ã¨å®Ÿè¡Œç®¡ç†"""
    
    def __init__(self, db_path: str = "task_history.db"):
        self.db_path = db_path
        self.task_queue: List[Dict[str, Any]] = []
        self.execution_history: List[Dict[str, Any]] = []
    
    async def prioritize_issues(self, issues: List[Issue]) -> List[Issue]:
        """Issueã®å„ªå…ˆé †ä½ã‚’æ±ºå®š"""
        scored_issues = []
        
        for issue in issues:
            score = await self._calculate_priority_score(issue)
            scored_issues.append((score, issue))
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        scored_issues.sort(key=lambda x: x[0], reverse=True)
        
        return [issue for _, issue in scored_issues]
    
    async def _calculate_priority_score(self, issue: Issue) -> float:
        """å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0.0
        
        # ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        label_weights = {
            "critical": 100,
            "high": 50,
            "medium": 20,
            "low": 10,
            "bug": 30,
            "security": 40,
            "performance": 25
        }
        
        for label in issue.labels:
            score += label_weights.get(label.name.lower(), 0)
        
        # å¤ã„Issueã¯å„ªå…ˆåº¦ã‚’ä¸Šã’ã‚‹
        age_days = (datetime.now() - issue.created_at.replace(tzinfo=None)).days
        score += min(age_days * 0.5, 20)  # æœ€å¤§20ãƒã‚¤ãƒ³ãƒˆ
        
        # ã‚³ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆé–¢å¿ƒåº¦ï¼‰
        score += min(issue.comments, 10) * 2
        
        # ğŸ‘ ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°
        if hasattr(issue, 'reactions') and '+1' in issue.reactions:
            score += issue.reactions['+1'] * 3
        
        return score
    
    async def record_execution(self, issue: Issue, result: Dict[str, Any]):
        """å®Ÿè¡Œçµæœã‚’è¨˜éŒ²"""
        execution_record = {
            "issue_number": issue.number,
            "timestamp": datetime.now().isoformat(),
            "success": result.get("success", False),
            "duration": result.get("_metrics", {}).get("processing_time", 0),
            "priority_score": await self._calculate_priority_score(issue)
        }
        
        self.execution_history.append(execution_record)
        
        # çµ±è¨ˆã‚’æ›´æ–°
        await self._update_statistics()
    
    async def _update_statistics(self):
        """å®Ÿè¡Œçµ±è¨ˆã‚’æ›´æ–°"""
        if len(self.execution_history) < 10:
            return
        
        recent = self.execution_history[-100:]  # ç›´è¿‘100ä»¶
        
        success_rate = sum(1 for r in recent if r["success"]) / len(recent)
        avg_duration = sum(r["duration"] for r in recent) / len(recent)
        
        logger.info(f"Task statistics - Success rate: {success_rate:.1%}, "
                   f"Avg duration: {avg_duration:.1f}s")


class IncidentSage:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€… - ã‚¨ãƒ©ãƒ¼ã¨å•é¡Œã®æ¤œå‡ºãƒ»å¯¾å¿œ"""
    
    def __init__(self):
        self.incident_log: List[Dict[str, Any]] = []
        self.alert_thresholds = {
            "error_rate": 0.3,  # 30%ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ç‡
            "processing_time": 300,  # 5åˆ†ä»¥ä¸Šã®å‡¦ç†æ™‚é–“
            "memory_usage": 1024  # 1GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨
        }
    
    async def pre_check(self, issue: Issue) -> Dict[str, Any]:
        """Issueå‡¦ç†å‰ã®ãƒã‚§ãƒƒã‚¯"""
        warnings = []
        
        # å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        dangerous_keywords = ["delete", "drop", "remove all", "clear all", "reset"]
        text = f"{issue.title} {issue.body or ''}".lower()
        
        for keyword in dangerous_keywords:
            if keyword in text:
                warnings.append(f"Dangerous keyword detected: {keyword}")
        
        # å¤§è¦æ¨¡å¤‰æ›´ã®æ¤œå‡º
        if "refactor" in text or "restructure" in text:
            warnings.append("Large-scale changes detected")
        
        return {
            "safe": len(warnings) == 0,
            "warnings": warnings,
            "risk_level": self._calculate_risk_level(warnings)
        }
    
    def _calculate_risk_level(self, warnings: List[str]) -> str:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—"""
        if not warnings:
            return "low"
        elif len(warnings) == 1:
            return "medium"
        else:
            return "high"
    
    async def monitor_execution(self, issue_number: int, metrics: Dict[str, Any]):
        """å®Ÿè¡Œä¸­ã®ç›£è¦–"""
        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        alerts = []
        
        if metrics.get("processing_time", 0) > self.alert_thresholds["processing_time"]:
            alerts.append(f"Processing time exceeded: {metrics['processing_time']}s")
        
        if metrics.get("memory_delta_mb", 0) > self.alert_thresholds["memory_usage"]:
            alerts.append(f"High memory usage: {metrics['memory_delta_mb']}MB")
        
        if alerts:
            await self._raise_incident(issue_number, alerts)
    
    async def _raise_incident(self, issue_number: int, alerts: List[str]):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’ç™ºç”Ÿ"""
        incident = {
            "issue_number": issue_number,
            "timestamp": datetime.now().isoformat(),
            "alerts": alerts,
            "severity": "high" if len(alerts) > 1 else "medium"
        }
        
        self.incident_log.append(incident)
        logger.warning(f"Incident raised for Issue #{issue_number}: {alerts}")
    
    async def post_mortem(self, issue: Issue, error: Exception) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼å¾Œã®äº‹å¾Œåˆ†æ"""
        analysis = {
            "error_type": error.__class__.__name__,
            "error_message": str(error),
            "timestamp": datetime.now().isoformat(),
            "recommendations": []
        }
        
        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ã®æ¨å¥¨äº‹é …
        if isinstance(error, MemoryError):
            analysis["recommendations"].append("Reduce batch size or increase memory")
        elif isinstance(error, TimeoutError):
            analysis["recommendations"].append("Increase timeout or optimize processing")
        elif "rate limit" in str(error).lower():
            analysis["recommendations"].append("Implement rate limit handling")
        
        return analysis


class RAGSage:
    """RAGè³¢è€… - æ¤œç´¢ã¨æƒ…å ±çµ±åˆ"""
    
    def __init__(self):
        self.vector_store = None  # å®Ÿéš›ã¯ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½¿ç”¨
        self.search_history: List[Dict[str, Any]] = []
    
    async def search_similar_issues(self, issue: Issue) -> List[Dict[str, Any]]:
        """é¡ä¼¼ã®Issueã‚’æ¤œç´¢"""
        # ç°¡æ˜“å®Ÿè£…ï¼ˆå®Ÿéš›ã¯ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’ä½¿ç”¨ï¼‰
        similar = []
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼æ€§ãƒã‚§ãƒƒã‚¯
        keywords = set(issue.title.lower().split())
        
        # TODO: å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚’å®Ÿè£…
        # ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        if "bug" in keywords:
            similar.append({
                "issue_number": 100,
                "title": "Similar bug fixed",
                "similarity": 0.85,
                "solution": "Applied patch X"
            })
        
        return similar
    
    async def aggregate_knowledge(self, issue: Issue) -> Dict[str, Any]:
        """é–¢é€£çŸ¥è­˜ã‚’é›†ç´„"""
        aggregated = {
            "similar_issues": await self.search_similar_issues(issue),
            "related_docs": await self._search_documentation(issue),
            "code_examples": await self._search_code_examples(issue)
        }
        
        return aggregated
    
    async def _search_documentation(self, issue: Issue) -> List[str]:
        """é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢"""
        # TODO: å®Ÿè£…
        return []
    
    async def _search_code_examples(self, issue: Issue) -> List[Dict[str, str]]:
        """é–¢é€£ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æ¤œç´¢"""
        # TODO: å®Ÿè£…
        return []


class FourSagesIntegration:
    """4è³¢è€…çµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: ProcessorConfig):
        self.config = config
        
        # å„è³¢è€…ã‚’åˆæœŸåŒ–
        self.knowledge_sage = KnowledgeSage()
        self.task_sage = TaskSage()
        self.incident_sage = IncidentSage()
        self.rag_sage = RAGSage()
        
        logger.info("Four Sages Integration initialized")
    
    async def analyze_issue(self, issue: Issue) -> Dict[str, Any]:
        """4è³¢è€…ã«ã‚ˆã‚‹ç·åˆåˆ†æ"""
        logger.info(f"ğŸ§™â€â™‚ï¸ Four Sages analyzing Issue #{issue.number}")
        
        # ä¸¦åˆ—ã§å„è³¢è€…ã®åˆ†æã‚’å®Ÿè¡Œ
        tasks = [
            self.knowledge_sage.analyze_issue(issue),
            self.incident_sage.pre_check(issue),
            self.rag_sage.aggregate_knowledge(issue)
        ]
        
        results = await asyncio.gather(*tasks)
        
        knowledge_analysis = results[0]
        incident_check = results[1]
        rag_knowledge = results[2]
        
        # ç·åˆåˆ¤å®š
        should_skip = False
        skip_reason = None
        
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ãŒé«˜ãƒªã‚¹ã‚¯ã¨åˆ¤å®š
        if incident_check["risk_level"] == "high":
            should_skip = True
            skip_reason = "High risk detected by Incident Sage"
        
        # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ãŒæ—¢çŸ¥ã®å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨åˆ¤å®š
        elif knowledge_analysis.get("known_pattern") and knowledge_analysis.get("confidence", 0) < 0.5:
            should_skip = True
            skip_reason = "Known failure pattern detected"
        
        return {
            "skip": should_skip,
            "reason": skip_reason,
            "knowledge": knowledge_analysis,
            "incident": incident_check,
            "rag": rag_knowledge,
            "summary": self._create_summary(knowledge_analysis, incident_check, rag_knowledge)
        }
    
    def _create_summary(self, knowledge: Dict, incident: Dict, rag: Dict) -> str:
        """åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        summary_parts = []
        
        if knowledge.get("known_pattern"):
            summary_parts.append(f"Known pattern detected (confidence: {knowledge['confidence']:.0%})")
        
        if incident.get("warnings"):
            summary_parts.append(f"Warnings: {', '.join(incident['warnings'])}")
        
        if rag.get("similar_issues"):
            summary_parts.append(f"Found {len(rag['similar_issues'])} similar issues")
        
        return " | ".join(summary_parts) if summary_parts else "No significant findings"
    
    async def report_critical_error(self, error: Exception, context: Dict[str, Any]):
        """é‡å¤§ã‚¨ãƒ©ãƒ¼ã‚’4è³¢è€…ã«å ±å‘Š"""
        logger.critical("ğŸš¨ Reporting critical error to Four Sages")
        
        # å„è³¢è€…ã«é€šçŸ¥
        await asyncio.gather(
            self._notify_knowledge_sage(error, context),
            self._notify_incident_sage(error, context),
            self._notify_task_sage(error, context),
            return_exceptions=True
        )
    
    async def _notify_knowledge_sage(self, error: Exception, context: Dict[str, Any]):
        """ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã«é€šçŸ¥"""
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
        error_pattern = {
            "error_type": error.__class__.__name__,
            "context": context,
            "timestamp": datetime.now().isoformat()
        }
        # TODO: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    
    async def _notify_incident_sage(self, error: Exception, context: Dict[str, Any]):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã«é€šçŸ¥"""
        await self.incident_sage.post_mortem(
            context.get("issue"),
            error
        )
    
    async def _notify_task_sage(self, error: Exception, context: Dict[str, Any]):
        """ã‚¿ã‚¹ã‚¯è³¢è€…ã«é€šçŸ¥"""
        # å¤±æ•—ã‚’è¨˜éŒ²
        if "issue" in context:
            await self.task_sage.record_execution(
                context["issue"],
                {"success": False, "error": str(error)}
            )
    
    async def optimize_processing_order(self, issues: List[Issue]) -> List[Issue]:
        """4è³¢è€…ã®çŸ¥è¦‹ã‚’å…ƒã«å‡¦ç†é †åºã‚’æœ€é©åŒ–"""
        # ã‚¿ã‚¹ã‚¯è³¢è€…ã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘
        prioritized = await self.task_sage.prioritize_issues(issues)
        
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
        safe_issues = []
        for issue in prioritized:
            check = await self.incident_sage.pre_check(issue)
            if check["risk_level"] != "high":
                safe_issues.append(issue)
            else:
                logger.warning(f"Issue #{issue.number} skipped due to high risk")
        
        return safe_issues