#!/usr/bin/env python3
"""
ğŸ§  Autonomous Learning System - è‡ªå¾‹çš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
4è³¢è€…å”èª¿ã«ã‚ˆã‚‹å®Œå…¨è‡ªå¾‹å­¦ç¿’ã®å®Ÿç¾

ã‚°ãƒ©ãƒ³ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼maru â†’ ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ â†’ 4è³¢è€… â†’ è©•è­°ä¼š â†’ ã‚µãƒ¼ãƒãƒ³ãƒˆ
å…¨éšå±¤ã§ã®çŸ¥è­˜å…±æœ‰ã¨ç›¸äº’å­¦ç¿’ã‚’å®Ÿç¾

Author: Claude Elder
Date: 2025-07-10
Phase: 2 (è‡ªå¾‹çš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…)
"""

import asyncio
import json
import logging
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set, Union
from dataclasses import dataclass, asdict
from pathlib import Path
from enum import Enum
import sqlite3
import threading
import queue
from collections import defaultdict, deque
import hashlib
import pickle
from abc import ABC, abstractmethod

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
try:
    from .elder_tree_vector_network import ElderTreeVectorNetwork, ElderNode
    from .multidimensional_vector_system import MultiDimensionalVectorSystem, KnowledgeType
    from .predictive_pattern_learning import PredictivePatternLearningSystem, TaskExecutionRecord
    from .realtime_monitoring_enhancement import RealtimeMonitoringEnhancement, AnomalyEvent
except ImportError:
    # ãƒ¢ãƒƒã‚¯å®Ÿè£…
    ElderTreeVectorNetwork = None
    MultiDimensionalVectorSystem = None
    PredictivePatternLearningSystem = None
    RealtimeMonitoringEnhancement = None

class LearningDomain(Enum):
    """å­¦ç¿’ãƒ‰ãƒ¡ã‚¤ãƒ³"""
    KNOWLEDGE = "knowledge"      # çŸ¥è­˜é ˜åŸŸ
    TASK = "task"               # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
    INCIDENT = "incident"       # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ
    SEARCH = "search"           # æ¤œç´¢ãƒ»RAG
    CROSS_DOMAIN = "cross"      # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³

class LearningStrategy(Enum):
    """å­¦ç¿’æˆ¦ç•¥"""
    SUPERVISED = "supervised"          # æ•™å¸«ã‚ã‚Šå­¦ç¿’
    UNSUPERVISED = "unsupervised"    # æ•™å¸«ãªã—å­¦ç¿’
    REINFORCEMENT = "reinforcement"   # å¼·åŒ–å­¦ç¿’
    TRANSFER = "transfer"             # è»¢ç§»å­¦ç¿’
    META = "meta"                     # ãƒ¡ã‚¿å­¦ç¿’
    FEDERATED = "federated"           # é€£åˆå­¦ç¿’

class SageType(Enum):
    """è³¢è€…ã‚¿ã‚¤ãƒ—"""
    KNOWLEDGE = "knowledge"    # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…
    TASK = "task"             # ã‚¿ã‚¹ã‚¯è³¢è€…
    INCIDENT = "incident"     # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…
    RAG = "rag"               # RAGè³¢è€…

@dataclass
class LearningExperience:
    """å­¦ç¿’çµŒé¨“"""
    experience_id: str
    timestamp: datetime
    domain: LearningDomain
    sage_type: SageType
    input_data: Dict[str, Any]
    output_result: Dict[str, Any]
    success: bool
    confidence: float
    lessons_learned: List[str]
    knowledge_vector: Optional[np.ndarray] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class CrossDomainInsight:
    """ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³æ´å¯Ÿ"""
    insight_id: str
    created_at: datetime
    source_domains: List[LearningDomain]
    insight_type: str
    discovery: str
    applicable_domains: List[LearningDomain]
    confidence: float
    evidence: List[Dict[str, Any]]
    potential_impact: Dict[str, float]

@dataclass
class MetaLearningPattern:
    """ãƒ¡ã‚¿å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³"""
    pattern_id: str
    discovered_at: datetime
    pattern_type: str
    effectiveness: float
    applicable_strategies: List[LearningStrategy]
    success_conditions: Dict[str, Any]
    failure_conditions: Dict[str, Any]
    optimization_hints: List[str]

@dataclass
class ElderKnowledgePacket:
    """ã‚¨ãƒ«ãƒ€ãƒ¼çŸ¥è­˜ãƒ‘ã‚±ãƒƒãƒˆ"""
    packet_id: str
    created_at: datetime
    source_elder: str
    target_elder: Optional[str]
    knowledge_type: str
    content: Dict[str, Any]
    vector_representation: Optional[np.ndarray]
    propagation_path: List[str]
    absorption_rate: float

class SageAgent(ABC):
    """è³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, sage_type: SageType, learning_system):
        self.sage_type = sage_type
        self.learning_system = learning_system
        self.logger = logging.getLogger(f"{self.__class__.__name__}_{sage_type.value}")
        self.knowledge_base = {}
        self.learning_history = deque(maxlen=1000)
        self.performance_metrics = defaultdict(float)
        
    @abstractmethod
    async def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:
        """çµŒé¨“ã‚’å‡¦ç†ã—ã¦å­¦ç¿’"""
        pass
    
    @abstractmethod
    async def share_knowledge(self) -> ElderKnowledgePacket:
        """çŸ¥è­˜ã‚’å…±æœ‰"""
        pass
    
    @abstractmethod
    async def receive_knowledge(self, packet: ElderKnowledgePacket):
        """çŸ¥è­˜ã‚’å—ä¿¡ã—ã¦çµ±åˆ"""
        pass
    
    async def evaluate_performance(self) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡"""
        return dict(self.performance_metrics)

class KnowledgeSageAgent(SageAgent):
    """ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    async def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:
        """çŸ¥è­˜é ˜åŸŸã®çµŒé¨“ã‚’å‡¦ç†"""
        try:
            # çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
            patterns = await self._extract_knowledge_patterns(experience)
            
            # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ›´æ–°
            await self._update_knowledge_base(patterns)
            
            # æ–°ã—ã„æ´å¯Ÿç”Ÿæˆ
            insights = await self._generate_insights(patterns)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°
            self.performance_metrics['processed_experiences'] += 1
            self.performance_metrics['knowledge_patterns'] += len(patterns)
            
            return {
                'patterns': patterns,
                'insights': insights,
                'knowledge_growth': len(self.knowledge_base)
            }
            
        except Exception as e:
            self.logger.error(f"Experience processing failed: {e}")
            return {'error': str(e)}
    
    async def share_knowledge(self) -> ElderKnowledgePacket:
        """æœ€ã‚‚ä¾¡å€¤ã®ã‚ã‚‹çŸ¥è­˜ã‚’å…±æœ‰"""
        # æœ€é‡è¦çŸ¥è­˜ã‚’é¸æŠ
        top_knowledge = await self._select_top_knowledge()
        
        packet = ElderKnowledgePacket(
            packet_id=f"knowledge_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            created_at=datetime.now(),
            source_elder=f"sage_{self.sage_type.value}",
            target_elder=None,  # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
            knowledge_type="knowledge_pattern",
            content=top_knowledge,
            vector_representation=None,  # ç°¡ç•¥åŒ–
            propagation_path=[f"sage_{self.sage_type.value}"],
            absorption_rate=0.0
        )
        
        return packet
    
    async def receive_knowledge(self, packet: ElderKnowledgePacket):
        """ä»–ã®è³¢è€…ã‹ã‚‰ã®çŸ¥è­˜ã‚’çµ±åˆ"""
        # çŸ¥è­˜ã®é–¢é€£æ€§è©•ä¾¡
        relevance = await self._evaluate_relevance(packet)
        
        if relevance > 0.5:
            # çŸ¥è­˜çµ±åˆ
            await self._integrate_knowledge(packet)
            packet.absorption_rate = relevance
            self.logger.info(f"Knowledge integrated: {packet.packet_id} (relevance: {relevance:.2f})")
    
    async def _extract_knowledge_patterns(self, experience: LearningExperience) -> List[Dict[str, Any]]:
        """çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        patterns = []
        
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³
        if experience.success and experience.confidence > 0.7:
            patterns.append({
                'type': 'success_pattern',
                'domain': experience.domain.value,
                'confidence': experience.confidence,
                'conditions': experience.input_data,
                'outcomes': experience.output_result
            })
        
        # å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif not experience.success:
            patterns.append({
                'type': 'failure_pattern',
                'domain': experience.domain.value,
                'lessons': experience.lessons_learned,
                'avoid_conditions': experience.input_data
            })
        
        return patterns
    
    async def _update_knowledge_base(self, patterns: List[Dict[str, Any]]):
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ›´æ–°"""
        for pattern in patterns:
            pattern_key = f"{pattern['type']}_{pattern['domain']}"
            if pattern_key not in self.knowledge_base:
                self.knowledge_base[pattern_key] = []
            self.knowledge_base[pattern_key].append(pattern)
    
    async def _generate_insights(self, patterns: List[Dict[str, Any]]) -> List[str]:
        """æ´å¯Ÿç”Ÿæˆ"""
        insights = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        for pattern in patterns:
            if pattern['type'] == 'success_pattern' and pattern['confidence'] > 0.8:
                insights.append(f"High confidence pattern discovered in {pattern['domain']}")
            elif pattern['type'] == 'failure_pattern':
                insights.append(f"Failure pattern identified: {', '.join(pattern['lessons'])}")
        
        return insights
    
    async def _select_top_knowledge(self) -> Dict[str, Any]:
        """æœ€é‡è¦çŸ¥è­˜é¸æŠ"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        return {
            'knowledge_count': len(self.knowledge_base),
            'top_patterns': list(self.knowledge_base.keys())[:5],
            'sage_type': self.sage_type.value
        }
    
    async def _evaluate_relevance(self, packet: ElderKnowledgePacket) -> float:
        """çŸ¥è­˜é–¢é€£æ€§è©•ä¾¡"""
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        if packet.knowledge_type == "knowledge_pattern":
            return 0.8
        elif packet.source_elder.startswith("sage_"):
            return 0.6
        else:
            return 0.3
    
    async def _integrate_knowledge(self, packet: ElderKnowledgePacket):
        """çŸ¥è­˜çµ±åˆ"""
        integrated_key = f"integrated_{packet.source_elder}_{packet.knowledge_type}"
        self.knowledge_base[integrated_key] = packet.content

class TaskSageAgent(SageAgent):
    """ã‚¿ã‚¹ã‚¯è³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    async def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡ŒçµŒé¨“ã‚’å‡¦ç†"""
        # ã‚¿ã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        task_patterns = await self._learn_task_patterns(experience)
        
        # æœ€é©åŒ–æˆ¦ç•¥ç”Ÿæˆ
        optimization_strategies = await self._generate_optimization_strategies(task_patterns)
        
        self.performance_metrics['task_experiences'] += 1
        self.performance_metrics['optimization_strategies'] += len(optimization_strategies)
        
        return {
            'task_patterns': task_patterns,
            'optimization_strategies': optimization_strategies
        }
    
    async def share_knowledge(self) -> ElderKnowledgePacket:
        """ã‚¿ã‚¹ã‚¯æœ€é©åŒ–çŸ¥è­˜ã‚’å…±æœ‰"""
        best_strategies = await self._get_best_strategies()
        
        return ElderKnowledgePacket(
            packet_id=f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            created_at=datetime.now(),
            source_elder=f"sage_{self.sage_type.value}",
            target_elder=None,
            knowledge_type="task_optimization",
            content=best_strategies,
            vector_representation=None,
            propagation_path=[f"sage_{self.sage_type.value}"],
            absorption_rate=0.0
        )
    
    async def receive_knowledge(self, packet: ElderKnowledgePacket):
        """ã‚¿ã‚¹ã‚¯é–¢é€£çŸ¥è­˜ã‚’å—ä¿¡"""
        if packet.knowledge_type in ["task_optimization", "execution_pattern"]:
            await self._apply_optimization_knowledge(packet)
            packet.absorption_rate = 0.9
    
    async def _learn_task_patterns(self, experience: LearningExperience) -> List[Dict[str, Any]]:
        """ã‚¿ã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        return [{
            'pattern_type': 'execution',
            'success_rate': 0.8 if experience.success else 0.2,
            'conditions': experience.input_data
        }]
    
    async def _generate_optimization_strategies(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æœ€é©åŒ–æˆ¦ç•¥ç”Ÿæˆ"""
        strategies = []
        for pattern in patterns:
            if pattern['success_rate'] > 0.7:
                strategies.append({
                    'strategy': 'replicate_success',
                    'pattern': pattern
                })
            else:
                strategies.append({
                    'strategy': 'avoid_failure',
                    'pattern': pattern
                })
        return strategies
    
    async def _get_best_strategies(self) -> Dict[str, Any]:
        """æœ€è‰¯æˆ¦ç•¥å–å¾—"""
        return {
            'top_strategies': list(self.knowledge_base.keys())[:3],
            'performance_metrics': dict(self.performance_metrics)
        }
    
    async def _apply_optimization_knowledge(self, packet: ElderKnowledgePacket):
        """æœ€é©åŒ–çŸ¥è­˜é©ç”¨"""
        self.knowledge_base[f"external_{packet.packet_id}"] = packet.content

class IncidentSageAgent(SageAgent):
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    async def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçµŒé¨“ã‚’å‡¦ç†"""
        # ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        anomaly_patterns = await self._learn_anomaly_patterns(experience)
        
        # äºˆé˜²ç­–ç”Ÿæˆ
        prevention_strategies = await self._generate_prevention_strategies(anomaly_patterns)
        
        self.performance_metrics['incidents_processed'] += 1
        self.performance_metrics['prevention_strategies'] += len(prevention_strategies)
        
        return {
            'anomaly_patterns': anomaly_patterns,
            'prevention_strategies': prevention_strategies
        }
    
    async def share_knowledge(self) -> ElderKnowledgePacket:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆäºˆé˜²çŸ¥è­˜ã‚’å…±æœ‰"""
        critical_patterns = await self._get_critical_patterns()
        
        return ElderKnowledgePacket(
            packet_id=f"incident_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            created_at=datetime.now(),
            source_elder=f"sage_{self.sage_type.value}",
            target_elder=None,
            knowledge_type="incident_prevention",
            content=critical_patterns,
            vector_representation=None,
            propagation_path=[f"sage_{self.sage_type.value}"],
            absorption_rate=0.0
        )
    
    async def receive_knowledge(self, packet: ElderKnowledgePacket):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé–¢é€£çŸ¥è­˜ã‚’å—ä¿¡"""
        if packet.knowledge_type in ["incident_prevention", "anomaly_pattern"]:
            await self._integrate_prevention_knowledge(packet)
            packet.absorption_rate = 0.95
    
    async def _learn_anomaly_patterns(self, experience: LearningExperience) -> List[Dict[str, Any]]:
        """ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        return [{
            'anomaly_type': 'system_anomaly',
            'severity': 'high' if not experience.success else 'low',
            'indicators': experience.input_data
        }]
    
    async def _generate_prevention_strategies(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """äºˆé˜²ç­–ç”Ÿæˆ"""
        strategies = []
        for pattern in patterns:
            if pattern['severity'] == 'high':
                strategies.append({
                    'action': 'immediate_prevention',
                    'target': pattern['anomaly_type'],
                    'priority': 'critical'
                })
        return strategies
    
    async def _get_critical_patterns(self) -> Dict[str, Any]:
        """é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³å–å¾—"""
        return {
            'critical_anomalies': list(self.knowledge_base.keys())[:5],
            'prevention_count': len(self.knowledge_base)
        }
    
    async def _integrate_prevention_knowledge(self, packet: ElderKnowledgePacket):
        """äºˆé˜²çŸ¥è­˜çµ±åˆ"""
        self.knowledge_base[f"prevention_{packet.packet_id}"] = packet.content

class RAGSageAgent(SageAgent):
    """RAGè³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    async def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:
        """æ¤œç´¢ãƒ»RAGçµŒé¨“ã‚’å‡¦ç†"""
        # æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        search_patterns = await self._learn_search_patterns(experience)
        
        # æ¤œç´¢æœ€é©åŒ–ç”Ÿæˆ
        search_optimizations = await self._generate_search_optimizations(search_patterns)
        
        self.performance_metrics['searches_processed'] += 1
        self.performance_metrics['search_optimizations'] += len(search_optimizations)
        
        return {
            'search_patterns': search_patterns,
            'search_optimizations': search_optimizations
        }
    
    async def share_knowledge(self) -> ElderKnowledgePacket:
        """æ¤œç´¢æœ€é©åŒ–çŸ¥è­˜ã‚’å…±æœ‰"""
        best_search_strategies = await self._get_best_search_strategies()
        
        return ElderKnowledgePacket(
            packet_id=f"rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            created_at=datetime.now(),
            source_elder=f"sage_{self.sage_type.value}",
            target_elder=None,
            knowledge_type="search_optimization",
            content=best_search_strategies,
            vector_representation=None,
            propagation_path=[f"sage_{self.sage_type.value}"],
            absorption_rate=0.0
        )
    
    async def receive_knowledge(self, packet: ElderKnowledgePacket):
        """æ¤œç´¢é–¢é€£çŸ¥è­˜ã‚’å—ä¿¡"""
        if packet.knowledge_type in ["search_optimization", "retrieval_pattern"]:
            await self._apply_search_knowledge(packet)
            packet.absorption_rate = 0.85
    
    async def _learn_search_patterns(self, experience: LearningExperience) -> List[Dict[str, Any]]:
        """æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        return [{
            'search_type': 'semantic_search',
            'effectiveness': experience.confidence,
            'query_patterns': experience.input_data
        }]
    
    async def _generate_search_optimizations(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ¤œç´¢æœ€é©åŒ–ç”Ÿæˆ"""
        optimizations = []
        for pattern in patterns:
            if pattern['effectiveness'] > 0.7:
                optimizations.append({
                    'optimization': 'enhance_query',
                    'method': pattern['search_type'],
                    'expected_improvement': 0.2
                })
        return optimizations
    
    async def _get_best_search_strategies(self) -> Dict[str, Any]:
        """æœ€è‰¯æ¤œç´¢æˆ¦ç•¥å–å¾—"""
        return {
            'top_search_methods': list(self.knowledge_base.keys())[:3],
            'search_performance': dict(self.performance_metrics)
        }
    
    async def _apply_search_knowledge(self, packet: ElderKnowledgePacket):
        """æ¤œç´¢çŸ¥è­˜é©ç”¨"""
        self.knowledge_base[f"search_{packet.packet_id}"] = packet.content

class AutonomousLearningSystem:
    """è‡ªå¾‹çš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - 4è³¢è€…å”èª¿ã«ã‚ˆã‚‹å®Œå…¨è‡ªå¾‹å­¦ç¿’"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.logger = logging.getLogger(__name__)
        self.config = config or self._default_config()
        
        # 4è³¢è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
        self.sages = {
            SageType.KNOWLEDGE: KnowledgeSageAgent(SageType.KNOWLEDGE, self),
            SageType.TASK: TaskSageAgent(SageType.TASK, self),
            SageType.INCIDENT: IncidentSageAgent(SageType.INCIDENT, self),
            SageType.RAG: RAGSageAgent(SageType.RAG, self)
        }
        
        # å­¦ç¿’çµŒé¨“ã‚­ãƒ¥ãƒ¼
        self.experience_queue = queue.Queue()
        self.knowledge_exchange_queue = queue.Queue()
        
        # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³æ´å¯Ÿ
        self.cross_domain_insights = []
        self.meta_learning_patterns = []
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.system_metrics = {
            'total_experiences': 0,
            'cross_domain_insights': 0,
            'meta_patterns_discovered': 0,
            'knowledge_packets_exchanged': 0,
            'learning_efficiency': 0.0
        }
        
        # å­¦ç¿’å±¥æ­´
        self.learning_history = deque(maxlen=10000)
        
        # ã‚¨ãƒ«ãƒ€ãƒ¼éšå±¤çµ±åˆ
        self.elder_hierarchy = {
            'grand_elder': {'knowledge_packets': [], 'decisions': []},
            'claude_elder': {'instructions': [], 'feedback': []},
            'council': {'proposals': [], 'votes': []},
            'servants': {'tasks': [], 'reports': []}
        }
        
        # å­¦ç¿’ã‚¹ãƒ¬ãƒƒãƒ‰
        self.learning_active = False
        self.learning_threads = []
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self._init_database()
        
        self.logger.info("ğŸ§  Autonomous Learning System initialized with 4 Sages")
    
    def _default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            'learning_rate': 0.001,
            'batch_size': 32,
            'exchange_interval': 60,  # çŸ¥è­˜äº¤æ›é–“éš”ï¼ˆç§’ï¼‰
            'meta_learning_threshold': 100,  # ãƒ¡ã‚¿å­¦ç¿’é–‹å§‹é–¾å€¤
            'cross_domain_threshold': 0.7,  # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ç›¸é–¢é–¾å€¤
            'database_path': str(PROJECT_ROOT / "data" / "autonomous_learning.db")
        }
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        try:
            db_path = self.config['database_path']
            Path(db_path).parent.mkdir(parents=True, exist_ok=True)
            
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # å­¦ç¿’çµŒé¨“ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS learning_experiences (
                    experience_id TEXT PRIMARY KEY,
                    timestamp TEXT,
                    domain TEXT,
                    sage_type TEXT,
                    input_data TEXT,
                    output_result TEXT,
                    success BOOLEAN,
                    confidence REAL,
                    lessons_learned TEXT,
                    metadata TEXT
                );
            """)
            
            # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³æ´å¯Ÿãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS cross_domain_insights (
                    insight_id TEXT PRIMARY KEY,
                    created_at TEXT,
                    source_domains TEXT,
                    insight_type TEXT,
                    discovery TEXT,
                    applicable_domains TEXT,
                    confidence REAL,
                    evidence TEXT,
                    potential_impact TEXT
                );
            """)
            
            # ãƒ¡ã‚¿å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS meta_learning_patterns (
                    pattern_id TEXT PRIMARY KEY,
                    discovered_at TEXT,
                    pattern_type TEXT,
                    effectiveness REAL,
                    applicable_strategies TEXT,
                    success_conditions TEXT,
                    failure_conditions TEXT,
                    optimization_hints TEXT
                );
            """)
            
            # çŸ¥è­˜ãƒ‘ã‚±ãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS knowledge_packets (
                    packet_id TEXT PRIMARY KEY,
                    created_at TEXT,
                    source_elder TEXT,
                    target_elder TEXT,
                    knowledge_type TEXT,
                    content TEXT,
                    propagation_path TEXT,
                    absorption_rate REAL
                );
            """)
            
            conn.commit()
            conn.close()
            
            self.logger.info("ğŸ“Š Learning database initialized")
            
        except Exception as e:
            self.logger.error(f"Database initialization failed: {e}")
    
    async def start_learning(self):
        """å­¦ç¿’é–‹å§‹"""
        if self.learning_active:
            self.logger.warning("Learning already active")
            return
        
        self.learning_active = True
        
        # å­¦ç¿’ã‚¿ã‚¹ã‚¯é–‹å§‹
        tasks = [
            asyncio.create_task(self._experience_processing_loop()),
            asyncio.create_task(self._knowledge_exchange_loop()),
            asyncio.create_task(self._cross_domain_analysis_loop()),
            asyncio.create_task(self._meta_learning_loop()),
            asyncio.create_task(self._elder_integration_loop())
        ]
        
        self.logger.info("ğŸš€ Autonomous learning started with 4 Sages")
        
        try:
            await asyncio.gather(*tasks)
        except Exception as e:
            self.logger.error(f"Learning error: {e}")
            self.learning_active = False
    
    async def stop_learning(self):
        """å­¦ç¿’åœæ­¢"""
        self.learning_active = False
        self.logger.info("ğŸ›‘ Autonomous learning stopped")
    
    async def submit_experience(self, 
                              domain: LearningDomain,
                              sage_type: SageType,
                              input_data: Dict[str, Any],
                              output_result: Dict[str, Any],
                              success: bool,
                              confidence: float,
                              lessons_learned: List[str] = None) -> str:
        """å­¦ç¿’çµŒé¨“ã‚’æŠ•ç¨¿"""
        experience = LearningExperience(
            experience_id=f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{sage_type.value}",
            timestamp=datetime.now(),
            domain=domain,
            sage_type=sage_type,
            input_data=input_data,
            output_result=output_result,
            success=success,
            confidence=confidence,
            lessons_learned=lessons_learned or []
        )
        
        # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        self.experience_queue.put(experience)
        self.system_metrics['total_experiences'] += 1
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        await self._persist_experience(experience)
        
        self.logger.info(f"ğŸ“ Experience submitted: {experience.experience_id}")
        return experience.experience_id
    
    async def _experience_processing_loop(self):
        """çµŒé¨“å‡¦ç†ãƒ«ãƒ¼ãƒ—"""
        while self.learning_active:
            try:
                # ãƒãƒƒãƒå‡¦ç†
                batch = []
                for _ in range(self.config['batch_size']):
                    try:
                        experience = self.experience_queue.get(timeout=1)
                        batch.append(experience)
                    except:
                        break
                
                if batch:
                    # å„è³¢è€…ã§å‡¦ç†
                    for experience in batch:
                        sage = self.sages[experience.sage_type]
                        result = await sage.process_experience(experience)
                        
                        # å±¥æ­´è¨˜éŒ²
                        self.learning_history.append({
                            'experience': experience,
                            'result': result,
                            'timestamp': datetime.now()
                        })
                
                await asyncio.sleep(1)
                
            except Exception as e:
                self.logger.error(f"Experience processing error: {e}")
                await asyncio.sleep(5)
    
    async def _knowledge_exchange_loop(self):
        """çŸ¥è­˜äº¤æ›ãƒ«ãƒ¼ãƒ—"""
        while self.learning_active:
            try:
                # å„è³¢è€…ã‹ã‚‰çŸ¥è­˜ã‚’åé›†
                for sage_type, sage in self.sages.items():
                    packet = await sage.share_knowledge()
                    
                    # ä»–ã®è³¢è€…ã«é…å¸ƒ
                    for other_sage_type, other_sage in self.sages.items():
                        if other_sage_type != sage_type:
                            await other_sage.receive_knowledge(packet)
                    
                    # çµ±è¨ˆæ›´æ–°
                    self.system_metrics['knowledge_packets_exchanged'] += 1
                    
                    # ä¿å­˜
                    await self._persist_knowledge_packet(packet)
                
                await asyncio.sleep(self.config['exchange_interval'])
                
            except Exception as e:
                self.logger.error(f"Knowledge exchange error: {e}")
                await asyncio.sleep(60)
    
    async def _cross_domain_analysis_loop(self):
        """ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ†æãƒ«ãƒ¼ãƒ—"""
        while self.learning_active:
            try:
                # ååˆ†ãªå±¥æ­´ãŒã‚ã‚‹å ´åˆ
                if len(self.learning_history) >= 50:
                    insights = await self._analyze_cross_domain_patterns()
                    
                    for insight in insights:
                        self.cross_domain_insights.append(insight)
                        self.system_metrics['cross_domain_insights'] += 1
                        
                        # ä¿å­˜
                        await self._persist_cross_domain_insight(insight)
                        
                        self.logger.info(f"ğŸ’¡ Cross-domain insight discovered: {insight.insight_type}")
                
                await asyncio.sleep(300)  # 5åˆ†æ¯
                
            except Exception as e:
                self.logger.error(f"Cross-domain analysis error: {e}")
                await asyncio.sleep(300)
    
    async def _meta_learning_loop(self):
        """ãƒ¡ã‚¿å­¦ç¿’ãƒ«ãƒ¼ãƒ—"""
        while self.learning_active:
            try:
                # ãƒ¡ã‚¿å­¦ç¿’é–¾å€¤ãƒã‚§ãƒƒã‚¯
                if len(self.learning_history) >= self.config['meta_learning_threshold']:
                    patterns = await self._discover_meta_patterns()
                    
                    for pattern in patterns:
                        self.meta_learning_patterns.append(pattern)
                        self.system_metrics['meta_patterns_discovered'] += 1
                        
                        # ä¿å­˜
                        await self._persist_meta_pattern(pattern)
                        
                        self.logger.info(f"ğŸ§© Meta-learning pattern discovered: {pattern.pattern_type}")
                
                await asyncio.sleep(600)  # 10åˆ†æ¯
                
            except Exception as e:
                self.logger.error(f"Meta-learning error: {e}")
                await asyncio.sleep(600)
    
    async def _elder_integration_loop(self):
        """ã‚¨ãƒ«ãƒ€ãƒ¼éšå±¤çµ±åˆãƒ«ãƒ¼ãƒ—"""
        while self.learning_active:
            try:
                # ã‚°ãƒ©ãƒ³ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ã¸ã®å ±å‘Š
                grand_elder_report = await self._generate_grand_elder_report()
                self.elder_hierarchy['grand_elder']['knowledge_packets'].append(grand_elder_report)
                
                # ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤ºå‡¦ç†
                await self._process_claude_elder_instructions()
                
                # è©•è­°ä¼šã¸ã®ææ¡ˆ
                council_proposals = await self._generate_council_proposals()
                self.elder_hierarchy['council']['proposals'].extend(council_proposals)
                
                # ã‚µãƒ¼ãƒãƒ³ãƒˆã¸ã®ã‚¿ã‚¹ã‚¯é…å¸ƒ
                servant_tasks = await self._distribute_servant_tasks()
                self.elder_hierarchy['servants']['tasks'].extend(servant_tasks)
                
                await asyncio.sleep(3600)  # 1æ™‚é–“æ¯
                
            except Exception as e:
                self.logger.error(f"Elder integration error: {e}")
                await asyncio.sleep(3600)
    
    async def _analyze_cross_domain_patterns(self) -> List[CrossDomainInsight]:
        """ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥çµŒé¨“ã‚’åé›†
        domain_experiences = defaultdict(list)
        for entry in list(self.learning_history)[-100:]:  # æœ€æ–°100ä»¶
            experience = entry['experience']
            domain_experiences[experience.domain].append(experience)
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ç›¸é–¢åˆ†æ
        domains = list(domain_experiences.keys())
        for i, domain1 in enumerate(domains):
            for domain2 in domains[i+1:]:
                correlation = await self._calculate_domain_correlation(
                    domain_experiences[domain1],
                    domain_experiences[domain2]
                )
                
                if correlation > self.config['cross_domain_threshold']:
                    insight = CrossDomainInsight(
                        insight_id=f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                        created_at=datetime.now(),
                        source_domains=[domain1, domain2],
                        insight_type="domain_correlation",
                        discovery=f"Strong correlation between {domain1.value} and {domain2.value}",
                        applicable_domains=[domain1, domain2],
                        confidence=correlation,
                        evidence=[],
                        potential_impact={'efficiency': 0.3, 'accuracy': 0.2}
                    )
                    insights.append(insight)
        
        return insights
    
    async def _calculate_domain_correlation(self, 
                                          experiences1: List[LearningExperience],
                                          experiences2: List[LearningExperience]) -> float:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ç›¸é–¢è¨ˆç®—"""
        if not experiences1 or not experiences2:
            return 0.0
        
        # æˆåŠŸç‡ã®ç›¸é–¢
        success_rates1 = [exp.confidence if exp.success else 0 for exp in experiences1]
        success_rates2 = [exp.confidence if exp.success else 0 for exp in experiences2]
        
        # ç°¡æ˜“ç›¸é–¢è¨ˆç®—
        if len(success_rates1) == len(success_rates2):
            correlation = np.corrcoef(success_rates1, success_rates2)[0, 1]
            return abs(correlation) if not np.isnan(correlation) else 0.0
        
        return 0.0
    
    async def _discover_meta_patterns(self) -> List[MetaLearningPattern]:
        """ãƒ¡ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹"""
        patterns = []
        
        # å­¦ç¿’æˆ¦ç•¥ã®åŠ¹æœåˆ†æ
        strategy_effectiveness = defaultdict(list)
        
        for entry in list(self.learning_history)[-200:]:  # æœ€æ–°200ä»¶
            experience = entry['experience']
            result = entry['result']
            
            # æˆ¦ç•¥åˆ¤å®šï¼ˆç°¡ç•¥åŒ–ï¼‰
            if experience.success:
                strategy = LearningStrategy.SUPERVISED
            else:
                strategy = LearningStrategy.REINFORCEMENT
            
            effectiveness = experience.confidence if experience.success else 0.0
            strategy_effectiveness[strategy].append(effectiveness)
        
        # åŠ¹æœçš„ãªæˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        for strategy, effectiveness_list in strategy_effectiveness.items():
            if effectiveness_list:
                avg_effectiveness = np.mean(effectiveness_list)
                
                if avg_effectiveness > 0.7:
                    pattern = MetaLearningPattern(
                        pattern_id=f"meta_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                        discovered_at=datetime.now(),
                        pattern_type=f"high_effectiveness_{strategy.value}",
                        effectiveness=avg_effectiveness,
                        applicable_strategies=[strategy],
                        success_conditions={'confidence_threshold': 0.7},
                        failure_conditions={'error_rate': 0.3},
                        optimization_hints=['Increase batch size', 'Fine-tune learning rate']
                    )
                    patterns.append(pattern)
        
        return patterns
    
    async def _generate_grand_elder_report(self) -> Dict[str, Any]:
        """ã‚°ãƒ©ãƒ³ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼å‘ã‘ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        return {
            'timestamp': datetime.now().isoformat(),
            'system_metrics': dict(self.system_metrics),
            'sage_performance': {
                sage_type.value: await sage.evaluate_performance()
                for sage_type, sage in self.sages.items()
            },
            'key_insights': len(self.cross_domain_insights),
            'meta_patterns': len(self.meta_learning_patterns),
            'recommendations': [
                "Continue autonomous learning",
                "Increase cross-domain collaboration",
                "Optimize meta-learning strategies"
            ]
        }
    
    async def _process_claude_elder_instructions(self):
        """ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤ºå‡¦ç†"""
        # æŒ‡ç¤ºãŒã‚ã‚Œã°å‡¦ç†ï¼ˆãƒ¢ãƒƒã‚¯å®Ÿè£…ï¼‰
        pass
    
    async def _generate_council_proposals(self) -> List[Dict[str, Any]]:
        """è©•è­°ä¼šå‘ã‘ææ¡ˆç”Ÿæˆ"""
        proposals = []
        
        # é‡è¦ãªæ´å¯Ÿã«åŸºã¥ãææ¡ˆ
        for insight in self.cross_domain_insights[-5:]:  # æœ€æ–°5ä»¶
            if insight.confidence > 0.8:
                proposals.append({
                    'proposal_id': f"prop_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    'type': 'system_improvement',
                    'based_on': insight.insight_id,
                    'recommendation': f"Implement {insight.discovery}",
                    'expected_impact': insight.potential_impact
                })
        
        return proposals
    
    async def _distribute_servant_tasks(self) -> List[Dict[str, Any]]:
        """ã‚µãƒ¼ãƒãƒ³ãƒˆå‘ã‘ã‚¿ã‚¹ã‚¯é…å¸ƒ"""
        tasks = []
        
        # å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ
        for sage_type, sage in self.sages.items():
            performance = await sage.evaluate_performance()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ã„å ´åˆã¯ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
            if performance.get('efficiency', 1.0) < 0.7:
                tasks.append({
                    'task_id': f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    'assigned_to': 'elder_servants',
                    'task_type': 'improve_sage_performance',
                    'target_sage': sage_type.value,
                    'priority': 'high',
                    'deadline': (datetime.now() + timedelta(days=1)).isoformat()
                })
        
        return tasks
    
    async def _persist_experience(self, experience: LearningExperience):
        """çµŒé¨“æ°¸ç¶šåŒ–"""
        try:
            conn = sqlite3.connect(self.config['database_path'])
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO learning_experiences 
                (experience_id, timestamp, domain, sage_type, input_data,
                 output_result, success, confidence, lessons_learned, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                experience.experience_id,
                experience.timestamp.isoformat(),
                experience.domain.value,
                experience.sage_type.value,
                json.dumps(experience.input_data),
                json.dumps(experience.output_result),
                experience.success,
                experience.confidence,
                json.dumps(experience.lessons_learned),
                json.dumps(experience.metadata)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Experience persistence failed: {e}")
    
    async def _persist_knowledge_packet(self, packet: ElderKnowledgePacket):
        """çŸ¥è­˜ãƒ‘ã‚±ãƒƒãƒˆæ°¸ç¶šåŒ–"""
        try:
            conn = sqlite3.connect(self.config['database_path'])
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO knowledge_packets 
                (packet_id, created_at, source_elder, target_elder,
                 knowledge_type, content, propagation_path, absorption_rate)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                packet.packet_id,
                packet.created_at.isoformat(),
                packet.source_elder,
                packet.target_elder,
                packet.knowledge_type,
                json.dumps(packet.content),
                json.dumps(packet.propagation_path),
                packet.absorption_rate
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Knowledge packet persistence failed: {e}")
    
    async def _persist_cross_domain_insight(self, insight: CrossDomainInsight):
        """ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³æ´å¯Ÿæ°¸ç¶šåŒ–"""
        try:
            conn = sqlite3.connect(self.config['database_path'])
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO cross_domain_insights 
                (insight_id, created_at, source_domains, insight_type,
                 discovery, applicable_domains, confidence, evidence, potential_impact)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                insight.insight_id,
                insight.created_at.isoformat(),
                json.dumps([d.value for d in insight.source_domains]),
                insight.insight_type,
                insight.discovery,
                json.dumps([d.value for d in insight.applicable_domains]),
                insight.confidence,
                json.dumps(insight.evidence),
                json.dumps(insight.potential_impact)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Cross-domain insight persistence failed: {e}")
    
    async def _persist_meta_pattern(self, pattern: MetaLearningPattern):
        """ãƒ¡ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³æ°¸ç¶šåŒ–"""
        try:
            conn = sqlite3.connect(self.config['database_path'])
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO meta_learning_patterns 
                (pattern_id, discovered_at, pattern_type, effectiveness,
                 applicable_strategies, success_conditions, failure_conditions, optimization_hints)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                pattern.pattern_id,
                pattern.discovered_at.isoformat(),
                pattern.pattern_type,
                pattern.effectiveness,
                json.dumps([s.value for s in pattern.applicable_strategies]),
                json.dumps(pattern.success_conditions),
                json.dumps(pattern.failure_conditions),
                json.dumps(pattern.optimization_hints)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Meta pattern persistence failed: {e}")
    
    async def get_learning_status(self) -> Dict[str, Any]:
        """å­¦ç¿’çŠ¶æ³å–å¾—"""
        sage_status = {}
        for sage_type, sage in self.sages.items():
            sage_status[sage_type.value] = {
                'performance': await sage.evaluate_performance(),
                'knowledge_base_size': len(sage.knowledge_base),
                'learning_history_size': len(sage.learning_history)
            }
        
        return {
            'system_metrics': dict(self.system_metrics),
            'sage_status': sage_status,
            'cross_domain_insights': len(self.cross_domain_insights),
            'meta_patterns': len(self.meta_learning_patterns),
            'learning_efficiency': self._calculate_learning_efficiency(),
            'elder_hierarchy_status': {
                'grand_elder_reports': len(self.elder_hierarchy['grand_elder']['knowledge_packets']),
                'council_proposals': len(self.elder_hierarchy['council']['proposals']),
                'servant_tasks': len(self.elder_hierarchy['servants']['tasks'])
            }
        }
    
    def _calculate_learning_efficiency(self) -> float:
        """å­¦ç¿’åŠ¹ç‡è¨ˆç®—"""
        if self.system_metrics['total_experiences'] == 0:
            return 0.0
        
        # æˆåŠŸçµŒé¨“ã®å‰²åˆ
        success_count = sum(1 for entry in self.learning_history 
                          if entry['experience'].success)
        
        efficiency = success_count / self.system_metrics['total_experiences']
        
        # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³æ´å¯Ÿã¨ãƒ¡ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ãƒœãƒ¼ãƒŠã‚¹
        insight_bonus = self.system_metrics['cross_domain_insights'] * 0.01
        meta_bonus = self.system_metrics['meta_patterns_discovered'] * 0.02
        
        return min(1.0, efficiency + insight_bonus + meta_bonus)


# ä½¿ç”¨ä¾‹
async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        learning_system = AutonomousLearningSystem()
        
        print("ğŸ§  Starting Autonomous Learning System with 4 Sages...")
        
        # å­¦ç¿’é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
        learning_task = asyncio.create_task(learning_system.start_learning())
        
        # ã‚µãƒ³ãƒ—ãƒ«çµŒé¨“æŠ•ç¨¿
        print("\nğŸ“ Submitting sample learning experiences...")
        
        # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã®çµŒé¨“
        await learning_system.submit_experience(
            domain=LearningDomain.KNOWLEDGE,
            sage_type=SageType.KNOWLEDGE,
            input_data={'query': 'pgvector integration', 'context': 'elders guild'},
            output_result={'patterns': ['vector_search', 'knowledge_graph'], 'quality': 0.9},
            success=True,
            confidence=0.9,
            lessons_learned=['Vector embeddings improve search quality']
        )
        
        # ã‚¿ã‚¹ã‚¯è³¢è€…ã®çµŒé¨“
        await learning_system.submit_experience(
            domain=LearningDomain.TASK,
            sage_type=SageType.TASK,
            input_data={'task': 'optimize_execution', 'complexity': 'high'},
            output_result={'optimization': 'parallel_processing', 'speedup': 2.5},
            success=True,
            confidence=0.85,
            lessons_learned=['Parallel processing effective for complex tasks']
        )
        
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã®çµŒé¨“
        await learning_system.submit_experience(
            domain=LearningDomain.INCIDENT,
            sage_type=SageType.INCIDENT,
            input_data={'anomaly': 'high_cpu', 'severity': 'critical'},
            output_result={'action': 'auto_scaling', 'prevented': True},
            success=True,
            confidence=0.95,
            lessons_learned=['Proactive scaling prevents incidents']
        )
        
        # RAGè³¢è€…ã®çµŒé¨“
        await learning_system.submit_experience(
            domain=LearningDomain.SEARCH,
            sage_type=SageType.RAG,
            input_data={'search_type': 'semantic', 'query_complexity': 'high'},
            output_result={'relevance': 0.92, 'response_time': 150},
            success=True,
            confidence=0.88,
            lessons_learned=['Semantic search handles complex queries well']
        )
        
        # å°‘ã—å¾…æ©Ÿ
        await asyncio.sleep(5)
        
        # å­¦ç¿’çŠ¶æ³ç¢ºèª
        print("\nğŸ“Š Checking learning status...")
        status = await learning_system.get_learning_status()
        
        print(f"\nğŸ¯ System Metrics:")
        print(f"  Total Experiences: {status['system_metrics']['total_experiences']}")
        print(f"  Knowledge Packets Exchanged: {status['system_metrics']['knowledge_packets_exchanged']}")
        print(f"  Cross-Domain Insights: {status['cross_domain_insights']}")
        print(f"  Meta Patterns: {status['meta_patterns']}")
        print(f"  Learning Efficiency: {status['learning_efficiency']:.2f}")
        
        print(f"\nğŸ§™â€â™‚ï¸ Sage Status:")
        for sage_type, sage_status in status['sage_status'].items():
            print(f"  {sage_type}:")
            print(f"    Knowledge Base: {sage_status['knowledge_base_size']} items")
            print(f"    Performance: {sage_status['performance']}")
        
        print(f"\nğŸ›ï¸ Elder Hierarchy Integration:")
        print(f"  Grand Elder Reports: {status['elder_hierarchy_status']['grand_elder_reports']}")
        print(f"  Council Proposals: {status['elder_hierarchy_status']['council_proposals']}")
        print(f"  Servant Tasks: {status['elder_hierarchy_status']['servant_tasks']}")
        
        # åœæ­¢
        await learning_system.stop_learning()
        learning_task.cancel()
        
        print("\nğŸ‰ Autonomous Learning System Phase 2 demonstration completed!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())