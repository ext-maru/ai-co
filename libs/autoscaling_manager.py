#!/usr/bin/env python3
"""
ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
è² è·ã«å¿œã˜ã¦è‡ªå‹•çš„ã«ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’èª¿æ•´
"""

import json
import logging
import subprocess
import time
from datetime import datetime, timedelta
from threading import Event, Thread
from typing import Dict, List, Optional, Tuple

import pika
import psutil


class AutoScalingManager:
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç®¡ç†"""

    def __init__(self, config: Optional[Dict] = None):
        """
        Args:
            config: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®š
                - min_workers: æœ€å°ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
                - max_workers: æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
                - scale_up_threshold: ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—é–¾å€¤ï¼ˆã‚­ãƒ¥ãƒ¼é•·ï¼‰
                - scale_down_threshold: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³é–¾å€¤
                - cooldown_period: ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ï¼ˆç§’ï¼‰
        """
        self.config = config or {
            "min_workers": 1,
            "max_workers": 10,
            "scale_up_threshold": 50,
            "scale_down_threshold": 10,
            "cooldown_period": 60,
            "check_interval": 10,
        }

        self.logger = logging.getLogger(__name__)
        self.connection = None
        self.channel = None
        self.stop_event = Event()

        # ãƒ¯ãƒ¼ã‚«ãƒ¼æƒ…å ±
        self.worker_processes: Dict[str, subprocess.Popen] = {}
        self.last_scale_time = datetime.now()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.metrics = {
            "scale_up_count": 0,
            "scale_down_count": 0,
            "current_workers": 0,
            "queue_length_history": [],
        }

    def connect(self):
        """RabbitMQã«æ¥ç¶š"""
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters("localhost")
        )
        self.channel = self.connection.channel()

    def get_queue_length(self, queue_name: str) -> int:
        """ã‚­ãƒ¥ãƒ¼ã®é•·ã•ã‚’å–å¾—"""
        try:
            method = self.channel.queue_declare(queue=queue_name, passive=True)
            return method.method.message_count
        except Exception as e:
            self.logger.error(f"Failed to get queue length: {str(e)}")
            return 0

    def get_system_load(self) -> Dict[str, float]:
        """ã‚·ã‚¹ãƒ†ãƒ è² è·ã‚’å–å¾—"""
        return {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "load_average": psutil.getloadavg()[0]
            if hasattr(psutil, "getloadavg")
            else 0,
        }

    def count_running_workers(self, worker_type: str) -> int:
        """å®Ÿè¡Œä¸­ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        count = 0
        for proc in psutil.process_iter(["pid", "name", "cmdline"]):
            try:
                cmdline = proc.info["cmdline"]
                if cmdline and worker_type in " ".join(cmdline):
                    count += 1
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

        # ç®¡ç†ä¸­ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚‚ç¢ºèª
        self.cleanup_dead_processes()
        return len([p for p in self.worker_processes.values() if p.poll() is None])

    def cleanup_dead_processes(self):
        """çµ‚äº†ã—ãŸãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        dead_workers = []
        for worker_id, proc in self.worker_processes.items():
            if proc.poll() is not None:
                dead_workers.append(worker_id)

        for worker_id in dead_workers:
            del self.worker_processes[worker_id]
            self.logger.info(f"ğŸ§¹ Cleaned up dead worker: {worker_id}")

    def spawn_worker(self, worker_type: str, worker_script: str) -> Optional[str]:
        """æ–°ã—ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•"""
        try:
            worker_id = f"{worker_type}_{int(time.time())}"

            # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•
            cmd = ["python3", worker_script, "--worker-id", worker_id]

            proc = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd="/home/aicompany/ai_co",
            )

            self.worker_processes[worker_id] = proc
            self.logger.info(f"ğŸš€ Spawned new worker: {worker_id} (PID: {proc.pid})")

            return worker_id

        except Exception as e:
            self.logger.error(f"Failed to spawn worker: {str(e)}")
            return None

    def terminate_worker(self, worker_id: str) -> bool:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†"""
        try:
            if worker_id in self.worker_processes:
                proc = self.worker_processes[worker_id]

                # å„ªé›…ã«çµ‚äº†ã‚’è©¦ã¿ã‚‹
                proc.terminate()
                time.sleep(2)

                # ã¾ã ç”Ÿãã¦ã„ã‚Œã°å¼·åˆ¶çµ‚äº†
                if proc.poll() is None:
                    proc.kill()

                del self.worker_processes[worker_id]
                self.logger.info(f"ğŸ›‘ Terminated worker: {worker_id}")
                return True

        except Exception as e:
            self.logger.error(f"Failed to terminate worker: {str(e)}")

        return False

    def should_scale_up(self, queue_length: int, system_load: Dict[str, float]) -> bool:
        """ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã¹ãã‹åˆ¤å®š"""
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ãªã„
        if datetime.now() - self.last_scale_time < timedelta(
            seconds=self.config["cooldown_period"]
        ):
            return False

        # ã‚­ãƒ¥ãƒ¼é•·ãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚‹
        if queue_length > self.config["scale_up_threshold"]:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã«ä½™è£•ãŒã‚ã‚‹
            if system_load["cpu_percent"] < 80 and system_load["memory_percent"] < 80:
                return True

        return False

    def should_scale_down(self, queue_length: int, current_workers: int) -> bool:
        """ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã™ã¹ãã‹åˆ¤å®š"""
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ãªã„
        if datetime.now() - self.last_scale_time < timedelta(
            seconds=self.config["cooldown_period"]
        ):
            return False

        # æœ€å°ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ä»¥ä¸‹ã«ã¯ã—ãªã„
        if current_workers <= self.config["min_workers"]:
            return False

        # ã‚­ãƒ¥ãƒ¼é•·ãŒé–¾å€¤æœªæº€
        return queue_length < self.config["scale_down_threshold"]

    def scale_workers(self, worker_type: str, worker_script: str, queue_name: str):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’èª¿æ•´"""
        queue_length = self.get_queue_length(queue_name)
        system_load = self.get_system_load()
        current_workers = self.count_running_workers(worker_type)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        self.metrics["queue_length_history"].append(
            {
                "timestamp": datetime.now().isoformat(),
                "queue_length": queue_length,
                "workers": current_workers,
            }
        )
        self.metrics["current_workers"] = current_workers

        # ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—åˆ¤å®š
        if (
            self.should_scale_up(queue_length, system_load)
            and current_workers < self.config["max_workers"]
        ):
            # ä¸€åº¦ã«1ã¤ãšã¤å¢—ã‚„ã™
            worker_id = self.spawn_worker(worker_type, worker_script)
            if worker_id:
                self.metrics["scale_up_count"] += 1
                self.last_scale_time = datetime.now()
                self.logger.info(f"ğŸ“ˆ Scaled up to {current_workers + 1} workers")

        # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³åˆ¤å®š
        elif self.should_scale_down(queue_length, current_workers):
            # æœ€ã‚‚å¤ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†
            if self.worker_processes:
                oldest_worker = list(self.worker_processes.keys())[0]
                if self.terminate_worker(oldest_worker):
                    self.metrics["scale_down_count"] += 1
                    self.last_scale_time = datetime.now()
                    self.logger.info(f"ğŸ“‰ Scaled down to {current_workers - 1} workers")

    def monitor_and_scale(self, worker_configs: List[Dict]):
        """ç›£è¦–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.connect()
        self.logger.info("ğŸ¯ AutoScaling Manager started")

        while not self.stop_event.is_set():
            try:
                for config in worker_configs:
                    self.scale_workers(
                        config["worker_type"],
                        config["worker_script"],
                        config["queue_name"],
                    )

                # æŒ‡å®šã•ã‚ŒãŸé–“éš”ã§å¾…æ©Ÿ
                self.stop_event.wait(self.config["check_interval"])

            except Exception as e:
                self.logger.error(f"Error in scaling loop: {str(e)}")
                time.sleep(10)

    def stop(self):
        """ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åœæ­¢"""
        self.logger.info("Stopping AutoScaling Manager...")
        self.stop_event.set()

        # å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†
        for worker_id in list(self.worker_processes.keys()):
            self.terminate_worker(worker_id)

        if self.connection and not self.connection.is_closed:
            self.connection.close()

    def get_stats(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            "metrics": self.metrics,
            "config": self.config,
            "last_scale_time": self.last_scale_time.isoformat(),
            "active_workers": list(self.worker_processes.keys()),
        }


class AutoScalableWorker:
    """ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³"""

    def register_with_scaler(self):
        """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã«è‡ªèº«ã‚’ç™»éŒ²"""
        # ãƒ¯ãƒ¼ã‚«ãƒ¼IDã¨èµ·å‹•æ™‚åˆ»ã‚’è¨˜éŒ²
        self.scaling_metadata = {
            "worker_id": self.worker_id,
            "start_time": datetime.now(),
            "pid": psutil.Process().pid,
        }

        # ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã®ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        import signal

        signal.signal(signal.SIGTERM, self._handle_termination)

    def _handle_termination(self, signum, frame):
        """çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        self.logger.info(f"Received termination signal, shutting down gracefully...")
        self.stop()
