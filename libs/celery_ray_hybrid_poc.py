#!/usr/bin/env python3
"""
Celery + Ray ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰POC - OSSç§»è¡Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
Celeryã§ã‚¿ã‚¹ã‚¯ç®¡ç†ã€Rayã§ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿç¾ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
"""
import asyncio
import logging
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import psutil
import ray
from celery import Celery

# Celeryã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = Celery("hybrid_workers")
app.config_from_object(
    {
        "broker_url": "redis://localhost:6379/1",
        "result_backend": "redis://localhost:6379/1",
    }
)

# Rayã®åˆæœŸåŒ–ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã«åˆæœŸåŒ–ï¼‰
# ray.init(address='auto')  # Rayã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«æ¥ç¶š


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""

    task_id: str
    processing_time: float
    method: str  # 'celery', 'ray', 'hybrid'
    result: Any
    metrics: Dict[str, Any]


class HybridWorkerOptimizer:
    """Celery + Rayãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–å™¨"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.logger = logging.getLogger(__name__)
        self.ray_initialized = False

    def _ensure_ray(self):
        """Rayã®åˆæœŸåŒ–ã‚’ç¢ºèª"""
        if not self.ray_initialized:
            try:
                ray.init(address="auto", ignore_reinit_error=True)
                self.ray_initialized = True
            except:
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
                ray.init(ignore_reinit_error=True)
                self.ray_initialized = True

    async def optimize_with_ray(self, items: List[Any], func) -> List[Any]:
        """Rayã‚’ä½¿ç”¨ã—ãŸä¸¦åˆ—å‡¦ç†"""
        self._ensure_ray()

        # Rayãƒªãƒ¢ãƒ¼ãƒˆé–¢æ•°ã®å®šç¾©
        @ray.remote
        def ray_process_item(item):
            return func(item)

        # ä¸¦åˆ—å®Ÿè¡Œ
        futures = [ray_process_item.remote(item) for item in items]
        results = ray.get(futures)

        return results

    def optimize_with_celery(self, items: List[Any], task_name: str) -> List[Any]:
        """Celeryã‚’ä½¿ç”¨ã—ãŸã‚¿ã‚¹ã‚¯ç®¡ç†"""
        from celery import group

        # Celeryã‚¿ã‚¹ã‚¯ã®å–å¾—
        task = app.tasks.get(task_name)
        if not task:
            raise ValueError(f"Task {task_name} not found")

        # ã‚°ãƒ«ãƒ¼ãƒ—ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œ
        job = group(task.s(item) for item in items)
        result = job.apply_async()

        return result.get(timeout=300)

    async def hybrid_optimization(
        self, items: List[Any], threshold: int = 100
    ) -> OptimizationResult:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–

        å°è¦æ¨¡ã‚¿ã‚¹ã‚¯: Celeryï¼ˆã‚¿ã‚¹ã‚¯ç®¡ç†ã®åˆ©ç‚¹ï¼‰
        å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯: Rayï¼ˆé«˜é€Ÿä¸¦åˆ—å‡¦ç†ï¼‰
        """
        start_time = time.time()

        if len(items) < threshold:
            # å°è¦æ¨¡: Celeryã‚’ä½¿ç”¨
            self.logger.info(f"Using Celery for {len(items)} items")
            results = self.optimize_with_celery(items, "process_small_batch")
            method = "celery"
        else:
            # å¤§è¦æ¨¡: Rayã‚’ä½¿ç”¨
            self.logger.info(f"Using Ray for {len(items)} items")
            results = await self.optimize_with_ray(items, self._process_large_item)
            method = "ray"

        processing_time = time.time() - start_time

        return OptimizationResult(
            task_id=f"hybrid_{int(time.time())}",
            processing_time=processing_time,
            method=method,
            result=results,
            metrics={
                "items_count": len(items),
                "avg_time_per_item": processing_time / len(items),
                "memory_usage": psutil.Process().memory_info().rss / 1024 / 1024,  # MB
            },
        )

    def _process_large_item(self, item):
        """å¤§è¦æ¨¡ã‚¢ã‚¤ãƒ†ãƒ ã®å‡¦ç†ï¼ˆRayç”¨ï¼‰"""
        # é‡ã„è¨ˆç®—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        import numpy as np

        data = np.random.rand(1000, 1000)
        result = np.sum(data)
        return {"item": item, "result": result}

    def create_adaptive_pipeline(self) -> "AdaptivePipeline":
        """é©å¿œçš„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ"""
        return AdaptivePipeline(self)


class AdaptivePipeline:
    """é©å¿œçš„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆCelery + Rayï¼‰"""

    def __init__(self, optimizer: HybridWorkerOptimizer):
        self.optimizer = optimizer
        self.stages = []

    def add_stage(self, name: str, func, use_ray: bool = False):
        """ã‚¹ãƒ†ãƒ¼ã‚¸ã®è¿½åŠ """
        self.stages.append({"name": name, "func": func, "use_ray": use_ray})
        return self

    async def execute(self, data: Any) -> Any:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""
        result = data

        for stage in self.stages:
            if stage["use_ray"]:
                # Rayã§å®Ÿè¡Œ
                self.optimizer._ensure_ray()
                remote_func = ray.remote(stage["func"])
                result = await remote_func.remote(result)
            else:
                # é€šå¸¸å®Ÿè¡Œ
                result = stage["func"](result)

        return result


# Celeryã‚¿ã‚¹ã‚¯å®šç¾©
@app.task(name="process_small_batch")
def process_small_batch(item: Dict[str, Any]) -> Dict[str, Any]:
    """å°è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ï¼ˆCeleryï¼‰"""
    # è»½ã„å‡¦ç†
    return {"id": item.get("id"), "processed_by": "celery", "timestamp": time.time()}


@app.task(name="orchestrate_hybrid_job")
def orchestrate_hybrid_job(job_config: Dict[str, Any]) -> Dict[str, Any]:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¸ãƒ§ãƒ–ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    optimizer = HybridWorkerOptimizer()

    # éåŒæœŸå‡¦ç†ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ
    import asyncio

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    items = job_config.get("items", [])
    threshold = job_config.get("threshold", 100)

    result = loop.run_until_complete(optimizer.hybrid_optimization(items, threshold))

    return {
        "job_id": result.task_id,
        "method": result.method,
        "processing_time": result.processing_time,
        "metrics": result.metrics,
    }


# Ray ã‚¢ã‚¯ã‚¿ãƒ¼ï¼ˆã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«ãªå‡¦ç†ç”¨ï¼‰
@ray.remote
class RayWorkerPool:
    """Rayãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«"""

    def __init__(self, size: int = 4):
        self.size = size
        self.tasks_processed = 0

    def process_batch(self, items: List[Any]) -> List[Any]:
        """ãƒãƒƒãƒå‡¦ç†"""
        results = []
        for item in items:
            # å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
            result = {"item": item, "processed": True}
            results.append(result)
            self.tasks_processed += 1
        return results

    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã®å–å¾—"""
        return {"pool_size": self.size, "tasks_processed": self.tasks_processed}


class PerformanceComparator:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒãƒ„ãƒ¼ãƒ«"""

    def __init__(self):
        self.results = []

    async def compare_methods(self, items: List[Any], iterations: int = 3):
        """Celery vs Ray vs Hybrid ã®æ¯”è¼ƒ"""
        methods = ["celery", "ray", "hybrid"]

        for method in methods:
            times = []
            for i in range(iterations):
                start = time.time()

                if method == "celery":
                    # Celeryã®ã¿
                    optimizer = HybridWorkerOptimizer()
                    result = optimizer.optimize_with_celery(
                        items, "process_small_batch"
                    )
                elif method == "ray":
                    # Rayã®ã¿
                    optimizer = HybridWorkerOptimizer()
                    result = await optimizer.optimize_with_ray(
                        items, lambda x: {"processed": x}
                    )
                else:
                    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰
                    optimizer = HybridWorkerOptimizer()
                    result = await optimizer.hybrid_optimization(items)

                elapsed = time.time() - start
                times.append(elapsed)

            avg_time = sum(times) / len(times)
            self.results.append(
                {
                    "method": method,
                    "avg_time": avg_time,
                    "items_count": len(items),
                    "throughput": len(items) / avg_time,
                }
            )

        return self.results

    def print_comparison(self):
        """æ¯”è¼ƒçµæœã®è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("Performance Comparison: Celery vs Ray vs Hybrid")
        print("=" * 60)

        for result in self.results:
            print(f"\nMethod: {result['method']}")
            print(f"  Average Time: {result['avg_time']:.3f}s")
            print(f"  Throughput: {result['throughput']:.1f} items/s")


# ãƒ‡ãƒ¢ç”¨é–¢æ•°
async def demo_hybrid_optimization():
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–ã®ãƒ‡ãƒ¢"""
    print("ğŸš€ Hybrid Worker Optimization Demo")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    small_batch = [{"id": i, "data": f"item-{i}"} for i in range(50)]
    large_batch = [{"id": i, "data": f"item-{i}"} for i in range(500)]

    optimizer = HybridWorkerOptimizer()

    # å°è¦æ¨¡ãƒãƒƒãƒï¼ˆCeleryä½¿ç”¨ï¼‰
    print("\nğŸ“¦ Small batch optimization...")
    small_result = await optimizer.hybrid_optimization(small_batch, threshold=100)
    print(f"Method: {small_result.method}")
    print(f"Time: {small_result.processing_time:.3f}s")

    # å¤§è¦æ¨¡ãƒãƒƒãƒï¼ˆRayä½¿ç”¨ï¼‰
    print("\nğŸ“¦ Large batch optimization...")
    large_result = await optimizer.hybrid_optimization(large_batch, threshold=100)
    print(f"Method: {large_result.method}")
    print(f"Time: {large_result.processing_time:.3f}s")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
    print("\nğŸ“Š Performance comparison...")
    comparator = PerformanceComparator()
    await comparator.compare_methods(small_batch)
    comparator.print_comparison()


if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    import asyncio

    asyncio.run(demo_hybrid_optimization())
