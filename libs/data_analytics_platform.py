#!/usr/bin/env python3
"""
é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆåˆ†æãƒ»äºˆæ¸¬ã™ã‚‹åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ 

è¨­è¨ˆ: RAGã‚¨ãƒ«ãƒ€ãƒ¼ Ã— ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼
æ‰¿èª: ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºè©•è­°ä¼šï¼ˆäºˆå®šï¼‰
å®Ÿè£…æ—¥: 2025å¹´7æœˆ9æ—¥
"""

import asyncio
import json
import logging
import sqlite3
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AnalyticsType(Enum):
    """åˆ†æã‚¿ã‚¤ãƒ—"""

    COMMIT_PATTERN = "commit_pattern"  # ã‚³ãƒŸãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    SAGE_PERFORMANCE = "sage_performance"  # 4è³¢è€…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    SYSTEM_HEALTH = "system_health"  # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹äºˆæ¸¬
    PROTOCOL_EFFICIENCY = "protocol_efficiency"  # ãƒ—ãƒ­ãƒˆã‚³ãƒ«åŠ¹ç‡åˆ†æ
    ERROR_PREDICTION = "error_prediction"  # ã‚¨ãƒ©ãƒ¼äºˆæ¸¬
    BOTTLENECK_DETECTION = "bottleneck_detection"  # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º


@dataclass
class AnalyticsResult:
    """åˆ†æçµæœ"""

    type: AnalyticsType
    timestamp: datetime
    metrics: Dict[str, Any]
    insights: List[str]
    predictions: Dict[str, Any]
    recommendations: List[str]
    confidence: float


class DataCollector:
    """ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, project_root: Path):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.project_root = Path(project_root)
        self.logs_dir = self.project_root / "logs"
        self.db_path = self.project_root / "elder_dashboard.db"

    async def collect_commit_data(self) -> pd.DataFrame:
        """ã‚³ãƒŸãƒƒãƒˆãƒ‡ãƒ¼ã‚¿åé›†"""
        try:
            conn = sqlite3connect(str(self.db_path))

            # ãƒ—ãƒ­ãƒˆã‚³ãƒ«å±¥æ­´ã‚’å–å¾—
            query = """
                SELECT
                    timestamp,
                    protocol,
                    message,
                    approved,
                    execution_time,
                    sage_count,
                    risk_score,
                    files_changed,
                    complexity
                FROM protocol_history
                ORDER BY timestamp
            """

            df = pd.read_sql_query(query, conn)
            conn.close()

            # æ—¥æ™‚å‹ã«å¤‰æ›
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            logger.info(f"ğŸ“Š {len(df)}ä»¶ã®ã‚³ãƒŸãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
            return df

        except Exception as e:
            logger.error(f"âŒ ã‚³ãƒŸãƒƒãƒˆãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    async def collect_sage_consultation_data(self) -> pd.DataFrame:
        """4è³¢è€…ç›¸è«‡ãƒ‡ãƒ¼ã‚¿åé›†"""
        try:
            conn = sqlite3connect(str(self.db_path))

            query = """
                SELECT
                    sc.sage_name,
                    sc.approval,
                    sc.risk_score,
                    sc.advice,
                    sc.timestamp,
                    ph.protocol,
                    ph.complexity
                FROM sage_consultations sc
                JOIN protocol_history ph ON sc.protocol_id = ph.id
                ORDER BY sc.timestamp
            """

            df = pd.read_sql_query(query, conn)
            conn.close()

            df["timestamp"] = pd.to_datetime(df["timestamp"])

            logger.info(f"ğŸ§™â€â™‚ï¸ {len(df)}ä»¶ã®è³¢è€…ç›¸è«‡ãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
            return df

        except Exception as e:
            logger.error(f"âŒ è³¢è€…ç›¸è«‡ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    async def collect_system_metrics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        metrics = {
            "timestamp": datetime.now(),
            "active_workers": 0,
            "error_logs": 0,
            "warning_logs": 0,
            "total_log_files": 0,
            "disk_usage_mb": 0,
        }

        try:
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
            log_files = list(self.logs_dir.glob("*.log"))
            metrics["total_log_files"] = len(log_files)

            # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šã‚«ã‚¦ãƒ³ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            for log_file in log_files[:10]:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                try:
                    with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                        metrics["error_logs"] += content.count("ERROR")
                        metrics["warning_logs"] += content.count("WARNING")
                except:
                    pass

            # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
            total_size = sum(f.stat().st_size for f in log_files)
            metrics["disk_usage_mb"] = total_size / (1024 * 1024)

            logger.info(f"ğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†")
            return metrics

        except Exception as e:
            logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return metrics


class PredictionModel:
    """é«˜åº¦ãªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.time_series_models = {}
        self.anomaly_detectors = {}
        self.trained = False

    async def train_time_series(
        self, df: pd.DataFrame, target_column: str, time_column: str = "timestamp"
    ):
        """æ™‚ç³»åˆ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        if df.empty or target_column not in df.columns:
            logger.warning(f"âš ï¸ æ™‚ç³»åˆ—è¨“ç·´ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {target_column}")
            return

        # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
        df_sorted = df.sort_values(time_column)

        # ç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.time_series_models[target_column] = {
            "type": "moving_average",
            "window_sizes": [3, 7, 14],
            "data": {},
        }

        # å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ç§»å‹•å¹³å‡ã‚’è¨ˆç®—
        for window in self.time_series_models[target_column]["window_sizes"]:
            if len(df_sorted) >= window:
                ma = df_sorted[target_column].rolling(window=window).mean()
                self.time_series_models[target_column]["data"][f"ma_{window}"] = (
                    ma.iloc[-1]
                )

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if len(df_sorted) > 10:
            # ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¨ˆç®—
            x = np.arange(len(df_sorted))
            y = df_sorted[target_column].values
            if np.issubdtype(y.dtype, np.number):
                coeffs = np.polyfit(x, y, 1)
                self.time_series_models[target_column]["trend"] = {
                    "slope": coeffs[0],
                    "intercept": coeffs[1],
                    "direction": "increasing" if coeffs[0] > 0 else "decreasing",
                }

        logger.info(f"ğŸ“ˆ æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†: {target_column}")

    async def detect_anomalies(
        self, df: pd.DataFrame, column: str, threshold: float = 2.0
    ):
        """ç•°å¸¸æ¤œå‡º"""
        if df.empty or column not in df.columns:
            return []

        anomalies = []
        values = df[column].dropna()

        if len(values) > 3:
            # çµ±è¨ˆçš„ç•°å¸¸æ¤œå‡ºï¼ˆZã‚¹ã‚³ã‚¢æ³•ï¼‰
            mean = values.mean()
            std = values.std()

            if std > 0:
                z_scores = np.abs((values - mean) / std)
                anomaly_indices = z_scores[z_scores > threshold].index

                for idx in anomaly_indices:
                    anomalies.append(
                        {
                            "index": idx,
                            "value": values[idx],
                            "z_score": z_scores[idx],
                            "severity": "high" if z_scores[idx] > 3 else "medium",
                        }
                    )

                # ç•°å¸¸æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                self.anomaly_detectors[column] = {
                    "mean": mean,
                    "std": std,
                    "threshold": threshold,
                    "anomaly_count": len(anomalies),
                }

        return anomalies

    async def forecast(self, column: str, periods: int = 5) -> List[float]:
        """å°†æ¥å€¤ã®äºˆæ¸¬"""
        predictions = []

        if column in self.time_series_models:
            model = self.time_series_models[column]

            # ç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬
            if "data" in model and model["data"]:
                # æœ€æ–°ã®ç§»å‹•å¹³å‡å€¤ã‚’ä½¿ç”¨
                latest_ma = list(model["data"].values())[-1]

                # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è€ƒæ…®
                if "trend" in model:
                    slope = model["trend"]["slope"]
                    for i in range(periods):
                        prediction = latest_ma + (slope * (i + 1))
                        predictions.append(prediction)
                else:
                    # ãƒˆãƒ¬ãƒ³ãƒ‰ãŒãªã„å ´åˆã¯æœ€æ–°å€¤ã‚’ç¹°ã‚Šè¿”ã™
                    predictions = [latest_ma] * periods

        return predictions

    def get_model_summary(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã‚’å–å¾—"""
        return {
            "time_series_models": list(self.time_series_models.keys()),
            "anomaly_detectors": list(self.anomaly_detectors.keys()),
            "total_models": len(self.time_series_models) + len(self.anomaly_detectors),
            "trained": self.trained,
        }


class AnalyticsEngine:
    """åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.ml_models = {}  # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ ¼ç´ç”¨
        self.prediction_model = PredictionModel()  # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

    async def analyze_commit_patterns(self, df: pd.DataFrame) -> AnalyticsResult:
        """ã‚³ãƒŸãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []
        predictions = {}
        metrics = {}

        if df.empty:
            return self._empty_result(AnalyticsType.COMMIT_PATTERN)

        # åŸºæœ¬çµ±è¨ˆ
        metrics["total_commits"] = len(df)
        metrics["approval_rate"] = df["approved"].mean() * 100
        metrics["avg_execution_time"] = df["execution_time"].mean()
        metrics["avg_complexity"] = df["complexity"].mean()

        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆ¥åˆ†æ
        protocol_stats = (
            df.groupby("protocol")
            .agg(
                {
                    "approved": ["count", "mean"],
                    "execution_time": "mean",
                    "complexity": "mean",
                }
            )
            .round(2)
        )

        # MultiIndexã‚’å‡¦ç†ã—ã‚„ã™ã„å½¢ã«å¤‰æ›
        protocol_distribution = {}
        for protocol in protocol_stats.index:
            protocol_distribution[protocol] = {
                "count": int(protocol_stats.loc[protocol, ("approved", "count")]),
                "approval_rate": float(
                    protocol_stats.loc[protocol, ("approved", "mean")]
                ),
                "avg_execution_time": float(
                    protocol_stats.loc[protocol, ("execution_time", "mean")]
                ),
                "avg_complexity": float(
                    protocol_stats.loc[protocol, ("complexity", "mean")]
                ),
            }

        metrics["protocol_distribution"] = protocol_distribution

        # æ™‚ç³»åˆ—åˆ†æ
        df["hour"] = df["timestamp"].dt.hour
        hourly_commits = df.groupby("hour").size()
        peak_hour = hourly_commits.idxmax()

        insights.append(f"ğŸ“Š ãƒ”ãƒ¼ã‚¯ã‚³ãƒŸãƒƒãƒˆæ™‚é–“: {peak_hour}æ™‚å°")
        insights.append(f"âš¡ å¹³å‡å®Ÿè¡Œæ™‚é–“: {metrics['avg_execution_time']:0.1f}ç§’")

        # äºˆæ¸¬
        if len(df) > 10:
            # ç°¡æ˜“çš„ãªæ¬¡å›ã‚³ãƒŸãƒƒãƒˆæ™‚é–“äºˆæ¸¬
            commit_intervals = df["timestamp"].diff().dropna()
            avg_interval = commit_intervals.mean()
            next_commit = df["timestamp"].iloc[-1] + avg_interval
            predictions["next_commit_time"] = next_commit.isoformat()
            predictions["expected_protocol"] = df["protocol"].mode()[0]

        # æ¨å¥¨äº‹é …
        recommendations = []
        if metrics["avg_execution_time"] > 10:
            recommendations.append(
                "ğŸš€ å®Ÿè¡Œæ™‚é–“ãŒé•·ã„ãŸã‚ã€Lightning Protocol ã®æ´»ç”¨ã‚’æ¨å¥¨"
            )
        if metrics["approval_rate"] < 90:
            recommendations.append("âš ï¸ æ‰¿èªç‡ãŒä½ä¸‹å‚¾å‘ã€‚å“è³ªãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–ã‚’æ¨å¥¨")

        return AnalyticsResult(
            type=AnalyticsType.COMMIT_PATTERN,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.85,
        )

    async def analyze_sage_performance(self, df: pd.DataFrame) -> AnalyticsResult:
        """4è³¢è€…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        insights = []
        predictions = {}
        metrics = {}

        if df.empty:
            return self._empty_result(AnalyticsType.SAGE_PERFORMANCE)

        # è³¢è€…åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        sage_stats = (
            df.groupby("sage_name")
            .agg({"approval": ["count", "mean"], "risk_score": "mean"})
            .round(3)
        )

        # MultiIndexã‚’å‡¦ç†ã—ã‚„ã™ã„å½¢ã«å¤‰æ›
        sage_performance = {}
        for sage in sage_stats.index:
            sage_performance[sage] = {
                "consultation_count": int(sage_stats.loc[sage, ("approval", "count")]),
                "approval_rate": float(sage_stats.loc[sage, ("approval", "mean")]),
                "avg_risk_score": float(sage_stats.loc[sage, ("risk_score", "mean")]),
            }

        metrics["sage_performance"] = sage_performance

        # è³¢è€…é–“ã®ç›¸é–¢åˆ†æ
        sage_approvals = df.pivot_table(
            index="timestamp", columns="sage_name", values="approval", aggfunc="mean"
        )

        if len(sage_approvals.columns) > 1:
            correlation = sage_approvals.corr()
            metrics["sage_correlation"] = correlation.to_dict()

            # é«˜ç›¸é–¢ãƒšã‚¢ã®æ¤œå‡º
            high_corr_pairs = []
            for i in range(len(correlation.columns)):
                for j in range(i + 1, len(correlation.columns)):
                    corr_value = correlation.iloc[i, j]
                    if corr_value > 0.7:
                        high_corr_pairs.append(
                            {
                                "pair": f"{correlation.columns[i]} - {correlation.columns[j]}",
                                "correlation": corr_value,
                            }
                        )

            if high_corr_pairs:
                insights.append(f"ğŸ¤ é«˜ç›¸é–¢è³¢è€…ãƒšã‚¢æ¤œå‡º: {len(high_corr_pairs)}çµ„")

        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆ¥ã®è³¢è€…æ‰¿èªç‡
        protocol_sage_approval = df.groupby(["protocol", "sage_name"])[
            "approval"
        ].mean()

        # MultiIndexã‚’å‡¦ç†ã—ã‚„ã™ã„å½¢ã«å¤‰æ›
        approval_dict = {}
        for (protocol, sage_name), approval_rate in protocol_sage_approval.items():
            if protocol not in approval_dict:
                approval_dict[protocol] = {}
            approval_dict[protocol][sage_name] = float(approval_rate)

        metrics["protocol_sage_approval"] = approval_dict

        # æ¨å¥¨äº‹é …
        recommendations = []
        for sage, stats in sage_stats.iterrows():
            approval_rate = stats[("approval", "mean")] * 100
            if approval_rate < 80:
                recommendations.append(f"âš ï¸ {sage}ã®æ‰¿èªç‡ãŒ{approval_rate:0.1f}%ã¨ä½ã„")

        return AnalyticsResult(
            type=AnalyticsType.SAGE_PERFORMANCE,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.90,
        )

    async def predict_system_health(
        self, commit_df: pd.DataFrame, system_metrics: Dict
    ) -> AnalyticsResult:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹äºˆæ¸¬"""
        insights = []
        predictions = {}
        metrics = {}

        # ç¾åœ¨ã®ãƒ˜ãƒ«ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
        health_score = 100.0

        # ã‚¨ãƒ©ãƒ¼ç‡ã«ã‚ˆã‚‹æ¸›ç‚¹
        if system_metrics["error_logs"] > 100:
            health_score -= 20
            insights.append("âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå¤šæ•°æ¤œå‡º")

        # è­¦å‘Šç‡ã«ã‚ˆã‚‹æ¸›ç‚¹
        if system_metrics["warning_logs"] > 500:
            health_score -= 10
            insights.append("âš ï¸ è­¦å‘Šãƒ­ã‚°ãŒå¢—åŠ å‚¾å‘")

        # ã‚³ãƒŸãƒƒãƒˆæ‰¿èªç‡ã«ã‚ˆã‚‹è©•ä¾¡
        if not commit_df.empty:
            approval_rate = commit_df["approved"].mean() * 100
            if approval_rate < 80:
                health_score -= 15
                insights.append(f"ğŸ“‰ ã‚³ãƒŸãƒƒãƒˆæ‰¿èªç‡ãŒ{approval_rate:0.1f}%ã¨ä½ä¸‹")

        metrics["current_health_score"] = health_score
        metrics["error_rate"] = system_metrics["error_logs"] / max(
            system_metrics["total_log_files"], 1
        )
        metrics["warning_rate"] = system_metrics["warning_logs"] / max(
            system_metrics["total_log_files"], 1
        )

        # ãƒ˜ãƒ«ã‚¹äºˆæ¸¬ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if health_score >= 80:
            predictions["next_24h_health"] = "è‰¯å¥½"
            predictions["maintenance_required"] = False
        elif health_score >= 60:
            predictions["next_24h_health"] = "æ³¨æ„"
            predictions["maintenance_required"] = True
            predictions["maintenance_type"] = "äºˆé˜²çš„ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"
        else:
            predictions["next_24h_health"] = "è¦å¯¾å¿œ"
            predictions["maintenance_required"] = True
            predictions["maintenance_type"] = "ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"

        # æ¨å¥¨äº‹é …
        recommendations = []
        if health_score < 80:
            recommendations.append("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œã‚’æ¨å¥¨")
        if metrics["error_rate"] > 0.1:
            recommendations.append("ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®è©³ç´°åˆ†æãŒå¿…è¦")

        return AnalyticsResult(
            type=AnalyticsType.SYSTEM_HEALTH,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.75,
        )

    async def analyze_protocol_efficiency(
        self, commit_df: pd.DataFrame
    ) -> AnalyticsResult:
        """ãƒ—ãƒ­ãƒˆã‚³ãƒ«åŠ¹ç‡åˆ†æ"""
        insights = []
        predictions = {}
        metrics = {}

        if commit_df.empty:
            return self._empty_result(AnalyticsType.PROTOCOL_EFFICIENCY)

        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆ¥ã®åŠ¹ç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        protocol_efficiency = (
            commit_df.groupby("protocol")
            .agg(
                {
                    "execution_time": ["mean", "std", "min", "max"],
                    "approved": "mean",
                    "files_changed": "mean",
                    "complexity": "mean",
                }
            )
            .round(2)
        )

        # åŠ¹ç‡ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆå®Ÿè¡Œæ™‚é–“ã¨æ‰¿èªç‡ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
        efficiency_scores = {}
        for protocol in protocol_efficiency.index:
            exec_time = protocol_efficiency.loc[protocol, ("execution_time", "mean")]
            approval_rate = protocol_efficiency.loc[protocol, ("approved", "mean")]

            # åŠ¹ç‡ã‚¹ã‚³ã‚¢ = æ‰¿èªç‡ / (1 + log(å®Ÿè¡Œæ™‚é–“))
            efficiency_score = approval_rate / (1 + np.log1p(exec_time))
            efficiency_scores[protocol] = round(efficiency_score, 3)

        metrics["efficiency_scores"] = efficiency_scores
        # Convert protocol_efficiency to a JSON-serializable format
        protocol_stats_dict = {}
        for protocol in protocol_efficiency.index:
            protocol_stats_dict[protocol] = {
                "execution_time_mean": float(
                    protocol_efficiency.loc[protocol, ("execution_time", "mean")]
                ),
                "execution_time_std": float(
                    protocol_efficiency.loc[protocol, ("execution_time", "std")]
                ),
                "execution_time_min": float(
                    protocol_efficiency.loc[protocol, ("execution_time", "min")]
                ),
                "execution_time_max": float(
                    protocol_efficiency.loc[protocol, ("execution_time", "max")]
                ),
                "approved_mean": float(
                    protocol_efficiency.loc[protocol, ("approved", "mean")]
                ),
                "files_changed_mean": float(
                    protocol_efficiency.loc[protocol, ("files_changed", "mean")]
                ),
                "complexity_mean": float(
                    protocol_efficiency.loc[protocol, ("complexity", "mean")]
                ),
            }
        metrics["protocol_stats"] = protocol_stats_dict

        # æœ€ã‚‚åŠ¹ç‡çš„ãªãƒ—ãƒ­ãƒˆã‚³ãƒ«
        best_protocol = max(efficiency_scores, key=efficiency_scores.get)
        insights.append(
            f"ğŸ† æœ€ã‚‚åŠ¹ç‡çš„ãªãƒ—ãƒ­ãƒˆã‚³ãƒ«: {best_protocol} (ã‚¹ã‚³ã‚¢: {efficiency_scores[best_protocol]})"
        )

        # æ™‚ç³»åˆ—ã§ã®åŠ¹ç‡å¤‰åŒ–åˆ†æ
        await self.prediction_model.train_time_series(commit_df, "execution_time")
        future_exec_times = await self.prediction_model.forecast(
            "execution_time", periods=5
        )

        if future_exec_times:
            predictions["execution_time_forecast"] = future_exec_times
            trend = "å¢—åŠ " if future_exec_times[-1] > future_exec_times[0] else "æ¸›å°‘"
            insights.append(f"ğŸ“ˆ å®Ÿè¡Œæ™‚é–“ã¯ä»Šå¾Œ{trend}å‚¾å‘ã¨äºˆæ¸¬")

        # æ¨å¥¨äº‹é …
        recommendations = []
        for protocol, score in efficiency_scores.items():
            if score < 0.5:
                recommendations.append(
                    f"âš¡ {protocol}ã®åŠ¹ç‡æ”¹å–„ãŒå¿…è¦ï¼ˆç¾åœ¨ã®ã‚¹ã‚³ã‚¢: {score}ï¼‰"
                )

        return AnalyticsResult(
            type=AnalyticsType.PROTOCOL_EFFICIENCY,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.82,
        )

    async def predict_errors(
        self, commit_df: pd.DataFrame, system_metrics: Dict
    ) -> AnalyticsResult:
        """ã‚¨ãƒ©ãƒ¼äºˆæ¸¬åˆ†æ"""
        insights = []
        predictions = {}
        metrics = {}

        # ã‚¨ãƒ©ãƒ¼ç‡ã®è¨ˆç®—
        current_error_rate = system_metrics.get("error_logs", 0) / max(
            system_metrics.get("total_log_files", 1), 1
        )
        metrics["current_error_rate"] = round(current_error_rate, 4)

        # ã‚³ãƒŸãƒƒãƒˆè¤‡é›‘åº¦ã¨ã‚¨ãƒ©ãƒ¼ã®ç›¸é–¢åˆ†æ
        if not commit_df.empty and "complexity" in commit_df.columns:
            # è¤‡é›‘åº¦ã«ã‚ˆã‚‹ç•°å¸¸æ¤œå‡º
            anomalies = await self.prediction_model.detect_anomalies(
                commit_df, "complexity"
            )

            if anomalies:
                metrics["complexity_anomalies"] = len(anomalies)
                insights.append(f"âš ï¸ {len(anomalies)}ä»¶ã®è¤‡é›‘åº¦ç•°å¸¸ã‚’æ¤œå‡º")

                # é«˜è¤‡é›‘åº¦ã‚³ãƒŸãƒƒãƒˆã®ç‰¹å®š
                high_complexity_threshold = commit_df["complexity"].quantile(0.9)
                high_complexity_commits = commit_df[
                    commit_df["complexity"] > high_complexity_threshold
                ]

                if not high_complexity_commits.empty:
                    predictions["high_risk_protocols"] = (
                        high_complexity_commits["protocol"]
                        .value_counts()
                        .head(3)
                        .to_dict()
                    )

        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿäºˆæ¸¬
        error_probability = min(current_error_rate * 2 + 0.1, 1.0)  # ç°¡æ˜“äºˆæ¸¬
        predictions["error_probability_24h"] = round(error_probability, 2)

        if error_probability > 0.3:
            insights.append(
                f"ğŸš¨ 24æ™‚é–“ä»¥å†…ã®ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç¢ºç‡: {error_probability*100:0.0f}%"
            )

        # æ¨å¥¨äº‹é …
        recommendations = []
        if current_error_rate > 0.05:
            recommendations.append("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®è©³ç´°åˆ†æã‚’å®Ÿæ–½")
        if metrics.get("complexity_anomalies", 0) > 5:
            recommendations.append("ğŸ” é«˜è¤‡é›‘åº¦ã‚³ãƒŸãƒƒãƒˆã®ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å¼·åŒ–")

        return AnalyticsResult(
            type=AnalyticsType.ERROR_PREDICTION,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.78,
        )

    async def detect_bottlenecks(
        self, commit_df: pd.DataFrame, sage_df: pd.DataFrame
    ) -> AnalyticsResult:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º"""
        insights = []
        predictions = {}
        metrics = {}

        bottlenecks = []

        # å®Ÿè¡Œæ™‚é–“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º
        if not commit_df.empty:
            # å®Ÿè¡Œæ™‚é–“ã®ç•°å¸¸å€¤æ¤œå‡º
            exec_time_anomalies = await self.prediction_model.detect_anomalies(
                commit_df, "execution_time"
            )

            if exec_time_anomalies:
                bottlenecks.extend(
                    [
                        {
                            "type": "execution_time",
                            "severity": a["severity"],
                            "value": a["value"],
                        }
                        for a in exec_time_anomalies
                    ]
                )

                insights.append(
                    f"â±ï¸ {len(exec_time_anomalies)}ä»¶ã®å®Ÿè¡Œæ™‚é–“ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ¤œå‡º"
                )

        # è³¢è€…æ‰¿èªã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º
        if not sage_df.empty:
            # è³¢è€…åˆ¥ã®å¹³å‡æ‰¿èªæ™‚é–“ï¼ˆãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’ä»£ç†æŒ‡æ¨™ã¨ã—ã¦ä½¿ç”¨ï¼‰
            sage_bottlenecks = sage_df.groupby("sage_name").agg(
                {"risk_score": "mean", "approval": "count"}
            )

            # é«˜ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã®è³¢è€…ã‚’ç‰¹å®š
            high_risk_sages = sage_bottlenecks[sage_bottlenecks["risk_score"] > 0.7]

            if not high_risk_sages.empty:
                for sage in high_risk_sages.index:
                    bottlenecks.append(
                        {
                            "type": "sage_approval",
                            "sage": sage,
                            "avg_risk_score": float(
                                high_risk_sages.loc[sage, "risk_score"]
                            ),
                        }
                    )

                insights.append(f"ğŸ§™â€â™‚ï¸ {len(high_risk_sages)}åã®è³¢è€…ã§æ‰¿èªé…å»¶ã®å¯èƒ½æ€§")

        metrics["total_bottlenecks"] = len(bottlenecks)
        metrics["bottleneck_details"] = bottlenecks

        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯è§£æ¶ˆã®äºˆæ¸¬
        if bottlenecks:
            predictions["resolution_time_hours"] = len(bottlenecks) * 2  # ç°¡æ˜“æ¨å®š
            predictions["impact_reduction"] = min(len(bottlenecks) * 0.15, 0.5)

        # æ¨å¥¨äº‹é …
        recommendations = []
        if any(b["type"] == "execution_time" for b in bottlenecks):
            recommendations.append("âš¡ Lightning Protocolã®é©ç”¨ç¯„å›²æ‹¡å¤§")
        if any(b["type"] == "sage_approval" for b in bottlenecks):
            recommendations.append("ğŸ‘¥ è³¢è€…é–“ã®è² è·åˆ†æ•£ã‚’æ¤œè¨")

        return AnalyticsResult(
            type=AnalyticsType.BOTTLENECK_DETECTION,
            timestamp=datetime.now(),
            metrics=metrics,
            insights=insights,
            predictions=predictions,
            recommendations=recommendations,
            confidence=0.85,
        )

    def _empty_result(self, analytics_type: AnalyticsType) -> AnalyticsResult:
        """ç©ºã®çµæœã‚’è¿”ã™"""
        return AnalyticsResult(
            type=analytics_type,
            timestamp=datetime.now(),
            metrics={},
            insights=["ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"],
            predictions={},
            recommendations=["ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿åé›†ãŒå¿…è¦ã§ã™"],
            confidence=0.0,
        )


class PredictiveAnalytics:
    """äºˆæ¸¬åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.models = {}

    async def train_models(self, commit_df: pd.DataFrame, sage_df: pd.DataFrame):
        """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        logger.info("ğŸ¤– äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´é–‹å§‹")

        # ã“ã“ã§ã¯ç°¡æ˜“çš„ãªçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        # å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯scikit-learnç­‰ã‚’ä½¿ç”¨

        if not commit_df.empty:
            # ã‚³ãƒŸãƒƒãƒˆé–“éš”äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
            commit_intervals = commit_df["timestamp"].diff().dropna()
            self.models["commit_interval"] = {
                "mean": commit_intervals.mean(),
                "std": commit_intervals.std(),
            }

            # ãƒ—ãƒ­ãƒˆã‚³ãƒ«é¸æŠäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
            protocol_dist = commit_df["protocol"].value_counts(normalize=True)
            self.models["protocol_selection"] = protocol_dist.to_dict()

        logger.info("âœ… äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´å®Œäº†")

    async def predict_next_commit(self) -> Dict[str, Any]:
        """æ¬¡å›ã‚³ãƒŸãƒƒãƒˆäºˆæ¸¬"""
        predictions = {}

        if "commit_interval" in self.models:
            model = self.models["commit_interval"]
            # æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ãŸäºˆæ¸¬
            next_interval = np.random.normal(
                model["mean"].total_seconds(), model["std"].total_seconds()
            )
            predictions["next_commit_in_seconds"] = max(0, next_interval)
            predictions["confidence"] = 0.7

        if "protocol_selection" in self.models:
            # ç¢ºç‡ã«åŸºã¥ããƒ—ãƒ­ãƒˆã‚³ãƒ«äºˆæ¸¬
            protocols = list(self.models["protocol_selection"].keys())
            probabilities = list(self.models["protocol_selection"].values())
            predictions["likely_protocol"] = np.random.choice(
                protocols, p=probabilities
            )

        return predictions


class AnalyticsReporter:
    """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""

    def __init__(self, project_root: Path):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.project_root = Path(project_root)
        self.reports_dir = self.project_root / "analytics_reports"
        self.reports_dir.mkdir(exist_ok=True)

    async def generate_comprehensive_report(
        self, results: List[AnalyticsResult]
    ) -> Path:
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timestamp = datetime.now()
        report = {
            "title": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ",
            "generated_at": timestamp.isoformat(),
            "summary": self._generate_summary(results),
            "detailed_results": [self._result_to_dict(r) for r in results],
            "executive_insights": self._generate_executive_insights(results),
            "action_items": self._generate_action_items(results),
        }

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_file = (
            self.reports_dir
            / f"analytics_report_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ“Š åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        return report_file

    def _generate_summary(self, results: List[AnalyticsResult]) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        return {
            "total_analyses": len(results),
            "average_confidence": np.mean([r.confidence for r in results]),
            "key_findings": sum(len(r.insights) for r in results),
            "recommendations": sum(len(r.recommendations) for r in results),
        }

    def _result_to_dict(self, result: AnalyticsResult) -> Dict[str, Any]:
        """çµæœã‚’è¾æ›¸ã«å¤‰æ›"""
        return {
            "type": result.type.value,
            "timestamp": result.timestamp.isoformat(),
            "metrics": result.metrics,
            "insights": result.insights,
            "predictions": result.predictions,
            "recommendations": result.recommendations,
            "confidence": result.confidence,
        }

    def _generate_executive_insights(self, results: List[AnalyticsResult]) -> List[str]:
        """ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å‘ã‘æ´å¯Ÿ"""
        insights = []

        # å„åˆ†æçµæœã‹ã‚‰é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡º
        for result in results:
            if result.confidence > 0.8 and result.insights:
                insights.extend(result.insights[:2])  # ä¸Šä½2ã¤ã®æ´å¯Ÿ

        return insights[:5]  # æœ€å¤§5ã¤

    def _generate_action_items(self, results: List[AnalyticsResult]) -> List[str]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ç”Ÿæˆ"""
        action_items = []

        # æ¨å¥¨äº‹é …ã‚’å„ªå…ˆåº¦ä»˜ã‘ã—ã¦é›†ç´„
        all_recommendations = []
        for result in results:
            for rec in result.recommendations:
                all_recommendations.append(
                    {
                        "recommendation": rec,
                        "confidence": result.confidence,
                        "type": result.type.value,
                    }
                )

        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        all_recommendations.sort(key=lambda x: x["confidence"], reverse=True)

        # ä¸Šä½ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸æŠ
        for item in all_recommendations[:5]:
            action_items.append(f"[{item['type']}] {item['recommendation']}")

        return action_items

    async def generate_html_report(self, results: List[AnalyticsResult]) -> Path:
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timestamp = datetime.now()

        # HTML ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ - {timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥')}</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap');

        * {{ margin: 0; padding: 0; box-sizing: border-box; }}

        body {{
            font-family: 'Orbitron', monospace;
            background: linear-gradient(135deg, #87CEEB 0%, #98FB98 50%, #FFB6C1 100%);
            color: #2F4F4F;
            line-height: 1.6;
            padding: 20px;
        }}

        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }}

        h1 {{
            background: linear-gradient(135deg, #4169E1, #00CED1);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 30px;
        }}

        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }}

        .metric-card {{
            background: linear-gradient(135deg, #f0f0f0, #e0e0e0);
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            transition: transform 0.3s;
        }}

        .metric-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }}

        .metric-value {{
            font-size: 2em;
            font-weight: bold;
            color: #4169E1;
        }}

        .analysis-section {{
            margin: 30px 0;
            padding: 20px;
            background: rgba(255,255,255,0.8);
            border-radius: 10px;
            border-left: 5px solid #4169E1;
        }}

        .insights-list {{
            list-style: none;
            padding: 10px 0;
        }}

        .insights-list li {{
            padding: 8px 0;
            border-bottom: 1px solid #eee;
        }}

        .recommendations {{
            background: #f0f8ff;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }}

        .chart-container {{
            margin: 20px 0;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }}

        .confidence-bar {{
            width: 100%;
            height: 20px;
            background: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }}

        .confidence-fill {{
            height: 100%;
            background: linear-gradient(90deg, #4169E1, #00CED1);
            transition: width 1s ease-in-out;
        }}

        @keyframes pulse {{
            0% {{ opacity: 1; }}
            50% {{ opacity: 0.7; }}
            100% {{ opacity: 1; }}
        }}

        .live-indicator {{
            display: inline-block;
            width: 10px;
            height: 10px;
            background: #32CD32;
            border-radius: 50%;
            animation: pulse 2s infinite;
            margin-right: 10px;
        }}
    </style>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="container">
        <h1>ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <p style="text-align: center; color: #666;">
            <span class="live-indicator"></span>
            ç”Ÿæˆæ—¥æ™‚: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
        </p>

        <div class="summary-grid">
            <div class="metric-card">
                <div class="metric-value">{len(results)}</div>
                <div>å®Ÿè¡Œæ¸ˆã¿åˆ†æ</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{sum(len(r.insights) for r in results)}</div>
                <div>æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿ</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{sum(len(r.recommendations) for r in results)}</div>
                <div>æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{np.mean([r.confidence for r in results]):0.1%}</div>
                <div>å¹³å‡ä¿¡é ¼åº¦</div>
            </div>
        </div>
"""

        # å„åˆ†æçµæœã‚’HTMLã«è¿½åŠ 
        for result in results:
            confidence_width = int(result.confidence * 100)
            html_content += f"""
        <div class="analysis-section">
            <h2>{result.type.value.replace('_', ' ').title()}</h2>
            <div class="confidence-bar">
                <div class="confidence-fill" style="width: {confidence_width}%"></div>
            </div>
            <p>ä¿¡é ¼åº¦: {result.confidence:0.1%}</p>

            <h3>ä¸»è¦ãªæ´å¯Ÿ</h3>
            <ul class="insights-list">
"""
            for insight in result.insights[:5]:
                html_content += f"                <li>{insight}</li>\n"

            html_content += """            </ul>

            <div class="recommendations">
                <h3>æ¨å¥¨äº‹é …</h3>
                <ul>
"""
            for rec in result.recommendations:
                html_content += f"                    <li>{rec}</li>\n"

            html_content += """                </ul>
            </div>
        </div>
"""

        # ãƒãƒ£ãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        html_content += (
            """
        <div class="chart-container">
            <h2>åˆ†æçµæœã‚µãƒãƒªãƒ¼</h2>
            <canvas id="confidenceChart" width="400" height="200"></canvas>
        </div>

        <script>
            // ä¿¡é ¼åº¦ãƒãƒ£ãƒ¼ãƒˆ
            const ctx = document.getElementById('confidenceChart').getContext('2d');
            const confidenceData = {
                labels: ["""
            + ", ".join([f'"{r.type.value}"' for r in results])
            + """],
                datasets: [{
                    label: 'ä¿¡é ¼åº¦',
                    data: ["""
            + ", ".join([str(r.confidence) for r in results])
            + """],
                    backgroundColor: 'rgba(65, 105, 225, 0.6)',
                    borderColor: 'rgba(65, 105, 225, 1)',
                    borderWidth: 2
                }]
            };

            new Chart(ctx, {
                type: 'bar',
                data: confidenceData,
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1
                        }
                    }
                }
            });
        </script>
    </div>
</body>
</html>"""
        )

        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        html_file = (
            self.reports_dir
            / f"analytics_report_{timestamp.strftime('%Y%m%d_%H%M%S')}.html"
        )
        with open(html_file, "w", encoding="utf-8") as f:
            f.write(html_content)

        logger.info(f"ğŸ“Š ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {html_file}")
        return html_file

    async def generate_api_response(
        self, results: List[AnalyticsResult]
    ) -> Dict[str, Any]:
        """APIç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return {
            "timestamp": datetime.now().isoformat(),
            "summary": self._generate_summary(results),
            "results": [self._result_to_dict(r) for r in results],
            "executive_insights": self._generate_executive_insights(results),
            "action_items": self._generate_action_items(results),
            "visualizations": {
                "confidence_scores": {r.type.value: r.confidence for r in results},
                "insights_count": {r.type.value: len(r.insights) for r in results},
                "recommendations_count": {
                    r.type.value: len(r.recommendations) for r in results
                },
            },
        }


class DataAnalyticsPlatform:
    """é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, project_root: Path):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.project_root = Path(project_root)
        self.collector = DataCollector(self.project_root)
        self.analytics = AnalyticsEngine()
        self.predictive = PredictiveAnalytics()
        self.reporter = AnalyticsReporter(self.project_root)

        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆæœŸåŒ–å®Œäº†")

    async def run_full_analysis(self) -> Path:
        """å®Œå…¨åˆ†æå®Ÿè¡Œ"""
        logger.info("ğŸš€ å®Œå…¨åˆ†æé–‹å§‹")

        try:
            # ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚§ãƒ¼ã‚º
            logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚§ãƒ¼ã‚º")
            commit_df = await self.collector.collect_commit_data()
            sage_df = await self.collector.collect_sage_consultation_data()
            system_metrics = await self.collector.collect_system_metrics()

            # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            await self.predictive.train_models(commit_df, sage_df)

            # åˆ†æå®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º
            logger.info("ğŸ” åˆ†æå®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º")
            results = []

            # ã‚³ãƒŸãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            commit_analysis = await self.analytics.analyze_commit_patterns(commit_df)
            results.append(commit_analysis)

            # 4è³¢è€…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            sage_analysis = await self.analytics.analyze_sage_performance(sage_df)
            results.append(sage_analysis)

            # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹äºˆæ¸¬
            health_prediction = await self.analytics.predict_system_health(
                commit_df, system_metrics
            )
            results.append(health_prediction)

            # ãƒ—ãƒ­ãƒˆã‚³ãƒ«åŠ¹ç‡åˆ†æ
            protocol_efficiency = await self.analytics.analyze_protocol_efficiency(
                commit_df
            )
            results.append(protocol_efficiency)

            # ã‚¨ãƒ©ãƒ¼äºˆæ¸¬
            error_prediction = await self.analytics.predict_errors(
                commit_df, system_metrics
            )
            results.append(error_prediction)

            # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º
            bottleneck_detection = await self.analytics.detect_bottlenecks(
                commit_df, sage_df
            )
            results.append(bottleneck_detection)

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
            logger.info("ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º")
            json_report_path = await self.reporter.generate_comprehensive_report(
                results
            )
            html_report_path = await self.reporter.generate_html_report(results)

            logger.info("âœ… å®Œå…¨åˆ†æå®Œäº†")
            return {
                "json_report": json_report_path,
                "html_report": html_report_path,
                "api_data": await self.reporter.generate_api_response(results),
            }

        except Exception as e:
            logger.error(f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
async def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    platform = DataAnalyticsPlatform(Path("/home/aicompany/ai_co"))
    results = await platform.run_full_analysis()
    print(f"ğŸ“Š åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†:")
    print(f"  - JSONãƒ¬ãƒãƒ¼ãƒˆ: {results['json_report']}")
    print(f"  - HTMLãƒ¬ãƒãƒ¼ãƒˆ: {results['html_report']}")
    print(f"  - API ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨å¯èƒ½")


if __name__ == "__main__":
    asyncio.run(main())
