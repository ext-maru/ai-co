#!/usr/bin/env python3
"""
Elder Council Proactive Guidance System - ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šäº‹å‰æŒ‡æ‘˜ãƒ»äºˆé˜²å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ 
äº‹å‰ã«å•é¡Œã‚’äºˆæ¸¬ã—ã€æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹å…ˆåˆ¶çš„è©•è­°ä¼šã‚·ã‚¹ãƒ†ãƒ 

ğŸ”® ä¸»è¦æ©Ÿèƒ½:
- äºˆæ¸¬åˆ†æã«ã‚ˆã‚‹å•é¡Œã®äº‹å‰ç™ºè¦‹
- æˆ¦ç•¥çš„æ”¹å–„ææ¡ˆã®è‡ªå‹•ç”Ÿæˆ
- ç¶™ç¶šçš„å­¦ç¿’ã«ã‚ˆã‚‹æŒ‡æ‘˜ç²¾åº¦å‘ä¸Š
- é–‹ç™ºãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«çµ±åˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
- 4è³¢è€…é€£æºã«ã‚ˆã‚‹åŒ…æ‹¬çš„æ´å¯Ÿ

ğŸ¯ äºˆé˜²ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:
1. ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‚¾å‘åˆ†æ â†’ å•é¡Œäºˆæ¸¬
2. ğŸ§  ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ â†’ æ”¹å–„æ©Ÿä¼šç™ºè¦‹
3. ğŸ’¡ æˆ¦ç•¥çš„ææ¡ˆ â†’ å…ˆåˆ¶çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
4. ğŸ”„ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å­¦ç¿’ â†’ ç²¾åº¦å‘ä¸Š
"""

import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from collections import defaultdict, deque
import numpy as np

# AI Company 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
try:
    from libs.four_sages_integration import FourSagesOrchestrator, SageConsultationType
    from libs.elder_council_summoner import ElderCouncilSummoner, TriggerCategory
    from libs.elder_council_auto_decision import ElderCouncilAutoDecision
except ImportError:
    # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®ä»£æ›¿å®Ÿè£…
    class FourSagesOrchestrator:
        async def consult_all_sages(self, topic, context): 
            return {"knowledge": {}, "task": {}, "incident": {}, "rag": {}}
    class ElderCouncilSummoner:
        def __init__(self): pass
    class ElderCouncilAutoDecision:
        def __init__(self): pass
    class SageConsultationType:
        STRATEGIC_PLANNING = "strategic_planning"
    class TriggerCategory:
        CRITICAL = "critical"

logger = logging.getLogger(__name__)

class ProactiveGuidanceType(Enum):
    """å…ˆåˆ¶çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—"""
    STRATEGIC_GUIDANCE = "strategic_guidance"         # æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
    PREVENTIVE_ACTION = "preventive_action"           # äºˆé˜²çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    IMPROVEMENT_OPPORTUNITY = "improvement_opportunity"  # æ”¹å–„æ©Ÿä¼š
    EVOLUTION_PLANNING = "evolution_planning"          # é€²åŒ–è¨ˆç”»
    QUALITY_ENHANCEMENT = "quality_enhancement"       # å“è³ªå‘ä¸Š
    PERFORMANCE_OPTIMIZATION = "performance_optimization"  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    DEVELOPMENT_GUIDANCE = "development_guidance"     # é–‹ç™ºã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

class UrgencyLevel(Enum):
    """ç·Šæ€¥åº¦ãƒ¬ãƒ™ãƒ«"""
    IMMEDIATE = "immediate"      # å³åº§ã«å¯¾å¿œã™ã¹ã
    HIGH = "high"               # é«˜å„ªå…ˆåº¦
    MEDIUM = "medium"           # ä¸­å„ªå…ˆåº¦  
    LOW = "low"                # ä½å„ªå…ˆåº¦
    STRATEGIC = "strategic"     # æˆ¦ç•¥çš„ï¼ˆé•·æœŸè¦–ç‚¹ï¼‰

@dataclass
class ProactiveInsight:
    """å…ˆåˆ¶çš„æ´å¯Ÿ"""
    insight_id: str
    guidance_type: ProactiveGuidanceType
    urgency: UrgencyLevel
    title: str
    description: str
    
    # åˆ†æãƒ‡ãƒ¼ã‚¿
    detected_patterns: List[str]
    predicted_impact: float        # 0-1: äºˆæƒ³å½±éŸ¿åº¦
    confidence_score: float        # 0-1: äºˆæ¸¬ä¿¡é ¼åº¦
    time_to_action: timedelta     # å¯¾å¿œæ¨å¥¨æœŸé™
    
    # ææ¡ˆå†…å®¹
    recommended_actions: List[str]
    expected_benefits: List[str]
    resource_requirements: Dict[str, Any]
    implementation_steps: List[str]
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    detected_at: datetime
    source_metrics: List[str]
    sage_consultations: Dict[str, Any]
    learning_context: Dict[str, Any]

@dataclass
class PredictiveMetrics:
    """äºˆæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    metric_name: str
    current_value: float
    predicted_value: float
    prediction_timeframe: timedelta
    confidence: float
    trend_direction: str  # 'increasing', 'decreasing', 'stable'
    anomaly_score: float

class ProactiveTrendAnalyzer:
    """å…ˆåˆ¶çš„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå™¨"""
    
    def __init__(self):
        self.metric_history = defaultdict(deque)
        self.pattern_library = {}
        self.prediction_models = {}
        
    def add_metric_data(self, metric_name: str, value: float, timestamp: datetime):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿è¿½åŠ """
        self.metric_history[metric_name].append({
            'value': value,
            'timestamp': timestamp
        })
        
        # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(self.metric_history[metric_name]) > 100:
            self.metric_history[metric_name].popleft()
    
    def analyze_trends(self, lookback_hours: int = 24) -> List[PredictiveMetrics]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ã‚ˆã‚‹äºˆæ¸¬"""
        predictions = []
        cutoff_time = datetime.now() - timedelta(hours=lookback_hours)
        
        for metric_name, history in self.metric_history.items():
            recent_data = [
                entry for entry in history 
                if entry['timestamp'] > cutoff_time
            ]
            
            if len(recent_data) < 5:  # æœ€ä½5ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆå¿…è¦
                continue
                
            prediction = self._predict_metric_future(metric_name, recent_data)
            if prediction:
                predictions.append(prediction)
        
        return predictions
    
    def _predict_metric_future(self, metric_name: str, data: List[Dict]) -> Optional[PredictiveMetrics]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æœªæ¥äºˆæ¸¬"""
        values = [entry['value'] for entry in data]
        timestamps = [entry['timestamp'] for entry in data]
        
        if len(values) < 5:
            return None
        
        # ç°¡å˜ãªç·šå½¢å›å¸°ã«ã‚ˆã‚‹äºˆæ¸¬
        current_value = values[-1]
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        recent_values = values[-5:]
        trend_slope = (recent_values[-1] - recent_values[0]) / len(recent_values)
        
        # æœªæ¥äºˆæ¸¬ï¼ˆ1æ™‚é–“å¾Œï¼‰
        prediction_timeframe = timedelta(hours=1)
        predicted_value = current_value + trend_slope * 5  # 5ã‚¹ãƒ†ãƒƒãƒ—å…ˆ
        
        # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆå¤‰å‹•ã®é€†æ•°ï¼‰
        variance = np.var(recent_values) if len(recent_values) > 1 else 0
        confidence = 1.0 / (1.0 + variance) if variance > 0 else 0.9
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
        if abs(trend_slope) < 0.01:
            trend_direction = 'stable'
        elif trend_slope > 0:
            trend_direction = 'increasing'
        else:
            trend_direction = 'decreasing'
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢
        mean_value = np.mean(values)
        anomaly_score = abs(current_value - mean_value) / (np.std(values) + 0.001)
        
        return PredictiveMetrics(
            metric_name=metric_name,
            current_value=current_value,
            predicted_value=predicted_value,
            prediction_timeframe=prediction_timeframe,
            confidence=confidence,
            trend_direction=trend_direction,
            anomaly_score=anomaly_score
        )
    
    def detect_pattern_anomalies(self) -> List[Dict[str, Any]]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ç•°å¸¸æ¤œçŸ¥"""
        anomalies = []
        
        for metric_name, history in self.metric_history.items():
            if len(history) < 10:
                continue
                
            values = [entry['value'] for entry in history]
            
            # ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢æ¤œçŸ¥
            if len(values) >= 10:
                recent_avg = np.mean(values[-5:])
                historical_avg = np.mean(values[-20:-5]) if len(values) >= 20 else np.mean(values[:-5])
                
                deviation_ratio = abs(recent_avg - historical_avg) / (historical_avg + 0.001)
                
                if deviation_ratio > 0.3:  # 30%ä»¥ä¸Šã®ä¹–é›¢
                    anomalies.append({
                        'metric': metric_name,
                        'type': 'deviation_anomaly',
                        'severity': 'high' if deviation_ratio > 0.5 else 'medium',
                        'deviation_ratio': deviation_ratio,
                        'recent_avg': recent_avg,
                        'historical_avg': historical_avg
                    })
        
        return anomalies

class ProactiveOpportunityDetector:
    """å…ˆåˆ¶çš„æ©Ÿä¼šæ¤œå‡ºå™¨"""
    
    def __init__(self):
        self.opportunity_rules = self._load_opportunity_rules()
        self.success_patterns = {}
        
    def _load_opportunity_rules(self) -> Dict[str, Any]:
        """æ©Ÿä¼šæ¤œå‡ºãƒ«ãƒ¼ãƒ«å®šç¾©"""
        return {
            'performance_optimization': {
                'triggers': ['response_time_increase', 'memory_usage_growth'],
                'confidence_threshold': 0.7,
                'impact_potential': 0.8
            },
            'code_quality_improvement': {
                'triggers': ['error_rate_increase', 'complexity_growth'],
                'confidence_threshold': 0.6,
                'impact_potential': 0.7
            },
            'feature_enhancement': {
                'triggers': ['user_engagement_patterns', 'feature_usage_trends'],
                'confidence_threshold': 0.5,
                'impact_potential': 0.9
            },
            'infrastructure_scaling': {
                'triggers': ['resource_utilization_trends', 'capacity_approaching_limits'],
                'confidence_threshold': 0.8,
                'impact_potential': 0.8
            }
        }
    
    def detect_improvement_opportunities(self, system_metrics: Dict[str, Any], 
                                       trend_analysis: List[PredictiveMetrics]) -> List[Dict[str, Any]]:
        """æ”¹å–„æ©Ÿä¼šæ¤œå‡º"""
        opportunities = []
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ©Ÿä¼š
        perf_opportunities = self._detect_performance_opportunities(trend_analysis)
        opportunities.extend(perf_opportunities)
        
        # å“è³ªå‘ä¸Šæ©Ÿä¼š
        quality_opportunities = self._detect_quality_opportunities(system_metrics)
        opportunities.extend(quality_opportunities)
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ©Ÿä¼š
        scaling_opportunities = self._detect_scaling_opportunities(trend_analysis)
        opportunities.extend(scaling_opportunities)
        
        return opportunities
    
    def _detect_performance_opportunities(self, trends: List[PredictiveMetrics]) -> List[Dict[str, Any]]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ©Ÿä¼šæ¤œå‡º"""
        opportunities = []
        
        for trend in trends:
            if 'response_time' in trend.metric_name.lower():
                if (trend.trend_direction == 'increasing' and 
                    trend.predicted_value > trend.current_value * 1.2):
                    
                    opportunities.append({
                        'type': 'performance_optimization',
                        'title': 'Response Time Optimization Opportunity',
                        'description': f'{trend.metric_name}ãŒå¢—åŠ å‚¾å‘ã€‚æœ€é©åŒ–ã«ã‚ˆã‚Š{(trend.predicted_value - trend.current_value):.1f}msæ”¹å–„å¯èƒ½',
                        'predicted_impact': 0.8,
                        'confidence': trend.confidence,
                        'recommended_actions': [
                            'ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥è¦‹ç›´ã—',
                            'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæœ€é©åŒ–',
                            'éåŒæœŸå‡¦ç†å°å…¥æ¤œè¨'
                        ]
                    })
            
            elif 'memory' in trend.metric_name.lower():
                if (trend.trend_direction == 'increasing' and 
                    trend.anomaly_score > 2.0):
                    
                    opportunities.append({
                        'type': 'memory_optimization',
                        'title': 'Memory Usage Optimization',
                        'description': f'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã€‚ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯èƒ½æ€§ã‚ã‚Š',
                        'predicted_impact': 0.7,
                        'confidence': trend.confidence,
                        'recommended_actions': [
                            'ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ',
                            'ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœ€é©åŒ–',
                            'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¦‹ç›´ã—'
                        ]
                    })
        
        return opportunities
    
    def _detect_quality_opportunities(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å“è³ªå‘ä¸Šæ©Ÿä¼šæ¤œå‡º"""
        opportunities = []
        
        error_rate = metrics.get('error_rate', 0)
        test_coverage = metrics.get('test_coverage', 100)
        code_complexity = metrics.get('code_complexity', 1)
        
        if error_rate > 0.05:  # 5%ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ç‡
            opportunities.append({
                'type': 'error_reduction',
                'title': 'Error Rate Reduction Opportunity',
                'description': f'ã‚¨ãƒ©ãƒ¼ç‡{error_rate*100:.1f}%ã€‚å“è³ªå‘ä¸Šã«ã‚ˆã‚Šå¤§å¹…æ”¹å–„å¯èƒ½',
                'predicted_impact': 0.9,
                'confidence': 0.8,
                'recommended_actions': [
                    'ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ',
                    'å…¥åŠ›æ¤œè¨¼å¼·åŒ–',
                    'ä¾‹å¤–å‡¦ç†æ”¹å–„',
                    'ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ‹¡å……'
                ]
            })
        
        if test_coverage < 80:  # 80%æœªæº€ã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
            opportunities.append({
                'type': 'test_coverage_improvement',
                'title': 'Test Coverage Enhancement',
                'description': f'ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸{test_coverage}%ã€‚è¿½åŠ ãƒ†ã‚¹ãƒˆã§å“è³ªå‘ä¸Š',
                'predicted_impact': 0.7,
                'confidence': 0.9,
                'recommended_actions': [
                    'ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æå®Ÿè¡Œ',
                    'é‡è¦ãƒ‘ã‚¹ç‰¹å®š',
                    'ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè¿½åŠ ',
                    'çµ±åˆãƒ†ã‚¹ãƒˆå¼·åŒ–'
                ]
            })
        
        return opportunities
    
    def _detect_scaling_opportunities(self, trends: List[PredictiveMetrics]) -> List[Dict[str, Any]]:
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ©Ÿä¼šæ¤œå‡º"""
        opportunities = []
        
        for trend in trends:
            if 'cpu' in trend.metric_name.lower() or 'load' in trend.metric_name.lower():
                if (trend.current_value > 0.8 and 
                    trend.trend_direction == 'increasing'):
                    
                    opportunities.append({
                        'type': 'horizontal_scaling',
                        'title': 'Horizontal Scaling Opportunity',
                        'description': f'CPUä½¿ç”¨ç‡é«˜æ°´æº–ã€‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹è² è·åˆ†æ•£æ¨å¥¨',
                        'predicted_impact': 0.8,
                        'confidence': trend.confidence,
                        'recommended_actions': [
                            'ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°å¢—åŠ æ¤œè¨',
                            'ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼è¨­å®š',
                            'ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–å¼·åŒ–'
                        ]
                    })
        
        return opportunities

class ProactiveGuidanceEngine:
    """å…ˆåˆ¶çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.trend_analyzer = ProactiveTrendAnalyzer()
        self.opportunity_detector = ProactiveOpportunityDetector()
        self.four_sages = FourSagesOrchestrator()
        self.guidance_history = deque(maxlen=1000)
        self.effectiveness_tracker = {}
        
    async def generate_proactive_insights(self, system_context: Dict[str, Any]) -> List[ProactiveInsight]:
        """å…ˆåˆ¶çš„æ´å¯Ÿç”Ÿæˆ"""
        insights = []
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trend_predictions = self.trend_analyzer.analyze_trends()
        
        # æ©Ÿä¼šæ¤œå‡º
        opportunities = self.opportunity_detector.detect_improvement_opportunities(
            system_context.get('metrics', {}),
            trend_predictions
        )
        
        # 4è³¢è€…ç›¸è«‡çµ±åˆ
        for opportunity in opportunities:
            insight = await self._create_insight_with_sages(opportunity, system_context)
            if insight:
                insights.append(insight)
        
        # äºˆé˜²çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è­˜åˆ¥
        preventive_actions = await self._identify_preventive_actions(trend_predictions)
        insights.extend(preventive_actions)
        
        # æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ
        strategic_guidance = await self._generate_strategic_guidance(system_context)
        insights.extend(strategic_guidance)
        
        return insights
    
    async def _create_insight_with_sages(self, opportunity: Dict[str, Any], 
                                       context: Dict[str, Any]) -> Optional[ProactiveInsight]:
        """4è³¢è€…ç›¸è«‡çµ±åˆæ´å¯Ÿä½œæˆ"""
        try:
            # 4è³¢è€…ã«ç›¸è«‡
            sage_consultation = await self.four_sages.consult_all_sages(
                topic=opportunity['title'],
                context={
                    'opportunity': opportunity,
                    'system_context': context,
                    'consultation_type': SageConsultationType.STRATEGIC_PLANNING
                }
            )
            
            # æ´å¯Ÿä½œæˆ
            insight = ProactiveInsight(
                insight_id=f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{len(self.guidance_history)}",
                guidance_type=ProactiveGuidanceType.IMPROVEMENT_OPPORTUNITY,
                urgency=self._determine_urgency(opportunity),
                title=opportunity['title'],
                description=opportunity['description'],
                
                # åˆ†æãƒ‡ãƒ¼ã‚¿
                detected_patterns=[opportunity['type']],
                predicted_impact=opportunity['predicted_impact'],
                confidence_score=opportunity['confidence'],
                time_to_action=timedelta(days=7),  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1é€±é–“
                
                # ææ¡ˆå†…å®¹
                recommended_actions=opportunity['recommended_actions'],
                expected_benefits=[
                    f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š: {opportunity['predicted_impact']*100:.0f}%",
                    "ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§å‘ä¸Š",
                    "é‹ç”¨åŠ¹ç‡æ”¹å–„"
                ],
                resource_requirements={'time': '2-5æ—¥', 'complexity': 'ä¸­'},
                implementation_steps=self._generate_implementation_steps(opportunity),
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                detected_at=datetime.now(),
                source_metrics=[],
                sage_consultations=sage_consultation,
                learning_context={'source': 'opportunity_detector'}
            )
            
            return insight
            
        except Exception as e:
            logger.error(f"æ´å¯Ÿä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _determine_urgency(self, opportunity: Dict[str, Any]) -> UrgencyLevel:
        """ç·Šæ€¥åº¦åˆ¤å®š"""
        impact = opportunity.get('predicted_impact', 0)
        confidence = opportunity.get('confidence', 0)
        
        urgency_score = impact * confidence
        
        if urgency_score > 0.8:
            return UrgencyLevel.HIGH
        elif urgency_score > 0.6:
            return UrgencyLevel.MEDIUM
        elif urgency_score > 0.3:
            return UrgencyLevel.LOW
        else:
            return UrgencyLevel.STRATEGIC
    
    def _generate_implementation_steps(self, opportunity: Dict[str, Any]) -> List[str]:
        """å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆ"""
        base_steps = [
            "1. ç¾çŠ¶åˆ†æã¨è©³ç´°èª¿æŸ»",
            "2. å®Ÿè£…è¨ˆç”»ç­–å®š",
            "3. ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®æ¤œè¨¼",
            "4. æ®µéšçš„æœ¬ç•ªç’°å¢ƒé©ç”¨",
            "5. åŠ¹æœæ¸¬å®šã¨æœ€é©åŒ–"
        ]
        
        # æ©Ÿä¼šã‚¿ã‚¤ãƒ—åˆ¥ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
        if opportunity['type'] == 'performance_optimization':
            base_steps.insert(1, "1.5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å–å¾—")
        elif opportunity['type'] == 'test_coverage_improvement':
            base_steps.insert(2, "2.5. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¨­è¨ˆã¨å®Ÿè£…")
        
        return base_steps
    
    async def _identify_preventive_actions(self, predictions: List[PredictiveMetrics]) -> List[ProactiveInsight]:
        """äºˆé˜²çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è­˜åˆ¥"""
        preventive_insights = []
        
        for prediction in predictions:
            if prediction.confidence > 0.7 and prediction.anomaly_score > 1.5:
                insight = ProactiveInsight(
                    insight_id=f"preventive_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{prediction.metric_name}",
                    guidance_type=ProactiveGuidanceType.PREVENTIVE_ACTION,
                    urgency=UrgencyLevel.HIGH if prediction.anomaly_score > 2.5 else UrgencyLevel.MEDIUM,
                    title=f"Preventive Action Required: {prediction.metric_name}",
                    description=f"{prediction.metric_name}ã§ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã€‚äºˆé˜²çš„å¯¾å¿œãŒå¿…è¦",
                    
                    detected_patterns=[f"anomaly_score_{prediction.anomaly_score:.2f}"],
                    predicted_impact=0.7,
                    confidence_score=prediction.confidence,
                    time_to_action=timedelta(hours=24),
                    
                    recommended_actions=[
                        f"{prediction.metric_name}ã®è©³ç´°èª¿æŸ»",
                        "é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª",
                        "äºˆé˜²ä¿å®ˆã®å®Ÿè¡Œ"
                    ],
                    expected_benefits=["ã‚·ã‚¹ãƒ†ãƒ éšœå®³ã®äºˆé˜²", "å®‰å®šæ€§å‘ä¸Š"],
                    resource_requirements={'time': 'åŠæ—¥', 'complexity': 'ä½'},
                    implementation_steps=[
                        "1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°åˆ†æ",
                        "2. æ ¹æœ¬åŸå› ç‰¹å®š",
                        "3. äºˆé˜²ç­–å®Ÿè£…",
                        "4. ç›£è¦–å¼·åŒ–"
                    ],
                    
                    detected_at=datetime.now(),
                    source_metrics=[prediction.metric_name],
                    sage_consultations={},
                    learning_context={'prediction_data': asdict(prediction)}
                )
                
                preventive_insights.append(insight)
        
        return preventive_insights
    
    async def _generate_strategic_guidance(self, context: Dict[str, Any]) -> List[ProactiveInsight]:
        """æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ"""
        strategic_insights = []
        
        # é€±æ¬¡æˆ¦ç•¥ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
        if datetime.now().weekday() == 0:  # æœˆæ›œæ—¥
            weekly_guidance = ProactiveInsight(
                insight_id=f"weekly_strategic_{datetime.now().strftime('%Y%m%d')}",
                guidance_type=ProactiveGuidanceType.STRATEGIC_GUIDANCE,
                urgency=UrgencyLevel.STRATEGIC,
                title="Weekly Strategic Development Guidance",
                description="ä»Šé€±ã®é–‹ç™ºæˆ¦ç•¥ã¨å„ªå…ˆäº‹é …ã®ææ¡ˆ",
                
                detected_patterns=["weekly_cycle"],
                predicted_impact=0.6,
                confidence_score=0.8,
                time_to_action=timedelta(days=7),
                
                recommended_actions=[
                    "å„ªå…ˆæ©Ÿèƒ½ã®é–‹ç™ºãƒ•ã‚©ãƒ¼ã‚«ã‚¹",
                    "ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ‡ãƒ—ãƒˆè§£æ¶ˆ",
                    "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç¶™ç¶š"
                ],
                expected_benefits=[
                    "é–‹ç™ºåŠ¹ç‡å‘ä¸Š",
                    "ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„",
                    "ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§å¼·åŒ–"
                ],
                resource_requirements={'time': 'ç¶™ç¶šçš„', 'complexity': 'ä¸­'},
                implementation_steps=[
                    "1. é€±æ¬¡ç›®æ¨™è¨­å®š",
                    "2. ã‚¿ã‚¹ã‚¯å„ªå…ˆé †ä½ä»˜ã‘",
                    "3. æ—¥æ¬¡é€²æ—ç¢ºèª",
                    "4. é€±æœ«æŒ¯ã‚Šè¿”ã‚Š"
                ],
                
                detected_at=datetime.now(),
                source_metrics=["weekly_cycle"],
                sage_consultations={},
                learning_context={'guidance_type': 'weekly_strategic'}
            )
            
            strategic_insights.append(weekly_guidance)
        
        return strategic_insights
    
    def track_guidance_effectiveness(self, insight_id: str, outcome: str, metrics_change: Dict[str, float]):
        """ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹åŠ¹æœè¿½è·¡"""
        self.effectiveness_tracker[insight_id] = {
            'outcome': outcome,
            'metrics_change': metrics_change,
            'tracked_at': datetime.now()
        }
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨
        self._update_prediction_models(insight_id, outcome, metrics_change)
    
    def _update_prediction_models(self, insight_id: str, outcome: str, metrics: Dict[str, float]):
        """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ›´æ–°"""
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
        if outcome == 'successful':
            logger.info(f"æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’: {insight_id}")
            # å°†æ¥çš„ã«ã¯MLãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        elif outcome == 'failed':
            logger.warning(f"å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’: {insight_id}")
            # äºˆæ¸¬ç²¾åº¦æ”¹å–„ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åé›†

class ElderCouncilProactiveSystem:
    """ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šå…ˆåˆ¶çš„ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ"""
    
    def __init__(self):
        self.guidance_engine = ProactiveGuidanceEngine()
        self.elder_council_summoner = ElderCouncilSummoner()
        self.active_insights = {}
        self.scheduling_enabled = True
        
    async def start_proactive_monitoring(self):
        """å…ˆåˆ¶çš„ç›£è¦–é–‹å§‹"""
        logger.info("ğŸ”® Elder Council Proactive System é–‹å§‹")
        
        while self.scheduling_enabled:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†
                system_context = await self._collect_system_context()
                
                # å…ˆåˆ¶çš„æ´å¯Ÿç”Ÿæˆ
                insights = await self.guidance_engine.generate_proactive_insights(system_context)
                
                # æ´å¯Ÿã®å‡¦ç†ã¨ä¿å­˜
                for insight in insights:
                    await self._process_insight(insight)
                
                # 1æ™‚é–“æ¯ã®ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«
                await asyncio.sleep(3600)
                
            except Exception as e:
                logger.error(f"å…ˆåˆ¶çš„ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(300)  # 5åˆ†å¾Œã«ãƒªãƒˆãƒ©ã‚¤
    
    async def _collect_system_context(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†"""
        context = {
            'timestamp': datetime.now(),
            'metrics': {
                'error_rate': 0.02,
                'response_time': 150,
                'memory_usage': 0.65,
                'cpu_usage': 0.45,
                'test_coverage': 85,
                'code_complexity': 2.3
            },
            'active_processes': [],
            'recent_deployments': [],
            'user_feedback': []
        }
        
        return context
    
    async def _process_insight(self, insight: ProactiveInsight):
        """æ´å¯Ÿå‡¦ç†"""
        self.active_insights[insight.insight_id] = insight
        
        # é«˜ç·Šæ€¥åº¦ã®å ´åˆã¯ElderCouncilå¬é›†
        if insight.urgency in [UrgencyLevel.IMMEDIATE, UrgencyLevel.HIGH]:
            await self._trigger_elder_council_consultation(insight)
        
        # ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹è¨˜éŒ²
        await self._record_guidance(insight)
        
    async def _trigger_elder_council_consultation(self, insight: ProactiveInsight):
        """ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šç›¸è«‡å¬é›†"""
        logger.info(f"ğŸ›ï¸ ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šç·Šæ€¥ç›¸è«‡å¬é›†: {insight.title}")
        
        consultation_context = {
            'proactive_insight': asdict(insight),
            'trigger_type': 'proactive_guidance',
            'urgency_level': insight.urgency.value,
            'recommended_actions': insight.recommended_actions
        }
        
        # ElderCouncilSummonerçµŒç”±ã§ç›¸è«‡è¦è«‹
        # self.elder_council_summoner.trigger_emergency_consultation(consultation_context)
        
    async def _record_guidance(self, insight: ProactiveInsight):
        """ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹è¨˜éŒ²"""
        guidance_record = {
            'insight_id': insight.insight_id,
            'guidance_type': insight.guidance_type.value,
            'urgency': insight.urgency.value,
            'title': insight.title,
            'timestamp': insight.detected_at,
            'recommendations': insight.recommended_actions,
            'predicted_impact': insight.predicted_impact
        }
        
        # knowledge_base/elder_council_requests/ ã«ä¿å­˜
        guidance_file = PROJECT_ROOT / "knowledge_base" / "elder_council_requests" / f"proactive_guidance_{insight.insight_id}.md"
        guidance_file.parent.mkdir(parents=True, exist_ok=True)
        
        guidance_content = f"""# Proactive Guidance: {insight.title}

## ğŸ”® äº‹å‰æŒ‡æ‘˜æƒ…å ±
- **Insight ID**: {insight.insight_id}
- **ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—**: {insight.guidance_type.value}
- **ç·Šæ€¥åº¦**: {insight.urgency.value}
- **æ¤œå‡ºæ—¥æ™‚**: {insight.detected_at}
- **äºˆæ¸¬å½±éŸ¿åº¦**: {insight.predicted_impact:.2f}
- **ä¿¡é ¼åº¦**: {insight.confidence_score:.2f}

## ğŸ“Š åˆ†æçµæœ
{insight.description}

### æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
{chr(10).join(f'- {pattern}' for pattern in insight.detected_patterns)}

## ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
{chr(10).join(f'{i+1}. {action}' for i, action in enumerate(insight.recommended_actions))}

## ğŸ¯ æœŸå¾…åŠ¹æœ
{chr(10).join(f'- {benefit}' for benefit in insight.expected_benefits)}

## ğŸ› ï¸ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—
{chr(10).join(insight.implementation_steps)}

## ğŸ“‹ ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶
- **æ™‚é–“**: {insight.resource_requirements.get('time', 'TBD')}
- **è¤‡é›‘åº¦**: {insight.resource_requirements.get('complexity', 'TBD')}

## ğŸ§  4è³¢è€…ç›¸è«‡çµæœ
{json.dumps(insight.sage_consultations, indent=2, ensure_ascii=False)}

---
Generated by Elder Council Proactive System at {datetime.now()}
"""
        
        guidance_file.write_text(guidance_content, encoding='utf-8')
        logger.info(f"ğŸ“ å…ˆåˆ¶çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹è¨˜éŒ²: {guidance_file}")

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    proactive_system = ElderCouncilProactiveSystem()
    
    logger.info("ğŸš€ Elder Council Proactive System èµ·å‹•")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®æ´å¯Ÿç”Ÿæˆ
    test_context = {
        'metrics': {
            'error_rate': 0.03,
            'response_time': 200,
            'memory_usage': 0.75,
            'test_coverage': 75
        }
    }
    
    insights = await proactive_system.guidance_engine.generate_proactive_insights(test_context)
    
    for insight in insights:
        logger.info(f"ğŸ’¡ æ´å¯Ÿç”Ÿæˆ: {insight.title} (ç·Šæ€¥åº¦: {insight.urgency.value})")
        await proactive_system._process_insight(insight)

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())