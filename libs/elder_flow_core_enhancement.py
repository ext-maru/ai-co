#!/usr/bin/env python3
"""
Elder Flow Core Enhancement
„Ç®„É´„ÉÄ„Éº„Éï„É≠„Éº„Ç≥„Ç¢Âº∑Âåñ„Ç∑„Çπ„ÉÜ„É† - Ë®òÈå≤„ÉªÁõ£Ë¶ñ„ÉªÂìÅË≥™‰øùË®º„ÅÆÁµ±Âêà

„Ç®„É´„ÉÄ„Éº„Ç∫„ÇÆ„É´„ÉâË©ïË≠∞‰ºöÊâøË™ç - 2025Âπ¥7Êúà11Êó•
"""

import asyncio
import json
import logging
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib
import subprocess


class FlowPhase(Enum):
    """Elder Flow„Éï„Çß„Éº„Ç∫"""

    SAGE_CONSULTATION = "sage_consultation"  # 4Ë≥¢ËÄÖÁõ∏Ë´á
    SERVANT_EXECUTION = "servant_execution"  # „Çµ„Éº„Éê„É≥„ÉàÂÆüË°å
    QUALITY_GATE = "quality_gate"  # ÂìÅË≥™„Ç≤„Éº„Éà
    COUNCIL_REPORT = "council_report"  # Ë©ïË≠∞‰ºöÂ†±Âëä
    GIT_AUTOMATION = "git_automation"  # GitËá™ÂãïÂåñ


class FlowStatus(Enum):
    """„Éï„É≠„ÉºÁä∂ÊÖã"""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class FlowExecution:
    """„Éï„É≠„ÉºÂÆüË°åË®òÈå≤"""

    execution_id: str
    task_name: str
    priority: str
    phase: FlowPhase
    status: FlowStatus
    start_time: datetime
    end_time: Optional[datetime]
    duration_seconds: Optional[float]
    quality_score: Optional[float]
    violations_found: int
    violations_fixed: int
    sage_recommendations: List[Dict[str, Any]]
    servant_results: List[Dict[str, Any]]
    git_commits: List[str]
    error_log: List[str]
    metadata: Dict[str, Any]


class ElderFlowCoreEnhancement:
    """Elder Flow„Ç≥„Ç¢Âº∑Âåñ„Ç∑„Çπ„ÉÜ„É†"""

    def __init__(self):
        """ÂàùÊúüÂåñ„É°„ÇΩ„ÉÉ„Éâ"""
        self.logger = self._setup_logger()
        self.db_path = Path("data/elder_flow_core.db")
        self.flow_log = Path("logs/elder_flow_executions.log")
        self.metrics_file = Path("data/elder_flow_metrics.json")
        self._init_database()
        self._init_metrics()

    def _setup_logger(self) -> logging.Logger:
        """„É≠„Ç¨„ÉºË®≠ÂÆö"""
        logger = logging.getLogger("elder_flow_core_enhancement")
        logger.setLevel(logging.INFO)

        # „Ç≥„É≥„ÇΩ„Éº„É´„Éè„É≥„Éâ„É©
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            "%(asctime)s - Elder Flow Core - %(levelname)s - %(message)s"
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)

        # „Éï„Ç°„Ç§„É´„Éè„É≥„Éâ„É©
        self.flow_log.parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(self.flow_log, mode="a")
        file_handler.setFormatter(console_formatter)
        logger.addHandler(file_handler)

        return logger

    def _init_database(self):
        """„Éá„Éº„Çø„Éô„Éº„ÇπÂàùÊúüÂåñ"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # „Éï„É≠„ÉºÂÆüË°å„ÉÜ„Éº„Éñ„É´
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS flow_executions (
                execution_id TEXT PRIMARY KEY,
                task_name TEXT NOT NULL,
                priority TEXT NOT NULL,
                phase TEXT NOT NULL,
                status TEXT NOT NULL,
                start_time TEXT NOT NULL,
                end_time TEXT,
                duration_seconds REAL,
                quality_score REAL,
                violations_found INTEGER DEFAULT 0,
                violations_fixed INTEGER DEFAULT 0,
                sage_recommendations TEXT,
                servant_results TEXT,
                git_commits TEXT,
                error_log TEXT,
                metadata TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # „Éï„Çß„Éº„Ç∫Â±•Ê≠¥„ÉÜ„Éº„Éñ„É´
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS phase_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                phase TEXT NOT NULL,
                status TEXT NOT NULL,
                start_time TEXT NOT NULL,
                end_time TEXT,
                details TEXT,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        # ÂìÅË≥™„É°„Éà„É™„ÇØ„Çπ„ÉÜ„Éº„Éñ„É´
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                threshold REAL,
                passed BOOLEAN,
                recorded_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        # ÈÅïÂèçË®òÈå≤„ÉÜ„Éº„Éñ„É´
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS violation_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id TEXT NOT NULL,
                violation_type TEXT NOT NULL,
                severity TEXT NOT NULL,
                location TEXT,
                description TEXT,
                fixed BOOLEAN DEFAULT FALSE,
                fix_details TEXT,
                detected_at TEXT DEFAULT CURRENT_TIMESTAMP,
                fixed_at TEXT,
                FOREIGN KEY (execution_id) REFERENCES flow_executions(execution_id)
            )
        """
        )

        conn.commit()
        conn.close()

        self.logger.info("‚úÖ Elder Flow Core „Éá„Éº„Çø„Éô„Éº„ÇπÂàùÊúüÂåñÂÆå‰∫Ü")

    def _init_metrics(self):
        """„É°„Éà„É™„ÇØ„ÇπÂàùÊúüÂåñ"""
        if not self.metrics_file.exists():
            initial_metrics = {
                "total_executions": 0,
                "successful_executions": 0,
                "failed_executions": 0,
                "average_quality_score": 0.0,
                "total_violations_found": 0,
                "total_violations_fixed": 0,
                "average_execution_time": 0.0,
                "phase_success_rates": {phase.value: 0.0 for phase in FlowPhase},
                "last_updated": datetime.now().isoformat(),
            }

            self.metrics_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.metrics_file, "w") as f:
                json.dump(initial_metrics, f, indent=2)

    def generate_execution_id(self, task_name: str) -> str:
        """ÂÆüË°åIDÁîüÊàê"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        hash_input = f"{task_name}_{timestamp}".encode()
        hash_value = hashlib.md5(hash_input).hexdigest()[:8]
        return f"EF_{timestamp}_{hash_value}"

    async def start_flow_execution(
        self, task_name: str, priority: str = "normal"
    ) -> str:
        """„Éï„É≠„ÉºÂÆüË°åÈñãÂßã"""
        execution_id = self.generate_execution_id(task_name)

        self.logger.info(f"üöÄ Elder FlowÂÆüË°åÈñãÂßã: {execution_id} - {task_name}")

        # ÂÆüË°åË®òÈå≤‰ΩúÊàê
        execution = FlowExecution(
            execution_id=execution_id,
            task_name=task_name,
            priority=priority,
            phase=FlowPhase.SAGE_CONSULTATION,
            status=FlowStatus.IN_PROGRESS,
            start_time=datetime.now(),
            end_time=None,
            duration_seconds=None,
            quality_score=None,
            violations_found=0,
            violations_fixed=0,
            sage_recommendations=[],
            servant_results=[],
            git_commits=[],
            error_log=[],
            metadata={"priority": priority},
        )

        # „Éá„Éº„Çø„Éô„Éº„ÇπË®òÈå≤
        await self._record_execution_start(execution)

        return execution_id

    async def _record_execution_start(self, execution: FlowExecution):
        """ÂÆüË°åÈñãÂßãË®òÈå≤"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO flow_executions (
                execution_id, task_name, priority, phase, status,
                start_time, sage_recommendations, servant_results,
                git_commits, error_log, metadata
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                execution.execution_id,
                execution.task_name,
                execution.priority,
                execution.phase.value,
                execution.status.value,
                execution.start_time.isoformat(),
                json.dumps(execution.sage_recommendations),
                json.dumps(execution.servant_results),
                json.dumps(execution.git_commits),
                json.dumps(execution.error_log),
                json.dumps(execution.metadata),
            ),
        )

        conn.commit()
        conn.close()

    async def record_phase_transition(
        self,
        execution_id: str,
        from_phase: FlowPhase,
        to_phase: FlowPhase,
        details: Dict[str, Any] = None,
    ):
        """„Éï„Çß„Éº„Ç∫ÈÅ∑ÁßªË®òÈå≤"""
        self.logger.info(f"üîÑ „Éï„Çß„Éº„Ç∫ÈÅ∑Áßª: {from_phase.value} ‚Üí {to_phase.value}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # Ââç„Éï„Çß„Éº„Ç∫ÁµÇ‰∫Ü
        cursor.execute(
            """
            UPDATE phase_history
            SET end_time = ?, status = 'completed'
            WHERE execution_id = ? AND phase = ? AND end_time IS NULL
        """,
            (datetime.now().isoformat(), execution_id, from_phase.value),
        )

        # Êñ∞„Éï„Çß„Éº„Ç∫ÈñãÂßã
        cursor.execute(
            """
            INSERT INTO phase_history (execution_id, phase, status, start_time, details)
            VALUES (?, ?, ?, ?, ?)
        """,
            (
                execution_id,
                to_phase.value,
                FlowStatus.IN_PROGRESS.value,
                datetime.now().isoformat(),
                json.dumps(details) if details else None,
            ),
        )

        # „É°„Ç§„É≥ÂÆüË°åË®òÈå≤Êõ¥Êñ∞
        cursor.execute(
            """
            UPDATE flow_executions
            SET phase = ?
            WHERE execution_id = ?
        """,
            (to_phase.value, execution_id),
        )

        conn.commit()
        conn.close()

    async def record_sage_recommendation(
        self, execution_id: str, sage_name: str, recommendation: Dict[str, Any]
    ):
        """Ë≥¢ËÄÖÊé®Â•®Ë®òÈå≤"""
        self.logger.info(f"üßô‚Äç‚ôÇÔ∏è {sage_name}„Åã„Çâ„ÅÆÊé®Â•®Ë®òÈå≤")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # ÁèæÂú®„ÅÆÊé®Â•®„ÇíÂèñÂæó
        cursor.execute(
            """
            SELECT sage_recommendations FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        result = cursor.fetchone()
        if result:
            recommendations = json.loads(result[0]) if result[0] else []
            recommendations.append(
                {
                    "sage": sage_name,
                    "recommendation": recommendation,
                    "timestamp": datetime.now().isoformat(),
                }
            )

            cursor.execute(
                """
                UPDATE flow_executions
                SET sage_recommendations = ?
                WHERE execution_id = ?
            """,
                (json.dumps(recommendations), execution_id),
            )

            conn.commit()

        conn.close()

    async def record_violation(
        self,
        execution_id: str,
        violation_type: str,
        severity: str,
        location: str,
        description: str,
    ):
        """ÈÅïÂèçË®òÈå≤"""
        self.logger.warning(f"‚ö†Ô∏è ÈÅïÂèçÊ§úÂá∫: {violation_type} ({severity})")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO violation_records (
                execution_id, violation_type, severity, location, description
            ) VALUES (?, ?, ?, ?, ?)
        """,
            (execution_id, violation_type, severity, location, description),
        )

        # ÈÅïÂèçÊï∞Êõ¥Êñ∞
        cursor.execute(
            """
            UPDATE flow_executions
            SET violations_found = violations_found + 1
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        conn.commit()
        conn.close()

    async def record_violation_fix(
        self, execution_id: str, violation_id: int, fix_details: str
    ):
        """ÈÅïÂèç‰øÆÊ≠£Ë®òÈå≤"""
        self.logger.info(f"‚úÖ ÈÅïÂèç‰øÆÊ≠£: ID {violation_id}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            UPDATE violation_records
            SET fixed = TRUE, fix_details = ?, fixed_at = ?
            WHERE id = ? AND execution_id = ?
        """,
            (fix_details, datetime.now().isoformat(), violation_id, execution_id),
        )

        # ‰øÆÊ≠£Êï∞Êõ¥Êñ∞
        cursor.execute(
            """
            UPDATE flow_executions
            SET violations_fixed = violations_fixed + 1
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        conn.commit()
        conn.close()

    async def record_quality_metric(
        self,
        execution_id: str,
        metric_name: str,
        metric_value: float,
        threshold: float = None,
    ):
        """ÂìÅË≥™„É°„Éà„É™„ÇØ„ÇπË®òÈå≤"""
        passed = metric_value >= threshold if threshold else True

        self.logger.info(
            f"üìä ÂìÅË≥™„É°„Éà„É™„ÇØ„Çπ: {metric_name} = {metric_value} "
            f"({'PASS' if passed else 'FAIL'})"
        )

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO quality_metrics (
                execution_id, metric_name, metric_value, threshold, passed
            ) VALUES (?, ?, ?, ?, ?)
        """,
            (execution_id, metric_name, metric_value, threshold, passed),
        )

        conn.commit()
        conn.close()

    async def complete_flow_execution(
        self,
        execution_id: str,
        status: FlowStatus,
        quality_score: float,
        git_commits: List[str] = None,
    ):
        """„Éï„É≠„ÉºÂÆüË°åÂÆå‰∫Ü"""
        end_time = datetime.now()

        self.logger.info(f"üèÅ Elder FlowÂÆüË°åÂÆå‰∫Ü: {execution_id} - {status.value}")

        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # ÈñãÂßãÊôÇÂàªÂèñÂæó
        cursor.execute(
            """
            SELECT start_time FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        result = cursor.fetchone()
        if result:
            start_time = datetime.fromisoformat(result[0])
            duration = (end_time - start_time).total_seconds()

            cursor.execute(
                """
                UPDATE flow_executions
                SET status = ?, end_time = ?, duration_seconds = ?,
                    quality_score = ?, git_commits = ?
                WHERE execution_id = ?
            """,
                (
                    status.value,
                    end_time.isoformat(),
                    duration,
                    quality_score,
                    json.dumps(git_commits) if git_commits else None,
                    execution_id,
                ),
            )

            conn.commit()

        conn.close()

        # „É°„Éà„É™„ÇØ„ÇπÊõ¥Êñ∞
        await self._update_global_metrics()

    async def _update_global_metrics(self):
        """„Ç∞„É≠„Éº„Éê„É´„É°„Éà„É™„ÇØ„ÇπÊõ¥Êñ∞"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # Áµ±Ë®àÂèñÂæó
        cursor.execute(
            """
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as successful,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed,
                AVG(quality_score) as avg_quality,
                SUM(violations_found) as total_violations_found,
                SUM(violations_fixed) as total_violations_fixed,
                AVG(duration_seconds) as avg_duration
            FROM flow_executions
            WHERE end_time IS NOT NULL
        """
        )

        stats = cursor.fetchone()

        if stats:
            metrics = {
                "total_executions": stats[0] or 0,
                "successful_executions": stats[1] or 0,
                "failed_executions": stats[2] or 0,
                "average_quality_score": round(stats[3] or 0, 2),
                "total_violations_found": stats[4] or 0,
                "total_violations_fixed": stats[5] or 0,
                "average_execution_time": round(stats[6] or 0, 2),
                "phase_success_rates": await self._calculate_phase_success_rates(
                    cursor
                ),
                "last_updated": datetime.now().isoformat(),
            }

            with open(self.metrics_file, "w") as f:
                json.dump(metrics, f, indent=2)

        conn.close()

    async def _calculate_phase_success_rates(self, cursor) -> Dict[str, float]:
        """„Éï„Çß„Éº„Ç∫ÊàêÂäüÁéáË®àÁÆó"""
        rates = {}

        for phase in FlowPhase:
            cursor.execute(
                """
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as successful
                FROM phase_history
                WHERE phase = ?
            """,
                (phase.value,),
            )

            result = cursor.fetchone()
            if result and result[0] > 0:
                rates[phase.value] = round((result[1] / result[0]) * 100, 2)
            else:
                rates[phase.value] = 0.0

        return rates

    async def generate_execution_report(self, execution_id: str) -> str:
        """ÂÆüË°å„É¨„Éù„Éº„ÉàÁîüÊàê"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        # ÂÆüË°åÊÉÖÂ†±ÂèñÂæó
        cursor.execute(
            """
            SELECT * FROM flow_executions
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        execution = cursor.fetchone()
        if not execution:
            return "ÂÆüË°åË®òÈå≤„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"

        # „Éï„Çß„Éº„Ç∫Â±•Ê≠¥ÂèñÂæó
        cursor.execute(
            """
            SELECT phase, status, start_time, end_time
            FROM phase_history
            WHERE execution_id = ?
            ORDER BY start_time
        """,
            (execution_id,),
        )

        phases = cursor.fetchall()

        # ÈÅïÂèçË®òÈå≤ÂèñÂæó
        cursor.execute(
            """
            SELECT violation_type, severity, fixed
            FROM violation_records
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        violations = cursor.fetchall()

        # ÂìÅË≥™„É°„Éà„É™„ÇØ„ÇπÂèñÂæó
        cursor.execute(
            """
            SELECT metric_name, metric_value, threshold, passed
            FROM quality_metrics
            WHERE execution_id = ?
        """,
            (execution_id,),
        )

        metrics = cursor.fetchall()

        conn.close()

        # „É¨„Éù„Éº„ÉàÁîüÊàê
        report = f"""
# Elder FlowÂÆüË°å„É¨„Éù„Éº„Éà
## ÂÆüË°åID: {execution_id}

### üìã Âü∫Êú¨ÊÉÖÂ†±
- **„Çø„Çπ„ÇØÂêç**: {execution[1]}
- **ÂÑ™ÂÖàÂ∫¶**: {execution[2]}
- **„Çπ„ÉÜ„Éº„Çø„Çπ**: {execution[4]}
- **ÈñãÂßãÊôÇÂàª**: {execution[5]}
- **ÁµÇ‰∫ÜÊôÇÂàª**: {execution[6] or 'N/A'}
- **ÂÆüË°åÊôÇÈñì**: {execution[7] or 0:0.2f}Áßí
- **ÂìÅË≥™„Çπ„Ç≥„Ç¢**: {execution[8] or 0:0.2f}/100

### üîÑ „Éï„Çß„Éº„Ç∫ÈÄ≤Ë°å
"""

        for phase in phases:
            report += (
                f"- **{phase[0]}**: {phase[1]} ({phase[2]} ‚Üí {phase[3] or 'ÈÄ≤Ë°å‰∏≠'})\n"
            )

        report += f"""
### ‚ö†Ô∏è ÈÅïÂèçË®òÈå≤
- **Áô∫Ë¶ãÊï∞**: {execution[9]}
- **‰øÆÊ≠£Êï∞**: {execution[10]}

ÈÅïÂèçË©≥Á¥∞:
"""

        for violation in violations:
            status = "‚úÖ ‰øÆÊ≠£Ê∏à" if violation[2] else "‚ùå Êú™‰øÆÊ≠£"
            report += f"- {violation[0]} ({violation[1]}): {status}\n"

        report += "\n### üìä ÂìÅË≥™„É°„Éà„É™„ÇØ„Çπ\n"

        for metric in metrics:
            status = "‚úÖ" if metric[3] else "‚ùå"
            report += (
                f"- **{metric[0]}**: {metric[1]} / {metric[2] or 'N/A'} {status}\n"
            )

        # Ë≥¢ËÄÖÊé®Â•®
        if execution[11]:
            recommendations = json.loads(execution[11])
            report += f"\n### üßô‚Äç‚ôÇÔ∏è Ë≥¢ËÄÖÊé®Â•® ({len(recommendations)}‰ª∂)\n"
            for rec in recommendations:
                report += f"- **{rec['sage']}**: {rec['recommendation'].get('summary', 'N/A')}\n"

        # Git„Ç≥„Éü„ÉÉ„Éà
        if execution[13]:
            commits = json.loads(execution[13])
            report += f"\n### üì§ Git„Ç≥„Éü„ÉÉ„Éà ({len(commits)}‰ª∂)\n"
            for commit in commits:
                report += f"- {commit}\n"

        return report

    async def get_execution_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ÂÆüË°åÂ±•Ê≠¥ÂèñÂæó"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT execution_id, task_name, status, quality_score,
                   start_time, end_time, duration_seconds
            FROM flow_executions
            ORDER BY start_time DESC
            LIMIT ?
        """,
            (limit,),
        )

        history = []
        for row in cursor.fetchall():
            history.append(
                {
                    "execution_id": row[0],
                    "task_name": row[1],
                    "status": row[2],
                    "quality_score": row[3],
                    "start_time": row[4],
                    "end_time": row[5],
                    "duration": row[6],
                }
            )

        conn.close()
        return history

    async def monitor_active_flows(self) -> List[Dict[str, Any]]:
        """„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éï„É≠„ÉºÁõ£Ë¶ñ"""
        conn = sqlite3connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT execution_id, task_name, phase, start_time
            FROM flow_executions
            WHERE status = 'in_progress'
            ORDER BY start_time DESC
        """
        )

        active_flows = []
        for row in cursor.fetchall():
            duration = (datetime.now() - datetime.fromisoformat(row[3])).total_seconds()
            active_flows.append(
                {
                    "execution_id": row[0],
                    "task_name": row[1],
                    "current_phase": row[2],
                    "duration_seconds": duration,
                }
            )

        conn.close()
        return active_flows


# CLIÂÆüË°å
async def main():
    """„É°„Ç§„É≥ÂÆüË°å"""
    system = ElderFlowCoreEnhancement()

    print("üåä Elder Flow Core Enhancement System")
    print("=" * 50)

    # „ÉÜ„Çπ„ÉàÂÆüË°å
    execution_id = await system.start_flow_execution("Test Task", "high")
    print(f"‚úÖ ÂÆüË°åÈñãÂßã: {execution_id}")

    # „Éï„Çß„Éº„Ç∫ÈÅ∑Áßª
    await system.record_phase_transition(
        execution_id, FlowPhase.SAGE_CONSULTATION, FlowPhase.SERVANT_EXECUTION
    )

    # Ë≥¢ËÄÖÊé®Â•®Ë®òÈå≤
    await system.record_sage_recommendation(
        execution_id,
        "„Éä„É¨„ÉÉ„Ç∏Ë≥¢ËÄÖ",
        {"summary": "TDDÂÆüË£ÖÊé®Â•®", "details": "„ÉÜ„Çπ„Éà„Éï„Ç°„Éº„Çπ„ÉàÈñãÁô∫"},
    )

    # ÈÅïÂèçË®òÈå≤
    await system.record_violation(
        execution_id,
        "abstract_method",
        "critical",
        "workers/test_worker.py",
        "validate_configÊú™ÂÆüË£Ö",
    )

    # ÂìÅË≥™„É°„Éà„É™„ÇØ„Çπ
    await system.record_quality_metric(execution_id, "coverage", 85.5, 80.0)
    await system.record_quality_metric(execution_id, "complexity", 15.2, 20.0)

    # ÂÆüË°åÂÆå‰∫Ü
    await system.complete_flow_execution(
        execution_id, FlowStatus.COMPLETED, 85.5, ["feat: test implementation"]
    )

    # „É¨„Éù„Éº„ÉàÁîüÊàê
    report = await system.generate_execution_report(execution_id)
    print("\n" + report)

    # Â±•Ê≠¥Ë°®Á§∫
    print("\nüìä ÂÆüË°åÂ±•Ê≠¥:")
    history = await system.get_execution_history(5)
    for h in history:
        print(f"- {h['execution_id']}: {h['task_name']} ({h['status']})")


if __name__ == "__main__":
    asyncio.run(main())
