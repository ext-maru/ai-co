#!/usr/bin/env python3
"""
Elder Flow Quality Gate V2
Phase 3å¼·åŒ–ç‰ˆ: å®Ÿè£…ç³»Issueã«å¯¾ã™ã‚‹å³æ ¼ãªå“è³ªåŸºæº–

ä¸»ãªå¼·åŒ–ç‚¹:
1. æœ€ä½å“è³ªã‚¹ã‚³ã‚¢: 85ç‚¹ï¼ˆå®Ÿè£…ç³»ï¼‰ã€70ç‚¹ï¼ˆè¨­è¨ˆç³»ï¼‰
2. Iron Willé•å: å³åº§ä¸åˆæ ¼
3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯: ãƒ¬ãƒ™ãƒ«3ä»¥ä¸‹å¿…é ˆ
4. Issueç¨®åˆ¥ã«å¿œã˜ãŸå“è³ªåŸºæº–ã®è‡ªå‹•èª¿æ•´
"""

import asyncio
import re
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import logging
import json

# Phase 2ã§å®Ÿè£…ã—ãŸIssueåˆ†é¡å™¨
from libs.elder_system.issue_classifier_v2 import (
    IssueTypeClassifierV2, IssueCategory, IssueType
)

# æ—¢å­˜ã®å¼·åŒ–å“è³ªåŸºæº–
from libs.enhanced_quality_standards import (
    EnhancedQualityConfig, EnhancedQualityEvaluator,
    StrictIronWillValidator, EnhancedSecurityValidator,
    QualityViolation
)

logger = logging.getLogger(__name__)


class AdaptiveQualityConfig(EnhancedQualityConfig):
    """Issueç¨®åˆ¥ã«å¿œã˜ã¦é©å¿œã™ã‚‹å“è³ªè¨­å®š"""
    
    def __init__(self, issue_category: IssueCategory = IssueCategory.UNKNOWN):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        super().__init__()
        self.issue_category = issue_category
        self._apply_category_specific_config()
    
    def _apply_category_specific_config(self):
        """Issueç¨®åˆ¥ã«å¿œã˜ãŸå“è³ªåŸºæº–ã®èª¿æ•´"""
        if self.issue_category == IssueCategory.IMPLEMENTATION_ORIENTED:
            # å®Ÿè£…ç³»: æœ€ã‚‚å³æ ¼ãªåŸºæº–
            self.minimum_quality_score = 85.0
            self.iron_will_compliance_rate = 1.0  # 100%å¿…é ˆ
            self.maximum_security_risk_level = 3
            self.critical_issues_limit = 0
            self.complexity_threshold = 8
            self.maintainability_minimum = 60
            self.test_coverage_minimum = 90.0
            self.documentation_coverage_minimum = 80.0
            
        elif self.issue_category == IssueCategory.DESIGN_ORIENTED:
            # è¨­è¨ˆç³»: æ¨™æº–åŸºæº–
            self.minimum_quality_score = 70.0
            self.iron_will_compliance_rate = 1.0  # Iron Willã¯å¿…é ˆ
            self.maximum_security_risk_level = 5
            self.critical_issues_limit = 0
            self.complexity_threshold = 15  # è¨­è¨ˆæ–‡æ›¸ã¯è¤‡é›‘ã§ã‚‚OK
            self.maintainability_minimum = 50
            self.test_coverage_minimum = 80.0
            self.documentation_coverage_minimum = 90.0  # è¨­è¨ˆç³»ã¯æ–‡æ›¸é‡è¦–
            
        elif self.issue_category == IssueCategory.MAINTENANCE_ORIENTED:
            # ä¿å®ˆç³»: ä¸­é–“åŸºæº–
            self.minimum_quality_score = 80.0
            self.iron_will_compliance_rate = 1.0
            self.maximum_security_risk_level = 4
            self.critical_issues_limit = 0
            self.complexity_threshold = 10
            self.maintainability_minimum = 55
            self.test_coverage_minimum = 85.0
            self.documentation_coverage_minimum = 75.0


class ElderFlowQualityGateV2:
    """Phase 3å¼·åŒ–ç‰ˆå“è³ªã‚²ãƒ¼ãƒˆ"""
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.issue_classifier = IssueTypeClassifierV2()
        self.iron_will_validator = StrictIronWillValidator()
        self.security_validator = EnhancedSecurityValidator()
        self.feedback_history = []
    
    async def check_quality(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å“è³ªãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œï¼ˆIssueç¨®åˆ¥å¯¾å¿œï¼‰"""
        try:
            # Issueã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åˆ†é¡æƒ…å ±ã‚’å–å¾—
            issue_info = self._extract_issue_info(context)
            
            # Issueç¨®åˆ¥ã‚’åˆ¤å®šï¼ˆPhase 2ã®åˆ†é¡å™¨ä½¿ç”¨ï¼‰
            classification_result = None
            if issue_info:
                classification_result = self.issue_classifier.classify(issue_info)
                logger.info(f"Issue classified as: {classification_result.issue_type.value} "
                          f"(Category: {classification_result.category.value})")
            
            # Issueç¨®åˆ¥ã«å¿œã˜ãŸå“è³ªè¨­å®šã‚’é©ç”¨
            config = AdaptiveQualityConfig(
                classification_result.category if classification_result 
                else IssueCategory.UNKNOWN
            )
            
            # è©•ä¾¡å™¨ã‚’è¨­å®šä»˜ãã§åˆæœŸåŒ–
            evaluator = EnhancedQualityEvaluator(config)
            
            # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            quality_results = await self._run_quality_checks(
                context, evaluator, classification_result
            )
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
            feedback = self._generate_feedback(
                quality_results, classification_result, config
            )
            
            # å±¥æ­´ã«è¨˜éŒ²ï¼ˆå­¦ç¿’ç”¨ï¼‰
            self._record_feedback(quality_results, feedback, classification_result)
            
            return quality_results
            
        except Exception as e:
            logger.error(f"Quality gate error: {e}")
            return {
                'passed': False,
                'quality_score': 0,
                'violations': [{
                    'type': 'quality_gate_error',
                    'severity': 'critical',
                    'message': f'Quality gate failed: {str(e)}'
                }],
                'error': str(e)
            }
    
    def _extract_issue_info(self, context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰Issueæƒ…å ±ã‚’æŠ½å‡º"""
        # Elder Flowã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        task_name = context.get('task_name', '')
        
        # Issueç•ªå·ã‚’æŠ½å‡º
        issue_match = re.search(r'#(\d+)', task_name)
        issue_number = issue_match.group(1) if issue_match else None
        
        # å®Ÿéš›ã®Issueæƒ…å ±ãŒã‚ã‚Œã°ä½¿ç”¨
        if 'issue' in context:
            return context['issue']
        
        # ãªã‘ã‚Œã°ã‚¿ã‚¹ã‚¯åã‹ã‚‰æ¨æ¸¬
        return {
            'title': task_name,
            'body': context.get('task_description', ''),
            'labels': context.get('labels', []),
            'number': issue_number
        }
    
    async def _run_quality_checks(self, context: Dict[str, Any], 
                                 evaluator: EnhancedQualityEvaluator,
                                 classification: Any) -> Dict[str, Any]:
        """å“è³ªãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
        all_violations = []
        file_results = []
        total_score = 0
        files_analyzed = 0
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        files_to_check = self._get_files_to_check(context)
        
        for file_path in files_to_check:
            if not file_path.endswith('.py'):
                continue
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å“è³ªè©•ä¾¡
            result = evaluator.evaluate_file_quality(file_path)
            
            file_results.append({
                'file': file_path,
                'score': result['quality_score'],
                'compliant': result['elder_guild_compliant'],
                'violations': result['violations']
            })
            
            all_violations.extend(result['violations'])
            total_score += result['quality_score']
            files_analyzed += 1
        
        # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        average_score = total_score / max(1, files_analyzed) if files_analyzed > 0 else 0
        
        # Iron Willé•åã®ç‰¹åˆ¥ãƒã‚§ãƒƒã‚¯
        iron_will_violations = [v for v in all_violations 
                               if v.get('violation_type') == 'iron_will_violation']
        
        # æœ€çµ‚åˆ¤å®š
        passed = self._determine_gate_passed(
            average_score, all_violations, classification, evaluator.config
        )
        
        return {
            'passed': passed,
            'quality_score': average_score,
            'files_analyzed': files_analyzed,
            'file_results': file_results,
            'violations': all_violations,
            'iron_will_violations': len(iron_will_violations),
            'critical_violations': len([v for v in all_violations 
                                      if v.get('severity') == 'critical']),
            'issue_category': classification.category.value if classification else 'unknown',
            'issue_type': classification.issue_type.value if classification else 'unknown',
            'applied_standards': {
                'minimum_score': evaluator.config.minimum_quality_score,
                'iron_will_required': True,
                'max_security_risk': evaluator.config.maximum_security_risk_level,
                'complexity_threshold': evaluator.config.complexity_threshold
            }
        }
    
    def _get_files_to_check(self, context: Dict[str, Any]) -> List[str]:
        """ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—"""
        files = []
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        if 'generated_files' in context:
            files.extend(context['generated_files'])
        
        # å®Ÿè£…ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        if 'implementation' in context:
            # å®Ÿè£…å†…å®¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¨æ¸¬
            impl_content = context['implementation']
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ãƒã‚§ãƒƒã‚¯
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(impl_content)
                files.append(f.name)
        
        # Elder Servantã®å‡ºåŠ›
        if 'servant_outputs' in context:
            for servant, output in context['servant_outputs'].items():
                if 'files' in output:
                    files.extend(output['files'])
        
        return files
    
    def _determine_gate_passed(self, average_score: float, 
                              violations: List[Dict],
                              classification: Any,
                              config: AdaptiveQualityConfig) -> bool:
        """å“è³ªã‚²ãƒ¼ãƒˆé€šéåˆ¤å®š"""
        # Iron Willé•åã¯å³åº§ã«ä¸åˆæ ¼
        if any(v.get('violation_type') == 'iron_will_violation' for v in violations):
            logger.warning("Quality gate failed: Iron Will violation detected")
            return False
        
        # Criticalé•åã‚‚å³åº§ã«ä¸åˆæ ¼
        if any(v.get('severity') == 'critical' for v in violations):
            logger.warning("Quality gate failed: Critical violations detected")
            return False
        
        # ã‚¹ã‚³ã‚¢ãŒåŸºæº–æœªæº€
        if average_score < config.minimum_quality_score:
            logger.warning(f"Quality gate failed: Score {average_score:.1f} < {config.minimum_quality_score}")
            return False
        
        # å®Ÿè£…ç³»ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯
        if classification and classification.category == IssueCategory.IMPLEMENTATION_ORIENTED:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
            security_violations = [v for v in violations 
                                 if v.get('violation_type') == 'security_violation']
            if security_violations:
                logger.warning("Quality gate failed: Security violations in implementation")
                return False
        
        return True
    
    def _generate_feedback(self, results: Dict[str, Any], 
                          classification: Any,
                          config: AdaptiveQualityConfig) -> Dict[str, Any]:
        """è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ"""
        feedback = {
            'summary': '',
            'violations_by_type': {},
            'improvement_suggestions': [],
            'positive_points': [],
            'next_actions': []
        }
        
        # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        if results['passed']:
            feedback['summary'] = f"âœ… å“è³ªã‚²ãƒ¼ãƒˆé€šéï¼ˆã‚¹ã‚³ã‚¢: {results['quality_score']:.1f}/100ï¼‰"
        else:
            feedback['summary'] = f"âŒ å“è³ªã‚²ãƒ¼ãƒˆä¸åˆæ ¼ï¼ˆã‚¹ã‚³ã‚¢: {results['quality_score']:.1f}/100ï¼‰"
        
        # é•åã®åˆ†é¡
        for violation in results['violations']:
            v_type = violation.get('violation_type', 'unknown')
            if v_type not in feedback['violations_by_type']:
                feedback['violations_by_type'][v_type] = []
            feedback['violations_by_type'][v_type].append(violation)
        
        # æ”¹å–„ææ¡ˆ
        if results['iron_will_violations'] > 0:
            feedback['improvement_suggestions'].append({
                'priority': 'critical',
                'suggestion': 'TODO/FIXMEã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã€å®Œå…¨ãªå®Ÿè£…ã‚’è¡Œã£ã¦ãã ã•ã„',
                'affected_files': list(set(v['file_path'] for v in results['violations'] 
                                         if v.get('violation_type') == 'iron_will_violation'))
            })
        
        if results['quality_score'] < config.minimum_quality_score:
            feedback['improvement_suggestions'].append({
                'priority': 'high',
                'suggestion': f'å“è³ªã‚¹ã‚³ã‚¢ã‚’{config.minimum_quality_score}ç‚¹ä»¥ä¸Šã«æ”¹å–„ã—ã¦ãã ã•ã„',
                'current_score': results['quality_score']
            })
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹
        if results['quality_score'] >= 90:
            feedback['positive_points'].append('å„ªã‚ŒãŸå“è³ªã‚¹ã‚³ã‚¢')
        if results['iron_will_violations'] == 0:
            feedback['positive_points'].append('Iron Willå®Œå…¨éµå®ˆ')
        
        # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if not results['passed']:
            feedback['next_actions'].append('å“è³ªé•åã‚’ä¿®æ­£ã—ã¦ãã ã•ã„')
            if classification and classification.category == IssueCategory.IMPLEMENTATION_ORIENTED:
                feedback['next_actions'].append('å®Ÿè£…ç³»Issueã¯ç‰¹ã«å³æ ¼ãªåŸºæº–ãŒé©ç”¨ã•ã‚Œã¾ã™')
        
        return feedback
    
    def _record_feedback(self, results: Dict[str, Any], 
                        feedback: Dict[str, Any],
                        classification: Any):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å±¥æ­´ã«è¨˜éŒ²ï¼ˆå­¦ç¿’ç”¨ï¼‰"""
        record = {
            'timestamp': datetime.now().isoformat(),
            'quality_score': results['quality_score'],
            'passed': results['passed'],
            'issue_category': classification.category.value if classification else 'unknown',
            'issue_type': classification.issue_type.value if classification else 'unknown',
            'violations_count': len(results['violations']),
            'iron_will_violations': results['iron_will_violations'],
            'feedback': feedback
        }
        
        self.feedback_history.append(record)
        
        # å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæœ€å¤§100ä»¶ï¼‰
        history_file = Path('data/quality_gate_feedback_history.json')
        history_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            if history_file.exists():
                with open(history_file, 'r') as f:
                    all_history = json.load(f)
            else:
                all_history = []
            
            all_history.append(record)
            
            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            if len(all_history) > 100:
                all_history = all_history[-100:]
            
            with open(history_file, 'w') as f:
                json.dump(all_history, f, indent=2)
                
        except Exception as e:
            logger.warning(f"Failed to save feedback history: {e}")
    
    async def get_quality_trends(self) -> Dict[str, Any]:
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰"""
        history_file = Path('data/quality_gate_feedback_history.json')
        
        if not history_file.exists():
            return {'error': 'No history available'}
        
        try:
            with open(history_file, 'r') as f:
                history = json.load(f)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            implementation_scores = [h['quality_score'] for h in history 
                                   if h.get('issue_category') == 'implementation_oriented']
            design_scores = [h['quality_score'] for h in history 
                               if h.get('issue_category') == 'design_oriented']
            
            trends = {
                'total_checks': len(history),
                'pass_rate': sum(1 for h in history if h['passed']) / len(history) * 100,
                'average_score': sum(h['quality_score'] for h in history) / len(history),
                'implementation_average': sum(implementation_scores) / len(implementation_scores) \
                    if implementation_scores \
                    else 0,
                'design_average': sum(design_scores) / len(design_scores) if design_scores else 0,
                'iron_will_violation_rate': sum(h['iron_will_violations'] > 0 for h in history) / len(history) * 100,
                'recent_improvements': self._calculate_recent_improvements(history)
            }
            
            return trends
            
        except Exception as e:
            logger.error(f"Failed to analyze trends: {e}")
            return {'error': str(e)}
    
    def _calculate_recent_improvements(self, history: List[Dict]) -> Dict[str, float]:
        """æœ€è¿‘ã®æ”¹å–„å‚¾å‘ã‚’è¨ˆç®—"""
        if len(history) < 10:
            return {'insufficient_data': True}
        
        # æœ€æ–°10ä»¶ã¨å‰ã®10ä»¶ã‚’æ¯”è¼ƒ
        recent = history[-10:]
        previous = history[-20:-10] if len(history) >= 20 else history[:10]
        
        recent_avg = sum(h['quality_score'] for h in recent) / len(recent)
        previous_avg = sum(h['quality_score'] for h in previous) / len(previous)
        
        return {
            'score_improvement': recent_avg - previous_avg,
            'pass_rate_improvement': (
                sum(1 for h in recent if h['passed']) / len(recent) -
                sum(1 for h in previous if h['passed']) / len(previous)
            ) * 100
        }


# Integration with Elder Flow
class ElderFlowQualityIntegrationV2:
    """Elder Flowã¨ã®çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.quality_gate = ElderFlowQualityGateV2()
    
    async def run_quality_gate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Elder Flowã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹å“è³ªã‚²ãƒ¼ãƒˆå®Ÿè¡Œ"""
        logger.info("ğŸ›ï¸ Elder Flow Quality Gate V2 - Starting quality check")
        
        # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        results = await self.quality_gate.check_quality(context)
        
        # çµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆElder Flowäº’æ›ï¼‰
        formatted_results = {
            'passed': results['passed'],
            'score': results['quality_score'],
            'details': {
                'files_analyzed': results['files_analyzed'],
                'violations': results['violations'],
                'iron_will_compliant': results['iron_will_violations'] == 0,
                'issue_category': results.get('issue_category', 'unknown'),
                'applied_standards': results.get('applied_standards', {})
            },
            'feedback': results.get('feedback', {}),
            'timestamp': datetime.now().isoformat()
        }
        
        if results['passed']:
            logger.info(f"âœ… Quality gate PASSED (Score: {results['quality_score']:.1f}/100)")
        else:
            logger.warning(f"âŒ Quality gate FAILED (Score: {results['quality_score']:.1f}/100)")
            logger.warning(f"   Violations: {len(results['violations'])}")
            logger.warning(f"   Iron Will violations: {results['iron_will_violations']}")
        
        return formatted_results


# Export for Elder Flow integration
quality_gate_v2 = ElderFlowQualityIntegrationV2()


# CLI Testing
if __name__ == "__main__":
    import sys
    
    async def test_quality_gate():
        """Test the quality gate with sample context"""
        test_context = {
            'task_name': 'Implement OAuth2.0 authentication #123',
            'task_description': 'Add OAuth2.0 authentication with JWT tokens',
            'labels': ['enhancement', 'security'],
            'generated_files': sys.argv[1:] if len(sys.argv) > 1 else []
        }
        
        gate = ElderFlowQualityGateV2()
        results = await gate.check_quality(test_context)
        
        print("ğŸ›ï¸ Elder Flow Quality Gate V2 Test Results")
        print("=" * 50)
        print(f"Passed: {results['passed']}")
        print(f"Quality Score: {results['quality_score']:.1f}/100")
        print(f"Issue Category: {results.get('issue_category', 'unknown')}")
        print(f"Files Analyzed: {results['files_analyzed']}")
        print(f"Violations: {len(results['violations'])}")
        print(f"Iron Will Violations: {results['iron_will_violations']}")
        print(f"Applied Standards: {json.dumps(results.get('applied_standards', {}), indent=2)}")
        
        if not results['passed']:
            print("\nâŒ Violations:")
            for v in results['violations'][:5]:  # Show first 5
                print(f"  - [{v.get('severity')}] {v.get('message')}")
    
    asyncio.run(test_quality_gate())