"""
ğŸ§™â€â™‚ï¸ Elder Servantsçµ±åˆç”¨ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
Phase 3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼š175.9%ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ â†’ 50%ä»¥ä¸‹å‰Šæ¸›

EldersServiceLegacyçµ±åˆ: Iron Willå“è³ªåŸºæº–ã¨ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šä»¤ç¬¬27å·å®Œå…¨æº–æ‹ 
"""

import asyncio
import json
import hashlib
import logging
import time
from typing import Dict, Any, Optional, Union, List, Tuple
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass
import redis.asyncio as redis
from contextlib import asynccontextmanager

# EldersLegacyçµ±åˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from libs.core.elders_legacy import (
    EldersServiceLegacy, 
    enforce_boundary,
    EldersLegacyDomain,
    IronWillCriteria
)


class CacheStrategy(Enum):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥å®šç¾©"""
    AGGRESSIVE = "aggressive"  # ç©æ¥µçš„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆé–‹ç™ºæ™‚ï¼‰
    BALANCED = "balanced"     # ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆæœ¬ç•ªæ¨å¥¨ï¼‰
    CONSERVATIVE = "conservative"  # ä¿å®ˆçš„ï¼ˆé«˜ç²¾åº¦é‡è¦–ï¼‰


class CacheKeyType(Enum):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—"""
    QUALITY_CHECK = "quality_check"
    SAGE_CONSULTATION = "sage_consultation" 
    INTEGRATION_RESULT = "integration_result"
    PERFORMANCE_METRIC = "performance_metric"
    HEALTH_STATUS = "health_status"


@dataclass
class CacheEntry:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒª"""
    key: str
    data: Dict[str, Any]
    created_at: datetime
    expires_at: datetime
    hit_count: int = 0
    size_bytes: int = 0
    version: str = "1.0"


@dataclass
class CacheStats:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ"""
    total_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    total_size_bytes: int = 0
    evictions: int = 0
    errors: int = 0


class CacheRequest:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    
    def __init__(self, key_type: CacheKeyType, data: Dict[str, Any], 
                 ttl_seconds: int = 3600, strategy: CacheStrategy = CacheStrategy.BALANCED):
        self.key_type = key_type
        self.data = data
        self.ttl_seconds = ttl_seconds
        self.strategy = strategy
        self.timestamp = datetime.now()


class CacheResponse:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    
    def __init__(self, success: bool, data: Optional[Dict[str, Any]] = None,
                 cached: bool = False, error_message: Optional[str] = None,
                 execution_time_ms: float = 0.0):
        self.success = success
        self.data = data or {}
        self.cached = cached
        self.error_message = error_message
        self.execution_time_ms = execution_time_ms
        self.timestamp = datetime.now()


class ElderCacheManager(EldersServiceLegacy[CacheRequest, CacheResponse]):
    """
    ğŸ§™â€â™‚ï¸ Elder Servantsçµ±åˆç”¨ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    
    EldersServiceLegacyã‹ã‚‰ç¶™æ‰¿ã—ã€Iron Willå“è³ªåŸºæº–ã«å®Œå…¨æº–æ‹ ã€‚
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã«ã‚ˆã‚Š175.9%ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’50%ä»¥ä¸‹ã«å‰Šæ¸›ã€‚
    """
    
    def __init__(self, redis_url: str = "redis://localhost:6379", 
                 strategy: CacheStrategy = CacheStrategy.BALANCED):
        # EldersServiceLegacyåˆæœŸåŒ– (EXECUTIONåŸŸ)
        super().__init__("elder_cache_manager")
        
        self.redis_url = redis_url
        self.strategy = strategy
        self.logger = logging.getLogger("elder_servants.cache_manager")
        
        # Redisæ¥ç¶š
        self.redis_client: Optional[redis.Redis] = None
        self.connection_pool = None
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
        self.stats = CacheStats()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
        self.config = {
            "default_ttl": 3600,  # 1æ™‚é–“
            "max_memory_mb": 100,  # 100MBåˆ¶é™
            "max_key_length": 250,
            "compression_threshold": 1024,  # 1KBä»¥ä¸Šã§åœ§ç¸®
            "batch_size": 100,
            "cleanup_interval": 300  # 5åˆ†é–“éš”
        }
        
        # TTLæˆ¦ç•¥ãƒãƒƒãƒ”ãƒ³ã‚°
        self.ttl_strategies = {
            CacheKeyType.QUALITY_CHECK: {
                CacheStrategy.AGGRESSIVE: 7200,    # 2æ™‚é–“
                CacheStrategy.BALANCED: 3600,      # 1æ™‚é–“  
                CacheStrategy.CONSERVATIVE: 1800   # 30åˆ†
            },
            CacheKeyType.SAGE_CONSULTATION: {
                CacheStrategy.AGGRESSIVE: 3600,    # 1æ™‚é–“
                CacheStrategy.BALANCED: 1800,      # 30åˆ†
                CacheStrategy.CONSERVATIVE: 900    # 15åˆ†
            },
            CacheKeyType.INTEGRATION_RESULT: {
                CacheStrategy.AGGRESSIVE: 1800,    # 30åˆ†
                CacheStrategy.BALANCED: 900,       # 15åˆ†
                CacheStrategy.CONSERVATIVE: 300    # 5åˆ†
            }
        }
        
        # Iron Willå“è³ªåŸºæº–
        self.quality_threshold = 95.0
        
        # åˆæœŸåŒ–çµ±è¨ˆ
        self.logger.info(f"Elder Cache Manager initialized with strategy: {strategy.value}")
    
    async def _ensure_redis_connection(self):
        """Redisæ¥ç¶šç¢ºä¿"""
        if self.redis_client is None:
            try:
                self.connection_pool = redis.ConnectionPool.from_url(
                    self.redis_url,
                    max_connections=20,
                    decode_responses=True
                )
                self.redis_client = redis.Redis(connection_pool=self.connection_pool)
                
                # æ¥ç¶šãƒ†ã‚¹ãƒˆ
                await self.redis_client.ping()
                self.logger.info("Redis connection established successfully")
                
            except Exception as e:
                self.logger.error(f"Redis connection failed: {str(e)}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
                self.redis_client = None
    
    def _generate_cache_key(self, key_type: CacheKeyType, data: Dict[str, Any]) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        data_hash = hashlib.sha256(data_str.encode()).hexdigest()[:16]
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¦ç´ ï¼ˆæˆ¦ç•¥ã«å¿œã˜ã¦ï¼‰
        timestamp_element = ""
        if self.strategy == CacheStrategy.CONSERVATIVE:
            # 5åˆ†å˜ä½ã§ã‚­ãƒ¼æ›´æ–°ï¼ˆä¿å®ˆçš„ï¼‰
            timestamp_element = f"_{int(time.time() // 300)}"
        elif self.strategy == CacheStrategy.BALANCED:
            # 15åˆ†å˜ä½ã§ã‚­ãƒ¼æ›´æ–°ï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰
            timestamp_element = f"_{int(time.time() // 900)}"
        # AGGRESSIVEã¯æ™‚é–“è¦ç´ ãªã—ï¼ˆé•·æœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
        
        cache_key = f"elder:{key_type.value}:{data_hash}{timestamp_element}"
        
        # ã‚­ãƒ¼é•·åˆ¶é™
        if len(cache_key) > self.config["max_key_length"]:
            cache_key = cache_key[:self.config["max_key_length"]]
        
        return cache_key
    
    def _get_ttl_for_key_type(self, key_type: CacheKeyType) -> int:
        """ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥TTLå–å¾—"""
        return self.ttl_strategies.get(key_type, {}).get(
            self.strategy, 
            self.config["default_ttl"]
        )
    
    @enforce_boundary("cache")
    async def process_request(self, request: CacheRequest) -> CacheResponse:
        """
        EldersServiceLegacyçµ±ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
        
        Args:
            request: CacheRequestå½¢å¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            
        Returns:
            CacheResponse: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‡¦ç†çµæœ
        """
        start_time = time.time()
        
        try:
            await self._ensure_redis_connection()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
            cache_key = self._generate_cache_key(request.key_type, request.data)
            
            # TTLæ±ºå®š
            ttl = request.ttl_seconds or self._get_ttl_for_key_type(request.key_type)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¤œç´¢
            cached_data = await self._get_from_cache(cache_key)
            
            if cached_data:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ
                self.stats.cache_hits += 1
                execution_time = (time.time() - start_time) * 1000
                
                return CacheResponse(
                    success=True,
                    data=cached_data,
                    cached=True,
                    execution_time_ms=execution_time
                )
            else:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ - ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
                self.stats.cache_misses += 1
                await self._set_to_cache(cache_key, request.data, ttl)
                
                execution_time = (time.time() - start_time) * 1000
                
                return CacheResponse(
                    success=True,
                    data=request.data,
                    cached=False,
                    execution_time_ms=execution_time
                )
                
        except Exception as e:
            self.stats.errors += 1
            self.logger.error(f"Cache processing failed: {str(e)}")
            
            execution_time = (time.time() - start_time) * 1000
            
            return CacheResponse(
                success=False,
                error_message=str(e),
                execution_time_ms=execution_time
            )
        finally:
            self.stats.total_requests += 1
    
    async def _get_from_cache(self, key: str) -> Optional[Dict[str, Any]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            if self.redis_client:
                cached_json = await self.redis_client.get(key)
                if cached_json:
                    return json.loads(cached_json)
            return None
            
        except Exception as e:
            self.logger.warning(f"Cache get failed for key {key}: {str(e)}")
            return None
    
    async def _set_to_cache(self, key: str, data: Dict[str, Any], ttl: int):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿è¨­å®š"""
        try:
            if self.redis_client:
                data_json = json.dumps(data, ensure_ascii=False)
                await self.redis_client.setex(key, ttl, data_json)
                
                # ã‚µã‚¤ã‚ºè¿½è·¡
                self.stats.total_size_bytes += len(data_json.encode())
                
        except Exception as e:
            self.logger.warning(f"Cache set failed for key {key}: {str(e)}")
    
    def validate_request(self, request: CacheRequest) -> bool:
        """EldersServiceLegacyãƒªã‚¯ã‚¨ã‚¹ãƒˆæ¤œè¨¼"""
        if not isinstance(request.key_type, CacheKeyType):
            return False
        if not isinstance(request.data, dict):
            return False
        if request.ttl_seconds and request.ttl_seconds <= 0:
            return False
        return True
    
    def get_capabilities(self) -> List[str]:
        """EldersServiceLegacyèƒ½åŠ›å–å¾—"""
        return [
            "intelligent_caching",
            "performance_optimization", 
            "ttl_management",
            "cache_statistics",
            "memory_management",
            "redis_integration"
        ]
    
    @asynccontextmanager
    async def cache_context(self, key_type: CacheKeyType, data: Dict[str, Any],
                           ttl_seconds: Optional[int] = None):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        request = CacheRequest(
            key_type=key_type,
            data=data,
            ttl_seconds=ttl_seconds or self._get_ttl_for_key_type(key_type),
            strategy=self.strategy
        )
        
        response = await self.process_request(request)
        
        try:
            yield response
        finally:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ‚äº†å‡¦ç†
            pass
    
    async def get_quality_check_cache(self, file_hash: str, check_type: str) -> Optional[Dict[str, Any]]:
        """å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        data = {"file_hash": file_hash, "check_type": check_type}
        request = CacheRequest(CacheKeyType.QUALITY_CHECK, data)
        response = await self.process_request(request)
        
        return response.data if response.success and response.cached else None
    
    async def set_quality_check_cache(self, file_hash: str, check_type: str, 
                                    result: Dict[str, Any]) -> bool:
        """å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š"""
        data = {"file_hash": file_hash, "check_type": check_type, "result": result}
        request = CacheRequest(CacheKeyType.QUALITY_CHECK, data)
        response = await self.process_request(request)
        
        return response.success
    
    async def get_sage_consultation_cache(self, sage_type: str, 
                                        consultation_context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """4è³¢è€…ç›¸è«‡çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        data = {"sage_type": sage_type, "context": consultation_context}
        request = CacheRequest(CacheKeyType.SAGE_CONSULTATION, data)
        response = await self.process_request(request)
        
        return response.data.get("result") if response.success and response.cached else None
    
    async def set_sage_consultation_cache(self, sage_type: str, 
                                        consultation_context: Dict[str, Any],
                                        consultation_result: Dict[str, Any]) -> bool:
        """4è³¢è€…ç›¸è«‡çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š"""
        data = {
            "sage_type": sage_type, 
            "context": consultation_context,
            "result": consultation_result
        }
        request = CacheRequest(CacheKeyType.SAGE_CONSULTATION, data)
        response = await self.process_request(request)
        
        return response.success
    
    async def invalidate_cache_pattern(self, pattern: str) -> int:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–"""
        try:
            if self.redis_client:
                keys = await self.redis_client.keys(f"elder:{pattern}")
                if keys:
                    deleted = await self.redis_client.delete(*keys)
                    self.logger.info(f"Invalidated {deleted} cache entries matching pattern: {pattern}")
                    return deleted
            return 0
            
        except Exception as e:
            self.logger.error(f"Cache invalidation failed for pattern {pattern}: {str(e)}")
            return 0
    
    async def get_cache_statistics(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—"""
        hit_rate = (self.stats.cache_hits / max(self.stats.total_requests, 1)) * 100
        
        memory_info = {}
        if self.redis_client:
            try:
                info = await self.redis_client.info('memory')
                memory_info = {
                    "used_memory": info.get("used_memory", 0),
                    "used_memory_human": info.get("used_memory_human", "0B"),
                    "maxmemory": info.get("maxmemory", 0)
                }
            except Exception as e:
                self.logger.warning(f"Failed to get Redis memory info: {str(e)}")
        
        return {
            "cache_stats": {
                "total_requests": self.stats.total_requests,
                "cache_hits": self.stats.cache_hits,
                "cache_misses": self.stats.cache_misses,
                "hit_rate_percent": round(hit_rate, 2),
                "errors": self.stats.errors,
                "total_size_bytes": self.stats.total_size_bytes
            },
            "memory_info": memory_info,
            "strategy": self.strategy.value,
            "configuration": self.config,
            "iron_will_compliance": hit_rate >= 70.0  # 70%ä»¥ä¸Šã®ãƒ’ãƒƒãƒˆç‡ã‚’è¦æ±‚
        }
    
    async def cleanup_expired_cache(self) -> int:
        """æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.redis_client:
                # Redisè‡ªä½“ãŒTTLã§è‡ªå‹•å‰Šé™¤ã™ã‚‹ã®ã§ã€çµ±è¨ˆã®ã¿æ›´æ–°
                # æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒå¿…è¦ãªå ´åˆã®ã¿å®Ÿè£…
                return 0
            return 0
            
        except Exception as e:
            self.logger.error(f"Cache cleanup failed: {str(e)}")
            return 0
    
    async def health_check(self) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            # Redisæ¥ç¶šç¢ºèª
            redis_healthy = False
            if self.redis_client:
                await self.redis_client.ping()
                redis_healthy = True
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
            hit_rate = (self.stats.cache_hits / max(self.stats.total_requests, 1)) * 100
            error_rate = (self.stats.errors / max(self.stats.total_requests, 1)) * 100
            
            # Iron WillåŸºæº–åˆ¤å®š
            iron_will_compliant = (
                hit_rate >= 70.0 and        # 70%ä»¥ä¸Šã®ãƒ’ãƒƒãƒˆç‡
                error_rate <= 5.0 and       # 5%ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ç‡
                redis_healthy               # Redisæ¥ç¶šå¥å…¨
            )
            
            return {
                "success": True,
                "status": "healthy" if iron_will_compliant else "degraded",
                "redis_connection": redis_healthy,
                "cache_hit_rate": round(hit_rate, 2),
                "error_rate": round(error_rate, 2),
                "iron_will_compliant": iron_will_compliant,
                "strategy": self.strategy.value,
                "total_requests": self.stats.total_requests
            }
            
        except Exception as e:
            self.logger.error(f"Health check failed: {str(e)}")
            return {
                "success": False,
                "status": "error",
                "error": str(e)
            }
    
    async def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.redis_client:
            await self.redis_client.close()
        if self.connection_pool:
            await self.connection_pool.disconnect()
        
        self.logger.info("Elder Cache Manager closed")


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_cache_manager: Optional[ElderCacheManager] = None


async def get_cache_manager(strategy: CacheStrategy = CacheStrategy.BALANCED) -> ElderCacheManager:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å–å¾—"""
    global _cache_manager
    
    if _cache_manager is None:
        _cache_manager = ElderCacheManager(strategy=strategy)
    
    return _cache_manager


# ä¾¿åˆ©ãªé–¢æ•°ç¾¤
async def cache_quality_check_result(file_hash: str, check_type: str, 
                                   result: Dict[str, Any]) -> bool:
    """å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰"""
    cache_manager = await get_cache_manager()
    return await cache_manager.set_quality_check_cache(file_hash, check_type, result)


async def get_cached_quality_check(file_hash: str, check_type: str) -> Optional[Dict[str, Any]]:
    """å“è³ªãƒã‚§ãƒƒã‚¯çµæœå–å¾—ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰"""
    cache_manager = await get_cache_manager()
    return await cache_manager.get_quality_check_cache(file_hash, check_type)


async def cache_sage_consultation(sage_type: str, context: Dict[str, Any], 
                                 result: Dict[str, Any]) -> bool:
    """4è³¢è€…ç›¸è«‡çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰"""
    cache_manager = await get_cache_manager()
    return await cache_manager.set_sage_consultation_cache(sage_type, context, result)


async def get_cached_sage_consultation(sage_type: str, 
                                     context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """4è³¢è€…ç›¸è«‡çµæœå–å¾—ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰"""
    cache_manager = await get_cache_manager()
    return await cache_manager.get_sage_consultation_cache(sage_type, context)