#!/usr/bin/env python3
"""
Enhanced Error Classification System
242ä¸‡ä»¶ã®Otherã‚¨ãƒ©ãƒ¼ã‚’è©³ç´°åˆ†é¡ã—ã€è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ã‚’æä¾›
"""

import re
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import Counter, defaultdict
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ErrorPattern:
    """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    category: str
    pattern: str
    description: str
    auto_fix: Optional[str] = None
    severity: str = "medium"
    priority: int = 3

@dataclass
class ClassifiedError:
    """åˆ†é¡ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼"""
    original_error: str
    category: str
    subcategory: str
    severity: str
    confidence: float
    auto_fix_suggestion: Optional[str] = None
    timestamp: str = None

class EnhancedErrorClassifier:
    """å¼·åŒ–ã‚¨ãƒ©ãƒ¼åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.patterns = self._initialize_patterns()
        self.statistics = defaultdict(int)
        self.classified_cache = {}
        
    def _initialize_patterns(self) -> List[ErrorPattern]:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆæœŸåŒ–"""
        return [
            # ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "system", 
                r"ModuleNotFoundError.*(?:No module named|cannot import)",
                "Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„",
                "pip install <module_name>",
                "high", 1
            ),
            ErrorPattern(
                "system",
                r"FileNotFoundError.*(?:No such file|cannot find)",
                "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„",
                "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç¢ºèªã¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ",
                "medium", 2
            ),
            ErrorPattern(
                "system",
                r"PermissionError.*(?:Permission denied|Access denied)",
                "æ¨©é™ã‚¨ãƒ©ãƒ¼",
                "chmod +x ã¾ãŸã¯ sudo ã§æ¨©é™ã‚’å¤‰æ›´",
                "high", 1
            ),
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "network",
                r"ConnectionError.*(?:connection|refused|timeout)",
                "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼",
                "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã¨ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ç¢ºèª",
                "high", 1
            ),
            ErrorPattern(
                "network",
                r"TimeoutError.*(?:timeout|timed out)",
                "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼",
                "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã®èª¿æ•´ã¨ãƒªãƒˆãƒ©ã‚¤å®Ÿè£…",
                "medium", 2
            ),
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "database",
                r"(?:sqlite3|mysql|postgres).*(?:error|exception)",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨ã‚¯ã‚¨ãƒªã®ç¢ºèª",
                "high", 1
            ),
            ErrorPattern(
                "database",
                r"(?:IntegrityError|ConstraintError)",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼",
                "ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ã®ç¢ºèªã¨ä¿®æ­£",
                "medium", 2
            ),
            
            # ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "memory",
                r"MemoryError.*(?:out of memory|memory)",
                "ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼",
                "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–ã¨ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
                "high", 1
            ),
            ErrorPattern(
                "memory",
                r"(?:heap|stack) overflow",
                "ãƒ’ãƒ¼ãƒ—/ã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼",
                "å†å¸°åˆ¶é™ã®èª¿æ•´ã¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–",
                "high", 1
            ),
            
            # è¨­å®šã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "config",
                r"(?:KeyError|AttributeError).*(?:config|setting)",
                "è¨­å®šã‚¨ãƒ©ãƒ¼",
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª",
                "medium", 2
            ),
            ErrorPattern(
                "config",
                r"(?:Invalid|Missing).*(?:configuration|config)",
                "è¨­å®šä¸å‚™ã‚¨ãƒ©ãƒ¼",
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ­£ã¨æ¤œè¨¼",
                "medium", 2
            ),
            
            # APIãƒ»é€šä¿¡ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "api",
                r"(?:HTTPError|RequestException|API.*error)",
                "APIé€šä¿¡ã‚¨ãƒ©ãƒ¼",
                "APIã‚­ãƒ¼ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª",
                "medium", 2
            ),
            ErrorPattern(
                "api",
                r"(?:401|403|404|500).*(?:Unauthorized|Forbidden|Not Found|Internal Server Error)",
                "HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼",
                "èªè¨¼æƒ…å ±ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ã®ç¢ºèª",
                "medium", 2
            ),
            
            # ä¸¦è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "concurrency",
                r"(?:DeadlockError|RaceCondition|ThreadError)",
                "ä¸¦è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼",
                "ãƒ­ãƒƒã‚¯æ©Ÿæ§‹ã¨ã‚¹ãƒ¬ãƒƒãƒ‰å®‰å…¨æ€§ã®è¦‹ç›´ã—",
                "high", 1
            ),
            
            # JSON/ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "parsing",
                r"(?:JSONDecodeError|ParseError|SyntaxError).*(?:json|parse)",
                "ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼",
                "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨æ§‹æ–‡ã®ç¢ºèª",
                "medium", 2
            ),
            
            # å‹ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "type",
                r"TypeError.*(?:unsupported|not supported|expected)",
                "å‹ã‚¨ãƒ©ãƒ¼",
                "ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨å¤‰æ›å‡¦ç†ã®è¿½åŠ ",
                "low", 3
            ),
            
            # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "worker",
                r"(?:worker|task).*(?:failed|error|exception)",
                "ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ»ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼",
                "ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šã¨ã‚¿ã‚¹ã‚¯å‡¦ç†ã®ç¢ºèª",
                "medium", 2
            ),
            
            # ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼
            ErrorPattern(
                "system",
                r"(?:OSError|SystemError|RuntimeError)",
                "ã‚·ã‚¹ãƒ†ãƒ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼",
                "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã¨ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºèª",
                "medium", 2
            )
        ]
    
    def classify_error(self, error_message: str) -> ClassifiedError:
        """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†é¡"""
        error_message = error_message.strip()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if error_message in self.classified_cache:
            return self.classified_cache[error_message]
        
        best_match = None
        best_confidence = 0.0
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern in self.patterns:
            match = re.search(pattern.pattern, error_message, re.IGNORECASE)
            if match:
                # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆãƒãƒƒãƒã—ãŸæ–‡å­—æ•°ã®å‰²åˆï¼‰
                confidence = len(match.group(0)) / len(error_message)
                confidence = min(confidence * 1.2, 1.0)  # ãƒ–ãƒ¼ã‚¹ãƒˆé©ç”¨
                
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = pattern
        
        # åˆ†é¡çµæœä½œæˆ
        if best_match:
            classified = ClassifiedError(
                original_error=error_message,
                category=best_match.category,
                subcategory=best_match.description,
                severity=best_match.severity,
                confidence=best_confidence,
                auto_fix_suggestion=best_match.auto_fix,
                timestamp=datetime.now().isoformat()
            )
        else:
            # æœªåˆ†é¡ã®å ´åˆã¯Otherã¨ã—ã¦å‡¦ç†
            classified = ClassifiedError(
                original_error=error_message,
                category="other",
                subcategory="æœªåˆ†é¡ã‚¨ãƒ©ãƒ¼",
                severity="unknown",
                confidence=0.0,
                timestamp=datetime.now().isoformat()
            )
        
        # çµ±è¨ˆæ›´æ–°
        self.statistics[classified.category] += 1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        self.classified_cache[error_message] = classified
        
        return classified
    
    def bulk_classify_errors(self, error_list: List[str]) -> List[ClassifiedError]:
        """ã‚¨ãƒ©ãƒ¼ãƒªã‚¹ãƒˆã‚’ä¸€æ‹¬åˆ†é¡"""
        results = []
        
        for error in error_list:
            classified = self.classify_error(error)
            results.append(classified)
        
        return results
    
    def analyze_log_file(self, log_file_path: str) -> Dict[str, any]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ã‚’æŠ½å‡ºãƒ»åˆ†æ"""
        log_path = Path(log_file_path)
        
        if not log_path.exists():
            return {"error": f"Log file not found: {log_file_path}"}
        
        errors = []
        error_patterns_found = Counter()
        
        try:
            with open(log_path, 'r', errors='ignore') as f:
                content = f.read()
                
                # ã‚¨ãƒ©ãƒ¼ãƒ©ã‚¤ãƒ³æŠ½å‡º
                error_lines = re.findall(r'ERROR.*?(?=\n|$)', content, re.MULTILINE)
                
                for error_line in error_lines:
                    classified = self.classify_error(error_line)
                    errors.append(classified)
                    error_patterns_found[classified.category] += 1
        
        except Exception as e:
            return {"error": f"Failed to analyze log file: {str(e)}"}
        
        # çµ±è¨ˆæƒ…å ±ç”Ÿæˆ
        analysis = {
            "file": str(log_path),
            "timestamp": datetime.now().isoformat(),
            "total_errors": len(errors),
            "categories": dict(error_patterns_found),
            "classified_errors": errors[:100],  # æœ€åˆã®100ä»¶ã®ã¿ä¿å­˜
            "suggestions": self._generate_suggestions(error_patterns_found)
        }
        
        return analysis
    
    def _generate_suggestions(self, error_counts: Counter) -> List[str]:
        """ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã‹ã‚‰æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        suggestions = []
        
        # æœ€å¤šã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®å¯¾ç­–
        if error_counts:
            top_category = error_counts.most_common(1)[0]
            category, count = top_category
            
            if category == "system":
                suggestions.append(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚ä¾å­˜é–¢ä¿‚ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            elif category == "network":
                suggestions.append(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚æ¥ç¶šè¨­å®šã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            elif category == "database":
                suggestions.append(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚DBæ¥ç¶šã¨ã‚¯ã‚¨ãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            elif category == "memory":
                suggestions.append(f"ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚")
            elif category == "api":
                suggestions.append(f"APIé€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚èªè¨¼æƒ…å ±ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            elif category == "worker":
                suggestions.append(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼ãŒ{count}ä»¶ç™ºç”Ÿã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šã¨ã‚¿ã‚¹ã‚¯å‡¦ç†ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                suggestions.append(f"{category}ã‚«ãƒ†ã‚´ãƒªã§{count}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚")
        
        # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹å ´åˆ
        if len(error_counts) > 3:
            suggestions.append("è¤‡æ•°ã®ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚åŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ç‚¹æ¤œã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        
        return suggestions
    
    def get_statistics(self) -> Dict[str, any]:
        """åˆ†é¡çµ±è¨ˆã‚’å–å¾—"""
        total_errors = sum(self.statistics.values())
        
        return {
            "total_classified": total_errors,
            "categories": dict(self.statistics),
            "cache_size": len(self.classified_cache),
            "timestamp": datetime.now().isoformat()
        }
    
    def export_results(self, output_path: str):
        """åˆ†é¡çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        export_data = {
            "export_timestamp": datetime.now().isoformat(),
            "statistics": self.get_statistics(),
            "patterns_used": len(self.patterns),
            "classified_errors": [
                {
                    "error": error,
                    "category": classified.category,
                    "subcategory": classified.subcategory,
                    "severity": classified.severity,
                    "confidence": classified.confidence,
                    "auto_fix": classified.auto_fix_suggestion
                }
                for error, classified in self.classified_cache.items()
            ]
        }
        
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Classification results exported to {output_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° - ãƒ‡ãƒ¢ã¨ãƒ†ã‚¹ãƒˆ"""
    classifier = EnhancedErrorClassifier()
    
    # ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    test_errors = [
        "ModuleNotFoundError: No module named 'docker'",
        "FileNotFoundError: No such file or directory: '/tmp/test.txt'",
        "PermissionError: [Errno 13] Permission denied: '/etc/config'",
        "ConnectionError: Failed to establish connection to localhost:5432",
        "TimeoutError: Connection timed out after 30 seconds",
        "JSONDecodeError: Expecting ',' delimiter: line 1 column 45",
        "TypeError: unsupported operand type(s) for +: 'int' and 'str'",
        "MemoryError: Unable to allocate memory",
        "HTTPError: 404 Client Error: Not Found",
        "worker task failed with unknown error"
    ]
    
    print("ğŸ” Enhanced Error Classification System ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ã‚¨ãƒ©ãƒ¼åˆ†é¡ãƒ†ã‚¹ãƒˆ
    for error in test_errors:
        classified = classifier.classify_error(error)
        print(f"\nğŸ“ å…ƒã‚¨ãƒ©ãƒ¼: {error[:50]}...")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {classified.category}")
        print(f"   è©³ç´°: {classified.subcategory}")
        print(f"   é‡è¦åº¦: {classified.severity}")
        print(f"   ä¿¡é ¼åº¦: {classified.confidence:.2f}")
        if classified.auto_fix_suggestion:
            print(f"   ä¿®æ­£æ¡ˆ: {classified.auto_fix_suggestion}")
    
    # çµ±è¨ˆè¡¨ç¤º
    print(f"\nğŸ“Š åˆ†é¡çµ±è¨ˆ:")
    stats = classifier.get_statistics()
    for category, count in stats["categories"].items():
        print(f"   {category}: {count}ä»¶")
    
    print(f"\nâœ… Enhanced Error Classification System ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()