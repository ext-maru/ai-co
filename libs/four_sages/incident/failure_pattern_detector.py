#!/usr/bin/env python3
"""
ğŸ” Failure Pattern Detector - å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
Phase 26: Incident Sageçµ±åˆå®Ÿè£…
Created: 2025-07-17
Author: Claude Elder
Version: 1.0.0
"""

import asyncio
import json
import logging
import re
import sqlite3
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

# Elders Legacy Integration
from core.elders_legacy import EldersAILegacy
from libs.four_sages.incident.incident_sage import IncidentCategory, IncidentSeverity

logger = logging.getLogger("failure_pattern_detector")


@dataclass
class FailurePattern:
    """å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿æ§‹é€ """

    pattern_id: str
    pattern_type: str  # "error_message", "time_series", "resource", "dependency"
    category: IncidentCategory
    severity: IncidentSeverity
    description: str
    detection_rules: List[Dict]
    occurrence_count: int
    first_seen: datetime
    last_seen: datetime
    affected_systems: List[str]
    resolution_actions: List[str]
    confidence_score: float
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "pattern_id": self.pattern_id,
            "pattern_type": self.pattern_type,
            "category": self.category.value,
            "severity": self.severity.value,
            "description": self.description,
            "detection_rules": self.detection_rules,
            "occurrence_count": self.occurrence_count,
            "first_seen": self.first_seen.isoformat(),
            "last_seen": self.last_seen.isoformat(),
            "affected_systems": self.affected_systems,
            "resolution_actions": self.resolution_actions,
            "confidence_score": self.confidence_score,
            "metadata": self.metadata,
        }


class FailurePatternDetector(EldersAILegacy):
    """å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        tracking_db_path: str = "elder_flow_tracking.db",
        incident_db_path: str = "data/incident_sage.db",
    ):
        super().__init__(
            name="FailurePatternDetector", model_type="pattern-detection-v1"
        )
        self.tracking_db_path = tracking_db_path
        self.incident_db_path = incident_db_path
        self.pattern_registry: Dict[str, FailurePattern] = {}
        self.pattern_threshold = 3  # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜é–¾å€¤
        self.analysis_window = timedelta(days=30)  # åˆ†æå¯¾è±¡æœŸé–“

        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒ«ãƒ¼ãƒ«
        self.error_patterns = {
            "timeout": r"(timeout|timed out|deadline exceeded)",
            "memory": r"(out of memory|memory error|oom|heap space)",
            "connection": r"(connection refused|connection error|cannot connect)",
            "permission": r"(permission denied|access denied|unauthorized)",
            "notfound": r"(not found|404|missing|does not exist)",
            "syntax": r"(syntax error|parse error|invalid syntax)",
            "dependency": r"(dependency error|import error|module not found)",
            "disk": r"(disk full|no space left|storage error)",
        }

        logger.info("ğŸ” Failure Pattern Detector initialized")

    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        request_type = request.get("type", "analyze")

        if request_type == "analyze":
            return await self._analyze_failures(request)
        elif request_type == "detect":
            return await self._detect_patterns(request)
        elif request_type == "predict":
            return await self._predict_failure(request)
        elif request_type == "get_patterns":
            return await self._get_patterns(request)
        else:
            return {"success": False, "error": f"Unknown request type: {request_type}"}

    async def analyze_historical_failures(self, days_back: int = 30) -> Dict[str, Any]:
        """éå»ã®å¤±æ•—ãƒ‡ãƒ¼ã‚¿åˆ†æ"""
        try:
            logger.info(f"ğŸ” Analyzing failures from past {days_back} days")

            # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å¤±æ•—ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            failures = await self._extract_failure_data(days_back)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
            patterns = await self._extract_patterns(failures)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡ã¨è©•ä¾¡
            for pattern in patterns:
                classified = await self._classify_pattern(pattern)
                severity = await self._evaluate_pattern_severity(pattern)
                pattern["category"] = classified
                pattern["severity"] = severity

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¸ã‚¹ãƒˆãƒªæ›´æ–°
            await self._update_pattern_registry(patterns)

            return {
                "success": True,
                "total_failures": len(failures),
                "patterns_found": len(patterns),
                "pattern_summary": self._summarize_patterns(patterns),
            }

        except Exception as e:
            logger.error(f"âŒ Historical analysis failed: {e}")
            return {"success": False, "error": str(e)}

    async def _extract_failure_data(self, days_back: int) -> List[Dict[str, Any]]:
        """å¤±æ•—ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        failures = []
        cutoff_date = datetime.now() - timedelta(days=days_back)

        try:
            conn = sqlite3.connect(self.tracking_db_path)
            conn.row_factory = sqlite3.Row

            # å¤±æ•—ã—ãŸå®Ÿè¡Œè©³ç´°ã‚’å–å¾—
            cursor = conn.execute(
                """
                SELECT ed.*, t.description as task_description, t.priority
                FROM execution_details ed
                JOIN tasks t ON ed.task_id = t.task_id
                WHERE ed.success = 0
                AND ed.timestamp > ?
                ORDER BY ed.timestamp DESC
            """,
                (cutoff_date.isoformat(),),
            )

            for row in cursor:
                failure = {
                    "task_id": row["task_id"],
                    "task_description": row["task_description"],
                    "detail_type": row["detail_type"],
                    "command": row["command"],
                    "stderr": row["stderr"],
                    "exit_code": row["exit_code"],
                    "execution_time": row["execution_time"],
                    "timestamp": row["timestamp"],
                    "priority": row["priority"],
                }
                failures.append(failure)

            conn.close()
            logger.info(f"ğŸ“Š Extracted {len(failures)} failure records")
            return failures

        except Exception as e:
            logger.error(f"âŒ Failed to extract failure data: {e}")
            return []

    async def _extract_patterns(
        self, failures: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        patterns = []

        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³
        error_patterns = await self._extract_error_patterns(failures)
        patterns.extend(error_patterns)

        # æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³
        time_patterns = await self._extract_time_patterns(failures)
        patterns.extend(time_patterns)

        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        resource_patterns = await self._extract_resource_patterns(failures)
        patterns.extend(resource_patterns)

        # ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³
        dependency_patterns = await self._extract_dependency_patterns(failures)
        patterns.extend(dependency_patterns)

        return patterns

    async def _extract_error_patterns(
        self, failures: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        error_groups = defaultdict(list)

        # ç¹°ã‚Šè¿”ã—å‡¦ç†
        for failure in failures:
            stderr = failure.get("stderr", "")
            if not stderr:
                continue

            # æ—¢çŸ¥ã®ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãƒãƒƒãƒãƒ³ã‚°
            for pattern_name, pattern_regex in self.error_patterns.items():
                if re.search(pattern_regex, stderr, re.IGNORECASE):
                    error_groups[pattern_name].append(failure)
                    break
            else:
                # æœªçŸ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ±ç”¨ã‚°ãƒ«ãƒ¼ãƒ—ã¸
                error_groups["unknown"].append(failure)

        # ãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–
        patterns = []
        for pattern_name, failures_list in error_groups.items():
            if len(failures_list) >= self.pattern_threshold:
                pattern = {
                    "pattern_type": "error_message",
                    "pattern_name": pattern_name,
                    "occurrences": len(failures_list),
                    "examples": failures_list[:5],  # æœ€åˆã®5ä¾‹
                    "affected_tasks": list(set(f["task_id"] for f in failures_list)),
                    "common_stderr": self._find_common_substring(
                        [f["stderr"] for f in failures_list]
                    ),
                }
                patterns.append(pattern)

        return patterns

    async def _extract_time_patterns(
        self, failures: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        patterns = []

        # æ™‚é–“å¸¯åˆ¥ã®å¤±æ•—å‚¾å‘
        hourly_failures = defaultdict(list)
        for failure in failures:
            timestamp = datetime.fromisoformat(failure["timestamp"])
            hour = timestamp.hour
            hourly_failures[hour].append(failure)

        # ç‰¹å®šæ™‚é–“å¸¯ã«é›†ä¸­ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        for hour, failures_list in hourly_failures.items():
            if len(failures_list) >= self.pattern_threshold * 2:
                pattern = {
                    "pattern_type": "time_series",
                    "pattern_name": f"peak_hour_{hour}",
                    "occurrences": len(failures_list),
                    "time_window": f"{hour:02d}:00-{hour:02d}:59",
                    "failure_rate": len(failures_list) / len(failures),
                }
                patterns.append(pattern)

        return patterns

    async def _extract_resource_patterns(
        self, failures: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        patterns = []

        # å®Ÿè¡Œæ™‚é–“ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
        execution_times = [
            f["execution_time"] for f in failures if f["execution_time"] > 0
        ]
        if execution_times:
            avg_time = sum(execution_times) / len(execution_times)
            slow_failures = [f for f in failures if f["execution_time"] > avg_time * 2]

            if len(slow_failures) >= self.pattern_threshold:
                pattern = {
                    "pattern_type": "resource",
                    "pattern_name": "slow_execution",
                    "occurrences": len(slow_failures),
                    "average_execution_time": sum(
                        f["execution_time"] for f in slow_failures
                    )
                    / len(slow_failures),
                    "threshold": avg_time * 2,
                }
                patterns.append(pattern)

        return patterns

    async def _extract_dependency_patterns(
        self, failures: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        patterns = []

        # é€£é–çš„ãªå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³
        task_failures = defaultdict(list)
        for failure in failures:
            task_failures[failure["task_id"]].append(failure)

        # é »ç¹ã«å¤±æ•—ã™ã‚‹ã‚¿ã‚¹ã‚¯ã®çµ„ã¿åˆã‚ã›ã‚’æ¤œå‡º
        failure_chains = []
        for task_id, failures_list in task_failures.items():
            if len(failures_list) >= self.pattern_threshold:
                # è¿‘ã„æ™‚é–“ã«ç™ºç”Ÿã—ãŸä»–ã®ã‚¿ã‚¹ã‚¯ã®å¤±æ•—ã‚’æ¢ã™
                related_failures = self._find_related_failures(task_id, failures)
                if related_failures:
                    failure_chains.append(
                        {
                            "primary_task": task_id,
                            "related_tasks": related_failures,
                            "occurrences": len(failures_list),
                        }
                    )

        if failure_chains:
            pattern = {
                "pattern_type": "dependency",
                "pattern_name": "failure_chain",
                "chains": failure_chains,
                "total_chains": len(failure_chains),
            }
            patterns.append(pattern)

        return patterns

    def _find_related_failures(
        self, task_id: str, all_failures: List[Dict[str, Any]]
    ) -> List[str]:
        """é–¢é€£ã™ã‚‹å¤±æ•—ã‚’æ¤œå‡º"""
        related = set()
        task_failures = [f for f in all_failures if f["task_id"] == task_id]

        for failure in task_failures:
            failure_time = datetime.fromisoformat(failure["timestamp"])
            # å‰å¾Œ5åˆ†ä»¥å†…ã®ä»–ã®ã‚¿ã‚¹ã‚¯ã®å¤±æ•—ã‚’æ¢ã™
            for other in all_failures:
                if other["task_id"] != task_id:
                    other_time = datetime.fromisoformat(other["timestamp"])
                    if abs((failure_time - other_time).total_seconds()) <= 300:
                        related.add(other["task_id"])

        return list(related)

    def _find_common_substring(self, strings: List[str]) -> str:
        """å…±é€šéƒ¨åˆ†æ–‡å­—åˆ—ã‚’æ¤œå‡º"""
        if not strings:
            return ""

        # ç°¡æ˜“çš„ãªå…±é€šéƒ¨åˆ†æ¤œå‡º
        words_counter = Counter()
        for s in strings:
            words = s.lower().split()
            words_counter.update(words)

        # æœ€ã‚‚é »å‡ºã™ã‚‹å˜èªã‚’è¿”ã™
        common_words = [
            word
            for word, count in words_counter.most_common(5)
            if count >= len(strings) * 0.5
        ]
        return " ".join(common_words)

    async def _classify_pattern(self, pattern: Dict[str, Any]) -> IncidentCategory:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡"""
        pattern_type = pattern.get("pattern_type", "")
        pattern_name = pattern.get("pattern_name", "")

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š
        if pattern_type == "error_message":
            if pattern_name in ["timeout", "slow_execution"]:
                return IncidentCategory.PERFORMANCE_ISSUE
            elif pattern_name in ["connection", "network"]:
                return IncidentCategory.NETWORK_ISSUE
            elif pattern_name in ["permission", "unauthorized"]:
                return IncidentCategory.SECURITY_BREACH
            elif pattern_name in ["syntax", "dependency"]:
                return IncidentCategory.CONFIGURATION_ERROR
            elif pattern_name in ["memory", "disk"]:
                return IncidentCategory.SYSTEM_FAILURE
        elif pattern_type == "dependency":
            return IncidentCategory.SYSTEM_FAILURE
        elif pattern_type == "resource":
            return IncidentCategory.PERFORMANCE_ISSUE

        return IncidentCategory.SYSTEM_FAILURE  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    async def _evaluate_pattern_severity(
        self, pattern: Dict[str, Any]
    ) -> IncidentSeverity:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³é‡è¦åº¦è©•ä¾¡"""
        occurrences = pattern.get("occurrences", 0)
        pattern_type = pattern.get("pattern_type", "")

        # ç™ºç”Ÿé »åº¦ãƒ™ãƒ¼ã‚¹ã®é‡è¦åº¦
        if occurrences >= 50:
            base_severity = IncidentSeverity.CRITICAL
        elif occurrences >= 20:
            base_severity = IncidentSeverity.HIGH
        elif occurrences >= 10:
            base_severity = IncidentSeverity.MEDIUM
        else:
            base_severity = IncidentSeverity.LOW

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹èª¿æ•´
        if pattern_type == "dependency":
            # ä¾å­˜é–¢ä¿‚ã®å¤±æ•—ã¯å½±éŸ¿ãŒå¤§ãã„
            if base_severity == IncidentSeverity.MEDIUM:
                return IncidentSeverity.HIGH
            elif base_severity == IncidentSeverity.LOW:
                return IncidentSeverity.MEDIUM

        return base_severity

    async def _update_pattern_registry(self, patterns: List[Dict[str, Any]]):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¸ã‚¹ãƒˆãƒªæ›´æ–°"""
        for pattern_data in patterns:
            pattern_id = (
                f"{pattern_data['pattern_type']}_{pattern_data['pattern_name']}"
            )

            if pattern_id in self.pattern_registry:
                # æ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³æ›´æ–°
                existing = self.pattern_registry[pattern_id]
                existing.occurrence_count += pattern_data.get("occurrences", 0)
                existing.last_seen = datetime.now()
                existing.confidence_score = min(1.0, existing.confidence_score + 0.1)
            else:
                # æ–°è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ç™»éŒ²
                pattern = FailurePattern(
                    pattern_id=pattern_id,
                    pattern_type=pattern_data["pattern_type"],
                    category=pattern_data.get(
                        "category", IncidentCategory.SYSTEM_FAILURE
                    ),
                    severity=pattern_data.get("severity", IncidentSeverity.MEDIUM),
                    description=f"Pattern: {pattern_data['pattern_name']}",
                    detection_rules=[pattern_data],
                    occurrence_count=pattern_data.get("occurrences", 0),
                    first_seen=datetime.now(),
                    last_seen=datetime.now(),
                    affected_systems=pattern_data.get("affected_tasks", []),
                    resolution_actions=[],
                    confidence_score=0.5,
                    metadata=pattern_data,
                )
                self.pattern_registry[pattern_id] = pattern

    def _summarize_patterns(self, patterns: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        summary = {
            "by_type": defaultdict(int),
            "by_severity": defaultdict(int),
            "total_occurrences": 0,
        }

        for pattern in patterns:
            pattern_type = pattern.get("pattern_type", "unknown")
            severity = pattern.get("severity", IncidentSeverity.MEDIUM)
            occurrences = pattern.get("occurrences", 0)

            summary["by_type"][pattern_type] += 1
            summary["by_severity"][severity.value] += 1
            summary["total_occurrences"] += occurrences

        return {
            "by_type": dict(summary["by_type"]),
            "by_severity": dict(summary["by_severity"]),
            "total_occurrences": summary["total_occurrences"],
        }

    async def predict_failure(self, current_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """å¤±æ•—äºˆæ¸¬"""
        try:
            predictions = []

            # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã—ã¦äºˆæ¸¬ç¢ºç‡ã‚’è¨ˆç®—
            for pattern_id, pattern in self.pattern_registry.items():
                probability = await self._calculate_failure_probability(
                    pattern, current_metrics
                )
                if probability > 0.3:  # 30%ä»¥ä¸Šã®ç¢ºç‡ã§è­¦å‘Š
                    predictions.append(
                        {
                            "pattern_id": pattern_id,
                            "probability": probability,
                            "severity": pattern.severity.value,
                            "category": pattern.category.value,
                            "description": pattern.description,
                            "recommended_actions": self._get_recommended_actions(
                                pattern
                            ),
                        }
                    )

            # ç¢ºç‡é †ã«ã‚½ãƒ¼ãƒˆ
            predictions.sort(key=lambda x: x["probability"], reverse=True)

            return {
                "success": True,
                "predictions": predictions[:5],  # ä¸Šä½5ä»¶
                "highest_risk": predictions[0] if predictions else None,
                "risk_level": self._calculate_overall_risk(predictions),
            }

        except Exception as e:
            logger.error(f"âŒ Failure prediction failed: {e}")
            return {"success": False, "error": str(e)}

    async def _calculate_failure_probability(
        self, pattern: FailurePattern, current_metrics: Dict[str, Any]
    ) -> float:
        """å¤±æ•—ç¢ºç‡è¨ˆç®—"""
        base_probability = 0.0

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’åŸºæº–ã«
        base_probability = pattern.confidence_score * 0.3

        # æœ€è¿‘ã®ç™ºç”Ÿé »åº¦ã‚’è€ƒæ…®
        time_since_last = (
            datetime.now() - pattern.last_seen
        ).total_seconds() / 3600  # æ™‚é–“å˜ä½
        if time_since_last < 1:  # 1æ™‚é–“ä»¥å†…
            base_probability += 0.3
        elif time_since_last < 24:  # 24æ™‚é–“ä»¥å†…
            base_probability += 0.2
        elif time_since_last < 168:  # 1é€±é–“ä»¥å†…
            base_probability += 0.1

        # ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã®é¡ä¼¼åº¦
        if pattern.pattern_type == "resource":
            # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã‚’ãƒã‚§ãƒƒã‚¯
            cpu_usage = current_metrics.get("cpu_usage", 0)
            memory_usage = current_metrics.get("memory_usage", 0)
            if cpu_usage > 80 or memory_usage > 80:
                base_probability += 0.2

        return min(1.0, base_probability)

    def _get_recommended_actions(self, pattern: FailurePattern) -> List[str]:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å–å¾—"""
        actions = []

        if pattern.pattern_type == "error_message":
            if "timeout" in pattern.pattern_id:
                actions.extend(
                    [
                        "Increase timeout values",
                        "Optimize slow operations",
                        "Check network latency",
                    ]
                )
            elif "memory" in pattern.pattern_id:
                actions.extend(
                    [
                        "Increase memory allocation",
                        "Check for memory leaks",
                        "Optimize memory usage",
                    ]
                )
            elif "connection" in pattern.pattern_id:
                actions.extend(
                    [
                        "Check network connectivity",
                        "Verify service availability",
                        "Review firewall rules",
                    ]
                )
        elif pattern.pattern_type == "resource":
            actions.extend(
                [
                    "Scale up resources",
                    "Optimize resource usage",
                    "Implement resource limits",
                ]
            )
        elif pattern.pattern_type == "dependency":
            actions.extend(
                [
                    "Review dependency chain",
                    "Implement circuit breakers",
                    "Add retry mechanisms",
                ]
            )

        return actions

    def _calculate_overall_risk(self, predictions: List[Dict[str, Any]]) -> str:
        """å…¨ä½“çš„ãªãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è¨ˆç®—"""
        if not predictions:
            return "low"

        # æœ€é«˜ç¢ºç‡ã¨ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªäºˆæ¸¬ã®æ•°ã‚’è€ƒæ…®
        max_probability = max(p["probability"] for p in predictions)
        critical_count = sum(1 for p in predictions if p["severity"] == "critical")

        if max_probability > 0.8 or critical_count >= 2:
            return "critical"
        elif max_probability > 0.6 or critical_count >= 1:
            return "high"
        elif max_probability > 0.4:
            return "medium"
        else:
            return "low"

    async def _analyze_failures(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """å¤±æ•—åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        days_back = request.get("days_back", 30)
        return await self.analyze_historical_failures(days_back)

    async def _detect_patterns(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        failures = request.get("failures", [])
        patterns = await self._extract_patterns(failures)
        return {"success": True, "patterns": patterns, "count": len(patterns)}

    async def _predict_failure(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """å¤±æ•—äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        metrics = request.get("metrics", {})
        return await self.predict_failure(metrics)

    async def _get_patterns(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        pattern_type = request.get("pattern_type")
        severity = request.get("severity")

        patterns = []
        for pattern_id, pattern in self.pattern_registry.items():
            if pattern_type and pattern.pattern_type != pattern_type:
                continue
            if severity and pattern.severity.value != severity:
                continue
            patterns.append(pattern.to_dict())

        return {"success": True, "patterns": patterns, "count": len(patterns)}

    def get_capabilities(self) -> List[str]:
        """èƒ½åŠ›ä¸€è¦§"""
        return [
            "failure_pattern_detection",
            "pattern_classification",
            "severity_evaluation",
            "failure_prediction",
            "risk_assessment",
            "recommendation_generation",
        ]


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = ["FailurePatternDetector", "FailurePattern"]
