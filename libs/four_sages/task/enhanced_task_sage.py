#!/usr/bin/env python3
"""
Enhanced Task Sage - è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç‰ˆ
Created: 2025-07-17
Author: Claude Elder
"""

import asyncio
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from libs.four_sages.task.task_sage import TaskSage, TaskEntry, TaskStatus
from libs.four_sages.task.dynamic_priority_engine import DynamicPriorityEngine
from libs.four_sages.task.execution_time_predictor import ExecutionTimePredictor
from libs.four_sages.task.resource_optimization_engine import ResourceOptimizationEngine
from libs.four_sages.task.task_scheduling_optimizer import TaskSchedulingOptimizer, SchedulingConstraint
from libs.tracking.unified_tracking_db import UnifiedTrackingDB
from core.lightweight_logger import get_logger

logger = get_logger("enhanced_task_sage")

class EnhancedTaskSage(TaskSage):
    """è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç‰ˆ Task Sage"""
    
    def __init__(self):
        super().__init__()
        
        # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.tracking_db = UnifiedTrackingDB()
        
        # çµ±åˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.priority_engine = DynamicPriorityEngine(self, self.tracking_db)
        self.time_predictor = ExecutionTimePredictor(self.tracking_db)
        self.resource_engine = ResourceOptimizationEngine(self, self.tracking_db)
        self.scheduling_optimizer = TaskSchedulingOptimizer(
            self, self.priority_engine, self.time_predictor
        )
        
        # æ‹¡å¼µæ©Ÿèƒ½ãƒ•ãƒ©ã‚°
        self.enhanced_features = {
            'dynamic_priority': True,
            'time_prediction': True,
            'resource_optimization': True,
            'smart_scheduling': True
        }
        
        logger.info("ğŸš€ Enhanced Task Sage initialized with tracking integration")
    
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """æ‹¡å¼µãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        request_type = request.get("type", "unknown")
        
        # æ–°ã—ã„çµ±åˆæ©Ÿèƒ½ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
        if request_type == "optimize_schedule":
            return await self._optimize_schedule_request(request)
        elif request_type == "predict_completion":
            return await self._predict_completion_request(request)
        elif request_type == "analyze_resources":
            return await self._analyze_resources_request(request)
        elif request_type == "get_recommendations":
            return await self._get_recommendations_request(request)
        elif request_type == "update_tracking":
            return await self._update_tracking_request(request)
        else:
            # åŸºæœ¬ã‚¯ãƒ©ã‚¹ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return await super().process_request(request)
    
    async def _optimize_schedule_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            # å¯¾è±¡ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            status = request.get("status", "pending")
            tasks = await self.database.search_tasks(
                status=TaskStatus(status),
                limit=request.get("limit", 100)
            )
            
            if not tasks:
                return {
                    "success": True,
                    "message": "No tasks to optimize",
                    "optimized_schedule": []
                }
            
            # åˆ¶ç´„æ¡ä»¶ã‚’è¨­å®š
            constraints = SchedulingConstraint(
                max_parallel_tasks=request.get("max_parallel", 10),
                respect_due_dates=request.get("respect_due_dates", True),
                allow_overtime=request.get("allow_overtime", False)
            )
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–å®Ÿè¡Œ
            optimized_schedule = await self.scheduling_optimizer.optimize_schedule(
                tasks, constraints
            )
            
            # ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–ã‚‚å®Ÿè¡Œ
            resource_result = await self.resource_engine.optimize_resource_allocation(tasks)
            
            # çµæœã‚’çµ±åˆ
            schedule_data = []
            for scheduled_task in optimized_schedule:
                schedule_data.append({
                    'task_id': scheduled_task.task.id,
                    'title': scheduled_task.task.title,
                    'priority': scheduled_task.task.priority.value,
                    'dynamic_priority': scheduled_task.dynamic_priority,
                    'scheduled_start': scheduled_task.scheduled_start.isoformat(),
                    'scheduled_end': scheduled_task.scheduled_end.isoformat(),
                    'predicted_duration': scheduled_task.predicted_time,
                    'parallel_group': scheduled_task.parallel_group
                })
            
            # ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆ
            gantt_data = self.scheduling_optimizer.get_gantt_chart_data(optimized_schedule)
            
            return {
                "success": True,
                "optimized_schedule": schedule_data,
                "gantt_chart": gantt_data,
                "resource_optimization": resource_result,
                "metrics": {
                    "total_tasks": len(tasks),
                    "scheduled_tasks": len(optimized_schedule),
                    "parallelization_factor": resource_result.get('parallel_groups', []),
                    "estimated_total_time": sum(st.predicted_time for st in optimized_schedule)
                }
            }
            
        except Exception as e:
            logger.error(f"Schedule optimization failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _predict_completion_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """å®Œäº†æ™‚é–“äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            task_id = request.get("task_id")
            if not task_id:
                return {
                    "success": False,
                    "error": "Task ID required"
                }
            
            # ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            task = await self.database.retrieve_task(task_id)
            if not task:
                return {
                    "success": False,
                    "error": "Task not found"
                }
            
            # å®Ÿè¡Œæ™‚é–“äºˆæ¸¬
            predicted_time, confidence_interval = await self.time_predictor.predict_execution_time(task)
            
            # å‹•çš„å„ªå…ˆåº¦è¨ˆç®—
            dynamic_priority = await self.priority_engine.calculate_dynamic_priority(task)
            
            # ç¾åœ¨ã®å®Ÿè¡ŒçŠ¶æ³ã‚’è€ƒæ…®ã—ãŸé–‹å§‹æ™‚åˆ»äºˆæ¸¬
            pending_tasks = await self.database.search_tasks(
                status=TaskStatus.PENDING,
                limit=100
            )
            
            # ç°¡æ˜“çš„ãªé–‹å§‹æ™‚åˆ»è¨ˆç®—
            queue_position = len([t for t in pending_tasks if t.id != task_id])
            estimated_start = datetime.now() + timedelta(seconds=queue_position * 300)  # 5åˆ†/ã‚¿ã‚¹ã‚¯
            estimated_end = estimated_start + timedelta(seconds=predicted_time)
            
            return {
                "success": True,
                "prediction": {
                    "task_id": task_id,
                    "predicted_duration_seconds": predicted_time,
                    "confidence_interval": {
                        "lower": confidence_interval[0],
                        "upper": confidence_interval[1]
                    },
                    "dynamic_priority": dynamic_priority,
                    "estimated_start": estimated_start.isoformat(),
                    "estimated_completion": estimated_end.isoformat(),
                    "queue_position": queue_position
                },
                "accuracy_metrics": self.time_predictor.get_model_accuracy(task.task_type)
            }
            
        except Exception as e:
            logger.error(f"Completion prediction failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _analyze_resources_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªã‚½ãƒ¼ã‚¹åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
            current_resources = await self.resource_engine.resource_monitor.get_current_usage()
            
            # å®Ÿè¡Œä¸­ã‚¿ã‚¹ã‚¯ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
            executing_tasks = await self.database.search_tasks(
                status=TaskStatus.IN_PROGRESS,
                limit=50
            )
            
            # ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã‚¹ã‚³ã‚¢
            efficiency_score = self.resource_engine.get_resource_efficiency_score()
            
            # å¹³å‡ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
            avg_resources = self.resource_engine.resource_monitor.get_average_usage(minutes=10)
            
            return {
                "success": True,
                "resource_analysis": {
                    "current": {
                        "cpu_percent": current_resources.cpu_percent,
                        "memory_percent": current_resources.memory_percent,
                        "cpu_cores": current_resources.cpu_cores,
                        "memory_available_gb": current_resources.memory_available_gb,
                        "disk_io_mb": current_resources.disk_io_read_mb + current_resources.disk_io_write_mb,
                        "network_io_mb": current_resources.network_io_send_mb + current_resources.network_io_recv_mb
                    },
                    "average_10min": {
                        "cpu_percent": avg_resources.cpu_percent if avg_resources else 0,
                        "memory_percent": avg_resources.memory_percent if avg_resources else 0
                    } if avg_resources else None,
                    "executing_tasks": len(executing_tasks),
                    "efficiency_score": efficiency_score,
                    "recommendations": [
                        f"System is {'healthy' if efficiency_score > 0.7 else 'under stress'}",
                        f"{len(executing_tasks)} tasks currently executing"
                    ]
                }
            }
            
        except Exception as e:
            logger.error(f"Resource analysis failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _get_recommendations_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯æ¨å¥¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            limit = request.get("limit", 10)
            
            # å‹•çš„å„ªå…ˆåº¦ã«åŸºã¥ãæ¨å¥¨ã‚¿ã‚¹ã‚¯
            priority_recommendations = await self.priority_engine.get_priority_recommendations(limit)
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            schedule_metrics = await self.scheduling_optimizer.get_schedule_metrics()
            
            # ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–æ¨å¥¨
            pending_tasks = await self.database.search_tasks(
                status=TaskStatus.PENDING,
                limit=50
            )
            
            resource_optimization = await self.resource_engine.optimize_resource_allocation(
                pending_tasks[:limit]
            )
            
            return {
                "success": True,
                "recommendations": {
                    "priority_tasks": priority_recommendations,
                    "schedule_metrics": schedule_metrics,
                    "resource_recommendations": resource_optimization.get('recommendations', []),
                    "summary": {
                        "high_priority_count": len([r for r in priority_recommendations if r['dynamic_priority'] > 100]),
                        "optimal_parallel_groups": len(resource_optimization.get('parallel_groups', [])),
                        "system_efficiency": self.resource_engine.get_resource_efficiency_score()
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"Get recommendations failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _update_tracking_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """è¿½è·¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            task_id = request.get("task_id")
            if not task_id:
                return {
                    "success": False,
                    "error": "Task ID required"
                }
            
            # ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            task = await self.database.retrieve_task(task_id)
            if not task:
                return {
                    "success": False,
                    "error": "Task not found"
                }
            
            # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            tracking_data = {
                'task_id': task_id,
                'description': task.title,
                'priority': task.priority.value,
                'status': task.status.value,
                'created_at': task.created_at,
                'metadata': {
                    'task_type': task.task_type.value,
                    'tags': list(task.tags),
                    'dependency_count': len(task.dependencies),
                    'resource_count': len(task.resources),
                    'has_due_date': task.due_date is not None,
                    'description_length': len(task.description),
                    'estimated_hours': task.estimated_duration.total_seconds() / 3600 if task.estimated_duration else 0
                }
            }
            
            # å®Ÿè¡Œæ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
            if task.actual_duration:
                tracking_data['execution_time_seconds'] = task.actual_duration.total_seconds()
                tracking_data['completed_at'] = task.completed_at
                
                # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
                await self.time_predictor.update_prediction(
                    task_id, task.actual_duration.total_seconds()
                )
                
                # å„ªå…ˆåº¦å­¦ç¿’ã‚’æ›´æ–°
                performance_data = {
                    'success': task.status == TaskStatus.COMPLETED,
                    'execution_time': task.actual_duration.total_seconds(),
                    'quality_score': 0.8  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                }
                await self.priority_engine.update_priority_learning(task_id, performance_data)
            
            # UnifiedTrackingDBã«è¨˜éŒ²
            result = self.tracking_db.create_task(
                task_id=task_id,
                description=task.title,
                priority=task.priority.value,
                metadata=tracking_data['metadata']
            )
            
            return {
                "success": True,
                "message": "Tracking data updated",
                "task_id": task_id,
                "tracking_result": result
            }
            
        except Exception as e:
            logger.error(f"Update tracking failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_capabilities(self) -> List[str]:
        """æ‹¡å¼µèƒ½åŠ›ä¸€è¦§"""
        base_capabilities = super().get_capabilities()
        enhanced_capabilities = [
            "dynamic_priority_calculation",     # å‹•çš„å„ªå…ˆåº¦è¨ˆç®—
            "execution_time_prediction",        # å®Ÿè¡Œæ™‚é–“äºˆæ¸¬
            "resource_optimization",            # ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–
            "smart_task_scheduling",           # ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
            "performance_tracking",            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
            "ml_based_predictions",            # æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
            "real_time_monitoring",            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
            "advanced_analytics"               # é«˜åº¦ãªåˆ†æ
        ]
        
        return base_capabilities + enhanced_capabilities

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
enhanced_task_sage = None

def get_enhanced_task_sage_instance():
    """Enhanced Task Sage ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global enhanced_task_sage
    if enhanced_task_sage is None:
        enhanced_task_sage = EnhancedTaskSage()
    return enhanced_task_sage

# Export
__all__ = ['EnhancedTaskSage', 'get_enhanced_task_sage_instance']