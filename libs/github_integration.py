#!/usr/bin/env python3
"""
GitHubé€£æºå¼·åŒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
"""
import os
import json
import logging
import subprocess
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import requests
from pathlib import Path

logger = logging.getLogger(__name__)

class GitHubIntegrationManager:
    def __init__(self, repo_url: str = None, token: str = None):
        self.repo_url = repo_url or self._get_repo_url()
        self.token = token or os.getenv('GITHUB_TOKEN')
        self.api_base = "https://api.github.com"
        
        # ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’è§£æ
        if self.repo_url:
            self._parse_repo_info()
    
    def _get_repo_url(self) -> Optional[str]:
        """ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªURLã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ['git', 'config', '--get', 'remote.origin.url'],
                capture_output=True, text=True
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except:
            pass
        return None
    
    def _parse_repo_info(self):
        """ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’è§£æ"""
        # SSH URL: git@github.com:owner/repo.git
        # HTTPS URL: https://github.com/owner/repo.git
        if 'github.com' in self.repo_url:
            if self.repo_url.startswith('git@'):
                parts = self.repo_url.split(':')[1].replace('.git', '').split('/')
            else:
                parts = self.repo_url.split('github.com/')[1].replace('.git', '').split('/')
            
            self.owner = parts[0]
            self.repo = parts[1]
            self.api_repo_url = f"{self.api_base}/repos/{self.owner}/{self.repo}"
        else:
            self.owner = None
            self.repo = None
            self.api_repo_url = None
    
    def get_repository_structure(self, path: str = "") -> List[Dict]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®æ§‹é€ ã‚’å–å¾—"""
        if not self.api_repo_url:
            logger.error("ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        url = f"{self.api_repo_url}/contents/{path}"
        headers = {'Authorization': f'token {self.token}'} if self.token else {}
        
        try:
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"GitHub API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return []
        except Exception as e:
            logger.error(f"ãƒªãƒã‚¸ãƒˆãƒªæ§‹é€ å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_file_content(self, file_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—"""
        url = f"{self.api_repo_url}/contents/{file_path}"
        headers = {'Authorization': f'token {self.token}'} if self.token else {}
        
        try:
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                data = response.json()
                if data.get('content'):
                    import base64
                    content = base64.b64decode(data['content']).decode('utf-8')
                    return content
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None
    
    def analyze_codebase(self, target_dirs: List[str] = ['libs', 'workers']) -> Dict:
        """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’åˆ†æ"""
        analysis = {
            'total_files': 0,
            'file_types': {},
            'key_modules': [],
            'dependencies': set(),
            'structure': {}
        }
        
        for target_dir in target_dirs:
            files = self.get_repository_structure(target_dir)
            
            for file_info in files:
                if file_info['type'] == 'file':
                    analysis['total_files'] += 1
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—çµ±è¨ˆ
                    ext = Path(file_info['name']).suffix
                    analysis['file_types'][ext] = analysis['file_types'].get(ext, 0) + 1
                    
                    # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€å†…å®¹ã‚’åˆ†æ
                    if ext == '.py':
                        content = self.get_file_content(file_info['path'])
                        if content:
                            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆåˆ†æ
                            imports = self._extract_imports(content)
                            analysis['dependencies'].update(imports)
                            
                            # ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
                            if any(keyword in content for keyword in ['class', 'def']):
                                analysis['key_modules'].append({
                                    'path': file_info['path'],
                                    'name': file_info['name'],
                                    'size': file_info['size']
                                })
        
        analysis['dependencies'] = list(analysis['dependencies'])
        return analysis
    
    def _extract_imports(self, content: str) -> set:
        """ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æŠ½å‡º"""
        imports = set()
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('import '):
                module = line.split()[1].split('.')[0]
                imports.add(module)
            elif line.startswith('from '):
                parts = line.split()
                if len(parts) > 1:
                    module = parts[1].split('.')[0]
                    imports.add(module)
        
        return imports
    
    def create_enhanced_commit(self, task_id: str, files_changed: List[str], 
                             task_summary: str) -> bool:
        """å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒŸãƒƒãƒˆï¼ˆè©³ç´°ãªæƒ…å ±ä»˜ãï¼‰"""
        # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
        change_summary = self._analyze_changes(files_changed)
        
        # ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        commit_message = f"ğŸ¤– AI Task #{task_id}: {task_summary}\n\n"
        commit_message += "ğŸ“ Changes:\n"
        for category, files in change_summary.items():
            if files:
                commit_message += f"- {category}: {', '.join(files)}\n"
        
        commit_message += f"\nğŸ”§ Task ID: {task_id}\n"
        commit_message += f"â° Timestamp: {datetime.now().isoformat()}\n"
        
        try:
            # Git add
            subprocess.run(['git', 'add'] + files_changed, check=True)
            
            # Git commit
            subprocess.run(['git', 'commit', '-m', commit_message], check=True)
            
            logger.info("å¼·åŒ–ã‚³ãƒŸãƒƒãƒˆæˆåŠŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"ã‚³ãƒŸãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _analyze_changes(self, files: List[str]) -> Dict[str, List[str]]:
        """å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡"""
        categories = {
            'workers': [],
            'libs': [],
            'scripts': [],
            'config': [],
            'other': []
        }
        
        for file in files:
            if 'workers/' in file:
                categories['workers'].append(Path(file).name)
            elif 'libs/' in file:
                categories['libs'].append(Path(file).name)
            elif 'scripts/' in file:
                categories['scripts'].append(Path(file).name)
            elif 'config/' in file:
                categories['config'].append(Path(file).name)
            else:
                categories['other'].append(Path(file).name)
        
        return categories
    
    def create_pull_request(self, title: str, body: str, 
                          base: str = 'main', head: str = None) -> Optional[Dict]:
        """ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ"""
        if not all([self.api_repo_url, self.token]):
            logger.error("GitHub APIèªè¨¼æƒ…å ±ãŒä¸è¶³")
            return None
        
        # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒåã‚’å–å¾—
        if not head:
            result = subprocess.run(
                ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],
                capture_output=True, text=True
            )
            head = result.stdout.strip() if result.returncode == 0 else None
        
        if not head or head == base:
            logger.error("PRã‚’ä½œæˆã™ã‚‹ã«ã¯åˆ¥ãƒ–ãƒ©ãƒ³ãƒãŒå¿…è¦ã§ã™")
            return None
        
        url = f"{self.api_repo_url}/pulls"
        headers = {
            'Authorization': f'token {self.token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        
        data = {
            'title': title,
            'body': body,
            'head': head,
            'base': base
        }
        
        try:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 201:
                pr_data = response.json()
                logger.info(f"PRä½œæˆæˆåŠŸ: #{pr_data['number']}")
                return pr_data
            else:
                logger.error(f"PRä½œæˆå¤±æ•—: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"PRä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_code_context_for_ai(self, relevant_paths: List[str]) -> str:
        """AIãŒç†è§£ã—ã‚„ã™ã„å½¢å¼ã§ã‚³ãƒ¼ãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        context = "ã€é–¢é€£ã‚³ãƒ¼ãƒ‰æƒ…å ±ã€‘\n\n"
        
        for path in relevant_paths:
            content = self.get_file_content(path)
            if content:
                # é‡è¦ãªéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆã‚¯ãƒ©ã‚¹å®šç¾©ã€é–¢æ•°å®šç¾©ãªã©ï¼‰
                important_parts = self._extract_important_parts(content)
                
                context += f"ğŸ“„ {path}:\n"
                context += f"```python\n{important_parts}\n```\n\n"
        
        # ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®åˆ†ææƒ…å ±ã‚‚è¿½åŠ 
        analysis = self.analyze_codebase()
        context += f"\nã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ¦‚è¦ã€‘\n"
        context += f"- ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {analysis['total_files']}\n"
        context += f"- ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {len(analysis['key_modules'])}å€‹\n"
        context += f"- ä¾å­˜é–¢ä¿‚: {', '.join(analysis['dependencies'][:10])}\n"
        
        return context
    
    def _extract_important_parts(self, content: str, max_lines: int = 50) -> str:
        """ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é‡è¦ãªéƒ¨åˆ†ã‚’æŠ½å‡º"""
        lines = content.split('\n')
        important_lines = []
        
        in_class = False
        in_function = False
        
        for i, line in enumerate(lines):
            # ã‚¯ãƒ©ã‚¹å®šç¾©
            if line.strip().startswith('class '):
                in_class = True
                important_lines.append(line)
            # é–¢æ•°å®šç¾©
            elif line.strip().startswith('def '):
                in_function = True
                important_lines.append(line)
                # docstringã‚‚å«ã‚ã‚‹
                if i + 1 < len(lines) and '"""' in lines[i + 1]:
                    j = i + 1
                    while j < len(lines) and j < i + 10:
                        important_lines.append(lines[j])
                        if lines[j].strip().endswith('"""') and j > i + 1:
                            break
                        j += 1
            
            if len(important_lines) >= max_lines:
                break
        
        return '\n'.join(important_lines[:max_lines])
    
    def get_recent_commits(self, limit: int = 10) -> List[Dict]:
        """æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—"""
        if not self.api_repo_url:
            return []
        
        url = f"{self.api_repo_url}/commits"
        headers = {'Authorization': f'token {self.token}'} if self.token else {}
        params = {'per_page': limit}
        
        try:
            response = requests.get(url, headers=headers, params=params)
            if response.status_code == 200:
                commits = response.json()
                return [{
                    'sha': c['sha'][:7],
                    'message': c['commit']['message'].split('\n')[0],
                    'author': c['commit']['author']['name'],
                    'date': c['commit']['author']['date']
                } for c in commits]
        except Exception as e:
            logger.error(f"ã‚³ãƒŸãƒƒãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return []
