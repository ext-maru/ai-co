#!/usr/bin/env python3
"""
ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
ã‚¨ãƒ©ãƒ¼ã‚„å•é¡Œã‚’ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¨ã—ã¦è¨˜éŒ²ãƒ»ç®¡ç†
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import logging


class IncidentManager:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€… (Crisis Sage) - 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
    
    Elders Guildã®4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€ç¿¼ã‚’æ‹…ã†ã€å±æ©Ÿå¯¾å¿œå°‚é–€ã®è³¢è€…ã€‚
    å•é¡Œã®å³åº§æ„ŸçŸ¥ãƒ»è§£æ±ºã€ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ã€è‡ªå‹•å¾©æ—§ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ç®¡ç†ã‚’è¡Œã†ã€‚
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.incident_file = Path('/home/aicompany/ai_co/knowledge_base/incident_history.json')
        self._ensure_incident_file()
        
        # 4è³¤è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
        self.sage_type = "Crisis Sage"
        self.wisdom_level = "incident_response"
        self.collaboration_mode = True
        self.crisis_detection_enabled = True
        
        self.logger.info(f"ğŸ˜¨ {self.sage_type} åˆæœŸåŒ–å®Œäº† - å±æ©Ÿå¯¾å¿œã‚·ã‚¹ãƒ†ãƒ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
    
    def _ensure_incident_file(self):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        if not self.incident_file.exists():
            self.incident_file.parent.mkdir(parents=True, exist_ok=True)
            initial_data = {
                "metadata": {
                    "version": "1.0",
                    "created": datetime.now().strftime("%Y-%m-%d"),
                    "last_updated": datetime.now().isoformat(),
                    "total_incidents": 0,
                    "open_incidents": 0,
                    "resolved_incidents": 0,
                    "categories": {
                        "error": "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãƒ»ä¾‹å¤–",
                        "failure": "ã‚µãƒ¼ãƒ“ã‚¹éšœå®³ãƒ»æ©Ÿèƒ½ä¸å…¨",
                        "request": "æ©Ÿèƒ½è¦æ±‚ãƒ»ã‚µãƒ¼ãƒ“ã‚¹è¦æ±‚",
                        "change": "å¤‰æ›´è¦æ±‚ãƒ»è¨­å®šå¤‰æ›´",
                        "security": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ",
                        "performance": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ"
                    }
                },
                "incidents": [],
                "category_statistics": {
                    "error": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "failure": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "request": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "change": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "security": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "performance": {"count": 0, "open": 0, "avg_resolution_time": None}
                },
                "priority_statistics": {
                    "critical": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "high": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "medium": {"count": 0, "open": 0, "avg_resolution_time": None},
                    "low": {"count": 0, "open": 0, "avg_resolution_time": None}
                }
            }
            with open(self.incident_file, 'w') as f:
                json.dump(initial_data, f, indent=2)
    
    def create_incident(self, 
                       category: str,
                       priority: str,
                       title: str,
                       description: str,
                       affected_components: List[str],
                       impact: str,
                       assignee: str = "ai_system",
                       metadata: Optional[Dict] = None) -> str:
        """æ–°ã—ã„ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’ä½œæˆ"""
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆIDç”Ÿæˆ
            incident_id = f"INC-{datetime.now().strftime('%Y%m%d')}-{str(data['metadata']['total_incidents'] + 1).zfill(4)}"
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
            incident = {
                "incident_id": incident_id,
                "timestamp": datetime.now().isoformat(),
                "category": category,
                "priority": priority,
                "title": title,
                "description": description,
                "affected_components": affected_components,
                "impact": impact,
                "status": "open",
                "assignee": assignee,
                "resolution": None,
                "timeline": [
                    {
                        "timestamp": datetime.now().isoformat(),
                        "action": "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ",
                        "details": f"ã‚«ãƒ†ã‚´ãƒª: {category}, å„ªå…ˆåº¦: {priority}"
                    }
                ],
                "metadata": metadata or {}
            }
            
            # ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            data['incidents'].append(incident)
            data['metadata']['total_incidents'] += 1
            data['metadata']['open_incidents'] += 1
            data['metadata']['last_updated'] = datetime.now().isoformat()
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆæ›´æ–°
            if category in data['category_statistics']:
                data['category_statistics'][category]['count'] += 1
                data['category_statistics'][category]['open'] += 1
            
            # å„ªå…ˆåº¦çµ±è¨ˆæ›´æ–°
            if priority in data['priority_statistics']:
                data['priority_statistics'][priority]['count'] += 1
                data['priority_statistics'][priority]['open'] += 1
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(self.incident_file, 'w') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"Created incident: {incident_id}")
            return incident_id
            
        except Exception as e:
            self.logger.error(f"Failed to create incident: {str(e)}")
            raise
    
    def add_action(self, incident_id: str, action: str, details: Optional[Dict] = None):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ """
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’æ¤œç´¢
            for incident in data['incidents']:
                if incident['incident_id'] == incident_id:
                    incident['timeline'].append({
                        "timestamp": datetime.now().isoformat(),
                        "action": action,
                        "details": details or {}
                    })
                    break
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(self.incident_file, 'w') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            self.logger.error(f"Failed to add action to incident {incident_id}: {str(e)}")
    
    def resolve_incident(self, 
                        incident_id: str,
                        resolution: str,
                        actions_taken: List[str],
                        root_cause: str,
                        preventive_measures: List[str]):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’è§£æ±º"""
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’æ¤œç´¢
            for incident in data['incidents']:
                if incident['incident_id'] == incident_id and incident['status'] == 'open':
                    # è§£æ±ºæƒ…å ±ã‚’è¿½åŠ 
                    incident['status'] = 'resolved'
                    incident['resolution'] = {
                        "timestamp": datetime.now().isoformat(),
                        "description": resolution,
                        "actions_taken": actions_taken,
                        "root_cause": root_cause,
                        "preventive_measures": preventive_measures
                    }
                    
                    # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«è¿½åŠ 
                    incident['timeline'].append({
                        "timestamp": datetime.now().isoformat(),
                        "action": "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè§£æ±º",
                        "details": {
                            "resolution": resolution,
                            "root_cause": root_cause
                        }
                    })
                    
                    # çµ±è¨ˆæ›´æ–°
                    data['metadata']['open_incidents'] -= 1
                    data['metadata']['resolved_incidents'] += 1
                    
                    # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆæ›´æ–°
                    category = incident['category']
                    if category in data['category_statistics']:
                        data['category_statistics'][category]['open'] -= 1
                    
                    # å„ªå…ˆåº¦çµ±è¨ˆæ›´æ–°
                    priority = incident['priority']
                    if priority in data['priority_statistics']:
                        data['priority_statistics'][priority]['open'] -= 1
                    
                    break
            
            data['metadata']['last_updated'] = datetime.now().isoformat()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(self.incident_file, 'w') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"Resolved incident: {incident_id}")
            
        except Exception as e:
            self.logger.error(f"Failed to resolve incident {incident_id}: {str(e)}")
    
    def get_open_incidents(self) -> List[Dict]:
        """ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’å–å¾—"""
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            return [inc for inc in data['incidents'] if inc['status'] == 'open']
            
        except Exception as e:
            self.logger.error(f"Failed to get open incidents: {str(e)}")
            return []
    
    def get_incident_statistics(self) -> Dict:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçµ±è¨ˆã‚’å–å¾—"""
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            return {
                'total': data['metadata']['total_incidents'],
                'open': data['metadata']['open_incidents'],
                'resolved': data['metadata']['resolved_incidents'],
                'by_category': data['category_statistics'],
                'by_priority': data['priority_statistics']
            }
            
        except Exception as e:
            self.logger.error(f"Failed to get statistics: {str(e)}")
            return {}
    
    def search_similar_incidents(self, error_text: str, limit: int = 5) -> List[Dict]:
        """é¡ä¼¼ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’æ¤œç´¢"""
        try:
            with open(self.incident_file, 'r') as f:
                data = json.load(f)
            
            # ç°¡æ˜“çš„ãªé¡ä¼¼åº¦è¨ˆç®—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼‰
            error_keywords = set(error_text.lower().split())
            similar_incidents = []
            
            for incident in data['incidents']:
                if incident['status'] == 'resolved':
                    incident_text = (incident['title'] + ' ' + incident['description']).lower()
                    incident_keywords = set(incident_text.split())
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡æ•°ã‚’è¨ˆç®—
                    common_keywords = len(error_keywords & incident_keywords)
                    if common_keywords > 2:  # 2ã¤ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´
                        similar_incidents.append({
                            'incident': incident,
                            'similarity': common_keywords
                        })
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            similar_incidents.sort(key=lambda x: x['similarity'], reverse=True)
            
            return [item['incident'] for item in similar_incidents[:limit]]
            
        except Exception as e:
            self.logger.error(f"Failed to search similar incidents: {str(e)}")
            return []
