#!/usr/bin/env python3
"""
ğŸ¤– GitHub Issue Auto Processor
å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«å‡¦ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import logging
import os

# Elder System imports
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

from github import Github
from github.Issue import Issue

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from libs.core.elders_legacy import EldersServiceLegacy

# Elder Systemå®Ÿè£…ã¯ç¾åœ¨ãƒ€ãƒŸãƒ¼ã¨ã—ã¦ä½¿ç”¨ï¼ˆå®Ÿè£…æ™‚ã«å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹ã«ç½®ãæ›ãˆï¼‰
try:
    from libs.rag_manager import RagManager as ActualRAGSage
except ImportError:
    ActualRAGSage = DummySage


# ãƒ€ãƒŸãƒ¼å®Ÿè£…ã‚¯ãƒ©ã‚¹ï¼ˆå®Ÿéš›ã®4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ãŒãªã„å ´åˆã®ä»£æ›¿ï¼‰
class DummyElderFlowEngine:
    async def process_request(self, request):
        return {"status": "success", "task_name": request.get("task_name", "")}


class DummySage:
    async def process_request(self, request):
        return {"status": "success", "message": "Dummy sage response"}


class DummyPRCreator:
    def create_pull_request(self, **kwargs):
        return {"success": False, "error": "PR creation not implemented yet"}


# å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹ã¾ãŸã¯ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨
try:
    from libs.elder_system.flow.elder_flow_engine import (
        ElderFlowEngine as ActualElderFlowEngine,
    )
except ImportError:
    ActualElderFlowEngine = DummyElderFlowEngine

try:
    from libs.four_sages.knowledge.knowledge_sage import (
        KnowledgeSage as ActualKnowledgeSage,
    )
except ImportError:
    ActualKnowledgeSage = DummySage

try:
    from libs.four_sages.task.task_sage import TaskSage as ActualTaskSage
except ImportError:
    ActualTaskSage = DummySage

try:
    from libs.four_sages.incident.incident_sage import (
        IncidentSage as ActualIncidentSage,
    )
except ImportError:
    ActualIncidentSage = DummySage

try:
    from libs.integrations.github.api_implementations.create_pull_request import (
        GitHubCreatePullRequestImplementation,
    )
except ImportError:
    GitHubCreatePullRequestImplementation = DummyPRCreator


class AutoIssueElderFlowEngine:
    """Auto Issue Processorå°‚ç”¨ã®Elder Flow Engine"""

    def __init__(self):
        self.elder_flow = ActualElderFlowEngine()
        # Ensure environment variables are loaded for PR creator
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("GITHUB_REPO_OWNER")
        repo_name = os.getenv("GITHUB_REPO_NAME")

        if not github_token or not repo_owner or not repo_name:
            # Use dummy PR creator if config is missing
            self.pr_creator = DummyPRCreator()
        else:
            self.pr_creator = GitHubCreatePullRequestImplementation(
                token=github_token, repo_owner=repo_owner, repo_name=repo_name
            )
        self.logger = logger

    async def execute_flow(self, request):
        """Auto Issueç”¨ã®Elder Flowå®Ÿè¡Œ"""
        try:
            task_name = request.get("task_name", "")
            context = request.get("context", {})
            issue_number = context.get("issue_number", 0)
            issue_title = context.get("issue_title", "")
            issue_body = context.get("issue_body", "")

            # Elder Flowã‚’å®Ÿè¡Œ
            flow_result = await self.elder_flow.process_request(
                {
                    "type": "execute",
                    "task_name": task_name,
                    "priority": request.get("priority", "medium"),
                }
            )

            if flow_result.get("status") == "success" or flow_result.get("task_name"):
                # PRä½œæˆã‚’å®Ÿè¡Œ
                pr_result = await self._create_pull_request(
                    issue_number, issue_title, issue_body, task_name
                )

                if pr_result.get("success"):
                    return {
                        "status": "success",
                        "pr_url": pr_result.get("pr_url"),
                        "message": f"Elder Flowå®Œäº†ã€PR #{pr_result.get('pr_number', 'XXX')} ã‚’ä½œæˆã—ã¾ã—ãŸ",
                        "flow_result": flow_result,
                        "pr_result": pr_result,
                    }
                else:
                    return {
                        "status": "partial_success",
                        "pr_url": None,
                        "message": f"Elder Flowå®Œäº†ã€ä½†ã—PRä½œæˆã«å¤±æ•—: {pr_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}",
                        "flow_result": flow_result,
                        "pr_error": pr_result.get("error"),
                    }
            else:
                return {
                    "status": "error",
                    "pr_url": None,
                    "message": f"Elder Flowå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {flow_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}",
                    "flow_result": flow_result,
                }

        except Exception as e:
            self.logger.error(f"Auto Issue Elder Flow execution error: {e}")
            return {
                "status": "error",
                "pr_url": None,
                "message": f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                "error": str(e),
            }

    async def _create_pull_request(
        self, issue_number, issue_title, issue_body, task_name
    ):
        """è‡ªå‹•ã§PRä½œæˆ"""
        try:
            # ãƒ–ãƒ©ãƒ³ãƒåã‚’ç”Ÿæˆ
            branch_name = f"auto-fix-issue-{issue_number}"

            # PRä½œæˆ
            pr_result = self.pr_creator.create_pull_request(
                title=f"Auto-fix: {issue_title} (#{issue_number})",
                head=branch_name,
                base="main",
                body=f"""ğŸ¤– **Auto Issue Processor** ã«ã‚ˆã‚‹è‡ªå‹•ä¿®æ­£

## ä¿®æ­£å†…å®¹
{task_name}

## å¯¾è±¡Issue
Closes #{issue_number}

## å…ƒã®Issueå†…å®¹
{issue_body}

---
*ã“ã®PRã¯Auto Issue Processorã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
""",
                labels=["auto-generated", "auto-fix"],
                draft=True,  # ãƒ‰ãƒ©ãƒ•ãƒˆã¨ã—ã¦ä½œæˆ
            )

            if pr_result.get("success"):
                pr_data = pr_result.get("pull_request", {})
                return {
                    "success": True,
                    "pr_url": pr_data.get("html_url"),
                    "pr_number": pr_data.get("number"),
                    "branch_name": branch_name,
                }
            else:
                return {
                    "success": False,
                    "error": pr_result.get("error", "ä¸æ˜ãªPRä½œæˆã‚¨ãƒ©ãƒ¼"),
                }

        except Exception as e:
            return {"success": False, "error": f"PRä½œæˆä¾‹å¤–: {str(e)}"}


# Setup logging
logger = logging.getLogger("AutoIssueProcessor")


class ComplexityScore:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢"""

    def __init__(self, score: float, factors: Dict[str, Any]):
        self.score = score
        self.factors = factors
        self.is_processable = score < 0.7  # 70%æœªæº€ãªã‚‰å‡¦ç†å¯èƒ½


class ProcessingLimiter:
    """å‡¦ç†åˆ¶é™ã‚’ç®¡ç†"""

    MAX_ISSUES_PER_HOUR = 10  # 1æ™‚é–“ã‚ãŸã‚Šæœ€å¤§10ã‚¤ã‚·ãƒ¥ãƒ¼ã¾ã§
    MAX_CONCURRENT = 1
    COOLDOWN_PERIOD = 300  # 5åˆ†

    def __init__(self):
        self.processing_log_file = Path("logs/auto_issue_processing.json")
        self.processing_log_file.parent.mkdir(exist_ok=True)

    async def can_process(self) -> bool:
        """å‡¦ç†å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.processing_log_file.exists():
            return True

        with open(self.processing_log_file, "r") as f:
            logs = json.load(f)

        # éå»1æ™‚é–“ã®å‡¦ç†æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        one_hour_ago = datetime.now() - timedelta(hours=1)
        recent_processes = [
            log
            for log in logs
            if datetime.fromisoformat(log["timestamp"]) > one_hour_ago
        ]

        return len(recent_processes) < self.MAX_ISSUES_PER_HOUR

    async def record_processing(self, issue_id: int):
        """å‡¦ç†è¨˜éŒ²ã‚’ä¿å­˜"""
        logs = []
        if self.processing_log_file.exists():
            with open(self.processing_log_file, "r") as f:
                logs = json.load(f)

        logs.append({"issue_id": issue_id, "timestamp": datetime.now().isoformat()})

        # å¤ã„ãƒ­ã‚°ã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = datetime.now() - timedelta(days=1)
        logs = [
            log for log in logs if datetime.fromisoformat(log["timestamp"]) > cutoff
        ]

        with open(self.processing_log_file, "w") as f:
            json.dump(logs, f, indent=2)


class ComplexityEvaluator:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚’è©•ä¾¡"""

    COMPLEXITY_FACTORS = {
        "file_count": {
            "low": (1, 3),
            "medium": (4, 10),
            "high": (11, None),
        },  # å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°
        "code_lines": {  # æ¨å®šã‚³ãƒ¼ãƒ‰è¡Œæ•°
            "low": (1, 50),
            "medium": (51, 200),
            "high": (201, None),
        },
        "dependencies": {
            "low": (0, 2),
            "medium": (3, 5),
            "high": (6, None),
        },  # ä¾å­˜é–¢ä¿‚æ•°
        "test_coverage": {  # å¿…è¦ãƒ†ã‚¹ãƒˆæ•°
            "low": (1, 5),
            "medium": (6, 15),
            "high": (16, None),
        },
    }

    PROCESSABLE_PATTERNS = [
        "typo",
        "documentation",
        "comment",
        "rename",
        "format",
        "style",
        "test",
        "simple bug",
    ]

    async def evaluate(self, issue: Issue) -> ComplexityScore:
        """è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        factors = {}
        total_score = 0

        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒœãƒ‡ã‚£ã‹ã‚‰è¤‡é›‘åº¦ã‚’æ¨å®š
        text = f"{issue.title} {issue.body or ''}".lower()

        # å˜ç´”ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        is_simple = any(pattern in text for pattern in self.PROCESSABLE_PATTERNS)
        if is_simple:
            factors["pattern_match"] = 0.3
            total_score += 0.3
        else:
            factors["pattern_match"] = 0.7
            total_score += 0.7

        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
        labels = [label.name for label in issue.labels]
        if "good first issue" in labels:
            factors["label_complexity"] = 0.2
            total_score += 0.2
        elif "bug" in labels and "critical" not in labels:
            factors["label_complexity"] = 0.4
            total_score += 0.4
        else:
            factors["label_complexity"] = 0.6
            total_score += 0.6

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(
            word in text
            for word in ["security", "vulnerability", "auth", "token", "password"]
        ):
            factors["security_related"] = 1.0
            total_score += 1.0

        # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_score = total_score / len(factors) if factors else 1.0

        return ComplexityScore(avg_score, factors)


class AutoIssueProcessor(EldersServiceLegacy):
    """
    GitHubã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
    å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«Elder Flowã§å‡¦ç†
    """

    def __init__(self):
        super().__init__("auto_issue_processor")
        self.domain = "GITHUB"
        self.service_name = "AutoIssueProcessor"

        # GitHub APIåˆæœŸåŒ–
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("GITHUB_REPO_OWNER", "ext-maru")
        repo_name = os.getenv("GITHUB_REPO_NAME", "ai-co")

        if not github_token:
            raise ValueError("GITHUB_TOKEN environment variable not set")

        self.github = Github(github_token)
        self.repo = self.github.get_repo(f"{repo_owner}/{repo_name}")

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.elder_flow = AutoIssueElderFlowEngine()
        self.task_sage = ActualTaskSage()
        self.incident_sage = ActualIncidentSage()
        self.knowledge_sage = ActualKnowledgeSage()
        self.rag_sage = ActualRAGSage()

        self.limiter = ProcessingLimiter()
        self.evaluator = ComplexityEvaluator()

        # å‡¦ç†å¯¾è±¡ã®å„ªå…ˆåº¦ï¼ˆä¸­ä»¥ä¸Šï¼‰
        self.target_priorities = ["critical", "high", "medium"]

    def get_capabilities(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®æ©Ÿèƒ½ã‚’è¿”ã™"""
        return {
            "service": "AutoIssueProcessor",
            "version": "1.0.0",
            "capabilities": [
                "GitHub issue scanning",
                "Complexity evaluation",
                "Automatic processing",
                "Elder Flow integration",
                "Quality gate validation",
            ],
            "limits": {
                "max_issues_per_hour": ProcessingLimiter.MAX_ISSUES_PER_HOUR,
                "max_concurrent": ProcessingLimiter.MAX_CONCURRENT,
                "target_priorities": self.target_priorities,
            },
        }

    def validate_request(self, request: Dict[str, Any]) -> bool:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®æ¤œè¨¼
        if "mode" in request and request["mode"] not in ["scan", "process", "dry_run"]:
            return False

        # ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®æ¤œè¨¼
        if "issue_number" in request:
            if not isinstance(request["issue_number"], int):
                return False

        return True

    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        mode = request.get("mode", "scan")

        try:
            if mode == "scan":
                # å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³
                issues = await self.scan_processable_issues()
                return {
                    "status": "success",
                    "processable_issues": len(issues),
                    "issues": [
                        {
                            "number": issue.number,
                            "title": issue.title,
                            "priority": self._determine_priority(issue),
                            "complexity": (await self.evaluator.evaluate(issue)).score,
                        }
                        for issue in issues[:5]  # æœ€å¤§5ä»¶ã¾ã§è¡¨ç¤º
                    ],
                }

            elif mode == "process":
                # å®Ÿéš›ã«å‡¦ç†ã‚’å®Ÿè¡Œ
                if not await self.limiter.can_process():
                    return {
                        "status": "rate_limited",
                        "message": "Processing limit reached. Please try again later.",
                    }

                issues = await self.scan_processable_issues()
                if not issues:
                    return {
                        "status": "no_issues",
                        "message": "No processable issues found.",
                    }

                # æœ€åˆã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å‡¦ç†
                issue = issues[0]
                result = await self.execute_auto_processing(issue)

                return {
                    "status": "success",
                    "processed_issue": {
                        "number": issue.number,
                        "title": issue.title,
                        "result": result,
                    },
                }

            elif mode == "dry_run":
                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã«ã¯å‡¦ç†ã—ãªã„ï¼‰
                issue_number = request.get("issue_number")
                if issue_number:
                    issue = self.repo.get_issue(issue_number)
                    complexity = await self.evaluator.evaluate(issue)

                    return {
                        "status": "dry_run",
                        "issue": {
                            "number": issue.number,
                            "title": issue.title,
                            "priority": self._determine_priority(issue),
                            "complexity": complexity.score,
                            "processable": complexity.is_processable,
                            "factors": complexity.factors,
                        },
                    }

        except Exception as e:
            logger.error(f"Error in process_request: {str(e)}")
            return {"status": "error", "message": str(e)}

    async def scan_processable_issues(self) -> List[Issue]:
        """å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        processable_issues = []

        # ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å–å¾—
        open_issues = self.repo.get_issues(state="open")

        for issue in open_issues:
            # PRã¯é™¤å¤–
            if issue.pull_request:
                continue

            # å„ªå…ˆåº¦ãƒã‚§ãƒƒã‚¯
            priority = self._determine_priority(issue)
            if priority not in self.target_priorities:
                continue

            # è¤‡é›‘åº¦è©•ä¾¡
            complexity = await self.evaluator.evaluate(issue)
            if complexity.is_processable:
                processable_issues.append(issue)

            # æœ€å¤§10ä»¶ã¾ã§
            if len(processable_issues) >= 10:
                break

        return processable_issues

    async def execute_auto_processing(self, issue: Issue) -> Dict[str, Any]:
        """Elder Flowã‚’ä½¿ç”¨ã—ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•å‡¦ç†"""
        try:
            # å‡¦ç†è¨˜éŒ²
            await self.limiter.record_processing(issue.number)

            # è¤‡é›‘åº¦è©•ä¾¡ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç”¨ï¼‰
            complexity = await self.evaluator.evaluate(issue)

            # 4è³¢è€…ã«ç›¸è«‡
            sage_advice = await self.consult_four_sages(issue)

            # Elder Flowãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰
            flow_request = {
                "task_name": f"Auto-fix Issue #{issue.number}: {issue.title}",
                "priority": self._determine_priority(issue),
                "context": {
                    "issue_number": issue.number,
                    "issue_title": issue.title,
                    "issue_body": issue.body or "",
                    "labels": [label.name for label in issue.labels],
                    "sage_advice": sage_advice,
                },
            }

            # Elder Flowå®Ÿè¡Œ
            result = await self.elder_flow.execute_flow(flow_request)

            # çµæœã«åŸºã¥ã„ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’æ›´æ–°
            if result.get("status") == "success":
                # PRãŒä½œæˆã•ã‚ŒãŸã‚‰ã‚¤ã‚·ãƒ¥ãƒ¼ã«ã‚³ãƒ¡ãƒ³ãƒˆ
                pr_url = result.get("pr_url")
                message = result.get("message", "")

                if pr_url:
                    issue.create_comment(
                        f"ğŸ¤– Auto-processed by Elder Flow\n\n"
                        f"PR created: {pr_url}\n\n"
                        f"This issue was automatically processed based on its complexity "
                        f"and priority level."
                    )
                elif message:
                    # PR URLãŒãªã„å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    related_links = result.get("related_links", {})

                    comment_text = f"ğŸ¤– Elder Flowå‡¦ç†å®Œäº†\n\n"
                    comment_text += f"{message}\n\n"

                    # é–¢é€£ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    if related_links:
                        comment_text += "ğŸ“š **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**\n"
                        if related_links.get("design_doc"):
                            comment_text += f"- [ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸]({related_links['design_doc']})\n"
                        if related_links.get("elder_flow_doc"):
                            comment_text += f"- [Elder Flowã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£]({related_links['elder_flow_doc']})\n"
                        if related_links.get("issue_link"):
                            comment_text += (
                                f"- [ã“ã®ã‚¤ã‚·ãƒ¥ãƒ¼]({related_links['issue_link']})\n"
                            )
                        comment_text += "\n"

                    comment_text += f"ğŸ“Š **å‡¦ç†æƒ…å ±:**\n"
                    comment_text += f"- è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢: {complexity.score:.2f}\n"
                    comment_text += f"- å‡¦ç†åŸºæº–: è¤‡é›‘åº¦ < 0.7 ã‹ã¤ å„ªå…ˆåº¦ Medium/Low\n"

                    issue.create_comment(comment_text)

            return result

        except Exception as e:
            logger.error(f"Error in auto processing: {str(e)}")
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã«å ±å‘Š
            await self.incident_sage.process_request(
                {
                    "type": "report_incident",
                    "severity": "medium",
                    "title": f"Auto-processing failed for issue #{issue.number}",
                    "description": str(e),
                }
            )

            return {"status": "error", "message": str(e)}

    async def consult_four_sages(self, issue: Issue) -> Dict[str, Any]:
        """4è³¢è€…ã¸ã®ç›¸è«‡"""
        sage_advice = {}

        try:
            # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…: éå»ã®é¡ä¼¼äº‹ä¾‹æ¤œç´¢
            knowledge_response = await self.knowledge_sage.process_request(
                {
                    "type": "search",
                    "query": f"similar issues to: {issue.title}",
                    "limit": 5,
                }
            )
            sage_advice["knowledge"] = knowledge_response.get("entries", [])

            # ã‚¿ã‚¹ã‚¯è³¢è€…: å®Ÿè¡Œè¨ˆç”»ç«‹æ¡ˆ
            task_response = await self.task_sage.process_request(
                {
                    "type": "create_plan",
                    "title": issue.title,
                    "description": issue.body or "",
                }
            )
            sage_advice["plan"] = task_response

            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…: ãƒªã‚¹ã‚¯è©•ä¾¡
            incident_response = await self.incident_sage.process_request(
                {
                    "type": "evaluate_risk",
                    "task": issue.title,
                    "context": issue.body or "",
                }
            )
            sage_advice["risks"] = incident_response

            # RAGè³¢è€…: æœ€é©è§£æ¢ç´¢
            rag_response = await self.rag_sage.process_request(
                {
                    "type": "search",
                    "query": f"how to fix: {issue.title}",
                    "max_results": 3,
                }
            )
            sage_advice["solution"] = rag_response.get("results", [])

        except Exception as e:
            logger.warning(f"Sage consultation partial failure: {str(e)}")

        return sage_advice

    def _determine_priority(self, issue: Issue) -> str:
        """ã‚¤ã‚·ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦ã‚’åˆ¤å®š"""
        labels = [label.name.lower() for label in issue.labels]

        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šï¼ˆpriority:xxxãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚‚å¯¾å¿œï¼‰
        if any(
            label in ["critical", "urgent", "p0", "priority:critical"]
            for label in labels
        ):
            return "critical"
        elif any(
            label in ["high", "important", "p1", "priority:high"] for label in labels
        ):
            return "high"
        elif any(
            label in ["medium", "moderate", "p2", "priority:medium"] for label in labels
        ):
            return "medium"
        elif any(label in ["low", "minor", "p3", "priority:low"] for label in labels):
            return "low"

        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
        title_lower = issue.title.lower()
        if any(word in title_lower for word in ["critical", "urgent", "emergency"]):
            return "critical"
        elif any(word in title_lower for word in ["important", "high priority"]):
            return "high"
        elif any(word in title_lower for word in ["bug", "fix", "error"]):
            return "medium"

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä½å„ªå…ˆåº¦
        return "low"


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    processor = AutoIssueProcessor()

    # ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
    result = await processor.process_request({"mode": "scan"})
    print(json.dumps(result, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
