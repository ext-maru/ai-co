#!/usr/bin/env python3
"""
ğŸ¤– GitHub Issue Auto Processor
å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«å‡¦ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging

from github import Github
from github.Issue import Issue

# Elder System imports
# ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
class EldersServiceLegacy:
    def __init__(self, component_id=None):
        self.component_id = component_id or "AutoIssueProcessor"
        
    def get_capabilities(self):
        return {}
        
    def validate_request(self, request):
        return True
        
    async def process_request(self, request):
        return {}

# Elder Flow Engineï¼ˆå¾Œã§å®Ÿè£…ï¼‰
class ElderFlowEngine:
    async def execute_flow(self, request):
        # TODO: å®Ÿéš›ã®PRä½œæˆã‚’å®Ÿè£…ã™ã‚‹
        # ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼å®Ÿè£…ã®ãŸã‚ã€PRãƒªãƒ³ã‚¯ã¯è¿”ã•ãªã„
        
        # ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ã‚’å–å¾—
        issue_number = request.get('context', {}).get('issue_number', 'XXX')
        
        # é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
        doc_links = {
            "design_doc": f"https://github.com/ext-maru/ai-co/blob/main/docs/AUTO_ISSUE_PROCESSOR_DESIGN.md",
            "issue_link": f"https://github.com/ext-maru/ai-co/issues/{issue_number}",
            "elder_flow_doc": f"https://github.com/ext-maru/ai-co/blob/main/docs/ELDER_FLOW_ARCHITECTURE.md"
        }
        
        return {
            "status": "success", 
            "pr_url": None,  # å®Ÿéš›ã®PRãŒä½œæˆã•ã‚Œã‚‹ã¾ã§ã¯Noneã‚’è¿”ã™
            "message": "Elder Flowå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆPRä½œæˆã¯æœªå®Ÿè£…ï¼‰",
            "related_links": doc_links
        }

# 4è³¢è€…ã®ãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼ˆå¾Œã§å®Ÿè£…ï¼‰
class TaskSage:
    async def process_request(self, request):
        return {"plan": "å®Ÿè£…è¨ˆç”»"}
        
class IncidentSage:
    async def process_request(self, request):
        return {"risks": "ä½ãƒªã‚¹ã‚¯"}
        
class KnowledgeSage:
    async def process_request(self, request):
        return {"entries": []}
        
class RAGSage:
    async def process_request(self, request):
        return {"results": []}

# Setup logging
logger = logging.getLogger("AutoIssueProcessor")


class ComplexityScore:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢"""
    def __init__(self, score: float, factors: Dict[str, Any]):
        self.score = score
        self.factors = factors
        self.is_processable = score < 0.7  # 70%æœªæº€ãªã‚‰å‡¦ç†å¯èƒ½


class ProcessingLimiter:
    """å‡¦ç†åˆ¶é™ã‚’ç®¡ç†"""
    
    MAX_ISSUES_PER_HOUR = 10  # 1æ™‚é–“ã‚ãŸã‚Šæœ€å¤§10ã‚¤ã‚·ãƒ¥ãƒ¼ã¾ã§
    MAX_CONCURRENT = 1
    COOLDOWN_PERIOD = 300  # 5åˆ†
    
    def __init__(self):
        self.processing_log_file = Path("logs/auto_issue_processing.json")
        self.processing_log_file.parent.mkdir(exist_ok=True)
        
    async def can_process(self) -> bool:
        """å‡¦ç†å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.processing_log_file.exists():
            return True
            
        with open(self.processing_log_file, 'r') as f:
            logs = json.load(f)
            
        # éå»1æ™‚é–“ã®å‡¦ç†æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        one_hour_ago = datetime.now() - timedelta(hours=1)
        recent_processes = [
            log for log in logs 
            if datetime.fromisoformat(log['timestamp']) > one_hour_ago
        ]
        
        return len(recent_processes) < self.MAX_ISSUES_PER_HOUR
        
    async def record_processing(self, issue_id: int):
        """å‡¦ç†è¨˜éŒ²ã‚’ä¿å­˜"""
        logs = []
        if self.processing_log_file.exists():
            with open(self.processing_log_file, 'r') as f:
                logs = json.load(f)
                
        logs.append({
            'issue_id': issue_id,
            'timestamp': datetime.now().isoformat()
        })
        
        # å¤ã„ãƒ­ã‚°ã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = datetime.now() - timedelta(days=1)
        logs = [
            log for log in logs 
            if datetime.fromisoformat(log['timestamp']) > cutoff
        ]
        
        with open(self.processing_log_file, 'w') as f:
            json.dump(logs, f, indent=2)


class ComplexityEvaluator:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚’è©•ä¾¡"""
    
    COMPLEXITY_FACTORS = {
        'file_count': {          # å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            'low': (1, 3),
            'medium': (4, 10),
            'high': (11, None)
        },
        'code_lines': {          # æ¨å®šã‚³ãƒ¼ãƒ‰è¡Œæ•°
            'low': (1, 50),
            'medium': (51, 200),
            'high': (201, None)
        },
        'dependencies': {        # ä¾å­˜é–¢ä¿‚æ•°
            'low': (0, 2),
            'medium': (3, 5),
            'high': (6, None)
        },
        'test_coverage': {       # å¿…è¦ãƒ†ã‚¹ãƒˆæ•°
            'low': (1, 5),
            'medium': (6, 15),
            'high': (16, None)
        }
    }
    
    PROCESSABLE_PATTERNS = [
        'typo', 'documentation', 'comment', 'rename', 
        'format', 'style', 'test', 'simple bug'
    ]
    
    async def evaluate(self, issue: Issue) -> ComplexityScore:
        """è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        factors = {}
        total_score = 0
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒœãƒ‡ã‚£ã‹ã‚‰è¤‡é›‘åº¦ã‚’æ¨å®š
        text = f"{issue.title} {issue.body or ''}".lower()
        
        # å˜ç´”ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        is_simple = any(pattern in text for pattern in self.PROCESSABLE_PATTERNS)
        if is_simple:
            factors['pattern_match'] = 0.3
            total_score += 0.3
        else:
            factors['pattern_match'] = 0.7
            total_score += 0.7
            
        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
        labels = [label.name for label in issue.labels]
        if 'good first issue' in labels:
            factors['label_complexity'] = 0.2
            total_score += 0.2
        elif 'bug' in labels and 'critical' not in labels:
            factors['label_complexity'] = 0.4
            total_score += 0.4
        else:
            factors['label_complexity'] = 0.6
            total_score += 0.6
            
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(word in text for word in ['security', 'vulnerability', 'auth', 'token', 'password']):
            factors['security_related'] = 1.0
            total_score += 1.0
            
        # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_score = total_score / len(factors) if factors else 1.0
        
        return ComplexityScore(avg_score, factors)


class AutoIssueProcessor(EldersServiceLegacy):
    """
    GitHubã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
    å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«Elder Flowã§å‡¦ç†
    """
    
    def __init__(self):
        super().__init__()
        self.domain = "GITHUB"
        self.service_name = "AutoIssueProcessor"
        
        # GitHub APIåˆæœŸåŒ–
        github_token = os.getenv("GITHUB_TOKEN")
        if not github_token:
            raise ValueError("GITHUB_TOKEN environment variable not set")
            
        self.github = Github(github_token)
        self.repo = self.github.get_repo("ext-maru/ai-co")
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.elder_flow = ElderFlowEngine()
        self.task_sage = TaskSage()
        self.incident_sage = IncidentSage()
        self.knowledge_sage = KnowledgeSage()
        self.rag_sage = RAGSage()
        
        self.limiter = ProcessingLimiter()
        self.evaluator = ComplexityEvaluator()
        
        # å‡¦ç†å¯¾è±¡ã®å„ªå…ˆåº¦ï¼ˆä¸­ä»¥ä¸Šï¼‰
        self.target_priorities = ['critical', 'high', 'medium']
        
    def get_capabilities(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®æ©Ÿèƒ½ã‚’è¿”ã™"""
        return {
            "service": "AutoIssueProcessor",
            "version": "1.0.0",
            "capabilities": [
                "GitHub issue scanning",
                "Complexity evaluation",
                "Automatic processing",
                "Elder Flow integration",
                "Quality gate validation"
            ],
            "limits": {
                "max_issues_per_hour": ProcessingLimiter.MAX_ISSUES_PER_HOUR,
                "max_concurrent": ProcessingLimiter.MAX_CONCURRENT,
                "target_priorities": self.target_priorities
            }
        }
        
    def validate_request(self, request: Dict[str, Any]) -> bool:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®æ¤œè¨¼
        if 'mode' in request and request['mode'] not in ['scan', 'process', 'dry_run']:
            return False
            
        # ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®æ¤œè¨¼
        if 'issue_number' in request:
            if not isinstance(request['issue_number'], int):
                return False
                
        return True
        
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        mode = request.get('mode', 'scan')
        
        try:
            if mode == 'scan':
                # å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³
                issues = await self.scan_processable_issues()
                return {
                    'status': 'success',
                    'processable_issues': len(issues),
                    'issues': [
                        {
                            'number': issue.number,
                            'title': issue.title,
                            'priority': self._determine_priority(issue),
                            'complexity': (await self.evaluator.evaluate(issue)).score
                        }
                        for issue in issues[:5]  # æœ€å¤§5ä»¶ã¾ã§è¡¨ç¤º
                    ]
                }
                
            elif mode == 'process':
                # å®Ÿéš›ã«å‡¦ç†ã‚’å®Ÿè¡Œ
                if not await self.limiter.can_process():
                    return {
                        'status': 'rate_limited',
                        'message': 'Processing limit reached. Please try again later.'
                    }
                    
                issues = await self.scan_processable_issues()
                if not issues:
                    return {
                        'status': 'no_issues',
                        'message': 'No processable issues found.'
                    }
                    
                # æœ€åˆã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å‡¦ç†
                issue = issues[0]
                result = await self.execute_auto_processing(issue)
                
                return {
                    'status': 'success',
                    'processed_issue': {
                        'number': issue.number,
                        'title': issue.title,
                        'result': result
                    }
                }
                
            elif mode == 'dry_run':
                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã«ã¯å‡¦ç†ã—ãªã„ï¼‰
                issue_number = request.get('issue_number')
                if issue_number:
                    issue = self.repo.get_issue(issue_number)
                    complexity = await self.evaluator.evaluate(issue)
                    
                    return {
                        'status': 'dry_run',
                        'issue': {
                            'number': issue.number,
                            'title': issue.title,
                            'priority': self._determine_priority(issue),
                            'complexity': complexity.score,
                            'processable': complexity.is_processable,
                            'factors': complexity.factors
                        }
                    }
                    
        except Exception as e:
            logger.error(f"Error in process_request: {str(e)}")
            return {
                'status': 'error',
                'message': str(e)
            }
            
    async def scan_processable_issues(self) -> List[Issue]:
        """å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        processable_issues = []
        
        # ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å–å¾—
        open_issues = self.repo.get_issues(state='open')
        
        for issue in open_issues:
            # PRã¯é™¤å¤–
            if issue.pull_request:
                continue
                
            # å„ªå…ˆåº¦ãƒã‚§ãƒƒã‚¯
            priority = self._determine_priority(issue)
            if priority not in self.target_priorities:
                continue
                
            # è¤‡é›‘åº¦è©•ä¾¡
            complexity = await self.evaluator.evaluate(issue)
            if complexity.is_processable:
                processable_issues.append(issue)
                
            # æœ€å¤§10ä»¶ã¾ã§
            if len(processable_issues) >= 10:
                break
                
        return processable_issues
        
    async def execute_auto_processing(self, issue: Issue) -> Dict[str, Any]:
        """Elder Flowã‚’ä½¿ç”¨ã—ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•å‡¦ç†"""
        try:
            # å‡¦ç†è¨˜éŒ²
            await self.limiter.record_processing(issue.number)
            
            # è¤‡é›‘åº¦è©•ä¾¡ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç”¨ï¼‰
            complexity = await self.evaluator.evaluate(issue)
            
            # 4è³¢è€…ã«ç›¸è«‡
            sage_advice = await self.consult_four_sages(issue)
            
            # Elder Flowãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰
            flow_request = {
                'task_name': f"Auto-fix Issue #{issue.number}: {issue.title}",
                'priority': self._determine_priority(issue),
                'context': {
                    'issue_number': issue.number,
                    'issue_title': issue.title,
                    'issue_body': issue.body or '',
                    'labels': [label.name for label in issue.labels],
                    'sage_advice': sage_advice
                }
            }
            
            # Elder Flowå®Ÿè¡Œ
            result = await self.elder_flow.execute_flow(flow_request)
            
            # çµæœã«åŸºã¥ã„ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’æ›´æ–°
            if result.get('status') == 'success':
                # PRãŒä½œæˆã•ã‚ŒãŸã‚‰ã‚¤ã‚·ãƒ¥ãƒ¼ã«ã‚³ãƒ¡ãƒ³ãƒˆ
                pr_url = result.get('pr_url')
                message = result.get('message', '')
                
                if pr_url:
                    issue.create_comment(
                        f"ğŸ¤– Auto-processed by Elder Flow\n\n"
                        f"PR created: {pr_url}\n\n"
                        f"This issue was automatically processed based on its complexity "
                        f"and priority level."
                    )
                elif message:
                    # PR URLãŒãªã„å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    related_links = result.get('related_links', {})
                    
                    comment_text = f"ğŸ¤– Elder Flowå‡¦ç†å®Œäº†\n\n"
                    comment_text += f"{message}\n\n"
                    
                    # é–¢é€£ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    if related_links:
                        comment_text += "ğŸ“š **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**\n"
                        if related_links.get('design_doc'):
                            comment_text += f"- [ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸]({related_links['design_doc']})\n"
                        if related_links.get('elder_flow_doc'):
                            comment_text += f"- [Elder Flowã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£]({related_links['elder_flow_doc']})\n"
                        if related_links.get('issue_link'):
                            comment_text += f"- [ã“ã®ã‚¤ã‚·ãƒ¥ãƒ¼]({related_links['issue_link']})\n"
                        comment_text += "\n"
                    
                    comment_text += f"ğŸ“Š **å‡¦ç†æƒ…å ±:**\n"
                    comment_text += f"- è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢: {complexity.score:.2f}\n"
                    comment_text += f"- å‡¦ç†åŸºæº–: è¤‡é›‘åº¦ < 0.7 ã‹ã¤ å„ªå…ˆåº¦ Medium/Low\n"
                    
                    issue.create_comment(comment_text)
                    
            return result
            
        except Exception as e:
            logger.error(f"Error in auto processing: {str(e)}")
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã«å ±å‘Š
            await self.incident_sage.process_request({
                'type': 'report_incident',
                'severity': 'medium',
                'title': f'Auto-processing failed for issue #{issue.number}',
                'description': str(e)
            })
            
            return {
                'status': 'error',
                'message': str(e)
            }
            
    async def consult_four_sages(self, issue: Issue) -> Dict[str, Any]:
        """4è³¢è€…ã¸ã®ç›¸è«‡"""
        sage_advice = {}
        
        try:
            # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…: éå»ã®é¡ä¼¼äº‹ä¾‹æ¤œç´¢
            knowledge_response = await self.knowledge_sage.process_request({
                'type': 'search',
                'query': f"similar issues to: {issue.title}",
                'limit': 5
            })
            sage_advice['knowledge'] = knowledge_response.get('entries', [])
            
            # ã‚¿ã‚¹ã‚¯è³¢è€…: å®Ÿè¡Œè¨ˆç”»ç«‹æ¡ˆ
            task_response = await self.task_sage.process_request({
                'type': 'create_plan',
                'title': issue.title,
                'description': issue.body or ''
            })
            sage_advice['plan'] = task_response
            
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…: ãƒªã‚¹ã‚¯è©•ä¾¡
            incident_response = await self.incident_sage.process_request({
                'type': 'evaluate_risk',
                'task': issue.title,
                'context': issue.body or ''
            })
            sage_advice['risks'] = incident_response
            
            # RAGè³¢è€…: æœ€é©è§£æ¢ç´¢
            rag_response = await self.rag_sage.process_request({
                'type': 'search',
                'query': f"how to fix: {issue.title}",
                'max_results': 3
            })
            sage_advice['solution'] = rag_response.get('results', [])
            
        except Exception as e:
            logger.warning(f"Sage consultation partial failure: {str(e)}")
            
        return sage_advice
        
    def _determine_priority(self, issue: Issue) -> str:
        """ã‚¤ã‚·ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦ã‚’åˆ¤å®š"""
        labels = [label.name.lower() for label in issue.labels]
        
        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šï¼ˆpriority:xxxãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚‚å¯¾å¿œï¼‰
        if any(label in ['critical', 'urgent', 'p0', 'priority:critical'] for label in labels):
            return 'critical'
        elif any(label in ['high', 'important', 'p1', 'priority:high'] for label in labels):
            return 'high'
        elif any(label in ['medium', 'moderate', 'p2', 'priority:medium'] for label in labels):
            return 'medium'
        elif any(label in ['low', 'minor', 'p3', 'priority:low'] for label in labels):
            return 'low'
            
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
        title_lower = issue.title.lower()
        if any(word in title_lower for word in ['critical', 'urgent', 'emergency']):
            return 'critical'
        elif any(word in title_lower for word in ['important', 'high priority']):
            return 'high'
        elif any(word in title_lower for word in ['bug', 'fix', 'error']):
            return 'medium'
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä½å„ªå…ˆåº¦
        return 'low'


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    processor = AutoIssueProcessor()
    
    # ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
    result = await processor.process_request({'mode': 'scan'})
    print(json.dumps(result, indent=2))


if __name__ == "__main__":
    asyncio.run(main())