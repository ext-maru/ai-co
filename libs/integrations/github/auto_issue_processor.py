#!/usr/bin/env python3
"""
ğŸ¤– GitHub Issue Auto Processor
å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«å‡¦ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import logging
import os

# Elder System imports
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

from github import Github
from github.Issue import Issue

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from libs.core.elders_legacy import EldersServiceLegacy

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from libs.rag_manager import RagManager
from libs.elder_system.flow.elder_flow_engine import ElderFlowEngine
from libs.knowledge_sage import KnowledgeSage
from libs.task_sage import TaskSage
from libs.incident_sage import IncidentSage
from libs.integrations.github.api_implementations.create_pull_request import GitHubCreatePullRequestImplementation
from libs.code_generation.template_manager import CodeGenerationTemplateManager
from libs.integrations.github.safe_git_operations import SafeGitOperations


class AutoIssueElderFlowEngine:
    """Auto Issue Processorå°‚ç”¨ã®Elder Flow Engine"""

    def __init__(self):
        self.elder_flow = ElderFlowEngine()
        
        # GitHubè¨­å®šã®æ¤œè¨¼ã¨åˆæœŸåŒ–
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("GITHUB_REPO_OWNER")
        repo_name = os.getenv("GITHUB_REPO_NAME")

        if not github_token:
            raise ValueError("GITHUB_TOKEN environment variable is required")
        if not repo_owner:
            raise ValueError("GITHUB_REPO_OWNER environment variable is required") 
        if not repo_name:
            raise ValueError("GITHUB_REPO_NAME environment variable is required")

        self.pr_creator = GitHubCreatePullRequestImplementation(
            token=github_token, repo_owner=repo_owner, repo_name=repo_name
        )
        # è‡ªå‹•ãƒãƒ¼ã‚¸ã‚’æœ‰åŠ¹åŒ–
        self.pr_creator.auto_merge_enabled = True
        self.logger = logger
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
        self.template_manager = CodeGenerationTemplateManager()

    async def execute_flow(self, request):
        """Auto Issueç”¨ã®Elder Flowå®Ÿè¡Œ"""
        try:
            task_name = request.get("task_name", "")
            context = request.get("context", {})
            issue_number = context.get("issue_number", 0)
            issue_title = context.get("issue_title", "")
            issue_body = context.get("issue_body", "")

            # Elder Flowã‚’å®Ÿè¡Œ
            flow_result = await self.elder_flow.process_request(
                {
                    "type": "execute",
                    "task_name": task_name,
                    "priority": request.get("priority", "medium"),
                }
            )

            if flow_result.get("status") == "success" or flow_result.get("task_name"):
                # PRä½œæˆã‚’å®Ÿè¡Œ
                pr_result = await self._create_pull_request(
                    issue_number, issue_title, issue_body, task_name
                )

                if pr_result.get("success"):
                    return {
                        "status": "success",
                        "pr_url": pr_result.get("pr_url"),
                        "message": f"Elder Flowå®Œäº†ã€PR #{pr_result.get('pr_number', 'XXX')} ã‚’ä½œæˆã—ã¾ã—ãŸ",
                        "flow_result": flow_result,
                        "pr_result": pr_result,
                    }
                else:
                    return {
                        "status": "partial_success",
                        "pr_url": None,
                        "message": f"Elder Flowå®Œäº†ã€ä½†ã—PRä½œæˆã«å¤±æ•—: {pr_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}",
                        "flow_result": flow_result,
                        "pr_error": pr_result.get("error"),
                    }
            else:
                return {
                    "status": "error",
                    "pr_url": None,
                    "message": f"Elder Flowå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {flow_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}",
                    "flow_result": flow_result,
                }

        except Exception as e:
            self.logger.error(f"Auto Issue Elder Flow execution error: {e}")
            return {
                "status": "error",
                "pr_url": None,
                "message": f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                "error": str(e),
            }

    async def _create_pull_request(
        self, issue_number, issue_title, issue_body, task_name
    ):
        """è‡ªå‹•ã§PRä½œæˆï¼ˆSafeGitOperationsä½¿ç”¨ï¼‰"""
        try:
            # SafeGitOperationsã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            git_ops = SafeGitOperations()
            
            # ãƒ–ãƒ©ãƒ³ãƒåã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            timestamp = datetime.now().strftime("%H%M%S")
            use_timestamp = os.getenv("AUTO_ISSUE_USE_TIMESTAMP", "false").lower() == "true"
            
            if use_timestamp:
                branch_name = f"auto-fix/issue-{issue_number}-{timestamp}"
            else:
                branch_name = f"auto-fix-issue-{issue_number}"

            # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã‚’ä¿å­˜
            current_branch = git_ops.get_current_branch()
            
            # æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ã‚’ä¸€æ™‚ä¿å­˜
            stash_result = git_ops.stash_changes()
            if not stash_result["success"]:
                self.logger.warning(f"Failed to stash changes: {stash_result.get('error', 'Unknown error')}")
            
            try:
                # PRç”¨ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆï¼ˆæ—¢å­˜ãƒ–ãƒ©ãƒ³ãƒã¯è‡ªå‹•å‰Šé™¤ã•ã‚Œã‚‹ï¼‰
                branch_result = git_ops.create_pr_branch_workflow(
                    branch_name=branch_name,
                    commit_message=f"fix: Auto-fix for issue #{issue_number} - {issue_title[:50]}",
                    files_to_add=[]
                )
                
                if not branch_result["success"]:
                    self.logger.error(f"Failed to create branch: {branch_result.get('error', 'Unknown error')}")
                    return {
                        "success": False,
                        "error": f"ãƒ–ãƒ©ãƒ³ãƒä½œæˆã‚¨ãƒ©ãƒ¼: {branch_result.get('error', 'Unknown error')}"
                    }
                
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
                files_created = []
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
                context = self.template_manager.create_context_from_issue(
                    issue_number=issue_number,
                    issue_title=issue_title,
                    issue_body=issue_body
                )
                
                # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ¤œå‡º
                tech_stack = context['tech_stack']
                self.logger.info(f"Detected tech stack for issue #{issue_number}: {tech_stack}")
                
                # å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
                os.makedirs("auto_implementations", exist_ok=True)
                impl_code = self.template_manager.generate_code(
                    template_type='class',
                    tech_stack=tech_stack,
                    context=context
                )
                
                impl_file_path = f"auto_implementations/issue_{issue_number}_implementation.py"
                with open(impl_file_path, "w") as f:
                    f.write(impl_code)
                files_created.append(impl_file_path)
                
                # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
                os.makedirs("tests/auto_generated", exist_ok=True)
                test_code = self.template_manager.generate_code(
                    template_type='test',
                    tech_stack=tech_stack,
                    context=context
                )
                
                test_file_path = f"tests/auto_generated/test_issue_{issue_number}.py"
                with open(test_file_path, "w") as f:
                    f.write(test_code)
                files_created.append(test_file_path)
                
                # è¨­è¨ˆæ›¸ã‚‚ä½œæˆ
                fix_file_path = f"auto_fixes/issue_{issue_number}_fix.md"
                os.makedirs("auto_fixes", exist_ok=True)
                
                with open(fix_file_path, "w") as f:
                    f.write(f"""# Auto-fix for Issue #{issue_number}

## Task: {task_name}

## Original Issue
{issue_title}

{issue_body}

## Generated Files
- Implementation: `{impl_file_path}`
- Test: `{test_file_path}`
- Tech Stack: {tech_stack}

## Template System Info
- Detected keywords: {', '.join(context['requirements']['imports'])}
- Template version: Jinja2 Enhanced Templates (Issue #184 Phase 1)

---
*This file was auto-generated by Elder Flow Auto Issue Processor with Template System*
""")
                files_created.append(fix_file_path)
                
                # ã™ã¹ã¦ã®ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
                for file_path in files_created:
                    subprocess.run(["git", "add", file_path], check=True)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒŸãƒƒãƒˆï¼ˆSafeGitOperationsä½¿ç”¨ï¼‰
                commit_message = f"fix: Auto-fix for issue #{issue_number} - {issue_title[:50]}"
                commit_result = git_ops.auto_commit_if_changes(
                    files=files_created,
                    commit_message=commit_message
                )
                
                if commit_result["success"]:
                    # ãƒ–ãƒ©ãƒ³ãƒã‚’push
                    push_result = git_ops.push_branch_safely(branch_name)
                    if not push_result["success"]:
                        self.logger.error(f"Failed to push branch: {push_result.get('error', 'Unknown error')}")
                        return {
                            "success": False,
                            "error": f"ãƒ–ãƒ©ãƒ³ãƒã®ãƒ—ãƒƒã‚·ãƒ¥ã«å¤±æ•—: {push_result.get('error', 'Unknown error')}"
                        }
                else:
                    self.logger.info("No changes to commit or commit failed")
                    # å¤‰æ›´ãŒãªã„å ´åˆã§ã‚‚PRã¯ä½œæˆå¯èƒ½
                    
            finally:
                # å…ƒã®ãƒ–ãƒ©ãƒ³ãƒã«æˆ»ã‚‹
                git_ops.checkout_branch(current_branch)
                
                # stashã—ãŸå¤‰æ›´ã‚’å¾©å…ƒ
                if stash_result["success"]:
                    git_ops.stash_pop()

            # PRä½œæˆ
            # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
            impl_file_path = files_created[0] if len(files_created) > 0 else "N/A"
            test_file_path = files_created[1] if len(files_created) > 1 else "N/A"
            tech_stack = context.get('tech_stack', 'Unknown') if 'context' in locals() else 'Unknown'
            
            pr_result = self.pr_creator.create_pull_request(
                title=f"Auto-fix: {issue_title} (#{issue_number})",
                head=branch_name,
                base="main",
                body=f"""ğŸ¤– **Auto Issue Processor** ã«ã‚ˆã‚‹è‡ªå‹•ä¿®æ­£

## ä¿®æ­£å†…å®¹
{task_name}

## å¯¾è±¡Issue
Closes #{issue_number}

## å…ƒã®Issueå†…å®¹
{issue_body}

## ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
- å®Ÿè£…: `{impl_file_path}`
- ãƒ†ã‚¹ãƒˆ: `{test_file_path}`
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {tech_stack}

---
*ã“ã®PRã¯Auto Issue Processorã«ã‚ˆã‚ŠSafeGitOperationsã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
""",
                labels=["auto-generated", "auto-fix"],
                draft=False,  # é€šå¸¸ã®PRã¨ã—ã¦ä½œæˆï¼ˆè‡ªå‹•ãƒãƒ¼ã‚¸å¯èƒ½ï¼‰
            )

            if pr_result.get("success"):
                pr_data = pr_result.get("pull_request", {})
                return {
                    "success": True,
                    "pr_url": pr_data.get("html_url"),
                    "pr_number": pr_data.get("number"),
                    "branch_name": branch_name,
                }
            else:
                return {
                    "success": False,
                    "error": pr_result.get("error", "ä¸æ˜ãªPRä½œæˆã‚¨ãƒ©ãƒ¼"),
                }

        except Exception as e:
            return {"success": False, "error": f"PRä½œæˆä¾‹å¤–: {str(e)}"}


# Setup logging
logger = logging.getLogger("AutoIssueProcessor")


class ComplexityScore:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢"""

    def __init__(self, score: float, factors: Dict[str, Any]):
        self.score = score
        self.factors = factors
        self.is_processable = score < 0.7  # 70%æœªæº€ãªã‚‰å‡¦ç†å¯èƒ½


class ProcessingLimiter:
    """å‡¦ç†åˆ¶é™ã‚’ç®¡ç†"""

    MAX_ISSUES_PER_HOUR = 30  # 1æ™‚é–“ã‚ãŸã‚Šæœ€å¤§30ã‚¤ã‚·ãƒ¥ãƒ¼ã¾ã§
    MAX_CONCURRENT = 3  # åŒæ™‚ã«3ã¤ã¾ã§å‡¦ç†å¯èƒ½
    COOLDOWN_PERIOD = 60  # 1åˆ†

    def __init__(self):
        self.processing_log_file = Path("logs/auto_issue_processing.json")
        self.processing_log_file.parent.mkdir(exist_ok=True)

    async def can_process(self) -> bool:
        """å‡¦ç†å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.processing_log_file.exists():
            return True

        with open(self.processing_log_file, "r") as f:
            logs = json.load(f)

        # éå»1æ™‚é–“ã®å‡¦ç†æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        one_hour_ago = datetime.now() - timedelta(hours=1)
        recent_processes = [
            log
            for log in logs
            if datetime.fromisoformat(log["timestamp"]) > one_hour_ago
        ]

        return len(recent_processes) < self.MAX_ISSUES_PER_HOUR

    async def record_processing(self, issue_id: int):
        """å‡¦ç†è¨˜éŒ²ã‚’ä¿å­˜"""
        logs = []
        if self.processing_log_file.exists():
            with open(self.processing_log_file, "r") as f:
                logs = json.load(f)

        logs.append({"issue_id": issue_id, "timestamp": datetime.now().isoformat()})

        # å¤ã„ãƒ­ã‚°ã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = datetime.now() - timedelta(days=1)
        logs = [
            log for log in logs if datetime.fromisoformat(log["timestamp"]) > cutoff
        ]

        with open(self.processing_log_file, "w") as f:
            json.dump(logs, f, indent=2)


class ComplexityEvaluator:
    """ã‚¤ã‚·ãƒ¥ãƒ¼ã®è¤‡é›‘åº¦ã‚’è©•ä¾¡"""

    COMPLEXITY_FACTORS = {
        "file_count": {
            "low": (1, 3),
            "medium": (4, 10),
            "high": (11, None),
        },  # å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°
        "code_lines": {  # æ¨å®šã‚³ãƒ¼ãƒ‰è¡Œæ•°
            "low": (1, 50),
            "medium": (51, 200),
            "high": (201, None),
        },
        "dependencies": {
            "low": (0, 2),
            "medium": (3, 5),
            "high": (6, None),
        },  # ä¾å­˜é–¢ä¿‚æ•°
        "test_coverage": {  # å¿…è¦ãƒ†ã‚¹ãƒˆæ•°
            "low": (1, 5),
            "medium": (6, 15),
            "high": (16, None),
        },
    }

    PROCESSABLE_PATTERNS = [
        "typo",
        "documentation",
        "comment",
        "rename",
        "format",
        "style",
        "test",
        "simple bug",
    ]

    async def evaluate(self, issue: Issue) -> ComplexityScore:
        """è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        factors = {}
        total_score = 0

        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒœãƒ‡ã‚£ã‹ã‚‰è¤‡é›‘åº¦ã‚’æ¨å®š
        text = f"{issue.title} {issue.body or ''}".lower()

        # å˜ç´”ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        is_simple = any(pattern in text for pattern in self.PROCESSABLE_PATTERNS)
        if is_simple:
            factors["pattern_match"] = 0.3
            total_score += 0.3
        else:
            factors["pattern_match"] = 0.7
            total_score += 0.7

        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
        labels = [label.name for label in issue.labels]
        if "good first issue" in labels:
            factors["label_complexity"] = 0.2
            total_score += 0.2
        elif "bug" in labels and "critical" not in labels:
            factors["label_complexity"] = 0.4
            total_score += 0.4
        else:
            factors["label_complexity"] = 0.6
            total_score += 0.6

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(
            word in text
            for word in ["security", "vulnerability", "auth", "token", "password"]
        ):
            factors["security_related"] = 1.0
            total_score += 1.0

        # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_score = total_score / len(factors) if factors else 1.0

        return ComplexityScore(avg_score, factors)


class AutoIssueProcessor(EldersServiceLegacy):
    """
    GitHubã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
    å„ªå…ˆåº¦Medium/Lowã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•çš„ã«Elder Flowã§å‡¦ç†
    """

    def __init__(self):
        super().__init__("auto_issue_processor")
        self.domain = "GITHUB"
        self.service_name = "AutoIssueProcessor"

        # GitHub APIåˆæœŸåŒ–
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("GITHUB_REPO_OWNER", "ext-maru")
        repo_name = os.getenv("GITHUB_REPO_NAME", "ai-co")

        if not github_token:
            raise ValueError("GITHUB_TOKEN environment variable not set")

        self.github = Github(github_token)
        self.repo = self.github.get_repo(f"{repo_owner}/{repo_name}")

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.elder_flow = AutoIssueElderFlowEngine()
        self.task_sage = TaskSage()
        self.incident_sage = IncidentSage()
        self.knowledge_sage = KnowledgeSage()
        self.rag_sage = RagManager()

        self.limiter = ProcessingLimiter()
        self.evaluator = ComplexityEvaluator()

        # å‡¦ç†å¯¾è±¡ã®å„ªå…ˆåº¦ï¼ˆä¸­ä»¥ä¸Šï¼‰
        self.target_priorities = ["critical", "high", "medium"]
        
        # å‡¦ç†å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«
        self.processing_history_file = "logs/auto_issue_processing.json"

    def get_capabilities(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®æ©Ÿèƒ½ã‚’è¿”ã™"""
        return {
            "service": "AutoIssueProcessor",
            "version": "1.0.0",
            "capabilities": [
                "GitHub issue scanning",
                "Complexity evaluation",
                "Automatic processing",
                "Elder Flow integration",
                "Quality gate validation",
            ],
            "limits": {
                "max_issues_per_hour": ProcessingLimiter.MAX_ISSUES_PER_HOUR,
                "max_concurrent": ProcessingLimiter.MAX_CONCURRENT,
                "target_priorities": self.target_priorities,
            },
        }

    def validate_request(self, request: Dict[str, Any]) -> bool:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®æ¤œè¨¼
        if "mode" in request and request["mode"] not in ["scan", "process", "dry_run"]:
            return False

        # ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®æ¤œè¨¼
        if "issue_number" in request:
            if not isinstance(request["issue_number"], int):
                return False

        return True

    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        mode = request.get("mode", "scan")

        try:
            if mode == "scan":
                # å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³
                issues = await self.scan_processable_issues()
                return {
                    "status": "success",
                    "processable_issues": len(issues),
                    "issues": [
                        {
                            "number": issue.number,
                            "title": issue.title,
                            "priority": self._determine_priority(issue),
                            "complexity": (await self.evaluator.evaluate(issue)).score,
                        }
                        for issue in issues[:5]  # æœ€å¤§5ä»¶ã¾ã§è¡¨ç¤º
                    ],
                }

            elif mode == "process":
                # å®Ÿéš›ã«å‡¦ç†ã‚’å®Ÿè¡Œ
                if not await self.limiter.can_process():
                    return {
                        "status": "rate_limited",
                        "message": "Processing limit reached. Please try again later.",
                    }

                issues = await self.scan_processable_issues()
                if not issues:
                    return {
                        "status": "no_issues",
                        "message": "No processable issues found.",
                    }

                # æœ€åˆã®ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å‡¦ç†
                issue = issues[0]
                result = await self.execute_auto_processing(issue)

                return {
                    "status": "success",
                    "processed_issue": {
                        "number": issue.number,
                        "title": issue.title,
                        "result": result,
                    },
                }

            elif mode == "dry_run":
                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã«ã¯å‡¦ç†ã—ãªã„ï¼‰
                issue_number = request.get("issue_number")
                if issue_number:
                    issue = self.repo.get_issue(issue_number)
                    complexity = await self.evaluator.evaluate(issue)

                    return {
                        "status": "dry_run",
                        "issue": {
                            "number": issue.number,
                            "title": issue.title,
                            "priority": self._determine_priority(issue),
                            "complexity": complexity.score,
                            "processable": complexity.is_processable,
                            "factors": complexity.factors,
                        },
                    }

        except Exception as e:
            logger.error(f"Error in process_request: {str(e)}")
            return {"status": "error", "message": str(e)}

    async def scan_processable_issues(self) -> List[Issue]:
        """å‡¦ç†å¯èƒ½ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆé‡è¤‡å‡¦ç†é˜²æ­¢æ©Ÿèƒ½ä»˜ãï¼‰"""
        processable_issues = []

        # æœ€è¿‘å‡¦ç†ã•ã‚ŒãŸã‚¤ã‚·ãƒ¥ãƒ¼ã‚’ç¢ºèªï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        recently_processed = self._get_recently_processed_issues()

        # ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å–å¾—
        open_issues = self.repo.get_issues(state="open")

        for issue in open_issues:
            # PRã¯é™¤å¤–
            if issue.pull_request:
                continue

            # é‡è¤‡å‡¦ç†é˜²æ­¢ãƒã‚§ãƒƒã‚¯
            if issue.number in recently_processed:
                logger.info(f"Issue #{issue.number} ã¯æœ€è¿‘å‡¦ç†æ¸ˆã¿ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                continue

            # å„ªå…ˆåº¦ãƒã‚§ãƒƒã‚¯
            priority = self._determine_priority(issue)
            if priority not in self.target_priorities:
                continue

            # è¤‡é›‘åº¦è©•ä¾¡
            complexity = await self.evaluator.evaluate(issue)
            if complexity.is_processable:
                processable_issues.append(issue)

            # æœ€å¤§10ä»¶ã¾ã§
            if len(processable_issues) >= 10:
                break

        return processable_issues

    def _get_recently_processed_issues(self, hours=24) -> Set[int]:
        """æŒ‡å®šæ™‚é–“å†…ã«å‡¦ç†ã•ã‚ŒãŸã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ã‚’å–å¾—"""
        recently_processed = set()
        
        try:
            import json
            from datetime import datetime, timedelta
            
            if not os.path.exists(self.processing_history_file):
                return recently_processed
                
            with open(self.processing_history_file, 'r') as f:
                history = json.load(f)
                
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            for record in history:
                try:
                    record_time = datetime.fromisoformat(record.get("timestamp", ""))
                    if record_time > cutoff_time:
                        issue_id = record.get("issue_id") or record.get("issue_number")
                        if issue_id:
                            recently_processed.add(int(issue_id))
                except (ValueError, TypeError):
                    continue
                    
        except Exception as e:
            logger.warning(f"å‡¦ç†å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            
        return recently_processed

    async def execute_auto_processing(self, issue: Issue) -> Dict[str, Any]:
        """Elder Flowã‚’ä½¿ç”¨ã—ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’è‡ªå‹•å‡¦ç†"""
        try:
            # æ—¢å­˜ã®PRã‚’ãƒã‚§ãƒƒã‚¯
            existing_pr = await self._check_existing_pr_for_issue(issue.number)
            if existing_pr:
                logger.info(f"PR already exists for issue #{issue.number}: PR #{existing_pr['number']}")
                return {
                    "status": "already_exists",
                    "message": f"PR #{existing_pr['number']} already exists for this issue",
                    "pr_url": existing_pr['html_url'],
                    "pr_number": existing_pr['number']
                }
            
            # å‡¦ç†è¨˜éŒ²
            await self.limiter.record_processing(issue.number)

            # è¤‡é›‘åº¦è©•ä¾¡ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç”¨ï¼‰
            complexity = await self.evaluator.evaluate(issue)

            # 4è³¢è€…ã«ç›¸è«‡
            sage_advice = await self.consult_four_sages(issue)

            # Elder Flowãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰
            flow_request = {
                "task_name": f"Auto-fix Issue #{issue.number}: {issue.title}",
                "priority": self._determine_priority(issue),
                "context": {
                    "issue_number": issue.number,
                    "issue_title": issue.title,
                    "issue_body": issue.body or "",
                    "labels": [label.name for label in issue.labels],
                    "sage_advice": sage_advice,
                },
            }

            # Elder Flowå®Ÿè¡Œ
            result = await self.elder_flow.execute_flow(flow_request)

            # çµæœã«åŸºã¥ã„ã¦ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’æ›´æ–°
            if result.get("status") == "already_exists":
                # æ—¢å­˜ã®PRãŒã‚ã‚‹å ´åˆ
                issue.create_comment(
                    f"ğŸ¤– Auto Issue Processor Notice\n\n"
                    f"This issue already has an associated PR: {result.get('pr_url')}\n"
                    f"Skipping automatic processing to avoid duplication."
                )
                return result
            elif result.get("status") == "success":
                # PRãŒä½œæˆã•ã‚ŒãŸã‚‰ã‚¤ã‚·ãƒ¥ãƒ¼ã«ã‚³ãƒ¡ãƒ³ãƒˆ
                pr_url = result.get("pr_url")
                message = result.get("message", "")

                if pr_url:
                    issue.create_comment(
                        f"ğŸ¤– Auto-processed by Elder Flow\n\n"
                        f"PR created: {pr_url}\n\n"
                        f"This issue was automatically processed based on its complexity "
                        f"and priority level."
                    )
                elif message:
                    # PR URLãŒãªã„å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    related_links = result.get("related_links", {})

                    comment_text = f"ğŸ¤– Elder Flowå‡¦ç†å®Œäº†\n\n"
                    comment_text += f"{message}\n\n"

                    # é–¢é€£ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    if related_links:
                        comment_text += "ğŸ“š **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**\n"
                        if related_links.get("design_doc"):
                            comment_text += f"- [ã‚¤ã‚·ãƒ¥ãƒ¼è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸]({related_links['design_doc']})\n"
                        if related_links.get("elder_flow_doc"):
                            comment_text += f"- [Elder Flowã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£]({related_links['elder_flow_doc']})\n"
                        if related_links.get("issue_link"):
                            comment_text += (
                                f"- [ã“ã®ã‚¤ã‚·ãƒ¥ãƒ¼]({related_links['issue_link']})\n"
                            )
                        comment_text += "\n"

                    comment_text += f"ğŸ“Š **å‡¦ç†æƒ…å ±:**\n"
                    comment_text += f"- è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢: {complexity.score:.2f}\n"
                    comment_text += f"- å‡¦ç†åŸºæº–: è¤‡é›‘åº¦ < 0.7 ã‹ã¤ å„ªå…ˆåº¦ Medium/Low\n"

                    issue.create_comment(comment_text)

            return result

        except Exception as e:
            logger.error(f"Error in auto processing: {str(e)}")
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã«å ±å‘Š
            await self.incident_sage.process_request(
                {
                    "type": "report_incident",
                    "severity": "medium",
                    "title": f"Auto-processing failed for issue #{issue.number}",
                    "description": str(e),
                }
            )

            return {"status": "error", "message": str(e)}

    async def consult_four_sages(self, issue: Issue) -> Dict[str, Any]:
        """4è³¢è€…ã¸ã®ç›¸è«‡"""
        sage_advice = {}

        try:
            # ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…: éå»ã®é¡ä¼¼äº‹ä¾‹æ¤œç´¢
            knowledge_response = await self.knowledge_sage.process_request(
                {
                    "type": "search",
                    "query": f"similar issues to: {issue.title}",
                    "limit": 5,
                }
            )
            sage_advice["knowledge"] = knowledge_response.get("entries", [])

            # ã‚¿ã‚¹ã‚¯è³¢è€…: å®Ÿè¡Œè¨ˆç”»ç«‹æ¡ˆ
            task_response = await self.task_sage.process_request(
                {
                    "type": "create_plan",
                    "title": issue.title,
                    "description": issue.body or "",
                }
            )
            sage_advice["plan"] = task_response

            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…: ãƒªã‚¹ã‚¯è©•ä¾¡
            incident_response = await self.incident_sage.process_request(
                {
                    "type": "evaluate_risk",
                    "task": issue.title,
                    "context": issue.body or "",
                }
            )
            sage_advice["risks"] = incident_response

            # RAGè³¢è€…: æœ€é©è§£æ¢ç´¢
            rag_response = await self.rag_sage.process_request(
                {
                    "type": "search",
                    "query": f"how to fix: {issue.title}",
                    "max_results": 3,
                }
            )
            sage_advice["solution"] = rag_response.get("results", [])

        except Exception as e:
            logger.warning(f"Sage consultation partial failure: {str(e)}")

        return sage_advice

    def _determine_priority(self, issue: Issue) -> str:
        """ã‚¤ã‚·ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦ã‚’åˆ¤å®š"""
        labels = [label.name.lower() for label in issue.labels]

        # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šï¼ˆpriority:xxxãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚‚å¯¾å¿œï¼‰
        if any(
            label in ["critical", "urgent", "p0", "priority:critical"]
            for label in labels
        ):
            return "critical"
        elif any(
            label in ["high", "important", "p1", "priority:high"] for label in labels
        ):
            return "high"
        elif any(
            label in ["medium", "moderate", "p2", "priority:medium"] for label in labels
        ):
            return "medium"
        elif any(label in ["low", "minor", "p3", "priority:low"] for label in labels):
            return "low"

        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
        title_lower = issue.title.lower()
        if any(word in title_lower for word in ["critical", "urgent", "emergency"]):
            return "critical"
        elif any(word in title_lower for word in ["important", "high priority"]):
            return "high"
        elif any(word in title_lower for word in ["bug", "fix", "error"]):
            return "medium"

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä½å„ªå…ˆåº¦
        return "low"
    
    async def _check_existing_pr_for_issue(self, issue_number: int) -> Optional[Dict[str, Any]]:
        """æŒ‡å®šã•ã‚ŒãŸã‚¤ã‚·ãƒ¥ãƒ¼ã«å¯¾ã™ã‚‹æ—¢å­˜ã®PRã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # ã‚ªãƒ¼ãƒ—ãƒ³ãªPRã‚’æ¤œç´¢
            pulls = self.repo.get_pulls(state='open')
            
            for pr in pulls:
                # PRã®ãƒœãƒ‡ã‚£å†…ã§ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ã¸ã®å‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯
                if pr.body and f"#{issue_number}" in pr.body:
                    return {
                        "number": pr.number,
                        "html_url": pr.html_url,
                        "title": pr.title,
                        "state": pr.state
                    }
                
                # ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚¤ã‚·ãƒ¥ãƒ¼ç•ªå·ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if f"#{issue_number}" in pr.title:
                    return {
                        "number": pr.number,
                        "html_url": pr.html_url,
                        "title": pr.title,
                        "state": pr.state
                    }
            
            # ã‚¯ãƒ­ãƒ¼ã‚ºã•ã‚ŒãŸPRã‚‚ç¢ºèªï¼ˆæœ€è¿‘ã®ã‚‚ã®ã®ã¿ï¼‰
            closed_pulls = self.repo.get_pulls(state='closed', sort='updated', direction='desc')
            count = 0
            for pr in closed_pulls:
                if count >= 20:  # æœ€è¿‘ã®20ä»¶ã®ã¿ãƒã‚§ãƒƒã‚¯
                    break
                    
                if pr.body and f"#{issue_number}" in pr.body:
                    return {
                        "number": pr.number,
                        "html_url": pr.html_url,
                        "title": pr.title,
                        "state": pr.state
                    }
                    
                if f"#{issue_number}" in pr.title:
                    return {
                        "number": pr.number,
                        "html_url": pr.html_url,
                        "title": pr.title,
                        "state": pr.state
                    }
                    
                count += 1
            
            return None
            
        except Exception as e:
            logger.warning(f"Error checking existing PRs: {str(e)}")
            return None



async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    processor = AutoIssueProcessor()

    # ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
    result = await processor.process_request({"mode": "scan"})
    print(json.dumps(result, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
