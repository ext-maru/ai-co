#!/usr/bin/env python3
"""
Elders Guild Knowledge Consolidation System
å…¨ã¦ã®è¨­è¨ˆãƒ»ãƒŠãƒ¬ãƒƒã‚¸ãƒ»å®Ÿè£…ã‚’çµ±åˆç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import hashlib
import json
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import logging

from core import EMOJI, BaseManager, get_config
from libs.slack_notifier import SlackNotifier


class KnowledgeConsolidator(BaseManager):
    """è¨­è¨ˆãƒ»ãƒŠãƒ¬ãƒƒã‚¸ãƒ»å®Ÿè£…ã®çµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        super().__init__(manager_name="knowledge_consolidator")
        self.config = get_config()
        self.project_root = Path("/home/aicompany/ai_co")
        self.knowledge_base = self.project_root / "knowledge_base"
        self.consolidated_kb = self.knowledge_base / "CONSOLIDATED_KNOWLEDGE"
        self.ensure_directories()

    def initialize(self):
        """BaseManagerã®æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…"""
        self.logger.info(f"{EMOJI['rocket']} Knowledge Consolidator initialized")

    def ensure_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.consolidated_kb.mkdir(parents=True, exist_ok=True)

    def scan_project_structure(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ã‚¹ã‚­ãƒ£ãƒ³"""
        self.logger.info(f"{EMOJI['info']} Scanning project structure...")

        structure = {
            "timestamp": datetime.now().isoformat(),
            "version": self._get_project_version(),
            "directories": {},
            "statistics": {"total_files": 0, "total_lines": 0, "file_types": {}},
        }

        # ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚­ãƒ£ãƒ³
        key_dirs = [
            "core",
            "workers",
            "libs",
            "scripts",
            "commands",
            "config",
            "templates",
            "knowledge_base",
            "web",
            "bin",
        ]

        for dir_name in key_dirs:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                structure["directories"][dir_name] = self._scan_directory(dir_path)

        # çµ±è¨ˆæƒ…å ±ã®é›†è¨ˆ
        self._calculate_statistics(structure)

        return structure

    def _scan_directory(self, path: Path) -> Dict[str, Any]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è©³ç´°ã‚¹ã‚­ãƒ£ãƒ³"""
        dir_info = {"files": [], "subdirs": {}, "total_files": 0, "total_size": 0}

        try:
            for item in path.iterdir():
                if item.name.startswith("."):
                    continue

                if item.is_file():
                    file_info = {
                        "name": item.name,
                        "size": item.stat().st_size,
                        "modified": datetime.fromtimestamp(
                            item.stat().st_mtime
                        ).isoformat(),
                        "lines": self._count_lines(item),
                    }
                    dir_info["files"].append(file_info)
                    dir_info["total_files"] += 1
                    dir_info["total_size"] += file_info["size"]

                elif item.is_dir() and item.name not in ["__pycache__", "venv", ".git"]:
                    dir_info["subdirs"][item.name] = self._scan_directory(item)

        except Exception as e:
            self.logger.warning(f"Error scanning {path}: {e}")

        return dir_info

    def _count_lines(self, file_path: Path) -> int:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if file_path.suffix not in [".py", ".sh", ".md", ".json", ".yaml", ".yml"]:
            return 0

        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                return sum(1 for _ in f)
        except:
            return 0

    def consolidate_knowledge_base(self) -> Dict[str, Any]:
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®çµ±åˆ"""
        self.logger.info(f"{EMOJI['template']} Consolidating knowledge base...")

        kb_files = []
        kb_content = {}

        # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†
        for kb_file in self.knowledge_base.glob("*.md"):
            try:
                content = kb_file.read_text(encoding="utf-8")
                kb_info = {
                    "filename": kb_file.name,
                    "size": len(content),
                    "lines": content.count("\n"),
                    "modified": datetime.fromtimestamp(
                        kb_file.stat().st_mtime
                    ).isoformat(),
                    "hash": hashlib.md5(content.encode()).hexdigest(),
                }
                kb_files.append(kb_info)
                kb_content[kb_file.name] = content

            except Exception as e:
                self.logger.error(f"Error reading {kb_file}: {e}")

        return {"files": kb_files, "content": kb_content, "total_files": len(kb_files)}

    def analyze_implementations(self) -> Dict[str, Any]:
        """å®Ÿè£…ã®åˆ†æ"""
        self.logger.info(f"{EMOJI['gear']} Analyzing implementations...")

        analysis = {"workers": {}, "managers": {}, "commands": {}, "core_modules": {}}

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ†æ
        for worker_file in (self.project_root / "workers").glob("*_worker.py"):
            analysis["workers"][worker_file.stem] = self._analyze_python_file(
                worker_file
            )

        # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆ†æ
        for manager_file in (self.project_root / "libs").glob("*_manager.py"):
            analysis["managers"][manager_file.stem] = self._analyze_python_file(
                manager_file
            )

        # ã‚³ãƒãƒ³ãƒ‰ã®åˆ†æ
        for cmd_file in (self.project_root / "commands").glob("ai_*.py"):
            analysis["commands"][cmd_file.stem] = self._analyze_python_file(cmd_file)

        # Coreãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ†æ
        for core_file in (self.project_root / "core").glob("*.py"):
            if not core_file.name.startswith("__"):
                analysis["core_modules"][core_file.stem] = self._analyze_python_file(
                    core_file
                )

        return analysis

    def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ"""
        try:
            content = file_path.read_text(encoding="utf-8")

            # ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã®æŠ½å‡º
            classes = re.findall(r"^class\s+(\w+)", content, re.MULTILINE)
            functions = re.findall(r"^def\s+(\w+)", content, re.MULTILINE)
            imports = re.findall(
                r"^(?:from|import)\s+(.+?)(?:\s+import|$)", content, re.MULTILINE
            )

            # docstringã®æŠ½å‡º
            docstring_match = re.search(r'^"""(.+?)"""', content, re.DOTALL)
            docstring = docstring_match.group(1).strip() if docstring_match else ""

            return {
                "classes": classes,
                "functions": functions,
                "imports": list(set(imports)),
                "docstring": docstring,
                "lines": content.count("\n"),
                "size": len(content),
            }

        except Exception as e:
            self.logger.error(f"Error analyzing {file_path}: {e}")
            return {}

    def generate_system_map(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒãƒƒãƒ—ç”Ÿæˆ"""
        self.logger.info(f"{EMOJI['network']} Generating system map...")

        system_map = {
            "architecture": self._analyze_architecture(),
            "dependencies": self._analyze_dependencies(),
            "workflow": self._analyze_workflow(),
            "integration_points": self._analyze_integrations(),
        }

        return system_map

    def _analyze_architecture(self) -> Dict[str, Any]:
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æ"""
        return {
            "layers": {
                "presentation": ["commands", "web", "scripts"],
                "application": ["workers", "managers"],
                "domain": ["core", "libs"],
                "infrastructure": ["config", "db", "logs"],
            },
            "patterns": [
                "Message Queue (RabbitMQ)",
                "Worker Pattern",
                "Manager Pattern",
                "Command Pattern",
            ],
        }

    def _analyze_dependencies(self) -> Dict[str, Any]:
        """ä¾å­˜é–¢ä¿‚ã®åˆ†æ"""
        deps = {}

        # requirements.txtã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’èª­ã¿å–ã‚Š
        req_file = self.project_root / "requirements.txt"
        if req_file.exists():
            deps["python"] = [
                line.strip()
                for line in req_file.read_text().splitlines()
                if line.strip() and not line.startswith("#")
            ]

        # ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚
        deps["system"] = ["rabbitmq-server", "claude-cli", "git", "python3.12"]

        return deps

    def _analyze_workflow(self) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æ"""
        return {
            "task_flow": [
                "User -> ai-send/ai-dialog",
                "-> RabbitMQ",
                "-> TaskWorker (Claude CLI)",
                "-> PMWorker (File placement)",
                "-> ResultWorker (Notification)",
            ],
            "command_flow": [
                "AI creates command",
                "-> AI Command Executor",
                "-> Execute",
                "-> Result notification",
            ],
        }

    def _analyze_integrations(self) -> Dict[str, Any]:
        """çµ±åˆãƒã‚¤ãƒ³ãƒˆã®åˆ†æ"""
        return {
            "external": ["Claude CLI", "Slack", "GitHub"],
            "internal": ["RabbitMQ", "SQLite", "AI Command Executor"],
            "protocols": ["AMQP", "HTTP/HTTPS", "WebSocket"],
        }

    def generate_documentation(self) -> Path:
        """çµ±åˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç”Ÿæˆ"""
        self.logger.info(f"{EMOJI['file']} Generating consolidated documentation...")

        # å…¨æƒ…å ±ã®åé›†
        project_structure = self.scan_project_structure()
        knowledge_base = self.consolidate_knowledge_base()
        implementations = self.analyze_implementations()
        system_map = self.generate_system_map()

        # çµ±åˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        doc_path = self.consolidated_kb / f"AI_COMPANY_CONSOLIDATED_{timestamp}.md"

        with open(doc_path, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ¯ Elders Guild çµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
            f.write("## ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼\n\n")
            f.write(f"- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³**: {project_structure['version']}\n")
            f.write(
                f"- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {project_structure['statistics']['total_files']}\n"
            )
            f.write(f"- **ç·è¡Œæ•°**: {project_structure['statistics']['total_lines']}\n")
            f.write(f"- **ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°**: {len(implementations['workers'])}\n")
            f.write(f"- **ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æ•°**: {len(implementations['managers'])}\n")
            f.write(f"- **ã‚³ãƒãƒ³ãƒ‰æ•°**: {len(implementations['commands'])}\n\n")

            # ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
            f.write("## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n\n")
            f.write("### ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹æˆ\n")
            for layer, components in system_map["architecture"]["layers"].items():
                f.write(f"- **{layer.title()}**: {', '.join(components)}\n")
            f.write("\n")

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
            f.write("### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n")
            f.write("```\n")
            for flow in system_map["workflow"]["task_flow"]:
                f.write(f"{flow}\n")
            f.write("```\n\n")

            # å®Ÿè£…è©³ç´°
            f.write("## ğŸ”§ å®Ÿè£…è©³ç´°\n\n")

            # ãƒ¯ãƒ¼ã‚«ãƒ¼ä¸€è¦§
            f.write("### ãƒ¯ãƒ¼ã‚«ãƒ¼å®Ÿè£…\n")
            for worker_name, worker_info in implementations["workers"].items():
                f.write(f"#### {worker_name}\n")
                if worker_info.get("docstring"):
                    f.write(f"{worker_info['docstring']}\n")
                f.write(f"- ã‚¯ãƒ©ã‚¹: {', '.join(worker_info.get('classes', []))}\n")
                f.write(f"- é–¢æ•°æ•°: {len(worker_info.get('functions', []))}\n")
                f.write(f"- è¡Œæ•°: {worker_info.get('lines', 0)}\n\n")

            # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä¸€è¦§
            f.write("### ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å®Ÿè£…\n")
            for manager_name, manager_info in implementations["managers"].items():
                f.write(f"#### {manager_name}\n")
                if manager_info.get("docstring"):
                    f.write(f"{manager_info['docstring']}\n")
                f.write(f"- ã‚¯ãƒ©ã‚¹: {', '.join(manager_info.get('classes', []))}\n")
                f.write(f"- é–¢æ•°æ•°: {len(manager_info.get('functions', []))}\n\n")

            # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆ
            f.write("## ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹\n\n")
            f.write("### å«ã¾ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n")
            for kb_file in knowledge_base["files"]:
                f.write(f"- **{kb_file['filename']}** ({kb_file['lines']} lines)\n")
            f.write("\n")

            # çµ±è¨ˆæƒ…å ±
            f.write("## ğŸ“ˆ çµ±è¨ˆæƒ…å ±\n\n")
            f.write("### ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ\n")
            for file_type, count in project_structure["statistics"][
                "file_types"
            ].items():
                f.write(f"- {file_type}: {count} files\n")

        self.logger.info(f"{EMOJI['success']} Documentation generated: {doc_path}")
        return doc_path

    def _calculate_statistics(self, structure: Dict[str, Any]):
        """çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—"""
        total_files = 0
        total_lines = 0
        file_types = {}

        def count_in_dir(dir_info):
            nonlocal total_files, total_lines

            for file_info in dir_info.get("files", []):
                total_files += 1
                total_lines += file_info.get("lines", 0)

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®é›†è¨ˆ
                ext = Path(file_info["name"]).suffix
                if ext:
                    file_types[ext] = file_types.get(ext, 0) + 1

            for subdir in dir_info.get("subdirs", {}).values():
                count_in_dir(subdir)

        for dir_info in structure["directories"].values():
            count_in_dir(dir_info)

        structure["statistics"]["total_files"] = total_files
        structure["statistics"]["total_lines"] = total_lines
        structure["statistics"]["file_types"] = dict(sorted(file_types.items()))

    def _get_project_version(self) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å–å¾—"""
        try:
            # Gitã‚¿ã‚°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            result = subprocess.run(
                ["git", "describe", "--tags", "--always"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except:
            pass

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³
        return "v5.3-dev"

    def create_interactive_report(self) -> Path:
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.logger.info(f"{EMOJI['monitor']} Creating interactive report...")

        # ãƒ‡ãƒ¼ã‚¿åé›†
        data = {
            "structure": self.scan_project_structure(),
            "knowledge": self.consolidate_knowledge_base(),
            "implementations": self.analyze_implementations(),
            "system_map": self.generate_system_map(),
        }

        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.project_root / "web" / f"knowledge_report_{timestamp}.html"

        html_content = self._generate_html_report(data)
        report_path.write_text(html_content, encoding="utf-8")

        self.logger.info(
            f"{EMOJI['success']} Interactive report created: {report_path}"
        )
        return report_path

    def _generate_html_report(self, data: Dict[str, Any]) -> str:
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        return f"""<!DOCTYPE html>
<html>
<head>
    <title>Elders Guild Knowledge Report</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
        .stat-card {{ background: #ecf0f1; padding: 15px; border-radius: 5px; text-align: center; }}
        .stat-value {{ font-size: 2em; font-weight: bold; color: #3498db; }}
        .stat-label {{ color: #7f8c8d; margin-top: 5px; }}
        pre {{ background: #2c3e50; color: #ecf0f1; padding: 15px; border-radius: 5px; overflow-x: auto; }}
        .tree {{ font-family: monospace; white-space: pre; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background: #3498db; color: white; }}
        tr:nth-child(even) {{ background: #f2f2f2; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ Elders Guild Knowledge Report</h1>
        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

        <h2>ğŸ“Š Overview</h2>
        <div class="stats">
            <div class="stat-card">
                <div class="stat-value">{data['structure']['statistics']['total_files']}</div>
                <div class="stat-label">Total Files</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{data['structure']['statistics']['total_lines']:,}</div>
                <div class="stat-label">Total Lines</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{len(data['implementations']['workers'])}</div>
                <div class="stat-label">Workers</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{len(data['implementations']['managers'])}</div>
                <div class="stat-label">Managers</div>
            </div>
        </div>

        <h2>ğŸ—ï¸ Architecture</h2>
        <pre>{json.dumps(data['system_map']['architecture'], indent=2)}</pre>

        <h2>ğŸ“‹ Implementation Details</h2>
        <h3>Workers</h3>
        <table>
            <tr><th>Worker</th><th>Classes</th><th>Functions</th><th>Lines</th></tr>
            {"".join(f"<tr><td>{name}</td><td>{', '.join(info.get('classes', []))}</td><td>{len(info.get('functions', []))}</td><td>{info.get('lines', 0)}</td></tr>" for name, info in data['implementations']['workers'].items())}
        </table>

        <h3>Managers</h3>
        <table>
            <tr><th>Manager</th><th>Classes</th><th>Functions</th><th>Lines</th></tr>
            {"".join(f"<tr><td>{name}</td><td>{', '.join(info.get('classes', []))}</td><td>{len(info.get('functions', []))}</td><td>{info.get('lines', 0)}</td></tr>" for name, info in data['implementations']['managers'].items())}
        </table>

        <h2>ğŸ“š Knowledge Base</h2>
        <table>
            <tr><th>Document</th><th>Lines</th><th>Modified</th></tr>
            {"".join(f"<tr><td>{f['filename']}</td><td>{f['lines']}</td><td>{f['modified']}</td></tr>" for f in data['knowledge']['files'])}
        </table>
    </div>
</body>
</html>"""

    def run_consolidation(self):
        """çµ±åˆå‡¦ç†ã®å®Ÿè¡Œ"""
        try:
            self.logger.info(f"{EMOJI['rocket']} Starting knowledge consolidation...")

            # Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
            doc_path = self.generate_documentation()

            # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report_path = self.create_interactive_report()

            # JSONå½¢å¼ã§ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            self.export_to_json()

            # Slacké€šçŸ¥
            self._notify_completion(doc_path, report_path)

            self.logger.info(
                f"{EMOJI['party']} Knowledge consolidation completed successfully!"
            )

        except Exception as e:
            self.handle_error(e, "run_consolidation")
            raise

    def export_to_json(self):
        """JSONå½¢å¼ã§ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_path = self.consolidated_kb / f"knowledge_export_{timestamp}.json"

        export_data = {
            "timestamp": timestamp,
            "structure": self.scan_project_structure(),
            "implementations": self.analyze_implementations(),
            "system_map": self.generate_system_map(),
        }

        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        self.logger.info(f"Exported to JSON: {json_path}")

    def _notify_completion(self, doc_path: Path, report_path: Path):
        """å®Œäº†é€šçŸ¥"""
        try:
            from libs.slack_notifier import SlackNotifier

            notifier = SlackNotifier()

            message = f"""
{EMOJI['party']} Elders Guild Knowledge Consolidation Complete!

ğŸ“„ Documentation: {doc_path.name}
ğŸ“Š Interactive Report: {report_path.name}
ğŸ“ Location: {self.consolidated_kb}

Access the report at: http://localhost:8080/{report_path.name}
"""
            notifier.send_message(message)

        except Exception as e:
            self.logger.warning(f"Failed to send Slack notification: {e}")


if __name__ == "__main__":
    consolidator = KnowledgeConsolidator()
    consolidator.run_consolidation()
