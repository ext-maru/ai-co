#!/usr/bin/env python3
"""
ğŸ” Lightweight RAG Sage - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå®Ÿè£…
Elder Flowç”¨ã®è»½é‡ç‰ˆRAGè³¢è€…å®Ÿè£…

ä¸»ãªæœ€é©åŒ–:
- é…å»¶åˆæœŸåŒ–
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
- ãƒãƒƒãƒå‡¦ç†
- ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

ä½œæˆè€…: ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼
ä½œæˆæ—¥: 2025-07-20
"""

import gc
import hashlib
import json
import logging
import os
import sqlite3
import time
from collections import OrderedDict
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """æ¤œç´¢çµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆè»½é‡ç‰ˆï¼‰"""

    content: str
    source: str
    relevance_score: float
    timestamp: datetime
    metadata: Dict[str, Any]


class LightweightRAGSage:
    """
    ğŸ” è»½é‡ç‰ˆRAGè³¢è€… - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå®Ÿè£…

    Elder Flowç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸRAG Manager
    """

    def __init__(
        self,
        knowledge_base_path: str = "/home/aicompany/ai_co/knowledge_base",
        max_cache_size: int = 100,
        enable_connection_pool: bool = False,
    ):
        """è»½é‡ç‰ˆRAG Sageã‚’åˆæœŸåŒ–ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        self.knowledge_base_path = Path(knowledge_base_path)
        self.db_path = self.knowledge_base_path / "rag_knowledge_light.db"
        self.max_cache_size = max_cache_size
        self.enable_connection_pool = enable_connection_pool

        # é…å»¶åˆæœŸåŒ–ã®ãŸã‚ã®ãƒ•ãƒ©ã‚°
        self.is_initialized = False
        self._db_connection = None
        self._connection_count = 0

        # LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆOrderedDictã§å®Ÿè£…ï¼‰
        self.search_cache = OrderedDict()

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.knowledge_base_path.mkdir(exist_ok=True)

        # æœ€å°é™ã®åˆæœŸåŒ–ã®ã¿å®Ÿè¡Œ
        self.is_initialized = True
        logger.info("ğŸ” Lightweight RAG Sage åˆæœŸåŒ–å®Œäº†ï¼ˆé…å»¶åˆæœŸåŒ–ãƒ¢ãƒ¼ãƒ‰ï¼‰")

    def _get_connection(self) -> sqlite3.Connection:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._db_connection is None:
            self._init_database()
        return self._db_connection

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é…å»¶åˆæœŸåŒ–"""
        try:
            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªè¨­å®šã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            self._db_connection = sqlite3.connect(
                self.db_path, check_same_thread=False, isolation_level=None  # è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ
            )
            self._connection_count = 1

            # WALãƒ¢ãƒ¼ãƒ‰ã§ä¸¦è¡Œæ€§ã‚’å‘ä¸Š
            self._db_connection.execute("PRAGMA journal_mode=WAL")
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’åˆ¶é™
            self._db_connection.execute("PRAGMA cache_size=1000")

            cursor = self._db_connection.cursor()

            # æœ€å°é™ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS knowledge_items (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    source TEXT NOT NULL,
                    category TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """
            )

            # æœ€å°é™ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            cursor.execute(
                "CREATE INDEX IF NOT EXISTS idx_category ON knowledge_items(category)"
            )

            logger.info("ğŸ“Š è»½é‡ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def add_knowledge(self, content: str, source: str, category: str) -> str:
        """çŸ¥è­˜ã‚’è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            # IDã‚’ç”Ÿæˆ
            knowledge_id = hashlib.md5(f"{content[:100]}{source}".encode()).hexdigest()[
                :16
            ]

            cursor.execute(
                """
                INSERT OR REPLACE INTO knowledge_items
                (id, content, source, category)
                VALUES (?, ?, ?, ?)
            """,
                (knowledge_id, content, source, category),
            )

            return knowledge_id

        except Exception as e:
            logger.error(f"âŒ çŸ¥è­˜è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def add_knowledge_batch(self, batch_data: List[Tuple[str, str, str]]):
        """ãƒãƒƒãƒã§çŸ¥è­˜ã‚’è¿½åŠ """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            prepared_data = []
            for content, source, category in batch_data:
                knowledge_id = hashlib.md5(
                    f"{content[:100]}{source}".encode()
                ).hexdigest()[:16]
                prepared_data.append((knowledge_id, content, source, category))

            cursor.executemany(
                """
                INSERT OR REPLACE INTO knowledge_items
                (id, content, source, category)
                VALUES (?, ?, ?, ?)
            """,
                prepared_data,
            )

            logger.info(f"ğŸ“š ãƒãƒƒãƒè¿½åŠ å®Œäº†: {len(batch_data)}ä»¶")

        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒãƒè¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def search_knowledge(
        self, query: str, category: str = None, limit: int = 10
    ) -> List[SearchResult]:
        """çŸ¥è­˜ã‚’æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
            cache_key = f"{query}_{category}_{limit}"
            if cache_key in self.search_cache:
                # LRU: æœ€è¿‘ä½¿ç”¨ã—ãŸã‚‚ã®ã‚’æœ«å°¾ã«ç§»å‹•
                self.search_cache.move_to_end(cache_key)
                return self.search_cache[cache_key]

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢
            conn = self._get_connection()
            cursor = conn.cursor()

            # ã‚·ãƒ³ãƒ—ãƒ«ãªLIKEæ¤œç´¢
            if category:
                cursor.execute(
                    """
                    SELECT content, source, category, created_at
                    FROM knowledge_items
                    WHERE content LIKE ? AND category = ?
                    LIMIT ?
                """,
                    (f"%{query}%", category, limit),
                )
            else:
                cursor.execute(
                    """
                    SELECT content, source, category, created_at
                    FROM knowledge_items
                    WHERE content LIKE ?
                    LIMIT ?
                """,
                    (f"%{query}%", limit),
                )

            results = []
            for row in cursor.fetchall():
                content, source, cat, created_at = row

                # ç°¡æ˜“é–¢é€£æ€§ã‚¹ã‚³ã‚¢
                score = self._calculate_simple_relevance(query, content)

                result = SearchResult(
                    content=content,
                    source=source,
                    relevance_score=score,
                    timestamp=datetime.fromisoformat(created_at),
                    metadata={"category": cat},
                )
                results.append(result)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ä»˜ãï¼‰
            self._add_to_cache(cache_key, results)

            return results

        except Exception as e:
            logger.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _calculate_simple_relevance(self, query: str, content: str) -> float:
        """ç°¡æ˜“é–¢é€£æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        query_lower = query.lower()
        content_lower = content.lower()

        # å˜ç´”ãªå‡ºç¾å›æ•°ãƒ™ãƒ¼ã‚¹
        count = content_lower.count(query_lower)
        score = min(count / 10.0, 1.0)

        return score

    def _add_to_cache(self, key: str, value: Any):
        """LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.search_cache) >= self.max_cache_size:
            # æœ€ã‚‚å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            self.search_cache.popitem(last=False)

        self.search_cache[key] = value

    def index_knowledge_base(self, max_files: int = 100) -> int:
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™ä»˜ãï¼‰"""
        try:
            indexed_count = 0

            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆåˆ¶é™ä»˜ãï¼‰
            md_files = list(self.knowledge_base_path.glob("**/*.md"))[:max_files]

            # ãƒãƒƒãƒå‡¦ç†ç”¨ãƒªã‚¹ãƒˆ
            batch_data = []

            for md_file in md_files:
                try:
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èª­ã¿è¾¼ã¿
                    content = self._read_file_streaming(md_file)
                    category = self._infer_simple_category(md_file.name)

                    batch_data.append((content, str(md_file), category))

                    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰å‡¦ç†
                    if len(batch_data) >= 10:
                        self.add_knowledge_batch(batch_data)
                        batch_data = []
                        indexed_count += 10

                        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
                        gc.collect()

                except Exception as e:
                    logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {md_file}: {e}")

            # æ®‹ã‚Šã®ãƒãƒƒãƒã‚’å‡¦ç†
            if batch_data:
                self.add_knowledge_batch(batch_data)
                indexed_count += len(batch_data)

            logger.info(f"ğŸ“š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†: {indexed_count}ãƒ•ã‚¡ã‚¤ãƒ«")
            return indexed_count

        except Exception as e:
            logger.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def _read_file_streaming(self, file_path: Path, max_size: int = 10000) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§èª­ã¿è¾¼ã¿ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ä»˜ãï¼‰"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read(max_size)
                if len(content) == max_size:
                    content += "\n... (truncated)"
                return content
        except Exception as e:
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def process_file_streaming(self, file_path: Path):
        """å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                chunk_size = 1000  # 1000æ–‡å­—ãšã¤å‡¦ç†
                buffer = ""

                while True:
                    chunk = f.read(chunk_size)
                    if not chunk:
                        break

                    buffer += chunk
                    # æ®µè½ã”ã¨ã«å‡¦ç†
                    paragraphs = buffer.split("\n\n")

                    # æœ€å¾Œã®æ®µè½ä»¥å¤–ã‚’å‡¦ç†
                    for para in paragraphs[:-1]:
                        if para.strip():
                            self.add_knowledge(
                                para,
                                str(file_path),
                                self._infer_simple_category(file_path.name),
                            )

                    # æœ€å¾Œã®æ®µè½ã‚’ãƒãƒƒãƒ•ã‚¡ã«ä¿æŒ
                    buffer = paragraphs[-1]

                # æ®‹ã‚Šã‚’å‡¦ç†
                if buffer.strip():
                    self.add_knowledge(
                        buffer,
                        str(file_path),
                        self._infer_simple_category(file_path.name),
                    )

        except Exception as e:
            logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

    def _infer_simple_category(self, filename: str) -> str:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚«ãƒ†ã‚´ãƒªæ¨å®š"""
        filename_lower = filename.lower()

        if "test" in filename_lower:
            return "testing"
        elif "elder" in filename_lower:
            return "elders_guild"
        elif "guide" in filename_lower or "doc" in filename_lower:
            return "documentation"
        else:
            return "general"

    def consult_on_issue(self, issue_title: str, issue_body: str) -> Dict[str, Any]:
        """ã‚¤ã‚·ãƒ¥ãƒ¼ã«å¯¾ã™ã‚‹ç›¸è«‡ï¼ˆè»½é‡ç‰ˆï¼‰"""
        try:
            logger.info(f"ğŸ§™â€â™‚ï¸ è»½é‡ç‰ˆRAGè³¢è€…ç›¸è«‡: {issue_title}")

            # ã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œç´¢
            results = self.search_knowledge(
                f"{issue_title} {issue_body[:100]}", limit=3
            )

            # åŸºæœ¬çš„ãªåˆ†æ
            recommendations = []
            if "memory" in issue_body.lower() or "ãƒ¡ãƒ¢ãƒª" in issue_body:
                recommendations.append("ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½¿ç”¨ã‚’æ¨å¥¨")
                recommendations.append("é…å»¶åˆæœŸåŒ–ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚’æ¤œè¨")

            if "error" in issue_body.lower():
                recommendations.append("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–ã‚’æ¨å¥¨")

            return {
                "status": "success",
                "issue_analysis": {"title": issue_title, "complexity": "medium"},
                "recommendations": recommendations,
                "related_knowledge": [
                    {
                        "content": r.content[:100] + "...",
                        "source": r.source,
                        "relevance": r.relevance_score,
                    }
                    for r in results
                ],
                "consultation_metadata": {"sage": "è»½é‡ç‰ˆRAGè³¢è€…", "mode": "lightweight"},
            }

        except Exception as e:
            logger.error(f"âŒ ç›¸è«‡ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "error": str(e), "sage": "è»½é‡ç‰ˆRAGè³¢è€…"}

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self._db_connection:
                self._db_connection.close()
                self._db_connection = None

            self.search_cache.clear()
            gc.collect()

            logger.info("ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

        except Exception as e:
            logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆè»½é‡ç‰ˆï¼‰"""
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            cursor.execute("SELECT COUNT(*) FROM knowledge_items")
            total = cursor.fetchone()[0]

            return {
                "total_items": total,
                "cache_size": len(self.search_cache),
                "max_cache_size": self.max_cache_size,
                "mode": "lightweight",
            }

        except Exception as e:
            logger.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


# äº’æ›æ€§é–¢æ•°
def setup(*args, **kwargs):
    """è»½é‡ç‰ˆRAG Sage ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    logger.info("ğŸ” Lightweight RAG Sage setupå®Ÿè¡Œ")
    sage = LightweightRAGSage()
    sage.index_knowledge_base(max_files=50)  # åˆ¶é™ä»˜ãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    return sage


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸ” Lightweight RAG Sage èµ·å‹•")

    sage = LightweightRAGSage()
    stats = sage.get_stats()
    logger.info(f"ğŸ“Š çµ±è¨ˆ: {stats}")

    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    sage.cleanup()
    logger.info("ğŸ å®Œäº†")


if __name__ == "__main__":
    main()
