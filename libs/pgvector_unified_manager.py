#!/usr/bin/env python3
"""
pgvectorçµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
å…¨æ©Ÿèƒ½ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æä¾›
"""

import os
import json
import asyncio
import logging
import hashlib
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import sqlite3
import subprocess

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PgVectorUnifiedManager:
    """pgvectorçµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.config = {
            'postgres': {
                'host': 'localhost',
                'port': 8003,
                'database': 'elders_guild_pgvector',
                'user': 'aicompany',
                'password': 'secret123'
            },
            'sqlite_backup': '/home/aicompany/ai_co/knowledge_base/integrated_knowledge.db',
            'knowledge_base_path': '/home/aicompany/ai_co/knowledge_base',
            'docker_command_prefix': ['sg', 'docker', '-c']
        }
        
    async def health_check(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ” pgvectorã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–‹å§‹")
        
        health = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'unknown',
            'components': {}
        }
        
        # 1. Dockerã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ³
        try:
            result = subprocess.run(['docker', 'ps'], capture_output=True, text=True)
            postgres_running = 'elders-guild-postgres-new' in result.stdout
            health['components']['docker_container'] = {
                'status': 'healthy' if postgres_running else 'unhealthy',
                'details': 'PostgreSQL container running' if postgres_running else 'PostgreSQL container not found'
            }
        except Exception as e:
            health['components']['docker_container'] = {
                'status': 'error',
                'details': f'Docker check failed: {e}'
            }
            
        # 2. PostgreSQLæ¥ç¶š
        try:
            cmd = self.config['docker_command_prefix'] + [
                f"docker exec elders-guild-postgres-new psql -U {self.config['postgres']['user']} "
                f"-d {self.config['postgres']['database']} -c 'SELECT version();'"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                health['components']['postgresql'] = {
                    'status': 'healthy',
                    'details': 'PostgreSQL connection successful',
                    'version': result.stdout.strip()
                }
            else:
                health['components']['postgresql'] = {
                    'status': 'unhealthy',
                    'details': f'Connection failed: {result.stderr}'
                }
        except Exception as e:
            health['components']['postgresql'] = {
                'status': 'error',
                'details': f'PostgreSQL check failed: {e}'
            }
            
        # 3. pgvectoræ‹¡å¼µ
        try:
            cmd = self.config['docker_command_prefix'] + [
                f"docker exec elders-guild-postgres-new psql -U admin "
                f"-d {self.config['postgres']['database']} -c \"SELECT extname FROM pg_extension WHERE extname =  \
                    'vector';\""
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and 'vector' in result.stdout:
                health['components']['pgvector'] = {
                    'status': 'healthy',
                    'details': 'pgvector extension active',
                    'version_check': result.stdout.strip()
                }
            else:
                health['components']['pgvector'] = {
                    'status': 'unhealthy',
                    'details': f'pgvector extension not found. Output: {result.stdout}, Error: {result.stderr}'
                }
        except Exception as e:
            health['components']['pgvector'] = {
                'status': 'error',
                'details': f'pgvector check failed: {e}'
            }
            
        # 4. SQLiteãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        try:
            if os.path.exists(self.config['sqlite_backup']):
                size = os.path.getsize(self.config['sqlite_backup'])
                health['components']['sqlite_backup'] = {
                    'status': 'healthy',
                    'details': f'SQLite backup available ({size/1024/1024:.2f}MB)'
                }
            else:
                health['components']['sqlite_backup'] = {
                    'status': 'missing',
                    'details': 'SQLite backup file not found'
                }
        except Exception as e:
            health['components']['sqlite_backup'] = {
                'status': 'error',
                'details': f'SQLite check failed: {e}'
            }
            
        # 5. ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
        try:
            md_files = list(Path(self.config['knowledge_base_path']).rglob('*.md'))
            health['components']['knowledge_base'] = {
                'status': 'healthy',
                'details': f'{len(md_files)} markdown files found'
            }
        except Exception as e:
            health['components']['knowledge_base'] = {
                'status': 'error',
                'details': f'Knowledge base check failed: {e}'
            }
            
        # ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        statuses = [comp['status'] for comp in health['components'].values()]
        if all(s == 'healthy' for s in statuses):
            health['overall_status'] = 'healthy'
        elif any(s == 'error' for s in statuses):
            health['overall_status'] = 'error'
        else:
            health['overall_status'] = 'degraded'
            
        logger.info(f"âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†: {health['overall_status']}")
        return health
        
    async def setup_tables(self) -> bool:
        """PostgreSQLãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–"""
        logger.info("ğŸ”§ PostgreSQLãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–é–‹å§‹")
        
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆSQL
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS knowledge_documents (
                id SERIAL PRIMARY KEY,
                uuid UUID UNIQUE NOT NULL DEFAULT gen_random_uuid(),
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                source_file TEXT NOT NULL,
                file_hash TEXT NOT NULL,
                chunk_index INTEGER DEFAULT 0,
                total_chunks INTEGER DEFAULT 1,
                category TEXT NOT NULL,
                priority INTEGER NOT NULL,
                file_size INTEGER NOT NULL,
                embedding vector(384),
                metadata JSONB,
                sage_type TEXT DEFAULT 'knowledge_sage',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            CREATE INDEX IF NOT EXISTS idx_knowledge_source_file ON knowledge_documents(source_file);
            CREATE INDEX IF NOT EXISTS idx_knowledge_category ON knowledge_documents(category);
            CREATE INDEX IF NOT EXISTS idx_knowledge_priority ON knowledge_documents(priority);
            CREATE INDEX IF NOT EXISTS idx_knowledge_file_hash ON knowledge_documents(file_hash);
            CREATE INDEX IF NOT EXISTS idx_knowledge_embedding ON knowledge_documents 
                USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
            """
            
            cmd = self.config['docker_command_prefix'] + [
                f"docker exec elders-guild-postgres-new psql -U {self.config['postgres']['user']} "
                f"-d {self.config['postgres']['database']} -c \"{create_table_sql}\""
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("âœ… ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    async def migrate_from_sqlite(self) -> Dict[str, Any]:
        """SQLiteã‹ã‚‰PostgreSQLã¸ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        logger.info("ğŸ”„ SQLiteâ†’PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        
        migration_stats = {
            'start_time': datetime.now().isoformat(),
            'source_records': 0,
            'migrated_records': 0,
            'failed_records': 0,
            'status': 'unknown'
        }
        
        try:
            # SQLiteãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            sqlite_conn = sqlite3.connect(self.config['sqlite_backup'])
            sqlite_conn.row_factory = sqlite3.Row
            
            cursor = sqlite_conn.execute("SELECT COUNT(*) FROM knowledge_documents")
            migration_stats['source_records'] = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š SQLiteã‚½ãƒ¼ã‚¹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {migration_stats['source_records']}")
            
            # PostgreSQLæº–å‚™
            await self.setup_tables()
            
            # ãƒãƒƒãƒãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            cursor = sqlite_conn.execute("SELECT * FROM knowledge_documents ORDER BY priority, category" \
                "SELECT * FROM knowledge_documents ORDER BY priority, category")
            batch_size = 10  # ã‚ˆã‚Šå°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚º
            batch = []
            
            for row in cursor:
                batch.append(dict(row))
                
                if len(batch) >= batch_size:
                    success_count = await self._migrate_batch(batch)
                    migration_stats['migrated_records'] += success_count
                    migration_stats['failed_records'] += len(batch) - success_count
                    batch = []
                    
                    # é€²æ—è¡¨ç¤º
                    if migration_stats['migrated_records'] % 100 == 0:
                        logger.info(f"ğŸ“ˆ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é€²æ—: {migration_stats['migrated_records']}ä»¶")
                        
            # æ®‹ã‚Šã®ãƒãƒƒãƒå‡¦ç†
            if batch:
                success_count = await self._migrate_batch(batch)
                migration_stats['migrated_records'] += success_count
                migration_stats['failed_records'] += len(batch) - success_count
                
            sqlite_conn.close()
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
            success_rate = migration_stats['migrated_records'] / migration_stats['source_records']
            if success_rate >= 0.95:
                migration_stats['status'] = 'success'
            elif success_rate >= 0.8:
                migration_stats['status'] = 'partial_success'
            else:
                migration_stats['status'] = 'failed'
                
            migration_stats['end_time'] = datetime.now().isoformat()
            migration_stats['success_rate'] = success_rate
            
            logger.info(f"âœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {migration_stats['status']} "
                       f"({migration_stats['migrated_records']}/{migration_stats['source_records']})")
            
            return migration_stats
            
        except Exception as e:
            logger.error(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            migration_stats['status'] = 'error'
            migration_stats['error'] = str(e)
            return migration_stats
            
    async def _migrate_batch(self, batch: List[Dict]) -> int:
        """ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        try:
            # ç°¡æ˜“åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆ384æ¬¡å…ƒï¼‰
            def generate_simple_embedding(text:
                """generate_simple_embeddingç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰"""
            str) -> str:
                # æ–‡å­—é »åº¦ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ãƒ™ã‚¯ãƒˆãƒ«
                vector = [0.0] * 384
                for i, char in enumerate(text.lower()[:384]):
                    vector[i] = ord(char) / 255.0
                # æ­£è¦åŒ–
                norm = sum(x*x for x in vector) ** 0.5
                if norm > 0:
                    vector = [x/norm for x in vector]
                return '[' + ','.join(map(str, vector)) + ']'
            
            # ä¸€ä»¶ãšã¤å‡¦ç†ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³é•·åˆ¶é™å›é¿ï¼‰
            success_count = 0
            for row in batch:
                try:
                    embedding = generate_simple_embedding(row['content'])
                    metadata = row.get('metadata', '{}')
                    
                    # å®‰å…¨ãªæ–‡å­—åˆ—ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    title = row['title'].replace("'", "''")[:100]
                    content = row['content'].replace("'", "''")[:5000]  # çŸ­ç¸®
                    source_file = row['source_file'].replace("'", "''")
                    category = row['category'].replace("'", "''")
                    
                    insert_sql = f"""
                    INSERT INTO knowledge_documents (
                        title, content, source_file, file_hash, chunk_index, total_chunks,
                        category, priority, file_size, embedding, metadata, sage_type
                    ) VALUES (
                        '{title}', '{content}', '{source_file}', 
                        '{row['file_hash']}', {row['chunk_index']}, {row['total_chunks']}, 
                        '{category}', {row['priority']}, {row['file_size']}, 
                        '{embedding}', '{metadata}', 'knowledge_sage'
                    );
                    """
                    
                    # PostgreSQLå®Ÿè¡Œ
                    cmd = self.config['docker_command_prefix'] + [
                        f"docker exec elders-guild-postgres-new psql -U admin "
                        f"-d {self.config['postgres']['database']} -c \"{insert_sql}\""
                    ]
                    
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        success_count += 1
                    else:
                        logger.warning(f"âŒ å€‹åˆ¥æŒ¿å…¥å¤±æ•—: {result.stderr[:200]}")
                        
                except Exception as e:
                    logger.warning(f"âŒ å€‹åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰å‡¦ç†å¤±æ•—: {e}")
                    continue
                    
            return success_count
                
        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒãƒãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
            
    async def search_knowledge(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """çµ±åˆçŸ¥è­˜æ¤œç´¢"""
        logger.info(f"ğŸ” çŸ¥è­˜æ¤œç´¢: '{query}' (limit: {limit})")
        
        try:
            # PostgreSQLæ¤œç´¢ã‚’è©¦è¡Œï¼ˆsimilarityé–¢æ•°ãªã—ã®ç°¡æ˜“ç‰ˆï¼‰
            search_sql = f"""
            SELECT title, content, source_file, category, priority
            FROM knowledge_documents 
            WHERE content ILIKE '%{query}%' OR title ILIKE '%{query}%'
            ORDER BY priority ASC, created_at DESC
            LIMIT {limit};
            """
            
            cmd = self.config['docker_command_prefix'] + [
                f"docker exec elders-guild-postgres-new psql -U admin "
                f"-d {self.config['postgres']['database']} -t -c \"{search_sql}\""
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout.strip():
                # PostgreSQLçµæœã‚’ãƒ‘ãƒ¼ã‚¹
                results = []
                for line in result.stdout.strip().split('\n'):
                    if line.strip() and '|' in line:
                        parts = line.split('|')
                        if len(parts) >= 5:
                            try:
                                results.append({
                                    'title': parts[0].strip(),
                                    'content': parts[1].strip()[:500],
                                    'source_file': parts[2].strip(),
                                    'category': parts[3].strip(),
                                    'priority': int(parts[4].strip()) if parts[4].strip().isdigit() else 4,
                                    'source': 'postgresql'
                                })
                            except (ValueError, IndexError) as e:
                                logger.warning(f"âš ï¸ PostgreSQLçµæœãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                                continue
                
                if results:
                    logger.info(f"âœ… PostgreSQLæ¤œç´¢æˆåŠŸ: {len(results)}ä»¶")
                    return results
                else:
                    logger.info("ğŸ“ PostgreSQLæ¤œç´¢çµæœãŒç©ºã€SQLiteã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            
        except Exception as e:
            logger.warning(f"âš ï¸ PostgreSQLæ¤œç´¢å¤±æ•—: {e}")
            
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: SQLiteæ¤œç´¢
        try:
            sqlite_conn = sqlite3.connect(self.config['sqlite_backup'])
            sqlite_conn.row_factory = sqlite3.Row
            
            cursor = sqlite_conn.execute(
                "SELECT title, content, source_file, category, priority "
                "FROM knowledge_documents WHERE content LIKE ? "
                "ORDER BY priority ASC LIMIT ?",
                [f'%{query}%', limit]
            )
            
            results = []
            for row in cursor:
                results.append({
                    'title': row['title'],
                    'content': row['content'][:500],
                    'source_file': row['source_file'],
                    'category': row['category'],
                    'priority': row['priority'],
                    'source': 'sqlite'
                })
                
            sqlite_conn.close()
            logger.info(f"âœ… SQLiteãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢æˆåŠŸ: {len(results)}ä»¶")
            return results
            
        except Exception as e:
            logger.error(f"âŒ SQLiteæ¤œç´¢ã‚‚å¤±æ•—: {e}")
            return []
            
    async def get_status(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³å–å¾—"""
        logger.info("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³å–å¾—")
        
        health = await self.health_check()
        
        # è¿½åŠ çµ±è¨ˆæƒ…å ±
        try:
            # PostgreSQLçµ±è¨ˆ
            cmd = self.config['docker_command_prefix'] + [
                f"docker exec elders-guild-postgres-new psql -U {self.config['postgres']['user']} "
                f"-d {self.config['postgres']['database']} -t -c "
                f"'SELECT COUNT(*) FROM knowledge_documents;'"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            pg_count = 0
            if result.returncode == 0 and result.stdout.strip():
                pg_count = int(result.stdout.strip())
                
            # SQLiteçµ±è¨ˆ
            sqlite_count = 0
            if os.path.exists(self.config['sqlite_backup']):
                sqlite_conn = sqlite3.connect(self.config['sqlite_backup'])
                cursor = sqlite_conn.execute("SELECT COUNT(*) FROM knowledge_documents")
                sqlite_count = cursor.fetchone()[0]
                sqlite_conn.close()
                
            health['statistics'] = {
                'postgresql_documents': pg_count,
                'sqlite_documents': sqlite_count,
                'knowledge_base_files': len(list(Path(self.config['knowledge_base_path']).rglob('*.md')))
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ çµ±è¨ˆæƒ…å ±å–å¾—éƒ¨åˆ†å¤±æ•—: {e}")
            
        return health

# CLI ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
async def main():
    """ãƒ¡ã‚¤ãƒ³CLI"""
    import sys
    
    manager = PgVectorUnifiedManager()
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 pgvector_unified_manager.py <command>")
        print("ã‚³ãƒãƒ³ãƒ‰: health, setup, migrate, search <query>, status")
        return 1
        
    command = sys.argv[1]
    
    try:
        if command == 'health':
            health = await manager.health_check()
            print(json.dumps(health, indent=2, ensure_ascii=False))
            
        elif command == 'setup':
            success = await manager.setup_tables()
            print("âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æˆåŠŸ" if success else "âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—")
            
        elif command == 'migrate':
            stats = await manager.migrate_from_sqlite()
            print(json.dumps(stats, indent=2, ensure_ascii=False))
            
        elif command == 'search':
            if len(sys.argv) < 3:
                print("ä½¿ç”¨æ–¹æ³•: search <query>")
                return 1
            query = ' '.join(sys.argv[2:])
            results = await manager.search_knowledge(query)
            print(json.dumps(results, indent=2, ensure_ascii=False))
            
        elif command == 'status':
            status = await manager.get_status()
            print(json.dumps(status, indent=2, ensure_ascii=False))
            
        else:
            print(f"æœªçŸ¥ã®ã‚³ãƒãƒ³ãƒ‰: {command}")
            return 1
            
        return 0
        
    except Exception as e:
        logger.error(f"âŒ ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(asyncio.run(main()))