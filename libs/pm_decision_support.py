#!/usr/bin/env python3
"""
PMæ„æ€æ±ºå®šæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†æ„æ€æ±ºå®š

éå»ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã€å®Ÿè¡Œçµæœã€å“è³ªæŒ‡æ¨™ã‚’åˆ†æã—ã€
PMã®æ„æ€æ±ºå®šã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import logging
import sqlite3
import statistics

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
import sys
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core import BaseManager

logger = logging.getLogger(__name__)


class DecisionType(Enum):
    """æ„æ€æ±ºå®šã‚¿ã‚¤ãƒ—"""

    RESOURCE_ALLOCATION = "resource_allocation"  # ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
    TASK_PRIORITIZATION = "task_prioritization"  # ã‚¿ã‚¹ã‚¯å„ªå…ˆåº¦
    QUALITY_GATE = "quality_gate"  # å“è³ªã‚²ãƒ¼ãƒˆ
    TIMELINE_ADJUSTMENT = "timeline_adjustment"  # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«èª¿æ•´
    RISK_MITIGATION = "risk_mitigation"  # ãƒªã‚¹ã‚¯è»½æ¸›
    TEAM_ASSIGNMENT = "team_assignment"  # ãƒãƒ¼ãƒ é…å±
    TECHNOLOGY_CHOICE = "technology_choice"  # æŠ€è¡“é¸æŠ
    SCOPE_CHANGE = "scope_change"  # ã‚¹ã‚³ãƒ¼ãƒ—å¤‰æ›´


class DecisionUrgency(Enum):
    """æ„æ€æ±ºå®šã®ç·Šæ€¥åº¦"""

    LOW = "low"  # ä½: 1é€±é–“ä»¥å†…
    MEDIUM = "medium"  # ä¸­: 1æ—¥ä»¥å†…
    HIGH = "high"  # é«˜: æ•°æ™‚é–“ä»¥å†…
    CRITICAL = "critical"  # ç·Šæ€¥: å³åº§ã«


class ConfidenceLevel(Enum):
    """ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«"""

    VERY_LOW = "very_low"  # 30%æœªæº€
    LOW = "low"  # 30-50%
    MEDIUM = "medium"  # 50-70%
    HIGH = "high"  # 70-90%
    VERY_HIGH = "very_high"  # 90%ä»¥ä¸Š


@dataclass
class DecisionRecommendation:
    """æ„æ€æ±ºå®šæ¨å¥¨äº‹é …"""

    decision_id: str
    decision_type: DecisionType
    urgency: DecisionUrgency
    confidence: ConfidenceLevel
    recommendation: str
    reasoning: str
    supporting_data: Dict[str, Any]
    alternatives: List[str]
    risks: List[str]
    benefits: List[str]
    estimated_impact: float  # -1.0 to 1.0
    created_at: datetime


@dataclass
class ProjectMetrics:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    project_id: str
    completion_rate: float
    quality_score: float
    timeline_adherence: float
    resource_efficiency: float
    team_satisfaction: float
    defect_rate: float
    rework_rate: float
    cost_variance: float


class PMDecisionSupport(BaseManager):
    """PMæ„æ€æ±ºå®šæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        super().__init__("PMDecisionSupport")
        self.db_path = PROJECT_ROOT / "db" / "pm_decisions.db"

        # åˆ†æã®ãŸã‚ã®é‡ã¿è¨­å®š
        self.metric_weights = {
            "completion_rate": 0.25,
            "quality_score": 0.20,
            "timeline_adherence": 0.15,
            "resource_efficiency": 0.15,
            "team_satisfaction": 0.10,
            "defect_rate": 0.10,
            "rework_rate": 0.05,
        }

        # æ„æ€æ±ºå®šã—ãã„å€¤
        self.decision_thresholds = {
            DecisionType.RESOURCE_ALLOCATION: {
                "resource_efficiency": 0.6,  # 60%æœªæº€ã§è­¦å‘Š
                "timeline_adherence": 0.7,
            },
            DecisionType.TASK_PRIORITIZATION: {
                "completion_rate": 0.8,
                "quality_score": 0.7,
            },
            DecisionType.QUALITY_GATE: {
                "defect_rate": 0.05,  # 5%ä»¥ä¸Šã§è­¦å‘Š
                "quality_score": 0.8,
            },
            DecisionType.TIMELINE_ADJUSTMENT: {
                "timeline_adherence": 0.7,
                "completion_rate": 0.6,
            },
        }

        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.decision_history: List[DecisionRecommendation] = []
        self.project_metrics_cache: Dict[str, ProjectMetrics] = {}

        self.initialize()

    def initialize(self) -> bool:
        """åˆæœŸåŒ–å‡¦ç†"""
        try:
            self._init_database()
            self._load_historical_data()
            return True
        except Exception as e:
            self.handle_error(e, "åˆæœŸåŒ–")
            return False

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        with sqlite3.connect(self.db_path) as conn:
            # æ„æ€æ±ºå®šæ¨å¥¨ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS decision_recommendations (
                    decision_id TEXT PRIMARY KEY,
                    project_id TEXT NOT NULL,
                    decision_type TEXT NOT NULL,
                    urgency TEXT NOT NULL,
                    confidence TEXT NOT NULL,
                    recommendation TEXT NOT NULL,
                    reasoning TEXT NOT NULL,
                    supporting_data TEXT,
                    alternatives TEXT,
                    risks TEXT,
                    benefits TEXT,
                    estimated_impact REAL,
                    status TEXT DEFAULT 'pending',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    decided_at TIMESTAMP,
                    outcome TEXT
                )
            """
            )

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS project_metrics (
                    metric_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    project_id TEXT NOT NULL,
                    completion_rate REAL DEFAULT 0.0,
                    quality_score REAL DEFAULT 0.0,
                    timeline_adherence REAL DEFAULT 0.0,
                    resource_efficiency REAL DEFAULT 0.0,
                    team_satisfaction REAL DEFAULT 0.0,
                    defect_rate REAL DEFAULT 0.0,
                    rework_rate REAL DEFAULT 0.0,
                    cost_variance REAL DEFAULT 0.0,
                    measurement_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """
            )

            # æ„æ€æ±ºå®šãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS decision_patterns (
                    pattern_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_name TEXT NOT NULL,
                    conditions TEXT NOT NULL,
                    recommended_action TEXT NOT NULL,
                    success_rate REAL DEFAULT 0.0,
                    confidence_score REAL DEFAULT 0.0,
                    usage_count INTEGER DEFAULT 0,
                    last_used TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """
            )

            # æ„æ€æ±ºå®šæˆæœãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS decision_outcomes (
                    outcome_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    decision_id TEXT NOT NULL,
                    project_id TEXT NOT NULL,
                    actual_impact REAL,
                    success_rating INTEGER,
                    lessons_learned TEXT,
                    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (decision_id) REFERENCES decision_recommendations(decision_id)
                )
            """
            )

            # äºˆæ¸¬ç²¾åº¦ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS prediction_accuracy (
                    prediction_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    decision_type TEXT NOT NULL,
                    predicted_value REAL,
                    actual_value REAL,
                    accuracy_score REAL,
                    model_version TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """
            )

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_decisions_project ON " \
                    "decision_recommendations(project_id)"
            )
            conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_metrics_project ON project_metrics(project_id)"
            )
            conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_patterns_type ON decision_patterns(pattern_name)"
            )

    def _load_historical_data(self):
        """éå»ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # æ„æ€æ±ºå®šå±¥æ­´ã‚’èª­ã¿è¾¼ã¿
                cursor = conn.execute(
                    """
                    SELECT decision_id, decision_type, urgency, confidence,
                           recommendation, reasoning, supporting_data,
                           alternatives, risks, benefits, estimated_impact, created_at
                    FROM decision_recommendations
                    WHERE created_at >= datetime('now', '-30 days')
                    ORDER BY created_at DESC
                """
                )

                for row in cursor:
                    decision = DecisionRecommendation(
                        decision_id=row[0],
                        decision_type=DecisionType(row[1]),
                        urgency=DecisionUrgency(row[2]),
                        confidence=ConfidenceLevel(row[3]),
                        recommendation=row[4],
                        reasoning=row[5],
                        supporting_data=json.loads(row[6]) if row[6] else {},
                        alternatives=json.loads(row[7]) if row[7] else [],
                        risks=json.loads(row[8]) if row[8] else [],
                        benefits=json.loads(row[9]) if row[9] else [],
                        estimated_impact=row[10],
                        created_at=datetime.fromisoformat(row[11]),
                    )
                    self.decision_history.append(decision)

                logger.info(
                    f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.decision_history)}ä»¶ã®æ„æ€æ±ºå®š"
                )

        except Exception as e:
            logger.error(f"éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def analyze_project_status(self, project_id: str) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³ã®ç·åˆåˆ†æ"""
        try:
            logger.info(f"ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³åˆ†æé–‹å§‹: {project_id}")

            # ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
            metrics = self._get_project_metrics(project_id)

            # éå»ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
            historical_metrics = self._get_historical_metrics(project_id)

            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trends = self._analyze_trends(project_id, historical_metrics)

            # ãƒªã‚¹ã‚¯åˆ†æ
            risks = self._identify_risks(metrics, trends)

            # æ©Ÿä¼šã®ç‰¹å®š
            opportunities = self._identify_opportunities(metrics, trends)

            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
            overall_score = self._calculate_overall_score(metrics)

            analysis = {
                "project_id": project_id,
                "current_metrics": metrics.__dict__ if metrics else {},
                "trends": trends,
                "risks": risks,
                "opportunities": opportunities,
                "overall_score": overall_score,
                "health_status": self._determine_health_status(overall_score),
                "analysis_timestamp": datetime.now().isoformat(),
            }

            logger.info(f"âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³åˆ†æå®Œäº†: ã‚¹ã‚³ã‚¢{overall_score:.2f}")
            return analysis

        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def generate_decision_recommendations(
        self, project_id: str
    ) -> List[DecisionRecommendation]:
        """æ„æ€æ±ºå®šæ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        try:
            logger.info(f"ğŸ¤– æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆé–‹å§‹: {project_id}")

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ
            analysis = self.analyze_project_status(project_id)

            recommendations = []

            # å„æ„æ€æ±ºå®šã‚¿ã‚¤ãƒ—ã«ã¤ã„ã¦åˆ†æ
            for decision_type in DecisionType:
                recommendation = self._generate_recommendation_for_type(
                    project_id, decision_type, analysis
                )
                if recommendation:
                    recommendations.append(recommendation)

            # ç·Šæ€¥åº¦ã§ã‚½ãƒ¼ãƒˆ
            recommendations.sort(
                key=lambda x: self._get_urgency_priority(x.urgency), reverse=True
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            for rec in recommendations:
                self._save_recommendation(rec)

            logger.info(f"ğŸ“‹ æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆå®Œäº†: {len(recommendations)}ä»¶")
            return recommendations

        except Exception as e:
            logger.error(f"æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _generate_recommendation_for_type(
        self, project_id: str, decision_type: DecisionType, analysis: Dict[str, Any]
    ) -> Optional[DecisionRecommendation]:
        """ç‰¹å®šã‚¿ã‚¤ãƒ—ã®æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆ"""
        try:
            metrics = analysis.get("current_metrics", {})
            trends = analysis.get("trends", {})
            risks = analysis.get("risks", [])

            # æ„æ€æ±ºå®šãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
            if not self._needs_decision(decision_type, metrics, trends):
                return None

            # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
            recommendation_text = self._generate_recommendation_text(
                decision_type, metrics, trends
            )
            reasoning = self._generate_reasoning(decision_type, metrics, trends, risks)

            # ä»£æ›¿æ¡ˆã®ç”Ÿæˆ
            alternatives = self._generate_alternatives(decision_type, metrics)

            # ãƒªã‚¹ã‚¯ã¨åˆ©ç›Šã®åˆ†æ
            decision_risks = self._analyze_decision_risks(decision_type, metrics)
            benefits = self._analyze_decision_benefits(decision_type, metrics)

            # å½±éŸ¿åº¦ã®æ¨å®š
            estimated_impact = self._estimate_decision_impact(
                decision_type, metrics, trends
            )

            # ç·Šæ€¥åº¦ã®åˆ¤å®š
            urgency = self._determine_urgency(decision_type, metrics, trends)

            # ä¿¡é ¼åº¦ã®è¨ˆç®—
            confidence = self._calculate_confidence(decision_type, metrics, trends)

            decision_id = f"{project_id}_{decision_type.value}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            recommendation = DecisionRecommendation(
                decision_id=decision_id,
                decision_type=decision_type,
                urgency=urgency,
                confidence=confidence,
                recommendation=recommendation_text,
                reasoning=reasoning,
                supporting_data={"metrics": metrics, "trends": trends},
                alternatives=alternatives,
                risks=decision_risks,
                benefits=benefits,
                estimated_impact=estimated_impact,
                created_at=datetime.now(),
            )

            return recommendation

        except Exception as e:
            logger.error(f"æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({decision_type.value}): {e}")
            return None

    def _needs_decision(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> bool:
        """æ„æ€æ±ºå®šãŒå¿…è¦ã‹ã®åˆ¤å®š"""
        thresholds = self.decision_thresholds.get(decision_type, {})

        for metric_name, threshold in thresholds.items():
            current_value = metrics.get(metric_name, 0.0)

            # ã—ãã„å€¤ã‚’ä¸‹å›ã‚‹å ´åˆã¯æ„æ€æ±ºå®šãŒå¿…è¦
            if metric_name in ["defect_rate", "rework_rate"]:
                # ä½ã„ã»ã©è‰¯ã„æŒ‡æ¨™
                if current_value > threshold:
                    return True
            else:
                # é«˜ã„ã»ã©è‰¯ã„æŒ‡æ¨™
                if current_value < threshold:
                    return True

        # ãƒˆãƒ¬ãƒ³ãƒ‰ãŒæ‚ªåŒ–ã—ã¦ã„ã‚‹å ´åˆ
        for metric_name in thresholds.keys():
            trend = trends.get(metric_name, {})
            if (
                trend.get("direction") == "decreasing"
                and trend.get("significance", 0) > 0.5
            ):
                return True

        return False

    def _generate_recommendation_text(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> str:
        """æ¨å¥¨äº‹é …ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ"""
        templates = {
            DecisionType.RESOURCE_ALLOCATION: [
                "ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–ã‚’è¡Œã„ã€åŠ¹ç‡æ€§ã‚’{efficiency_improvement:.1f}%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                "ãƒãƒ¼ãƒ é–“ã®ãƒªã‚½ãƒ¼ã‚¹å†é…åˆ†ã«ã‚ˆã‚Šã€ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³éµå®ˆç‡ã‚’{timeline_improvement:.1f}%æ”¹å–„ã§ãã¾ã™ã€‚",
                "å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã®æ´»ç”¨ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ç‡ã‚’{completion_improvement:.1f}%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚",
            ],
            DecisionType.TASK_PRIORITIZATION: [
                "é«˜å„ªå…ˆåº¦ã‚¿ã‚¹ã‚¯ã®è¦‹ç›´ã—ã«ã‚ˆã‚Šã€å“è³ªã‚¹ã‚³ã‚¢ã‚’{quality_improvement:.1f}%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                "ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹ã®æœ€é©åŒ–ã«ã‚ˆã‚Šã€å®Œäº†ç‡ã‚’{completion_improvement:.1f}%æ”¹å–„ã§ãã¾ã™ã€‚",
                "ä¾å­˜é–¢ä¿‚ã®è§£æã«åŸºã¥ãã‚¿ã‚¹ã‚¯å„ªå…ˆåº¦ã®èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚",
            ],
            DecisionType.QUALITY_GATE: [
                "å“è³ªã‚²ãƒ¼ãƒˆã®å¼·åŒ–ã«ã‚ˆã‚Šã€æ¬ é™¥ç‡ã‚’{defect_reduction:.1f}%å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                "ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®æ”¹å–„ã«ã‚ˆã‚Šã€æ‰‹æˆ»ã‚Šç‡ã‚’{rework_reduction:.1f}%å‰Šæ¸›ã§ãã¾ã™ã€‚",
                "è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã®å°å…¥ã«ã‚ˆã‚Šã€å“è³ªã‚¹ã‚³ã‚¢ã‚’{quality_improvement:.1f}%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚",
            ],
            DecisionType.TIMELINE_ADJUSTMENT: [
                "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«èª¿æ•´ã«ã‚ˆã‚Šã€ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³éµå®ˆç‡ã‚’{timeline_improvement:.1f}%æ”¹å–„ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                "ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®è¦‹ç›´ã—ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ã®ç¢ºå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚",
                "ãƒãƒƒãƒ•ã‚¡æ™‚é–“ã®è¿½åŠ ã«ã‚ˆã‚Šã€ãƒªã‚¹ã‚¯ã‚’{risk_reduction:.1f}%å‰Šæ¸›ã§ãã¾ã™ã€‚",
            ],
        }

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ”¹å–„äºˆæ¸¬å€¤ã‚’è¨ˆç®—
        improvements = self._calculate_improvements(decision_type, metrics, trends)

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        template_list = templates.get(decision_type, ["ä¸€èˆ¬çš„ãªæ”¹å–„æ–½ç­–ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"])
        template = template_list[0]  # æœ€åˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨

        try:
            return template.format(**improvements)
        except KeyError:
            return template

    def _generate_reasoning(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
        risks: List[str],
    ) -> str:
        """æ¨è«–ç†ç”±ã®ç”Ÿæˆ"""
        reasoning_parts = []

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®ç†ç”±
        for metric_name, value in metrics.items():
            if metric_name in self.decision_thresholds.get(decision_type, {}):
                threshold = self.decision_thresholds[decision_type][metric_name]

                if metric_name in ["defect_rate", "rework_rate"]:
                    if value > threshold:
                        reasoning_parts.append(
                            f"{metric_name}ãŒ{value:.1f}%ã§ã—ãã„å€¤{threshold:.1f}%ã‚’è¶…é"
                        )
                else:
                    if value < threshold:
                        reasoning_parts.append(
                            f"{metric_name}ãŒ{value:.1f}%ã§ã—ãã„å€¤{threshold:.1f}%ã‚’ä¸‹å›ã‚‹"
                        )

        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç†ç”±
        for metric_name, trend in trends.items():
            if (
                trend.get("direction") == "decreasing"
                and trend.get("significance", 0) > 0.5
            ):
                reasoning_parts.append(f"{metric_name}ã«æ‚ªåŒ–å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã‚‹")

        # ãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®ç†ç”±
        relevant_risks = [risk for risk in risks if decision_type.value in risk.lower()]
        if relevant_risks:
            reasoning_parts.append(f"é–¢é€£ãƒªã‚¹ã‚¯: {', '.join(relevant_risks[:2])}")

        return (
            "; ".join(reasoning_parts)
            if reasoning_parts
            else "å®šæœŸçš„ãªè©•ä¾¡ã«åŸºã¥ãæ¨å¥¨"
        )

    def _generate_alternatives(
        self, decision_type: DecisionType, metrics: Dict[str, Any]
    ) -> List[str]:
        """ä»£æ›¿æ¡ˆã®ç”Ÿæˆ"""
        alternatives_map = {
            DecisionType.RESOURCE_ALLOCATION: [
                "å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã®æ´»ç”¨",
                "ãƒãƒ¼ãƒ é–“ã®ã‚¹ã‚­ãƒ«å…±æœ‰",
                "ä½œæ¥­ã®è‡ªå‹•åŒ–æ¨é€²",
                "å„ªå…ˆåº¦ã®å†è©•ä¾¡",
            ],
            DecisionType.TASK_PRIORITIZATION: [
                "MoSCoWåˆ†æã®å®Ÿæ–½",
                "ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ãƒ™ãƒ¼ã‚¹ã®å„ªå…ˆåº¦è¨­å®š",
                "ãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®å„ªå…ˆåº¦èª¿æ•´",
                "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã®å„ªå…ˆåº¦å†ç¢ºèª",
            ],
            DecisionType.QUALITY_GATE: [
                "æ®µéšçš„å“è³ªãƒã‚§ãƒƒã‚¯ã®å°å…¥",
                "è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã®æ‹¡å……",
                "ãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å¼·åŒ–",
                "å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¦‹ç›´ã—",
            ],
            DecisionType.TIMELINE_ADJUSTMENT: [
                "ã‚¹ã‚³ãƒ¼ãƒ—ã®èª¿æ•´",
                "ä¸¦åˆ—ä½œæ¥­ã®å¢—åŠ ",
                "å¤–éƒ¨æ”¯æ´ã®æ´»ç”¨",
                "ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®è¦‹ç›´ã—",
            ],
        }

        return alternatives_map.get(decision_type, ["ä»£æ›¿æ¡ˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„"])

    def _analyze_decision_risks(
        self, decision_type: DecisionType, metrics: Dict[str, Any]
    ) -> List[str]:
        """æ„æ€æ±ºå®šã®ãƒªã‚¹ã‚¯åˆ†æ"""
        risks_map = {
            DecisionType.RESOURCE_ALLOCATION: [
                "ãƒªã‚½ãƒ¼ã‚¹å¤‰æ›´ã«ã‚ˆã‚‹ä¸€æ™‚çš„ãªç”Ÿç”£æ€§ä½ä¸‹",
                "ãƒãƒ¼ãƒ å†…ã®ã‚¹ã‚­ãƒ«ä¸è¶³",
                "ã‚³ã‚¹ãƒˆå¢—åŠ ã®ãƒªã‚¹ã‚¯",
            ],
            DecisionType.TASK_PRIORITIZATION: [
                "å„ªå…ˆåº¦å¤‰æ›´ã«ã‚ˆã‚‹æ··ä¹±",
                "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã®ä¸æº€",
                "æ—¢å­˜ä½œæ¥­ã®åœæ»",
            ],
            DecisionType.QUALITY_GATE: [
                "å“è³ªãƒã‚§ãƒƒã‚¯å¼·åŒ–ã«ã‚ˆã‚‹é–‹ç™ºé…å»¶",
                "ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ›´ã¸ã®æŠµæŠ—",
                "åˆæœŸã‚³ã‚¹ãƒˆã®å¢—åŠ ",
            ],
            DecisionType.TIMELINE_ADJUSTMENT: [
                "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å¤‰æ›´ã«ã‚ˆã‚‹å½±éŸ¿ç¯„å›²æ‹¡å¤§",
                "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã®æœŸå¾…å€¤èª¿æ•´",
                "ã‚³ã‚¹ãƒˆå¢—åŠ ã®å¯èƒ½æ€§",
            ],
        }

        return risks_map.get(decision_type, ["ä¸€èˆ¬çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ã‚¯"])

    def _analyze_decision_benefits(
        self, decision_type: DecisionType, metrics: Dict[str, Any]
    ) -> List[str]:
        """æ„æ€æ±ºå®šã®åˆ©ç›Šåˆ†æ"""
        benefits_map = {
            DecisionType.RESOURCE_ALLOCATION: [
                "ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§ã®å‘ä¸Š",
                "ãƒãƒ¼ãƒ ã®ç”Ÿç”£æ€§å‘ä¸Š",
                "ã‚³ã‚¹ãƒˆæœ€é©åŒ–",
            ],
            DecisionType.TASK_PRIORITIZATION: [
                "é‡è¦ãªæ©Ÿèƒ½ã®æ—©æœŸæä¾›",
                "é¡§å®¢æº€è¶³åº¦ã®å‘ä¸Š",
                "ãƒªã‚¹ã‚¯ã®æ—©æœŸç™ºè¦‹",
            ],
            DecisionType.QUALITY_GATE: [
                "è£½å“å“è³ªã®å‘ä¸Š",
                "é•·æœŸçš„ãªä¿å®ˆã‚³ã‚¹ãƒˆå‰Šæ¸›",
                "é¡§å®¢ä¿¡é ¼ã®å‘ä¸Š",
            ],
            DecisionType.TIMELINE_ADJUSTMENT: [
                "ç¾å®Ÿçš„ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š",
                "ãƒãƒ¼ãƒ ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‘ä¸Š",
                "å“è³ªã®ç¢ºä¿",
            ],
        }

        return benefits_map.get(decision_type, ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæˆåŠŸç‡ã®å‘ä¸Š"])

    def _estimate_decision_impact(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> float:
        """æ„æ€æ±ºå®šã®å½±éŸ¿åº¦æ¨å®š"""
        # åŸºæœ¬å½±éŸ¿åº¦
        base_impact = {
            DecisionType.RESOURCE_ALLOCATION: 0.6,
            DecisionType.TASK_PRIORITIZATION: 0.4,
            DecisionType.QUALITY_GATE: 0.5,
            DecisionType.TIMELINE_ADJUSTMENT: 0.7,
        }.get(decision_type, 0.5)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®èª¿æ•´
        overall_score = self._calculate_overall_score_from_dict(metrics)

        # ã‚¹ã‚³ã‚¢ãŒä½ã„ã»ã©å½±éŸ¿ãŒå¤§ãã„
        impact_multiplier = 1.5 - overall_score

        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹ã®èª¿æ•´
        trend_multiplier = 1.0
        for trend in trends.values():
            if isinstance(trend, dict) and trend.get("direction") == "decreasing":
                trend_multiplier += 0.1

        final_impact = base_impact * impact_multiplier * trend_multiplier

        # -1.0 to 1.0 ã®ç¯„å›²ã«æ­£è¦åŒ–
        return max(-1.0, min(1.0, final_impact))

    def _determine_urgency(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> DecisionUrgency:
        """ç·Šæ€¥åº¦ã®åˆ¤å®š"""
        overall_score = self._calculate_overall_score_from_dict(metrics)

        # éå¸¸ã«ä½ã„ã‚¹ã‚³ã‚¢ã¯ç·Šæ€¥
        if overall_score < 0.3:
            return DecisionUrgency.CRITICAL

        # æ‚ªåŒ–å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã‚‹å ´åˆ
        negative_trends = sum(
            1
            for trend in trends.values()
            if isinstance(trend, dict) and trend.get("direction") == "decreasing"
        )

        if negative_trends >= 3:
            return DecisionUrgency.HIGH
        elif negative_trends >= 1:
            return DecisionUrgency.MEDIUM
        else:
            return DecisionUrgency.LOW

    def _calculate_confidence(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> ConfidenceLevel:
        """ä¿¡é ¼åº¦ã®è¨ˆç®—"""
        # ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        required_metrics = list(self.decision_thresholds.get(decision_type, {}).keys())
        available_metrics = [m for m in required_metrics if m in metrics]

        data_completeness = (
            len(available_metrics) / len(required_metrics) if required_metrics else 1.0
        )

        # éå»ã®é¡ä¼¼æ„æ€æ±ºå®šã®æˆåŠŸç‡
        historical_success = self._get_historical_success_rate(decision_type)

        # ç·åˆä¿¡é ¼åº¦
        confidence_score = (data_completeness * 0.6) + (historical_success * 0.4)

        if confidence_score >= 0.9:
            return ConfidenceLevel.VERY_HIGH
        elif confidence_score >= 0.7:
            return ConfidenceLevel.HIGH
        elif confidence_score >= 0.5:
            return ConfidenceLevel.MEDIUM
        elif confidence_score >= 0.3:
            return ConfidenceLevel.LOW
        else:
            return ConfidenceLevel.VERY_LOW

    def _get_historical_success_rate(self, decision_type: DecisionType) -> float:
        """éå»ã®æ„æ€æ±ºå®šæˆåŠŸç‡ã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(
                    """
                    SELECT AVG(success_rating)
                    FROM decision_outcomes do
                    JOIN decision_recommendations dr ON do.decision_id = dr.decision_id
                    WHERE dr.decision_type = ?
                """,
                    (decision_type.value,),
                )

                result = cursor.fetchone()
                return (
                    (result[0] / 5.0) if result and result[0] else 0.7
                )  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ70%

        except Exception as e:
            logger.error(f"éå»æˆåŠŸç‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.7

    def _calculate_improvements(
        self,
        decision_type: DecisionType,
        metrics: Dict[str, Any],
        trends: Dict[str, Any],
    ) -> Dict[str, float]:
        """æ”¹å–„äºˆæ¸¬å€¤ã®è¨ˆç®—"""
        improvements = {}

        # æ±ºå®šã‚¿ã‚¤ãƒ—åˆ¥ã®æ”¹å–„äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯
        if decision_type == DecisionType.RESOURCE_ALLOCATION:
            current_efficiency = metrics.get("resource_efficiency", 0.5)
            improvements["efficiency_improvement"] = (0.8 - current_efficiency) * 100
            improvements["timeline_improvement"] = max(
                10, 30 - (current_efficiency * 50)
            )
            improvements["completion_improvement"] = max(
                5, 20 - (current_efficiency * 40)
            )

        elif decision_type == DecisionType.QUALITY_GATE:
            current_quality = metrics.get("quality_score", 0.7)
            current_defect_rate = metrics.get("defect_rate", 0.05)
            improvements["quality_improvement"] = (0.9 - current_quality) * 100
            improvements["defect_reduction"] = current_defect_rate * 50
            improvements["rework_reduction"] = metrics.get("rework_rate", 0.1) * 60

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        for key in [
            "efficiency_improvement",
            "timeline_improvement",
            "completion_improvement",
            "quality_improvement",
            "defect_reduction",
            "rework_reduction",
            "risk_reduction",
        ]:
            if key not in improvements:
                improvements[key] = 15.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ15%æ”¹å–„

        return improvements

    def _get_urgency_priority(self, urgency: DecisionUrgency) -> int:
        """ç·Šæ€¥åº¦ã®å„ªå…ˆåº¦ã‚’æ•°å€¤ã§è¿”ã™"""
        return {
            DecisionUrgency.CRITICAL: 4,
            DecisionUrgency.HIGH: 3,
            DecisionUrgency.MEDIUM: 2,
            DecisionUrgency.LOW: 1,
        }.get(urgency, 1)

    def _save_recommendation(self, recommendation: DecisionRecommendation):
        """æ¨å¥¨äº‹é …ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    """
                    INSERT INTO decision_recommendations
                    (decision_id, project_id, decision_type, urgency, confidence,
                     recommendation, reasoning, supporting_data, alternatives,
                     risks, benefits, estimated_impact, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        recommendation.decision_id,
                        recommendation.decision_id.split("_")[0],  # project_id
                        recommendation.decision_type.value,
                        recommendation.urgency.value,
                        recommendation.confidence.value,
                        recommendation.recommendation,
                        recommendation.reasoning,
                        json.dumps(recommendation.supporting_data),
                        json.dumps(recommendation.alternatives),
                        json.dumps(recommendation.risks),
                        json.dumps(recommendation.benefits),
                        recommendation.estimated_impact,
                        recommendation.created_at,
                    ),
                )

        except Exception as e:
            logger.error(f"æ¨å¥¨äº‹é …ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _get_project_metrics(self, project_id: str) -> Optional[ProjectMetrics]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€WorkflowControllerã€ParallelExecutionManagerã€
        # PMQualityEvaluatorãªã©ã‹ã‚‰å®Ÿéš›ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        import random

        return ProjectMetrics(
            project_id=project_id,
            completion_rate=random.uniform(0.4, 0.9),
            quality_score=random.uniform(0.6, 0.95),
            timeline_adherence=random.uniform(0.5, 0.9),
            resource_efficiency=random.uniform(0.4, 0.8),
            team_satisfaction=random.uniform(0.6, 0.9),
            defect_rate=random.uniform(0.01, 0.08),
            rework_rate=random.uniform(0.02, 0.12),
            cost_variance=random.uniform(-0.2, 0.3),
        )

    def _get_historical_metrics(self, project_id: str) -> List[ProjectMetrics]:
        """éå»ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(
                    """
                    SELECT project_id, completion_rate, quality_score, timeline_adherence,
                           resource_efficiency, team_satisfaction, defect_rate, rework_rate,
                           cost_variance, measurement_date
                    FROM project_metrics
                    WHERE project_id = ?
                    ORDER BY measurement_date DESC
                    LIMIT 10
                """,
                    (project_id,),
                )

                metrics_list = []
                for row in cursor:
                    metrics = ProjectMetrics(*row[:-1])  # æœ€å¾Œã®timestampã‚’é™¤ã
                    metrics_list.append(metrics)

                return metrics_list

        except Exception as e:
            logger.error(f"éå»ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _analyze_trends(
        self, project_id: str, historical_metrics: List[ProjectMetrics]
    ) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        trends = {}

        if len(historical_metrics) < 2:
            return trends

        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—
        metrics_names = [
            "completion_rate",
            "quality_score",
            "timeline_adherence",
            "resource_efficiency",
            "team_satisfaction",
            "defect_rate",
            "rework_rate",
        ]

        for metric_name in metrics_names:
            values = [getattr(m, metric_name) for m in historical_metrics]

            if len(values) >= 2:
                # ç°¡å˜ãªç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰
                if values[0] > values[-1]:
                    direction = "decreasing"
                elif values[0] < values[-1]:
                    direction = "increasing"
                else:
                    direction = "stable"

                # å¤‰åŒ–ã®å¤§ãã•
                change_magnitude = abs(values[0] - values[-1])
                significance = min(
                    1.0, change_magnitude / values[0] if values[0] != 0 else 0
                )

                trends[metric_name] = {
                    "direction": direction,
                    "significance": significance,
                    "current_value": values[0],
                    "previous_value": values[-1],
                    "change_rate": (
                        (values[0] - values[-1]) / values[-1] if values[-1] != 0 else 0
                    ),
                }

        return trends

    def _identify_risks(
        self, metrics: Optional[ProjectMetrics], trends: Dict[str, Any]
    ) -> List[str]:
        """ãƒªã‚¹ã‚¯ã®ç‰¹å®š"""
        risks = []

        if not metrics:
            return risks

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®ãƒªã‚¹ã‚¯
        if metrics.completion_rate < 0.6:
            risks.append("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ç‡ãŒä½ã„")

        if metrics.quality_score < 0.7:
            risks.append("å“è³ªã‚¹ã‚³ã‚¢ãŒåŸºæº–ã‚’ä¸‹å›ã‚‹")

        if metrics.defect_rate > 0.05:
            risks.append("æ¬ é™¥ç‡ãŒé«˜ã„")

        if metrics.timeline_adherence < 0.7:
            risks.append("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«éµå®ˆç‡ãŒä½ã„")

        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒªã‚¹ã‚¯
        for metric_name, trend in trends.items():
            if isinstance(trend, dict) and trend.get("direction") == "decreasing":
                if trend.get("significance", 0) > 0.3:
                    risks.append(f"{metric_name}ã®æ‚ªåŒ–å‚¾å‘")

        return risks

    def _identify_opportunities(
        self, metrics: Optional[ProjectMetrics], trends: Dict[str, Any]
    ) -> List[str]:
        """æ©Ÿä¼šã®ç‰¹å®š"""
        opportunities = []

        if not metrics:
            return opportunities

        # æ”¹å–„å¯èƒ½ãªé ˜åŸŸ
        if metrics.resource_efficiency < 0.8:
            opportunities.append("ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®æ”¹å–„ä½™åœ°")

        if metrics.team_satisfaction < 0.8:
            opportunities.append("ãƒãƒ¼ãƒ æº€è¶³åº¦ã®å‘ä¸Šæ©Ÿä¼š")

        # å¥½èª¿ãªæŒ‡æ¨™ã®æ´»ç”¨
        if metrics.quality_score > 0.8:
            opportunities.append("é«˜å“è³ªãƒ—ãƒ­ã‚»ã‚¹ã®ä»–é ˜åŸŸã¸ã®å±•é–‹")

        if metrics.completion_rate > 0.8:
            opportunities.append("æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¨™æº–åŒ–")

        return opportunities

    def _calculate_overall_score(self, metrics: Optional[ProjectMetrics]) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not metrics:
            return 0.5

        return self._calculate_overall_score_from_dict(metrics.__dict__)

    def _calculate_overall_score_from_dict(self, metrics: Dict[str, Any]) -> float:
        """è¾æ›¸ã‹ã‚‰ã®ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—"""
        weighted_score = 0.0
        total_weight = 0.0

        for metric_name, weight in self.metric_weights.items():
            if metric_name in metrics:
                value = metrics[metric_name]

                # è² ã®æŒ‡æ¨™ã¯åè»¢
                if metric_name in ["defect_rate", "rework_rate"]:
                    value = 1.0 - min(1.0, value * 10)  # 10%ã‚’ä¸Šé™ã¨ã—ã¦æ­£è¦åŒ–

                weighted_score += value * weight
                total_weight += weight

        return weighted_score / total_weight if total_weight > 0 else 0.5

    def _determine_health_status(self, overall_score: float) -> str:
        """å¥åº·çŠ¶æ…‹ã®åˆ¤å®š"""
        if overall_score >= 0.8:
            return "excellent"
        elif overall_score >= 0.6:
            return "good"
        elif overall_score >= 0.4:
            return "fair"
        elif overall_score >= 0.2:
            return "poor"
        else:
            return "critical"

    def record_decision_outcome(
        self,
        decision_id: str,
        actual_impact: float,
        success_rating: int,
        lessons_learned: str = "",
    ):
        """æ„æ€æ±ºå®šã®çµæœã‚’è¨˜éŒ²"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # project_idã‚’å–å¾—
                cursor = conn.execute(
                    """
                    SELECT project_id FROM decision_recommendations
                    WHERE decision_id = ?
                """,
                    (decision_id,),
                )

                row = cursor.fetchone()
                if not row:
                    logger.error(f"æ„æ€æ±ºå®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {decision_id}")
                    return

                project_id = row[0]

                # çµæœã‚’è¨˜éŒ²
                conn.execute(
                    """
                    INSERT INTO decision_outcomes
                    (decision_id, project_id, actual_impact, success_rating, lessons_learned)
                    VALUES (?, ?, ?, ?, ?)
                """,
                    (
                        decision_id,
                        project_id,
                        actual_impact,
                        success_rating,
                        lessons_learned,
                    ),
                )

                # æ¨å¥¨äº‹é …ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                conn.execute(
                    """
                    UPDATE decision_recommendations
                    SET status = 'completed', decided_at = ?, outcome = ?
                    WHERE decision_id = ?
                """,
                    (datetime.now(), f"Rating: {success_rating}/5", decision_id),
                )

            logger.info(
                f"âœ… æ„æ€æ±ºå®šçµæœè¨˜éŒ²: {decision_id} (è©•ä¾¡: {success_rating}/5)"
            )

        except Exception as e:
            logger.error(f"æ„æ€æ±ºå®šçµæœè¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    def get_decision_dashboard(self, project_id: str) -> Dict[str, Any]:
        """æ„æ€æ±ºå®šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ç¾åœ¨ã®æ¨å¥¨äº‹é …
                cursor = conn.execute(
                    """
                    SELECT decision_id, decision_type, urgency, confidence,
                           recommendation, created_at, status
                    FROM decision_recommendations
                    WHERE project_id = ? AND status = 'pending'
                    ORDER BY
                        CASE urgency
                            WHEN 'critical' THEN 4
                            WHEN 'high' THEN 3
                            WHEN 'medium' THEN 2
                            WHEN 'low' THEN 1
                        END DESC,
                        created_at DESC
                """,
                    (project_id,),
                )

                pending_decisions = []
                for row in cursor:
                    pending_decisions.append(
                        {
                            "decision_id": row[0],
                            "decision_type": row[1],
                            "urgency": row[2],
                            "confidence": row[3],
                            "recommendation": row[4],
                            "created_at": row[5],
                            "status": row[6],
                        }
                    )

                # éå»ã®æ„æ€æ±ºå®šã®çµ±è¨ˆ
                cursor = conn.execute(
                    """
                    SELECT decision_type, COUNT(*) as count, AVG(success_rating) as avg_rating
                    FROM decision_outcomes do
                    JOIN decision_recommendations dr ON do.decision_id = dr.decision_id
                    WHERE dr.project_id = ?
                    GROUP BY decision_type
                """,
                    (project_id,),
                )

                decision_stats = {}
                for row in cursor:
                    decision_stats[row[0]] = {
                        "count": row[1],
                        "avg_rating": row[2] or 0,
                    }

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ
                analysis = self.analyze_project_status(project_id)

                return {
                    "project_id": project_id,
                    "pending_decisions": pending_decisions,
                    "decision_statistics": decision_stats,
                    "project_analysis": analysis,
                    "dashboard_updated": datetime.now().isoformat(),
                }

        except Exception as e:
            logger.error(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    pm_support = PMDecisionSupport()

    print("=" * 80)
    print("ğŸ¤– PM Decision Support System Test")
    print("=" * 80)

    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    test_project_id = "test_project_003"

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³åˆ†æ
    print(f"\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³åˆ†æ: {test_project_id}")
    analysis = pm_support.analyze_project_status(test_project_id)
    print(f"ç·åˆã‚¹ã‚³ã‚¢: {analysis.get('overall_score', 0):.2f}")
    print(f"å¥åº·çŠ¶æ…‹: {analysis.get('health_status', 'unknown')}")
    print(f"ãƒªã‚¹ã‚¯æ•°: {len(analysis.get('risks', []))}")
    print(f"æ©Ÿä¼šæ•°: {len(analysis.get('opportunities', []))}")

    # æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆ
    print(f"\nğŸ¤– æ„æ€æ±ºå®šæ¨å¥¨ç”Ÿæˆ")
    recommendations = pm_support.generate_decision_recommendations(test_project_id)

    for i, rec in enumerate(recommendations[:3]):  # ä¸Šä½3ä»¶ã‚’è¡¨ç¤º
        print(f"\nğŸ“‹ æ¨å¥¨äº‹é … {i+1}:")
        print(f"  ã‚¿ã‚¤ãƒ—: {rec.decision_type.value}")
        print(f"  ç·Šæ€¥åº¦: {rec.urgency.value}")
        print(f"  ä¿¡é ¼åº¦: {rec.confidence.value}")
        print(f"  æ¨å¥¨: {rec.recommendation}")
        print(f"  å½±éŸ¿åº¦: {rec.estimated_impact:+.2f}")

        if rec.risks:
            print(f"  ãƒªã‚¹ã‚¯: {rec.risks[0]}")
        if rec.benefits:
            print(f"  åˆ©ç›Š: {rec.benefits[0]}")

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º
    print(f"\nğŸ“Š æ„æ€æ±ºå®šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    dashboard = pm_support.get_decision_dashboard(test_project_id)

    pending_count = len(dashboard.get("pending_decisions", []))
    print(f"  æœªæ±ºå®šäº‹é …: {pending_count}ä»¶")

    stats = dashboard.get("decision_statistics", {})
    print(f"  éå»ã®æ„æ€æ±ºå®šçµ±è¨ˆ: {len(stats)}ã‚¿ã‚¤ãƒ—")
    for decision_type, stat in stats.items():
        print(
            f"    {decision_type}: {stat['count']}ä»¶ (å¹³å‡è©•ä¾¡: {stat['avg_rating']:.1f}/5)"
        )

    # æ„æ€æ±ºå®šçµæœè¨˜éŒ²ã®ãƒ†ã‚¹ãƒˆ
    if recommendations:
        test_decision_id = recommendations[0].decision_id
        print(f"\nâœ… æ„æ€æ±ºå®šçµæœè¨˜éŒ²ãƒ†ã‚¹ãƒˆ: {test_decision_id}")
        pm_support.record_decision_outcome(
            test_decision_id,
            actual_impact=0.8,
            success_rating=4,
            lessons_learned="ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–ã«ã‚ˆã‚ŠæœŸå¾…ä»¥ä¸Šã®åŠ¹æœ",
        )
        print("çµæœè¨˜éŒ²å®Œäº†")

    print(f"\nğŸ¯ PM Decision Support System ãƒ†ã‚¹ãƒˆå®Œäº†")
