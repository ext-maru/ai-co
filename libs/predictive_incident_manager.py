#!/usr/bin/env python3
"""
ğŸ”® äºˆæ¸¬ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹éšœå®³äºˆæ¸¬ã¨äºˆé˜²çš„å¯¾å¿œã§99.99%ç¨¼åƒç‡ã‚’å®Ÿç¾

ä½œæˆæ—¥: 2025å¹´7æœˆ8æ—¥
ä½œæˆè€…: ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼ï¼ˆé–‹ç™ºå®Ÿè¡Œè²¬ä»»è€…ï¼‰
æ‰¿èª: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ãƒ»ã‚¿ã‚¹ã‚¯è³¢è€…ã«ã‚ˆã‚‹å”è­°æ¸ˆã¿
"""

import asyncio
import numpy as np
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import math
import hashlib
from pathlib import Path
import sys
from collections import defaultdict, deque
import pickle

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .quantum_collaboration_engine import QuantumCollaborationEngine
    from .enhanced_incident_manager import EnhancedIncidentManager
except ImportError:
    # ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¹
    class QuantumCollaborationEngine:
        async def quantum_consensus(self, request):
            return type('MockConsensus', (), {
                'solution': 'Apply predictive model',
                'confidence': 0.8,
                'coherence': 0.75
            })()
    
    class EnhancedIncidentManager:
        def get_incident_history(self):
            return []

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)


class RiskLevel(Enum):
    """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class IncidentType(Enum):
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—å®šç¾©"""
    MEMORY_LEAK = "memory_leak"
    CPU_SPIKE = "cpu_spike"
    DISK_FULL = "disk_full"
    NETWORK_TIMEOUT = "network_timeout"
    DATABASE_LOCK = "database_lock"
    API_OVERLOAD = "api_overload"
    SECURITY_BREACH = "security_breach"
    SERVICE_UNAVAILABLE = "service_unavailable"


@dataclass
class ThreatPattern:
    """è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³"""
    pattern_id: str
    severity: str
    indicators: List[str]
    confidence_threshold: float = 0.7
    historical_accuracy: float = 0.0
    last_updated: datetime = field(default_factory=datetime.now)


@dataclass
class PredictionModel:
    """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"""
    model_type: str
    accuracy: float
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    training_data_size: int = 0
    last_trained: datetime = field(default_factory=datetime.now)
    feature_importance: Dict[str, float] = field(default_factory=dict)


@dataclass
class PreventiveAction:
    """äºˆé˜²çš„å¯¾å¿œ"""
    action_type: str
    target: str
    effectiveness: float
    execution_time: float = 0.0
    cost_impact: str = "low"
    automation_level: str = "manual"  # manual, semi_auto, full_auto
    success_rate: float = 0.8


@dataclass
class RiskAssessment:
    """ãƒªã‚¹ã‚¯è©•ä¾¡"""
    risk_level: str
    probability: float
    impact: str
    business_impact: float = 0.0
    technical_severity: int = 1
    affected_services: List[str] = field(default_factory=list)
    mitigation_urgency: str = "normal"


@dataclass
class IncidentForecast:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆäºˆæ¸¬"""
    prediction_time: datetime
    incident_type: str
    confidence: float
    lead_time: timedelta
    affected_components: List[str] = field(default_factory=list)
    likelihood_factors: Dict[str, float] = field(default_factory=dict)


@dataclass
class MetricsSnapshot:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: datetime
    memory_usage: float
    cpu_usage: float
    disk_usage: float
    network_latency: float
    error_rate: float
    request_rate: float
    response_time: float
    custom_metrics: Dict[str, float] = field(default_factory=dict)


class IncidentPredictor:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆäºˆæ¸¬å™¨"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.models: Dict[str, PredictionModel] = {}
        self.feature_extractors = {
            "memory_trend": self._extract_memory_trend,
            "cpu_spikes": self._extract_cpu_spikes,
            "error_rate_growth": self._extract_error_rate_growth,
            "response_time_degradation": self._extract_response_time_degradation
        }
        self.anomaly_threshold = 2.5  # æ¨™æº–åå·®å€æ•°
    
    def _extract_memory_trend(self, metrics_history: List[MetricsSnapshot]) -> float:
        """ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´æŠ½å‡º"""
        if len(metrics_history) < 3:
            return 0.0
        
        memory_values = [m.memory_usage for m in metrics_history[-10:]]
        
        # ç·šå½¢å›å¸°ã§ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        x = np.arange(len(memory_values))
        coeffs = np.polyfit(x, memory_values, 1)
        trend_slope = coeffs[0]
        
        return trend_slope
    
    def _extract_cpu_spikes(self, metrics_history: List[MetricsSnapshot]) -> float:
        """CPUã‚¹ãƒ‘ã‚¤ã‚¯ç‰¹å¾´æŠ½å‡º"""
        if len(metrics_history) < 5:
            return 0.0
        
        cpu_values = [m.cpu_usage for m in metrics_history[-20:]]
        mean_cpu = np.mean(cpu_values)
        std_cpu = np.std(cpu_values)
        
        # å¹³å‡ã‹ã‚‰2æ¨™æº–åå·®ä»¥ä¸Šã®ã‚¹ãƒ‘ã‚¤ã‚¯æ•°
        spikes = sum(1 for cpu in cpu_values if cpu > mean_cpu + 2 * std_cpu)
        spike_ratio = spikes / len(cpu_values)
        
        return spike_ratio
    
    def _extract_error_rate_growth(self, metrics_history: List[MetricsSnapshot]) -> float:
        """ã‚¨ãƒ©ãƒ¼ç‡æˆé•·ç‰¹å¾´æŠ½å‡º"""
        if len(metrics_history) < 3:
            return 0.0
        
        error_rates = [m.error_rate for m in metrics_history[-10:]]
        
        # æŒ‡æ•°çš„æˆé•·ã®æ¤œå‡º
        if all(rate > 0 for rate in error_rates):
            growth_rate = (error_rates[-1] / error_rates[0]) ** (1 / len(error_rates)) - 1
        else:
            growth_rate = 0.0
        
        return max(0.0, growth_rate)
    
    def _extract_response_time_degradation(self, metrics_history: List[MetricsSnapshot]) -> float:
        """å¿œç­”æ™‚é–“åŠ£åŒ–ç‰¹å¾´æŠ½å‡º"""
        if len(metrics_history) < 5:
            return 0.0
        
        response_times = [m.response_time for m in metrics_history[-15:]]
        
        # ç§»å‹•å¹³å‡ã®å¢—åŠ å‚¾å‘
        window_size = min(5, len(response_times) // 3)
        if window_size < 2:
            return 0.0
        
        early_avg = np.mean(response_times[:window_size])
        late_avg = np.mean(response_times[-window_size:])
        
        degradation = (late_avg - early_avg) / early_avg if early_avg > 0 else 0.0
        return max(0.0, degradation)
    
    def analyze_time_series(self, time_series_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ™‚ç³»åˆ—åˆ†æ"""
        timestamps = time_series_data["timestamps"]
        values = time_series_data["values"]
        
        if len(values) < 3:
            return {
                "trend": "insufficient_data",
                "seasonality": False,
                "anomalies": []
            }
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        x = np.arange(len(values))
        trend_coeffs = np.polyfit(x, values, 1)
        trend_slope = trend_coeffs[0]
        
        if trend_slope > 0.1:
            trend = "increasing"
        elif trend_slope < -0.1:
            trend = "decreasing"
        else:
            trend = "stable"
        
        # å­£ç¯€æ€§æ¤œå‡ºï¼ˆç°¡ç•¥åŒ–ï¼‰
        if len(values) >= 24:  # 24æ™‚é–“ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿
            hourly_pattern = [values[i::24] for i in range(min(24, len(values)))]
            hourly_means = [np.mean(pattern) if pattern else 0 for pattern in hourly_pattern]
            seasonality = np.std(hourly_means) > np.mean(hourly_means) * 0.1
        else:
            seasonality = False
        
        # ç•°å¸¸æ¤œå‡º
        anomalies = self.detect_anomalies(values)
        
        return {
            "trend": trend,
            "seasonality": seasonality,
            "anomalies": anomalies,
            "trend_strength": abs(trend_slope),
            "volatility": np.std(values)
        }
    
    def detect_anomalies(self, data: List[float]) -> List[Dict[str, Any]]:
        """ç•°å¸¸æ¤œå‡º"""
        if len(data) < 5:
            return []
        
        data_array = np.array(data)
        median = np.median(data_array)
        mad = np.median(np.abs(data_array - median))
        
        # Modified Z-score ã«ã‚ˆã‚‹ç•°å¸¸æ¤œå‡º
        modified_z_scores = 0.6745 * (data_array - median) / mad if mad > 0 else np.zeros_like(data_array)
        
        anomalies = []
        for i, (value, z_score) in enumerate(zip(data, modified_z_scores)):
            if abs(z_score) > self.anomaly_threshold:
                anomalies.append({
                    "index": i,
                    "value": value,
                    "z_score": z_score,
                    "severity": "high" if abs(z_score) > 3.5 else "medium"
                })
        
        return anomalies


class PredictiveIncidentManager:
    """äºˆæ¸¬ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.quantum_engine = QuantumCollaborationEngine()
        self.incident_manager = EnhancedIncidentManager()
        self.predictor = IncidentPredictor()
        
        # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ç¾¤
        self.prediction_models: Dict[str, PredictionModel] = {}
        
        # è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.threat_patterns: List[ThreatPattern] = []
        self._initialize_default_patterns()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´
        self.metrics_history: deque = deque(maxlen=1000)
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_predictions": 0,
            "successful_predictions": 0,
            "false_positives": 0,
            "false_negatives": 0,
            "prevented_incidents": 0,
            "prediction_accuracy": 0.0
        }
        
        # ç¶™ç¶šç›£è¦–ã‚¿ã‚¹ã‚¯
        self.monitoring_task: Optional[asyncio.Task] = None
        
        logger.info("ğŸ”® äºˆæ¸¬ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_default_patterns(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–"""
        default_patterns = [
            ThreatPattern(
                pattern_id="memory_leak_pattern",
                severity="high",
                indicators=["memory_growth", "gc_pressure", "heap_exhaustion"],
                confidence_threshold=0.75
            ),
            ThreatPattern(
                pattern_id="cpu_spike_pattern", 
                severity="medium",
                indicators=["cpu_sudden_increase", "thread_contention", "high_load"],
                confidence_threshold=0.7
            ),
            ThreatPattern(
                pattern_id="disk_exhaustion_pattern",
                severity="high",
                indicators=["disk_growth_rate", "low_free_space", "write_errors"],
                confidence_threshold=0.8
            ),
            ThreatPattern(
                pattern_id="network_degradation_pattern",
                severity="medium", 
                indicators=["latency_increase", "packet_loss", "timeout_errors"],
                confidence_threshold=0.65
            )
        ]
        
        self.threat_patterns.extend(default_patterns)
    
    def detect_threat_patterns(self, metrics: Dict[str, Any]) -> List[ThreatPattern]:
        """è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        detected_patterns = []
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "memory_usage" in metrics:
            memory_values = metrics["memory_usage"]
            if isinstance(memory_values, list) and len(memory_values) >= 3:
                # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
                trend = np.polyfit(range(len(memory_values)), memory_values, 1)[0]
                if trend > 2 and memory_values[-1] > 80:  # 2%/interval ä¸Šæ˜‡ & 80%è¶…
                    pattern = next(p for p in self.threat_patterns if p.pattern_id == "memory_leak_pattern")
                    detected_patterns.append(pattern)
        
        # CPUæ€¥ä¸Šæ˜‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "cpu_usage" in metrics:
            cpu_values = metrics["cpu_usage"]
            if isinstance(cpu_values, list) and len(cpu_values) >= 3:
                recent_avg = np.mean(cpu_values[-3:])
                if recent_avg > 90:
                    pattern = next(p for p in self.threat_patterns if p.pattern_id == "cpu_spike_pattern")
                    detected_patterns.append(pattern)
        
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "disk_usage" in metrics:
            disk_values = metrics["disk_usage"]
            growth_rate = metrics.get("disk_growth_rate", [])
            
            if isinstance(disk_values, list) and disk_values:
                current_usage = disk_values[-1]
                if current_usage > 85:  # 85%è¶…
                    if growth_rate and max(growth_rate) > 5:  # 5%/hourè¶…ã®æˆé•·
                        pattern = next(p for p in self.threat_patterns if p.pattern_id == "disk_exhaustion_pattern")
                        detected_patterns.append(pattern)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "response_time" in metrics:
            response_times = metrics["response_time"]
            if isinstance(response_times, list) and len(response_times) >= 3:
                baseline = np.mean(response_times[:len(response_times)//2])
                recent = np.mean(response_times[len(response_times)//2:])
                if recent > baseline * 2:  # å¿œç­”æ™‚é–“ãŒ2å€ã«
                    pattern = next(p for p in self.threat_patterns if p.pattern_id == "network_degradation_pattern")
                    detected_patterns.append(pattern)
        
        return detected_patterns
    
    def train_prediction_model(self, model_name: str, training_data: List[Dict[str, Any]]) -> PredictionModel:
        """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        if len(training_data) < 10:
            logger.warning(f"Insufficient training data for {model_name}: {len(training_data)} samples")
        
        # ç‰¹å¾´æŠ½å‡º
        features = []
        labels = []
        
        for sample in training_data:
            feature_vector = sample.get("features", [])
            label = sample.get("incident_occurred", False)
            
            if feature_vector:
                features.append(feature_vector)
                labels.append(1 if label else 0)
        
        if not features:
            raise ValueError("No valid features found in training data")
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªé–¾å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ scikit-learn ãªã©ã‚’ä½¿ç”¨ï¼‰
        features_array = np.array(features)
        labels_array = np.array(labels)
        
        # å„ç‰¹å¾´ã®é‡è¦åº¦è¨ˆç®—
        feature_importance = {}
        for i in range(features_array.shape[1]):
            correlation = np.corrcoef(features_array[:, i], labels_array)[0, 1]
            feature_importance[f"feature_{i}"] = abs(correlation) if not np.isnan(correlation) else 0
        
        # ç²¾åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        positive_samples = features_array[labels_array == 1]
        negative_samples = features_array[labels_array == 0]
        
        if len(positive_samples) > 0 and len(negative_samples) > 0:
            pos_mean = np.mean(positive_samples, axis=0)
            neg_mean = np.mean(negative_samples, axis=0)
            
            # åˆ†é›¢åº¦ãƒ™ãƒ¼ã‚¹ã®ç²¾åº¦æ¨å®š
            separation = np.linalg.norm(pos_mean - neg_mean)
            accuracy = min(0.95, 0.5 + separation / 200)  # æ­£è¦åŒ–
        else:
            accuracy = 0.6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = PredictionModel(
            model_type="threshold_based",
            accuracy=accuracy,
            precision=accuracy * 0.9,  # æ¨å®š
            recall=accuracy * 0.8,     # æ¨å®š
            f1_score=accuracy * 0.85,  # æ¨å®š
            training_data_size=len(training_data),
            feature_importance=feature_importance
        )
        
        self.prediction_models[model_name] = model
        logger.info(f"âœ… äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« '{model_name}' è¨“ç·´å®Œäº† (ç²¾åº¦: {accuracy:.2f})")
        
        return model
    
    def validate_prediction_model(self, model: PredictionModel, validation_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼"""
        if not validation_data:
            return {"accuracy": 0.0, "precision": 0.0, "recall": 0.0}
        
        # ç°¡æ˜“æ¤œè¨¼ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè¤‡é›‘ãªæ¤œè¨¼ï¼‰
        correct_predictions = 0
        true_positives = 0
        false_positives = 0
        false_negatives = 0
        
        for sample in validation_data:
            features = sample.get("features", [])
            actual = sample.get("actual_incident", False)
            
            # ç°¡æ˜“äºˆæ¸¬ï¼ˆç‰¹å¾´ã®å¹³å‡ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹ã‹ï¼‰
            if features:
                prediction = np.mean(features) > 70  # ä»®ã®é–¾å€¤
                
                if prediction == actual:
                    correct_predictions += 1
                
                if prediction and actual:
                    true_positives += 1
                elif prediction and not actual:
                    false_positives += 1
                elif not prediction and actual:
                    false_negatives += 1
        
        total_samples = len(validation_data)
        accuracy = correct_predictions / total_samples if total_samples > 0 else 0
        
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        
        return {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        }
    
    async def predict_incidents(self, metrics: Dict[str, Any], horizon: str = "1h") -> List[IncidentForecast]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆäºˆæ¸¬"""
        self.stats["total_predictions"] += 1
        predictions = []
        
        # ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã‚’æ™‚é–“ã«å¤‰æ›
        if horizon == "1h":
            lead_time = timedelta(hours=1)
        elif horizon == "24h":
            lead_time = timedelta(hours=24)
        else:
            lead_time = timedelta(hours=1)
        
        # è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        detected_patterns = self.detect_threat_patterns(metrics)
        
        for pattern in detected_patterns:
            # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°
            incident_type_mapping = {
                "memory_leak_pattern": IncidentType.MEMORY_LEAK.value,
                "cpu_spike_pattern": IncidentType.CPU_SPIKE.value,
                "disk_exhaustion_pattern": IncidentType.DISK_FULL.value,
                "network_degradation_pattern": IncidentType.NETWORK_TIMEOUT.value
            }
            
            incident_type = incident_type_mapping.get(pattern.pattern_id, "unknown")
            
            # ä¿¡é ¼åº¦è¨ˆç®—
            base_confidence = pattern.confidence_threshold
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ·±åˆ»åº¦ã«ã‚ˆã‚‹èª¿æ•´
            severity_multiplier = 1.0
            if "memory_usage" in metrics and isinstance(metrics["memory_usage"], list):
                current_memory = metrics["memory_usage"][-1] if metrics["memory_usage"] else 0
                if current_memory > 90:
                    severity_multiplier = 1.2
                elif current_memory > 95:
                    severity_multiplier = 1.4
            
            confidence = min(0.95, base_confidence * severity_multiplier)
            
            # äºˆæ¸¬ä½œæˆ
            forecast = IncidentForecast(
                prediction_time=datetime.now() + lead_time,
                incident_type=incident_type,
                confidence=confidence,
                lead_time=lead_time,
                affected_components=self._identify_affected_components(pattern, metrics),
                likelihood_factors=self._calculate_likelihood_factors(pattern, metrics)
            )
            
            predictions.append(forecast)
        
        # é‡å­å”èª¿ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹äºˆæ¸¬ã®ç²¾åº¦å‘ä¸Š
        if predictions:
            quantum_request = {
                "problem": "validate_incident_predictions",
                "predictions": [{"type": p.incident_type, "confidence": p.confidence} for p in predictions],
                "current_metrics": metrics
            }
            
            try:
                quantum_result = await self.quantum_engine.quantum_consensus(quantum_request)
                
                # é‡å­çµæœã«ã‚ˆã‚‹ä¿¡é ¼åº¦èª¿æ•´
                quantum_confidence_adjustment = quantum_result.confidence * 0.1
                for prediction in predictions:
                    prediction.confidence = min(0.98, prediction.confidence + quantum_confidence_adjustment)
                    
                logger.info(f"ğŸŒŒ é‡å­å”èª¿ã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦å‘ä¸Š: +{quantum_confidence_adjustment:.2f}")
            except Exception as e:
                logger.warning(f"é‡å­å”èª¿ã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        
        return predictions
    
    def _identify_affected_components(self, pattern: ThreatPattern, metrics: Dict[str, Any]) -> List[str]:
        """å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç‰¹å®š"""
        components = []
        
        pattern_component_mapping = {
            "memory_leak_pattern": ["application_server", "jvm", "cache"],
            "cpu_spike_pattern": ["application_server", "background_workers"],
            "disk_exhaustion_pattern": ["database", "log_system", "file_storage"],
            "network_degradation_pattern": ["load_balancer", "api_gateway", "external_services"]
        }
        
        components = pattern_component_mapping.get(pattern.pattern_id, ["unknown"])
        return components
    
    def _calculate_likelihood_factors(self, pattern: ThreatPattern, metrics: Dict[str, Any]) -> Dict[str, float]:
        """å¯èƒ½æ€§è¦å› è¨ˆç®—"""
        factors = {}
        
        if pattern.pattern_id == "memory_leak_pattern":
            if "memory_usage" in metrics and isinstance(metrics["memory_usage"], list):
                memory_values = metrics["memory_usage"]
                if len(memory_values) >= 2:
                    growth_rate = memory_values[-1] - memory_values[0]
                    factors["memory_growth_rate"] = growth_rate / 100
                    factors["current_usage"] = memory_values[-1] / 100
        
        elif pattern.pattern_id == "cpu_spike_pattern":
            if "cpu_usage" in metrics and isinstance(metrics["cpu_usage"], list):
                cpu_values = metrics["cpu_usage"]
                if cpu_values:
                    factors["peak_cpu"] = max(cpu_values) / 100
                    factors["cpu_volatility"] = np.std(cpu_values) / 100 if len(cpu_values) > 1 else 0
        
        return factors
    
    def assess_risk(self, incident_forecast: IncidentForecast) -> RiskAssessment:
        """ãƒªã‚¹ã‚¯è©•ä¾¡"""
        # åŸºæœ¬ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if incident_forecast.confidence >= 0.9:
            risk_level = RiskLevel.CRITICAL.value
        elif incident_forecast.confidence >= 0.7:
            risk_level = RiskLevel.HIGH.value
        elif incident_forecast.confidence >= 0.5:
            risk_level = RiskLevel.MEDIUM.value
        else:
            risk_level = RiskLevel.LOW.value
        
        # å½±éŸ¿åº¦è©•ä¾¡
        impact_mapping = {
            IncidentType.MEMORY_LEAK.value: "significant",
            IncidentType.CPU_SPIKE.value: "moderate",
            IncidentType.DISK_FULL.value: "severe",
            IncidentType.NETWORK_TIMEOUT.value: "significant",
            IncidentType.DATABASE_LOCK.value: "severe",
            IncidentType.API_OVERLOAD.value: "moderate"
        }
        
        impact = impact_mapping.get(incident_forecast.incident_type, "moderate")
        
        # ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ã‚¹ã‚³ã‚¢
        business_impact_scores = {
            "minimal": 0.1,
            "moderate": 0.4,
            "significant": 0.7,
            "severe": 0.9
        }
        
        business_impact = business_impact_scores.get(impact, 0.4)
        
        # æŠ€è¡“çš„æ·±åˆ»åº¦
        severity_mapping = {
            RiskLevel.LOW.value: 1,
            RiskLevel.MEDIUM.value: 2,
            RiskLevel.HIGH.value: 3,
            RiskLevel.CRITICAL.value: 4
        }
        
        technical_severity = severity_mapping[risk_level]
        
        # ç·Šæ€¥åº¦
        if incident_forecast.lead_time < timedelta(hours=1):
            urgency = "immediate"
        elif incident_forecast.lead_time < timedelta(hours=4):
            urgency = "urgent"
        elif incident_forecast.lead_time < timedelta(hours=24):
            urgency = "normal"
        else:
            urgency = "low"
        
        return RiskAssessment(
            risk_level=risk_level,
            probability=incident_forecast.confidence,
            impact=impact,
            business_impact=business_impact,
            technical_severity=technical_severity,
            affected_services=incident_forecast.affected_components,
            mitigation_urgency=urgency
        )
    
    def prioritize_risks(self, risks: List[RiskAssessment]) -> List[RiskAssessment]:
        """ãƒªã‚¹ã‚¯å„ªå…ˆé †ä½ä»˜ã‘"""
        # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        def calculate_priority_score(risk: RiskAssessment) -> float:
            level_scores = {"low": 1, "medium": 2, "high": 3, "critical": 4}
            impact_scores = {"minimal": 1, "moderate": 2, "significant": 3, "severe": 4}
            urgency_scores = {"low": 1, "normal": 2, "urgent": 3, "immediate": 4}
            
            level_score = level_scores.get(risk.risk_level, 2)
            impact_score = impact_scores.get(risk.impact, 2)
            urgency_score = urgency_scores.get(risk.mitigation_urgency, 2)
            
            # é‡ã¿ä»˜ã‘ã‚¹ã‚³ã‚¢
            priority = (level_score * 0.4 + 
                       impact_score * 0.4 + 
                       urgency_score * 0.2 + 
                       risk.probability * 0.3)
            
            return priority
        
        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        prioritized = sorted(risks, key=calculate_priority_score, reverse=True)
        return prioritized
    
    async def generate_preventive_actions(self, risk: RiskAssessment, 
                                         threat_pattern: ThreatPattern) -> List[PreventiveAction]:
        """äºˆé˜²çš„å¯¾å¿œç”Ÿæˆ"""
        actions = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®äºˆé˜²å¯¾å¿œ
        action_templates = {
            "memory_leak_pattern": [
                PreventiveAction("restart_service", "application_server", 0.8, 30.0, "medium", "semi_auto"),
                PreventiveAction("clear_cache", "memory_cache", 0.6, 5.0, "low", "full_auto"),
                PreventiveAction("scale_up", "memory_allocation", 0.7, 120.0, "high", "semi_auto")
            ],
            "cpu_spike_pattern": [
                PreventiveAction("scale_out", "worker_instances", 0.85, 180.0, "high", "semi_auto"),
                PreventiveAction("optimize_config", "thread_pool", 0.6, 15.0, "low", "manual"),
                PreventiveAction("throttle_requests", "rate_limiter", 0.9, 2.0, "low", "full_auto")
            ],
            "disk_exhaustion_pattern": [
                PreventiveAction("cleanup_logs", "log_rotation", 0.7, 10.0, "low", "full_auto"),
                PreventiveAction("archive_data", "old_backups", 0.8, 300.0, "medium", "semi_auto"),
                PreventiveAction("scale_storage", "disk_volume", 0.9, 600.0, "high", "manual")
            ],
            "network_degradation_pattern": [
                PreventiveAction("restart_load_balancer", "nginx", 0.6, 20.0, "medium", "semi_auto"),
                PreventiveAction("switch_dns", "backup_region", 0.9, 5.0, "low", "full_auto"),
                PreventiveAction("optimize_connections", "connection_pool", 0.7, 30.0, "low", "manual")
            ]
        }
        
        pattern_actions = action_templates.get(threat_pattern.pattern_id, [])
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if risk.risk_level == "critical":
            # æœ€ã‚‚åŠ¹æœçš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
            actions = sorted(pattern_actions, key=lambda a: a.effectiveness, reverse=True)[:3]
        elif risk.risk_level == "high":
            # åŠ¹æœçš„ã§å®Ÿè¡Œæ™‚é–“ãŒçŸ­ã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å„ªå…ˆ
            actions = [a for a in pattern_actions if a.effectiveness > 0.6 and a.execution_time < 300]
        else:
            # ä½ã‚³ã‚¹ãƒˆãƒ»è‡ªå‹•åŒ–ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å„ªå…ˆ
            actions = [a for a in pattern_actions if a.cost_impact in ["low", "medium"] and a.automation_level != "manual"]
        
        # é‡å­å”èª¿ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹æœ€é©åŒ–
        if actions:
            quantum_request = {
                "problem": "optimize_preventive_actions",
                "risk_assessment": {
                    "level": risk.risk_level,
                    "probability": risk.probability,
                    "impact": risk.impact
                },
                "available_actions": [{"type": a.action_type, "effectiveness": a.effectiveness} for a in actions]
            }
            
            try:
                quantum_result = await self.quantum_engine.quantum_consensus(quantum_request)
                
                # é‡å­çµæœã«ã‚ˆã‚‹åŠ¹æœè£œæ­£
                quantum_boost = quantum_result.confidence * 0.1
                for action in actions:
                    action.effectiveness = min(0.98, action.effectiveness + quantum_boost)
                    
            except Exception as e:
                logger.warning(f"é‡å­æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        return actions
    
    async def execute_preventive_action(self, action: PreventiveAction) -> Dict[str, Any]:
        """äºˆé˜²çš„å¯¾å¿œå®Ÿè¡Œ"""
        start_time = datetime.now()
        
        try:
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            execution_time = action.execution_time
            
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã“ã§å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            if action.action_type == "clear_cache":
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
                await asyncio.sleep(execution_time / 100)  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                success = True
                effect_measured = 0.8
                
            elif action.action_type == "restart_service":
                # ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
                await asyncio.sleep(execution_time / 100)
                success = True
                effect_measured = 0.9
                
            elif action.action_type == "scale_up":
                # ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—
                await asyncio.sleep(execution_time / 100)
                success = True
                effect_measured = 0.85
                
            else:
                # ãã®ä»–ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                await asyncio.sleep(execution_time / 100)
                success = True
                effect_measured = action.effectiveness
            
            actual_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": success,
                "execution_time": actual_time,
                "effect_measured": effect_measured,
                "action_type": action.action_type,
                "target": action.target
            }
            
        except Exception as e:
            logger.error(f"äºˆé˜²çš„å¯¾å¿œå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "execution_time": (datetime.now() - start_time).total_seconds(),
                "effect_measured": 0.0,
                "error": str(e)
            }
    
    def learn_from_incident(self, incident_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‹ã‚‰ã®å­¦ç¿’"""
        incident_type = incident_data.get("type")
        occurred_at = incident_data.get("occurred_at", datetime.now())
        metrics_before = incident_data.get("metrics_before", {})
        
        learning_result = {
            "pattern_updated": False,
            "model_retrained": False,
            "accuracy_improvement": 0.0
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ›´æ–°
        relevant_pattern = None
        for pattern in self.threat_patterns:
            if incident_type in pattern.pattern_id:
                relevant_pattern = pattern
                break
        
        if relevant_pattern:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç²¾åº¦æ›´æ–°
            relevant_pattern.last_updated = datetime.now()
            relevant_pattern.historical_accuracy = min(0.98, relevant_pattern.historical_accuracy + 0.05)
            learning_result["pattern_updated"] = True
        
        # ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        training_sample = {
            "features": [
                metrics_before.get("cpu", 0),
                metrics_before.get("memory", 0),
                metrics_before.get("connections", 0)
            ],
            "incident_occurred": True,
            "incident_type": incident_type
        }
        
        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°ï¼ˆç°¡ç•¥åŒ–ï¼‰
        if incident_type in self.prediction_models:
            model = self.prediction_models[incident_type]
            model.accuracy = min(0.98, model.accuracy + 0.02)
            learning_result["model_retrained"] = True
            learning_result["accuracy_improvement"] = 0.02
        
        # çµ±è¨ˆæ›´æ–°
        self.stats["successful_predictions"] += 1
        
        logger.info(f"ğŸ“š ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå­¦ç¿’å®Œäº†: {incident_type}")
        return learning_result
    
    def handle_false_positive(self, prediction: IncidentForecast) -> Dict[str, Any]:
        """å½é™½æ€§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†"""
        self.stats["false_positives"] += 1
        
        # é–¢é€£ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼åº¦é–¾å€¤èª¿æ•´
        for pattern in self.threat_patterns:
            if prediction.incident_type in pattern.pattern_id:
                pattern.confidence_threshold = min(0.9, pattern.confidence_threshold + 0.05)
                break
        
        # äºˆæ¸¬ç²¾åº¦å†è¨ˆç®—
        total_predictions = self.stats["total_predictions"]
        if total_predictions > 0:
            accuracy = (self.stats["successful_predictions"] / 
                       (total_predictions - self.stats["false_positives"]))
            self.stats["prediction_accuracy"] = accuracy
        
        return {
            "model_adjusted": True,
            "threshold_updated": True,
            "confidence_recalibrated": True,
            "new_false_positive_rate": self.stats["false_positives"] / total_predictions if total_predictions > 0 else 0
        }
    
    async def start_continuous_monitoring(self, config: Dict[str, Any]) -> asyncio.Task:
        """ç¶™ç¶šç›£è¦–é–‹å§‹"""
        async def monitoring_loop():
            interval = config.get("interval", 60)
            alert_thresholds = config.get("alert_thresholds", {"high_risk": 0.8})
            
            while True:
                try:
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                    current_metrics = {
                        "memory_usage": [70 + np.random.normal(0, 5)],
                        "cpu_usage": [60 + np.random.normal(0, 10)],
                        "disk_usage": [50 + np.random.normal(0, 3)]
                    }
                    
                    # äºˆæ¸¬å®Ÿè¡Œ
                    predictions = await self.predict_incidents(current_metrics)
                    
                    # é«˜ãƒªã‚¹ã‚¯äºˆæ¸¬ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
                    for prediction in predictions:
                        if prediction.confidence >= alert_thresholds.get("high_risk", 0.8):
                            logger.warning(f"ğŸš¨ é«˜ãƒªã‚¹ã‚¯äºˆæ¸¬: {prediction.incident_type} (ä¿¡é ¼åº¦: {prediction.confidence:.2f})")
                    
                    await asyncio.sleep(interval)
                    
                except asyncio.CancelledError:
                    logger.info("ğŸ›‘ ç¶™ç¶šç›£è¦–åœæ­¢")
                    break
                except Exception as e:
                    logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                    await asyncio.sleep(interval)
        
        self.monitoring_task = asyncio.create_task(monitoring_loop())
        logger.info("ğŸ‘ï¸ ç¶™ç¶šç›£è¦–é–‹å§‹")
        return self.monitoring_task
    
    def generate_alert(self, risk: RiskAssessment, forecast: IncidentForecast) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alert_id = hashlib.md5(
            f"{forecast.incident_type}{forecast.prediction_time}".encode()
        ).hexdigest()[:8]
        
        severity_mapping = {
            "low": "info",
            "medium": "warning", 
            "high": "error",
            "critical": "critical"
        }
        
        severity = severity_mapping.get(risk.risk_level, "warning")
        
        message = (f"äºˆæ¸¬ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ: {forecast.incident_type} "
                  f"(ä¿¡é ¼åº¦: {forecast.confidence:.1%}, "
                  f"ç™ºç”Ÿäºˆæ¸¬: {forecast.prediction_time.strftime('%H:%M')})")
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        recommended_actions = []
        if risk.risk_level in ["high", "critical"]:
            recommended_actions.extend([
                "å³åº§ã«äºˆé˜²çš„å¯¾å¿œã‚’å®Ÿæ–½",
                "é–¢é€£ãƒãƒ¼ãƒ ã«ç·Šæ€¥é€šçŸ¥",
                "ç›£è¦–å¼·åŒ–"
            ])
        else:
            recommended_actions.extend([
                "çŠ¶æ³ç›£è¦–ç¶™ç¶š",
                "äºˆé˜²çš„å¯¾å¿œæº–å‚™"
            ])
        
        return {
            "alert_id": alert_id,
            "severity": severity,
            "message": message,
            "incident_type": forecast.incident_type,
            "confidence": forecast.confidence,
            "risk_level": risk.risk_level,
            "affected_services": risk.affected_services,
            "recommended_actions": recommended_actions,
            "created_at": datetime.now().isoformat()
        }
    
    def get_prediction_metrics(self) -> Dict[str, Any]:
        """äºˆæ¸¬ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        total = self.stats["total_predictions"]
        
        if total == 0:
            return {
                "overall_accuracy": 0.0,
                "precision_by_type": {},
                "recall_by_type": {},
                "false_positive_rate": 0.0,
                "prediction_lead_time": 0.0,
                "model_performance": {}
            }
        
        accuracy = self.stats["successful_predictions"] / total
        fp_rate = self.stats["false_positives"] / total
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥æ€§èƒ½
        model_performance = {}
        for name, model in self.prediction_models.items():
            model_performance[name] = {
                "accuracy": model.accuracy,
                "precision": model.precision,
                "recall": model.recall,
                "f1_score": model.f1_score
            }
        
        return {
            "overall_accuracy": accuracy,
            "precision_by_type": {m: model.precision for m, model in self.prediction_models.items()},
            "recall_by_type": {m: model.recall for m, model in self.prediction_models.items()},
            "false_positive_rate": fp_rate,
            "prediction_lead_time": 3600.0,  # 1æ™‚é–“ï¼ˆç§’ï¼‰
            "model_performance": model_performance,
            "total_predictions": total,
            "prevented_incidents": self.stats["prevented_incidents"]
        }
    
    def get_system_health(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§å–å¾—"""
        # ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ äºˆæ¸¬
        current_risk_level = "low"  # ç°¡ç•¥åŒ–
        uptime_predictions = {
            "low": 99.99,
            "medium": 99.9,
            "high": 99.5,
            "critical": 99.0
        }
        
        uptime_prediction = uptime_predictions.get(current_risk_level, 99.0)
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–è„…å¨æ•°
        active_threats = len([p for p in self.threat_patterns if p.historical_accuracy > 0.7])
        
        # äºˆé˜²çš„å¯¾å¿œå®Ÿæ–½æ•°
        preventive_actions_taken = self.stats.get("preventive_actions_executed", 0)
        
        # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹
        healthy_models = len([m for m in self.prediction_models.values() if m.accuracy > 0.7])
        total_models = len(self.prediction_models)
        
        model_status = "healthy" if healthy_models == total_models else "degraded"
        
        return {
            "uptime_prediction": uptime_prediction,
            "risk_level": current_risk_level,
            "active_threats": active_threats,
            "preventive_actions_taken": preventive_actions_taken,
            "model_status": model_status,
            "healthy_models": healthy_models,
            "total_models": total_models,
            "prediction_accuracy": self.stats["prediction_accuracy"],
            "last_update": datetime.now().isoformat()
        }
    
    async def run_prediction_cycle(self, current_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """å®Œå…¨äºˆæ¸¬ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        cycle_start = datetime.now()
        
        # Step 1: äºˆæ¸¬å®Ÿè¡Œ
        predictions = await self.predict_incidents(current_metrics)
        
        # Step 2: ãƒªã‚¹ã‚¯è©•ä¾¡
        risks = []
        for prediction in predictions:
            risk = self.assess_risk(prediction)
            risks.append(risk)
        
        # Step 3: ãƒªã‚¹ã‚¯å„ªå…ˆé †ä½ä»˜ã‘
        prioritized_risks = self.prioritize_risks(risks)
        
        # Step 4: äºˆé˜²çš„å¯¾å¿œæ¨å¥¨
        recommended_actions = []
        for i, risk in enumerate(prioritized_risks[:3]):  # ä¸Šä½3ã¤
            if i < len(predictions):
                # å¯¾å¿œã™ã‚‹è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
                relevant_pattern = None
                for pattern in self.threat_patterns:
                    if predictions[i].incident_type in pattern.pattern_id:
                        relevant_pattern = pattern
                        break
                
                if relevant_pattern:
                    actions = await self.generate_preventive_actions(risk, relevant_pattern)
                    recommended_actions.extend(actions[:2])  # ä¸Šä½2ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        
        # Step 5: ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ
        alerts = []
        for prediction, risk in zip(predictions, risks):
            if risk.risk_level in ["high", "critical"]:
                alert = self.generate_alert(risk, prediction)
                alerts.append(alert)
        
        cycle_time = (datetime.now() - cycle_start).total_seconds()
        
        return {
            "predictions": predictions,
            "risks_assessed": len(risks),
            "actions_recommended": recommended_actions,
            "alerts_generated": alerts,
            "cycle_time": cycle_time,
            "timestamp": datetime.now().isoformat()
        }


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = [
    "PredictiveIncidentManager",
    "IncidentPredictor",
    "ThreatPattern",
    "PredictionModel",
    "PreventiveAction",
    "RiskAssessment",
    "IncidentForecast",
    "MetricsSnapshot",
    "RiskLevel",
    "IncidentType"
]