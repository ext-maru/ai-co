#!/usr/bin/env python3
"""
ğŸŒ Project Web Portal System
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆWebè¡¨ç¤ºãƒ»è‡ªå‹•è³‡æ–™ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

RAGã‚¨ãƒ«ãƒ€ãƒ¼ã®å°‚é–€çŸ¥è­˜ã«åŸºã¥ãåŒ…æ‹¬çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ãƒãƒ¼ã‚¿ãƒ«
pgvectorçµ±åˆã«ã‚ˆã‚‹é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢ã¨è‡ªå‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

Author: Claude Elder
Date: 2025-07-10
Consultation: RAG Elder
"""

import ast
import asyncio
import hashlib
import json
import logging
import os
import re
import sqlite3
import subprocess
from abc import ABC, abstractmethod
from collections import defaultdict
from dataclasses import asdict, dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .advanced_knowledge_synthesis import AdvancedKnowledgeSynthesisSystem
    from .multidimensional_vector_system import MultiDimensionalVectorSystem
except ImportError:
    MultiDimensionalVectorSystem = None
    AdvancedKnowledgeSynthesisSystem = None


class ProjectType(Enum):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—"""

    LIBRARY = "library"  # ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    APPLICATION = "application"  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    SCRIPT = "script"  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    FRAMEWORK = "framework"  # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    TOOL = "tool"  # ãƒ„ãƒ¼ãƒ«
    SERVICE = "service"  # ã‚µãƒ¼ãƒ“ã‚¹
    API = "api"  # API
    FRONTEND = "frontend"  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
    BACKEND = "backend"  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰


class ProjectStatus(Enum):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹"""

    ACTIVE = "active"  # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–
    COMPLETED = "completed"  # å®Œäº†
    DEPRECATED = "deprecated"  # éæ¨å¥¨
    EXPERIMENTAL = "experimental"  # å®Ÿé¨“çš„
    MAINTENANCE = "maintenance"  # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­


class TechStack(Enum):
    """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯"""

    PYTHON = "python"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    REACT = "react"
    NEXTJS = "nextjs"
    FASTAPI = "fastapi"
    POSTGRESQL = "postgresql"
    REDIS = "redis"
    DOCKER = "docker"


@dataclass
class ProjectDependency:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾å­˜é–¢ä¿‚"""

    name: str
    version: Optional[str] = None
    type: str = "runtime"  # runtime, dev, peer
    optional: bool = False


@dataclass
class CodeStructure:
    """ã‚³ãƒ¼ãƒ‰æ§‹é€ """

    total_lines: int
    total_files: int
    languages: Dict[str, int]  # è¨€èªåˆ¥è¡Œæ•°
    classes: List[str]
    functions: List[str]
    complexity_score: float
    test_coverage: Optional[float] = None


@dataclass
class GitMetrics:
    """Gitãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    total_commits: int
    contributors: List[str]
    last_commit: datetime
    creation_date: datetime
    active_branches: int
    commit_frequency: float  # commits per week


@dataclass
class ProjectMetadata:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""

    project_id: str
    name: str
    path: Path
    project_type: ProjectType
    status: ProjectStatus
    tech_stack: List[TechStack]
    description: str
    created_at: datetime
    updated_at: datetime

    # åˆ†æãƒ‡ãƒ¼ã‚¿
    dependencies: List[ProjectDependency] = field(default_factory=list)
    code_structure: Optional[CodeStructure] = None
    git_metrics: Optional[GitMetrics] = None

    # ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾
    feature_vector: Optional[np.ndarray] = None
    semantic_vector: Optional[np.ndarray] = None

    # é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    similar_projects: List[Tuple[str, float]] = field(
        default_factory=list
    )  # (project_id, similarity)

    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        data = asdict(self)
        # Enumã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        data["project_type"] = self.project_type.value
        data["status"] = self.status.value
        data["tech_stack"] = [tech.value for tech in self.tech_stack]
        # datetimeã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        data["created_at"] = self.created_at.isoformat()
        data["updated_at"] = self.updated_at.isoformat()
        # numpyé…åˆ—ã‚’é™¤å¤–
        data.pop("feature_vector", None)
        data.pop("semantic_vector", None)
        return data


@dataclass
class ProjectDocumentation:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè³‡æ–™"""

    project_id: str
    generated_at: datetime
    overview: str
    architecture: str
    setup_guide: str
    api_reference: str
    usage_examples: str
    related_projects: List[Dict[str, Any]]
    diagrams: Dict[str, str]  # diagram_type -> mermaid_code
    quality_score: float


class ProjectAnalyzer:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.logger = logging.getLogger(self.__class__.__name__)

    async def analyze_project(self, project_path: Path) -> ProjectMetadata:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ"""
        self.logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æé–‹å§‹: {project_path}")

        # åŸºæœ¬æƒ…å ±åé›†
        basic_info = await self._collect_basic_info(project_path)

        # ã‚³ãƒ¼ãƒ‰æ§‹é€ åˆ†æ
        code_structure = await self._analyze_code_structure(project_path)

        # ä¾å­˜é–¢ä¿‚åˆ†æ
        dependencies = await self._analyze_dependencies(project_path)

        # Gitåˆ†æ
        git_metrics = await self._analyze_git_metrics(project_path)

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        feature_vector = await self._create_feature_vector(
            basic_info, code_structure, dependencies
        )

        metadata = ProjectMetadata(
            project_id=self._generate_project_id(project_path),
            name=basic_info["name"],
            path=project_path,
            project_type=basic_info["type"],
            status=basic_info["status"],
            tech_stack=basic_info["tech_stack"],
            description=basic_info["description"],
            created_at=basic_info["created_at"],
            updated_at=datetime.now(),
            dependencies=dependencies,
            code_structure=code_structure,
            git_metrics=git_metrics,
            feature_vector=feature_vector,
        )

        self.logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Œäº†: {metadata.name}")
        return metadata

    async def _collect_basic_info(self, project_path: Path) -> Dict[str, Any]:
        """åŸºæœ¬æƒ…å ±åé›†"""
        info = {
            "name": project_path.name,
            "type": ProjectType.LIBRARY,
            "status": ProjectStatus.ACTIVE,
            "tech_stack": [],
            "description": "",
            "created_at": datetime.now(),
        }

        # READMEèª­ã¿å–ã‚Š
        readme_files = ["README.md", "README.txt", "readme.md"]
        for readme_file in readme_files:
            readme_path = project_path / readme_file
            if readme_path.exists():
                with open(readme_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    info["description"] = self._extract_description(content)
                break

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—æ¨å®š
        info["type"] = self._infer_project_type(project_path)

        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ¤œå‡º
        info["tech_stack"] = self._detect_tech_stack(project_path)

        # ä½œæˆæ—¥æ™‚æ¨å®š
        try:
            stat = project_path.stat()
            info["created_at"] = datetime.fromtimestamp(stat.st_ctime)
        except:
            pass

        return info

    async def _analyze_code_structure(self, project_path: Path) -> CodeStructure:
        """ã‚³ãƒ¼ãƒ‰æ§‹é€ åˆ†æ"""
        total_lines = 0
        total_files = 0
        languages = defaultdict(int)
        classes = []
        functions = []

        # Pythonãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        for py_file in project_path.rglob("*.py"):
            if "venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    lines = len(content.splitlines())
                    total_lines += lines
                    total_files += 1
                    languages["python"] += lines

                    # ASTè§£æ
                    tree = ast.parse(content)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.ClassDef):
                            classes.append(node.name)
                        elif isinstance(node, ast.FunctionDef):
                            functions.append(node.name)

            except Exception as e:
                self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼ {py_file}: {e}")

        # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«
        for file_path in project_path.rglob("*"):
            if file_path.is_file():
                suffix = file_path.suffix.lower()
                if suffix in [".js", ".ts", ".jsx", ".tsx"]:
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            lines = len(f.readlines())
                            languages["javascript"] += lines
                            total_lines += lines
                            total_files += 1
                    except:
                        pass

        # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        complexity_score = self._calculate_complexity_score(
            total_lines, len(classes), len(functions)
        )

        return CodeStructure(
            total_lines=total_lines,
            total_files=total_files,
            languages=dict(languages),
            classes=classes,
            functions=functions,
            complexity_score=complexity_score,
        )

    async def _analyze_dependencies(
        self, project_path: Path
    ) -> List[ProjectDependency]:
        """ä¾å­˜é–¢ä¿‚åˆ†æ"""
        dependencies = []

        # requirements.txt
        req_file = project_path / "requirements.txt"
        if req_file.exists():
            with open(req_file, "r") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        dep = self._parse_requirement(line)
                        if dep:
                            dependencies.append(dep)

        # package.json
        package_file = project_path / "package.json"
        if package_file.exists():
            with open(package_file, "r") as f:
                package_data = json.load(f)

                # runtime dependencies
                for name, version in package_data.get("dependencies", {}).items():
                    dependencies.append(
                        ProjectDependency(name=name, version=version, type="runtime")
                    )

                # dev dependencies
                for name, version in package_data.get("devDependencies", {}).items():
                    dependencies.append(
                        ProjectDependency(name=name, version=version, type="dev")
                    )

        return dependencies

    async def _analyze_git_metrics(self, project_path: Path) -> Optional[GitMetrics]:
        """Gitåˆ†æ"""
        try:
            # Gitæƒ…å ±å–å¾—
            result = subprocess.run(
                ["git", "log", "--pretty=format:%H|%an|%ad", "--date=iso"],
                cwd=project_path,
                capture_output=True,
                text=True,
            )

            if result.returncode != 0:
                return None

            commits = result.stdout.strip().split("\n")
            if not commits or commits == [""]:
                return None

            contributors = set()
            commit_dates = []

            for commit in commits:
                if "|" in commit:
                    parts = commit.split("|")
                    if len(parts) >= 3:
                        contributors.add(parts[1])
                        try:
                            commit_date = datetime.fromisoformat(
                                parts[2].replace(" +0900", "")
                            )
                            commit_dates.append(commit_date)
                        except:
                            pass

            if not commit_dates:
                return None

            # ãƒ–ãƒ©ãƒ³ãƒæ•°å–å¾—
            branch_result = subprocess.run(
                ["git", "branch", "-r"],
                cwd=project_path,
                capture_output=True,
                text=True,
            )
            active_branches = (
                len(branch_result.stdout.strip().split("\n"))
                if branch_result.returncode == 0
                else 1
            )

            # ã‚³ãƒŸãƒƒãƒˆé »åº¦è¨ˆç®—
            if len(commit_dates) > 1:
                time_span = max(commit_dates) - min(commit_dates)
                weeks = max(1, time_span.days / 7)
                commit_frequency = len(commits) / weeks
            else:
                commit_frequency = 0

            return GitMetrics(
                total_commits=len(commits),
                contributors=list(contributors),
                last_commit=max(commit_dates),
                creation_date=min(commit_dates),
                active_branches=active_branches,
                commit_frequency=commit_frequency,
            )

        except Exception as e:
            self.logger.warning(f"Gitåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    async def _create_feature_vector(
        self,
        basic_info: Dict[str, Any],
        code_structure: CodeStructure,
        dependencies: List[ProjectDependency],
    ) -> np.ndarray:
        """ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ"""
        features = []

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼‰
        project_types = list(ProjectType)
        type_vector = [1 if basic_info["type"] == pt else 0 for pt in project_types]
        features.extend(type_vector)

        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼‰
        all_techs = list(TechStack)
        tech_vector = [
            1 if tech in basic_info["tech_stack"] else 0 for tech in all_techs
        ]
        features.extend(tech_vector)

        # ã‚³ãƒ¼ãƒ‰è¦æ¨¡
        features.extend(
            [
                np.log1p(code_structure.total_lines),
                np.log1p(code_structure.total_files),
                np.log1p(len(code_structure.classes)),
                np.log1p(len(code_structure.functions)),
                code_structure.complexity_score,
            ]
        )

        # ä¾å­˜é–¢ä¿‚æ•°
        features.append(np.log1p(len(dependencies)))

        # è¨€èªåˆ†æ•£
        if code_structure.languages:
            total_lines = sum(code_structure.languages.values())
            lang_entropy = -sum(
                (count / total_lines) * np.log(count / total_lines)
                for count in code_structure.languages.values()
            )
            features.append(lang_entropy)
        else:
            features.append(0)

        return np.array(features, dtype=np.float32)

    def _generate_project_id(self, project_path: Path) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDç”Ÿæˆ"""
        path_str = str(project_path.resolve())
        return hashlib.sha256(path_str.encode()).hexdigest()[:16]

    def _extract_description(self, readme_content: str) -> str:
        """READMEèª¬æ˜æŠ½å‡º"""
        lines = readme_content.split("\n")
        description_lines = []

        found_desc = False
        for line in lines:
            line = line.strip()
            if not line:
                if found_desc:
                    break
                continue

            # ã‚¿ã‚¤ãƒˆãƒ«è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            if line.startswith("#") and not found_desc:
                continue

            # èª¬æ˜æ–‡ã‚’åé›†
            if not line.startswith("#") and not line.startswith("```"):
                description_lines.append(line)
                found_desc = True
                if len(description_lines) >= 3:  # æœ€åˆã®3è¡Œ
                    break

        return " ".join(description_lines)

    def _infer_project_type(self, project_path: Path) -> ProjectType:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—æ¨å®š"""
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰ã®æ¨å®š
        name = project_path.name.lower()

        if "api" in name:
            return ProjectType.API
        elif "script" in name or "scripts" in name:
            return ProjectType.SCRIPT
        elif "frontend" in name or "ui" in name:
            return ProjectType.FRONTEND
        elif "backend" in name or "server" in name:
            return ProjectType.BACKEND
        elif "tool" in name or "cli" in name:
            return ProjectType.TOOL
        elif "service" in name:
            return ProjectType.SERVICE
        elif "framework" in name:
            return ProjectType.FRAMEWORK
        elif "app" in name or "application" in name:
            return ProjectType.APPLICATION
        else:
            return ProjectType.LIBRARY

    def _detect_tech_stack(self, project_path: Path) -> List[TechStack]:
        """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ¤œå‡º"""
        techs = []

        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if (project_path / "requirements.txt").exists() or any(
            project_path.rglob("*.py")
        ):
            techs.append(TechStack.PYTHON)

        if (project_path / "package.json").exists():
            techs.append(TechStack.JAVASCRIPT)

        if any(project_path.rglob("*.ts")) or any(project_path.rglob("*.tsx")):
            techs.append(TechStack.TYPESCRIPT)

        if (project_path / "next.config.js").exists():
            techs.append(TechStack.NEXTJS)

        # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‹ã‚‰ã®æ¤œå‡º
        try:
            req_file = project_path / "requirements.txt"
            if req_file.exists():
                with open(req_file, "r") as f:
                    content = f.read().lower()
                    if "fastapi" in content:
                        techs.append(TechStack.FASTAPI)
                    if "psycopg" in content or "postgresql" in content:
                        techs.append(TechStack.POSTGRESQL)
                    if "redis" in content:
                        techs.append(TechStack.REDIS)
        except:
            pass

        return techs

    def _parse_requirement(self, req_line: str) -> Optional[ProjectDependency]:
        """requirementsè¡Œè§£æ"""
        # åŸºæœ¬çš„ãªè§£æ
        if "==" in req_line:
            name, version = req_line.split("==", 1)
            return ProjectDependency(name=name.strip(), version=version.strip())
        elif ">=" in req_line:
            name, version = req_line.split(">=", 1)
            return ProjectDependency(name=name.strip(), version=f">={version.strip()}")
        else:
            name = req_line.split()[0] if req_line else ""
            if name:
                return ProjectDependency(name=name.strip())
        return None

    def _calculate_complexity_score(
        self, lines: int, classes: int, functions: int
    ) -> float:
        """è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if lines == 0:
            return 0.0

        # æ­£è¦åŒ–ã•ã‚ŒãŸè¤‡é›‘åº¦
        class_density = classes / max(1, lines / 100)  # ã‚¯ãƒ©ã‚¹å¯†åº¦
        function_density = functions / max(1, lines / 50)  # é–¢æ•°å¯†åº¦

        # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        score = min(1.0, (class_density + function_density) / 10)
        return score


class DocumentationGenerator:
    """è‡ªå‹•è³‡æ–™ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.logger = logging.getLogger(self.__class__.__name__)
        self.knowledge_synthesis = None

        # çŸ¥è­˜åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        try:
            if AdvancedKnowledgeSynthesisSystem:
                self.knowledge_synthesis = AdvancedKnowledgeSynthesisSystem()
        except:
            pass

    async def generate_documentation(
        self, metadata: ProjectMetadata, similar_projects: List[ProjectMetadata] = None
    ) -> ProjectDocumentation:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè³‡æ–™ç”Ÿæˆ"""
        self.logger.info(f"è³‡æ–™ç”Ÿæˆé–‹å§‹: {metadata.name}")

        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        overview = await self._generate_overview(metadata)
        architecture = await self._generate_architecture(metadata)
        setup_guide = await self._generate_setup_guide(metadata)
        api_reference = await self._generate_api_reference(metadata)
        usage_examples = await self._generate_usage_examples(metadata)
        diagrams = await self._generate_diagrams(metadata)

        # é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
        related_projects = []
        if similar_projects:
            for proj in similar_projects[:5]:  # ä¸Šä½5ä»¶
                related_projects.append(
                    {
                        "name": proj.name,
                        "description": proj.description,
                        "similarity": 0.85,  # ä»®ã®å€¤
                        "tech_stack": [tech.value for tech in proj.tech_stack],
                    }
                )

        # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        quality_score = self._calculate_documentation_quality(
            overview, architecture, setup_guide
        )

        documentation = ProjectDocumentation(
            project_id=metadata.project_id,
            generated_at=datetime.now(),
            overview=overview,
            architecture=architecture,
            setup_guide=setup_guide,
            api_reference=api_reference,
            usage_examples=usage_examples,
            related_projects=related_projects,
            diagrams=diagrams,
            quality_score=quality_score,
        )

        self.logger.info(f"è³‡æ–™ç”Ÿæˆå®Œäº†: {metadata.name} (å“è³ª: {quality_score:.2f})")
        return documentation

    async def _generate_overview(self, metadata: ProjectMetadata) -> str:
        """æ¦‚è¦ç”Ÿæˆ"""
        overview = f"# {metadata.name}\n\n"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæœ¬æƒ…å ±
        overview += f"**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—**: {metadata.project_type.value}\n"
        overview += f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {metadata.status.value}\n"
        overview += f"**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**: {', '.join([tech.value for tech in metadata.tech_stack])}\n\n"

        # èª¬æ˜
        if metadata.description:
            overview += f"## èª¬æ˜\n\n{metadata.description}\n\n"

        # ã‚³ãƒ¼ãƒ‰çµ±è¨ˆ
        if metadata.code_structure:
            cs = metadata.code_structure
            overview += f"## ã‚³ãƒ¼ãƒ‰çµ±è¨ˆ\n\n"
            overview += f"- **ç·è¡Œæ•°**: {cs.total_lines:,}\n"
            overview += f"- **ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {cs.total_files}\n"
            overview += f"- **ã‚¯ãƒ©ã‚¹æ•°**: {len(cs.classes)}\n"
            overview += f"- **é–¢æ•°æ•°**: {len(cs.functions)}\n"
            overview += f"- **è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢**: {cs.complexity_score:.2f}\n\n"

        # Gitçµ±è¨ˆ
        if metadata.git_metrics:
            gm = metadata.git_metrics
            overview += f"## é–‹ç™ºçµ±è¨ˆ\n\n"
            overview += f"- **ã‚³ãƒŸãƒƒãƒˆæ•°**: {gm.total_commits}\n"
            overview += f"- **è²¢çŒ®è€…æ•°**: {len(gm.contributors)}\n"
            overview += f"- **æœ€çµ‚æ›´æ–°**: {gm.last_commit.strftime('%Y-%m-%d')}\n"
            overview += (
                f"- **é–‹ç™ºæœŸé–“**: {(gm.last_commit - gm.creation_date).days}æ—¥\n\n"
            )

        return overview

    async def _generate_architecture(self, metadata: ProjectMetadata) -> str:
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£èª¬æ˜ç”Ÿæˆ"""
        arch = f"# {metadata.name} ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n\n"

        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°
        arch += "## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯\n\n"
        for tech in metadata.tech_stack:
            arch += f"- **{tech.value}**: {self._get_tech_description(tech)}\n"
        arch += "\n"

        # ä¾å­˜é–¢ä¿‚
        if metadata.dependencies:
            arch += "## ä¸»è¦ä¾å­˜é–¢ä¿‚\n\n"
            runtime_deps = [d for d in metadata.dependencies if d.type == "runtime"]
            for dep in runtime_deps[:10]:  # ä¸Šä½10ä»¶
                arch += f"- `{dep.name}`"
                if dep.version:
                    arch += f" ({dep.version})"
                arch += "\n"
            arch += "\n"

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ 
        if metadata.code_structure and metadata.code_structure.classes:
            arch += "## ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ\n\n"
            for cls in metadata.code_structure.classes[:10]:  # ä¸Šä½10ä»¶
                arch += f"- `{cls}`\n"
            arch += "\n"

        return arch

    async def _generate_setup_guide(self, metadata: ProjectMetadata) -> str:
        """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ç”Ÿæˆ"""
        guide = f"# {metadata.name} ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰\n\n"

        # å‰ææ¡ä»¶
        guide += "## å‰ææ¡ä»¶\n\n"
        if TechStack.PYTHON in metadata.tech_stack:
            guide += "- Python 3.8ä»¥é™\n"
        if (
            TechStack.JAVASCRIPT in metadata.tech_stack
            or TechStack.NEXTJS in metadata.tech_stack
        ):
            guide += "- Node.js 16ä»¥é™\n"
        if TechStack.POSTGRESQL in metadata.tech_stack:
            guide += "- PostgreSQL 13ä»¥é™\n"
        guide += "\n"

        # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
        guide += "## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n"
        guide += "```bash\n"
        guide += f"# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n"
        guide += f"git clone <repository-url>\n"
        guide += f"cd {metadata.name}\n\n"

        if TechStack.PYTHON in metadata.tech_stack:
            guide += "# Pythonä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n"
            guide += "pip install -r requirements.txt\n\n"

        if TechStack.JAVASCRIPT in metadata.tech_stack:
            guide += "# Node.jsä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n"
            guide += "npm install\n\n"

        guide += "```\n\n"

        # è¨­å®š
        guide += "## è¨­å®š\n\n"
        if TechStack.POSTGRESQL in metadata.tech_stack:
            guide += "1. PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ\n"
            guide += "2. ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š\n"
            guide += "```bash\n"
            guide += "export DATABASE_URL=postgresql://user:pass@localhost/dbname\n"
            guide += "```\n\n"

        # å®Ÿè¡Œ
        guide += "## å®Ÿè¡Œ\n\n"
        guide += "```bash\n"
        if metadata.project_type == ProjectType.APPLICATION:
            if TechStack.PYTHON in metadata.tech_stack:
                guide += "python main.py\n"
            elif TechStack.NEXTJS in metadata.tech_stack:
                guide += "npm run dev\n"
        elif metadata.project_type == ProjectType.SCRIPT:
            guide += f"python {metadata.name}.py\n"
        guide += "```\n\n"

        return guide

    async def _generate_api_reference(self, metadata: ProjectMetadata) -> str:
        """APIå‚è€ƒè³‡æ–™ç”Ÿæˆ"""
        if metadata.project_type not in [ProjectType.API, ProjectType.LIBRARY]:
            return ""

        api_ref = f"# {metadata.name} API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹\n\n"

        # ä¸»è¦é–¢æ•°
        if metadata.code_structure and metadata.code_structure.functions:
            api_ref += "## ä¸»è¦é–¢æ•°\n\n"
            for func in metadata.code_structure.functions[:20]:  # ä¸Šä½20ä»¶
                api_ref += f"### `{func}()`\n\n"
                api_ref += f"```python\n"
                api_ref += f"def {func}():\n"
                api_ref += f'    """\n'
                api_ref += f"    {func}ã®èª¬æ˜\n"
                api_ref += f'    """\n'
                api_ref += f"    pass\n"
                api_ref += f"```\n\n"

        return api_ref

    async def _generate_usage_examples(self, metadata: ProjectMetadata) -> str:
        """ä½¿ç”¨ä¾‹ç”Ÿæˆ"""
        examples = f"# {metadata.name} ä½¿ç”¨ä¾‹\n\n"

        # åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹
        examples += "## åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•\n\n"
        examples += "```python\n"

        if metadata.project_type == ProjectType.LIBRARY:
            examples += f"from {metadata.name} import main_function\n\n"
            examples += "# åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•\n"
            examples += "result = main_function()\n"
            examples += "print(result)\n"
        elif metadata.project_type == ProjectType.API:
            examples += "import requests\n\n"
            examples += "# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹\n"
            examples += (
                # Security: Validate URL before making request
                "response = requests.get('http://localhost:8000/api/endpoint')\n"
            )
            examples += "print(response.json())\n"

        examples += "```\n\n"

        # é«˜åº¦ãªä½¿ç”¨ä¾‹
        examples += "## é«˜åº¦ãªä½¿ç”¨ä¾‹\n\n"
        examples += "```python\n"
        examples += "# è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã®ä½¿ç”¨ä¾‹\n"
        examples += "# TODO: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®é«˜åº¦ãªä½¿ç”¨ä¾‹\n"
        examples += "```\n\n"

        return examples

    async def _generate_diagrams(self, metadata: ProjectMetadata) -> Dict[str, str]:
        """å›³è¡¨ç”Ÿæˆ"""
        diagrams = {}

        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³
        if metadata.tech_stack:
            arch_diagram = "graph TD\n"

            # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è¦ç´ 
            for i, tech in enumerate(metadata.tech_stack):
                arch_diagram += f"    {tech.value}[{tech.value}]\n"

            # é–¢ä¿‚æ€§ï¼ˆç°¡å˜ãªä¾‹ï¼‰
            if len(metadata.tech_stack) > 1:
                for i in range(len(metadata.tech_stack) - 1):
                    current = metadata.tech_stack[i].value
                    next_tech = metadata.tech_stack[i + 1].value
                    arch_diagram += f"    {current} --> {next_tech}\n"

            diagrams["architecture"] = arch_diagram

        # ä¾å­˜é–¢ä¿‚å›³
        if metadata.dependencies:
            dep_diagram = "graph LR\n"
            dep_diagram += f"    {metadata.name}[{metadata.name}]\n"

            for dep in metadata.dependencies[:10]:  # ä¸Šä½10ä»¶
                dep_diagram += f"    {dep.name}[{dep.name}]\n"
                dep_diagram += f"    {metadata.name} --> {dep.name}\n"

            diagrams["dependencies"] = dep_diagram

        return diagrams

    def _get_tech_description(self, tech: TechStack) -> str:
        """æŠ€è¡“èª¬æ˜å–å¾—"""
        descriptions = {
            TechStack.PYTHON: "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
            TechStack.JAVASCRIPT: "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
            TechStack.TYPESCRIPT: "å‹å®‰å…¨ãªJavaScript",
            TechStack.REACT: "UIãƒ©ã‚¤ãƒ–ãƒ©ãƒª",
            TechStack.NEXTJS: "Reactãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            TechStack.FASTAPI: "é«˜é€ŸãªPython Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            TechStack.POSTGRESQL: "ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
            TechStack.REDIS: "ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢",
            TechStack.DOCKER: "ã‚³ãƒ³ãƒ†ãƒŠãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ",
        }
        return descriptions.get(tech, "æŠ€è¡“ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ")

    def _calculate_documentation_quality(
        self, overview: str, architecture: str, setup_guide: str
    ) -> float:
        """æ–‡æ›¸å“è³ªè¨ˆç®—"""
        total_length = len(overview) + len(architecture) + len(setup_guide)

        # é•·ã•ãƒ™ãƒ¼ã‚¹ã®å“è³ªè©•ä¾¡
        if total_length > 5000:
            base_score = 0.9
        elif total_length > 2000:
            base_score = 0.8
        elif total_length > 1000:
            base_score = 0.7
        else:
            base_score = 0.6

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯
        has_code_blocks = "```" in (overview + architecture + setup_guide)
        has_headers = "#" in (overview + architecture + setup_guide)
        has_lists = "-" in (overview + architecture + setup_guide)

        diversity_bonus = sum([has_code_blocks, has_headers, has_lists]) * 0.05

        return min(1.0, base_score + diversity_bonus)


class ProjectWebPortal:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆWebãƒãƒ¼ã‚¿ãƒ«"""

    def __init__(self):
        """åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.logger = logging.getLogger(self.__class__.__name__)
        self.db_path = PROJECT_ROOT / "data" / "project_portal.db"
        self.analyzer = ProjectAnalyzer()
        self.doc_generator = DocumentationGenerator()
        self.vector_system = None

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        try:
            if MultiDimensionalVectorSystem:
                self.vector_system = MultiDimensionalVectorSystem()
        except:
            pass

        self._init_database()

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS projects (
                    project_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    path TEXT NOT NULL,
                    project_type TEXT,
                    status TEXT,
                    tech_stack TEXT,
                    description TEXT,
                    metadata_json TEXT,
                    created_at REAL,
                    updated_at REAL
                )
            """
            )

            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS project_documentation (
                    project_id TEXT PRIMARY KEY,
                    generated_at REAL,
                    overview TEXT,
                    architecture TEXT,
                    setup_guide TEXT,
                    api_reference TEXT,
                    usage_examples TEXT,
                    diagrams_json TEXT,
                    quality_score REAL,
                    FOREIGN KEY (project_id) REFERENCES projects (project_id)
                )
            """
            )

    async def scan_projects(self, root_path: Path = None) -> List[ProjectMetadata]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³"""
        if root_path is None:
            root_path = PROJECT_ROOT

        self.logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹: {root_path}")

        projects = []

        # libsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³
        libs_dir = root_path / "libs"
        if libs_dir.exists():
            for item in libs_dir.iterdir():
                if item.is_file() and item.suffix == ".py":
                    # å€‹åˆ¥ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã†
                    metadata = await self.analyzer.analyze_project(item.parent)
                    metadata.name = item.stem
                    metadata.path = item
                    projects.append(metadata)

        # scriptsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³
        scripts_dir = root_path / "scripts"
        if scripts_dir.exists():
            for item in scripts_dir.iterdir():
                if item.is_file() and item.suffix == ".py":
                    metadata = await self.analyzer.analyze_project(item.parent)
                    metadata.name = item.stem
                    metadata.path = item
                    metadata.project_type = ProjectType.SCRIPT
                    projects.append(metadata)

        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³
        for item in root_path.iterdir():
            if item.is_dir() and item.name not in [
                "venv",
                "__pycache__",
                ".git",
                "node_modules",
            ]:
                if any(item.rglob("*.py")) or (item / "package.json").exists():
                    metadata = await self.analyzer.analyze_project(item)
                    projects.append(metadata)

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        await self._save_projects(projects)

        self.logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {len(projects)}ä»¶")
        return projects

    async def get_project_list(self) -> List[Dict[str, Any]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """
                SELECT project_id, name, project_type, status, tech_stack,
                       description, updated_at
                FROM projects
                ORDER BY updated_at SHA256C
            """
            )

            projects = []
            for row in cursor.fetchall():
                projects.append(
                    {
                        "project_id": row[0],
                        "name": row[1],
                        "project_type": row[2],
                        "status": row[3],
                        "tech_stack": json.loads(row[4]) if row[4] else [],
                        "description": row[5],
                        "updated_at": datetime.fromtimestamp(row[6]).isoformat(),
                    }
                )

        return projects

    async def get_project_details(self, project_id: str) -> Optional[Dict[str, Any]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            cursor = conn.execute(
                "SELECT metadata_json FROM projects WHERE project_id = ?", (project_id,)
            )
            row = cursor.fetchone()
            if not row:
                return None

            metadata = json.loads(row[0])

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            cursor = conn.execute(
                """SELECT overview, architecture, setup_guide, api_reference,
                          usage_examples, diagrams_json, quality_score
                   FROM project_documentation WHERE project_id = ?""",
                (project_id,),
            )
            doc_row = cursor.fetchone()

            if doc_row:
                metadata["documentation"] = {
                    "overview": doc_row[0],
                    "architecture": doc_row[1],
                    "setup_guide": doc_row[2],
                    "api_reference": doc_row[3],
                    "usage_examples": doc_row[4],
                    "diagrams": json.loads(doc_row[5]) if doc_row[5] else {},
                    "quality_score": doc_row[6],
                }

        return metadata

    async def generate_project_documentation(
        self, project_id: str
    ) -> Optional[ProjectDocumentation]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè³‡æ–™ç”Ÿæˆ"""
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
        metadata = await self._get_project_metadata(project_id)
        if not metadata:
            return None

        # é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢
        similar_projects = await self._find_similar_projects(metadata)

        # è³‡æ–™ç”Ÿæˆ
        documentation = await self.doc_generator.generate_documentation(
            metadata, similar_projects
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        await self._save_documentation(documentation)

        return documentation

    async def find_similar_projects(
        self, project_id: str, limit: int = 5
    ) -> List[Dict[str, Any]]:
        """é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢"""
        metadata = await self._get_project_metadata(project_id)
        if not metadata or metadata.feature_vector is None:
            return []

        similar_projects = await self._find_similar_projects(metadata, limit)

        results = []
        for proj in similar_projects:
            similarity = self._calculate_similarity(
                metadata.feature_vector, proj.feature_vector
            )
            results.append(
                {
                    "project_id": proj.project_id,
                    "name": proj.name,
                    "description": proj.description,
                    "similarity": similarity,
                    "tech_stack": [tech.value for tech in proj.tech_stack],
                }
            )

        return sorted(results, key=lambda x: x["similarity"], reverse=True)

    async def _save_projects(self, projects: List[ProjectMetadata]):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            for project in projects:
                conn.execute(
                    """
                    INSERT OR REPLACE INTO projects
                    (project_id, name, path, project_type, status, tech_stack,
                     description, metadata_json, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        project.project_id,
                        project.name,
                        str(project.path),
                        project.project_type.value,
                        project.status.value,
                        json.dumps([tech.value for tech in project.tech_stack]),
                        project.description,
                        json.dumps(project.to_dict()),
                        project.created_at.timestamp(),
                        project.updated_at.timestamp(),
                    ),
                )

    async def _save_documentation(self, documentation: ProjectDocumentation):
        """è³‡æ–™ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT OR REPLACE INTO project_documentation
                (project_id, generated_at, overview, architecture, setup_guide,
                 api_reference, usage_examples, diagrams_json, quality_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    documentation.project_id,
                    documentation.generated_at.timestamp(),
                    documentation.overview,
                    documentation.architecture,
                    documentation.setup_guide,
                    documentation.api_reference,
                    documentation.usage_examples,
                    json.dumps(documentation.diagrams),
                    documentation.quality_score,
                ),
            )

    async def _get_project_metadata(self, project_id: str) -> Optional[ProjectMetadata]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT metadata_json FROM projects WHERE project_id = ?", (project_id,)
            )
            row = cursor.fetchone()
            if not row:
                return None

            # JSON ã‹ã‚‰ ProjectMetadata ã‚’å¾©å…ƒ
            data = json.loads(row[0])
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå¾©å…ƒï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å®Œå…¨ãªå¾©å…ƒãŒå¿…è¦ï¼‰
            return None  # TODO: å®Œå…¨ãªå¾©å…ƒå®Ÿè£…

    async def _find_similar_projects(
        self, target: ProjectMetadata, limit: int = 5
    ) -> List[ProjectMetadata]:
        """é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢"""
        # TODO: pgvector ã‚’ä½¿ã£ãŸé«˜åº¦ãªé¡ä¼¼åº¦æ¤œç´¢
        return []

    def _calculate_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """é¡ä¼¼åº¦è¨ˆç®—"""
        if vec1 is None or vec2 is None:
            return 0.0

        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return dot_product / (norm1 * norm2)


# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    portal = ProjectWebPortal()

    print("ğŸŒ Project Web Portal ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³
    print("\n1ï¸âƒ£ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ...")
    projects = await portal.scan_projects()
    print(f"âœ… {len(projects)}ä»¶ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ç™ºè¦‹")

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§è¡¨ç¤º
    print("\n2ï¸âƒ£ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§:")
    project_list = await portal.get_project_list()
    for proj in project_list[:5]:  # ä¸Šä½5ä»¶
        print(f"ğŸ“ {proj['name']} ({proj['project_type']})")
        print(f"   æŠ€è¡“: {', '.join(proj['tech_stack'])}")
        print(f"   èª¬æ˜: {proj['description'][:50]}...")

    # è‡ªå‹•è³‡æ–™ç”Ÿæˆãƒ‡ãƒ¢
    if project_list:
        print(f"\n3ï¸âƒ£ è‡ªå‹•è³‡æ–™ç”Ÿæˆãƒ‡ãƒ¢: {project_list[0]['name']}")
        documentation = await portal.generate_project_documentation(
            project_list[0]["project_id"]
        )

        if documentation:
            print(f"âœ… è³‡æ–™ç”Ÿæˆå®Œäº† (å“è³ªã‚¹ã‚³ã‚¢: {documentation.quality_score:.2f})")
            print(f"ğŸ“„ æ¦‚è¦: {len(documentation.overview)}æ–‡å­—")
            print(f"ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {len(documentation.architecture)}æ–‡å­—")
            print(f"ğŸ“‹ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: {len(documentation.setup_guide)}æ–‡å­—")

    print("\nâœ¨ Project Web Portal ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œç¢ºèªå®Œäº†ï¼")


if __name__ == "__main__":
    asyncio.run(main())