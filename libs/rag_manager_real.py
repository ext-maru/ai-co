#!/usr/bin/env python3
"""
ğŸ” RAG Manager Real
RAG (Retrieval-Augmented Generation) ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

Created: 2025-07-17
Author: Claude Elder
Version: 2.0.0 - Elder Legacyæº–æ‹ 
Architecture: Elders Legacy AIå±¤
"""

import asyncio
import json
import sqlite3
import hashlib
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any, Union, Tuple
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
import sys

# Elder Legacyçµ±åˆ
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.elders_legacy import EldersAILegacy, enforce_boundary, DomainBoundary


class DocumentType(Enum):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—"""
    CODE = "code"
    DOCUMENTATION = "documentation"
    KNOWLEDGE_BASE = "knowledge_base"
    CONVERSATION = "conversation"
    TUTORIAL = "tutorial"
    SPECIFICATION = "specification"


class RetrievalStrategy(Enum):
    """æ¤œç´¢æˆ¦ç•¥"""
    SIMILARITY = "similarity"
    KEYWORD = "keyword"
    HYBRID = "hybrid"
    SEMANTIC = "semantic"


@dataclass
class Document:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"""
    id: str
    content: str
    doc_type: DocumentType
    metadata: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[List[float]] = None
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class Query:
    """ã‚¯ã‚¨ãƒª"""
    text: str
    strategy: RetrievalStrategy = RetrievalStrategy.HYBRID
    limit: int = 5
    filters: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RetrievalResult:
    """æ¤œç´¢çµæœ"""
    document: Document
    score: float
    relevance: str


@dataclass
class RAGResponse:
    """RAGå¿œç­”"""
    query: str
    answer: str
    sources: List[RetrievalResult]
    confidence: float
    generated_at: datetime = field(default_factory=datetime.now)


class RAGManager(EldersAILegacy):
    """
    ğŸ” RAGç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    Elder Legacy AIå±¤æº–æ‹ ã®RAGçµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, db_path: str = "data/rag_knowledge.db", config: Optional[Dict[str, Any]] = None):
        """
        RAGç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
            config: è¨­å®šè¾æ›¸
        """
        super().__init__(name="RAGManager")
        self.db_path = Path(db_path)
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self._initialize_database_sync()
        
        # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        self.document_index: Dict[str, Document] = {}
        self.keyword_index: Dict[str, Set[str]] = {}
    
    @enforce_boundary(DomainBoundary.WISDOM, "process_request")
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        RAGãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
        
        Args:
            request: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            å‡¦ç†çµæœ
        """
        try:
            operation = request.get("operation", "unknown")
            
            if operation == "add_document":
                return await self._add_document(
                    request.get("content"),
                    request.get("doc_type", "knowledge_base"),
                    request.get("metadata", {})
                )
            elif operation == "search_documents":
                return await self._search_documents(
                    request.get("query"),
                    request.get("strategy", "hybrid"),
                    request.get("limit", 5)
                )
            elif operation == "generate_answer":
                return await self._generate_answer(
                    request.get("query"),
                    request.get("context", [])
                )
            elif operation == "get_document":
                return await self._get_document(request.get("doc_id"))
            elif operation == "delete_document":
                return await self._delete_document(request.get("doc_id"))
            elif operation == "get_stats":
                return await self._get_stats()
            elif operation == "health_check":
                return await self._health_check()
            else:
                return {
                    "status": "error",
                    "message": f"Unknown operation: {operation}",
                    "operation": operation
                }
                
        except Exception as e:
            self.logger.error(f"Error processing request: {e}")
            return {
                "status": "error",
                "message": str(e),
                "operation": request.get("operation", "unknown")
            }
    
    async def validate_request(self, request: Dict[str, Any]) -> bool:
        """
        ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ¤œè¨¼
        
        Args:
            request: æ¤œè¨¼å¯¾è±¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            
        Returns:
            æ¤œè¨¼çµæœ
        """
        if not isinstance(request, dict):
            return False
            
        operation = request.get("operation")
        if not operation:
            return False
            
        # æ“ä½œåˆ¥æ¤œè¨¼
        if operation == "add_document":
            return "content" in request
        elif operation == "search_documents":
            return "query" in request
        elif operation == "generate_answer":
            return "query" in request
        elif operation in ["get_document", "delete_document"]:
            return "doc_id" in request
        elif operation in ["get_stats", "health_check"]:
            return True
        else:
            return False
    
    def get_capabilities(self) -> Dict[str, Any]:
        """
        ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½æƒ…å ±å–å¾—
        
        Returns:
            æ©Ÿèƒ½æƒ…å ±
        """
        return {
            "name": "RAGManager",
            "version": "2.0.0",
            "domain": "WISDOM",
            "operations": [
                "add_document",
                "search_documents",
                "generate_answer",
                "get_document",
                "delete_document",
                "get_stats",
                "health_check"
            ],
            "features": [
                "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†",
                "é¡ä¼¼æ€§æ¤œç´¢",
                "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢",
                "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢",
                "å›ç­”ç”Ÿæˆ",
                "Elder Legacyæº–æ‹ "
            ],
            "document_types": [dt.value for dt in DocumentType],
            "strategies": [rs.value for rs in RetrievalStrategy],
            "db_path": str(self.db_path),
            "config": self.config
        }
    
    def _initialize_database_sync(self) -> None:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ï¼ˆåŒæœŸç‰ˆï¼‰"""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS documents (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    doc_type TEXT NOT NULL,
                    metadata TEXT,
                    content_hash TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS keyword_index (
                    keyword TEXT,
                    doc_id TEXT,
                    frequency INTEGER DEFAULT 1,
                    PRIMARY KEY (keyword, doc_id),
                    FOREIGN KEY (doc_id) REFERENCES documents (id)
                )
            """)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_documents_type 
                ON documents(doc_type)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_documents_hash 
                ON documents(content_hash)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_keyword_frequency 
                ON keyword_index(frequency DESC)
            """)
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"RAG database initialized: {self.db_path}")
            
        except Exception as e:
            self.logger.error(f"Database initialization failed: {e}")
            raise
    
    def _extract_keywords(self, text: str) -> List[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        
        Args:
            text: å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        # ç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å½¢æ…‹ç´ è§£æç­‰ã‚’ä½¿ç”¨ï¼‰
        import re
        words = re.findall(r'\b\w+\b', text.lower())
        
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»
        stop_words = {
            'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 
            'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'a', 'an', 'this', 'that', 'these', 'those', 'ã§', 'ã¯', 'ãŒ', 
            'ã‚’', 'ã«', 'ã®', 'ã¨', 'ã‚‚', 'ã‹ã‚‰', 'ã¾ã§', 'ã§ã™', 'ã§ã‚ã‚‹'
        }
        
        keywords = [word for word in words if len(word) > 2 and word not in stop_words]
        
        # é »åº¦è¨ˆç®—
        from collections import Counter
        counter = Counter(keywords)
        
        # é »åº¦ä¸Šä½ã‚’è¿”ã™
        return [word for word, freq in counter.most_common(20)]
    
    def _calculate_content_hash(self, content: str) -> str:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        
        Args:
            content: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            
        Returns:
            ãƒãƒƒã‚·ãƒ¥å€¤
        """
        return hashlib.sha256(content.encode('utf-8')).hexdigest()
    
    async def _add_document(self, content: str, doc_type: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ 
        
        Args:
            content: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹
            doc_type: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            è¿½åŠ çµæœ
        """
        try:
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDç”Ÿæˆ
            doc_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(content.encode()).hexdigest()[:8]}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
            content_hash = self._calculate_content_hash(content)
            
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            cursor.execute("SELECT id FROM documents WHERE content_hash = ?", (content_hash,))
            existing = cursor.fetchone()
            
            if existing:
                conn.close()
                return {
                    "status": "warning",
                    "message": "Document with same content already exists",
                    "existing_id": existing[0],
                    "doc_id": doc_id
                }
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜
            cursor.execute("""
                INSERT INTO documents (id, content, doc_type, metadata, content_hash)
                VALUES (?, ?, ?, ?, ?)
            """, (doc_id, content, doc_type, json.dumps(metadata), content_hash))
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ»ä¿å­˜
            keywords = self._extract_keywords(content)
            for keyword in keywords:
                cursor.execute("""
                    INSERT OR REPLACE INTO keyword_index (keyword, doc_id, frequency)
                    VALUES (?, ?, COALESCE((SELECT frequency FROM keyword_index WHERE keyword = ? AND doc_id = ?), 0) + 1)
                """, (keyword, doc_id, keyword, doc_id))
            
            conn.commit()
            conn.close()
            
            # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
            doc = Document(
                id=doc_id,
                content=content,
                doc_type=DocumentType(doc_type),
                metadata=metadata
            )
            self.document_index[doc_id] = doc
            
            for keyword in keywords:
                if keyword not in self.keyword_index:
                    self.keyword_index[keyword] = set()
                self.keyword_index[keyword].add(doc_id)
            
            return {
                "status": "success",
                "message": "Document added successfully",
                "doc_id": doc_id,
                "keywords_count": len(keywords)
            }
            
        except Exception as e:
            self.logger.error(f"Error adding document: {e}")
            return {
                "status": "error",
                "message": str(e),
                "doc_id": None
            }
    
    async def _search_documents(self, query: str, strategy: str, limit: int) -> Dict[str, Any]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            limit: çµæœæ•°ä¸Šé™
            
        Returns:
            æ¤œç´¢çµæœ
        """
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            results = []
            
            if strategy == "keyword":
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
                query_keywords = self._extract_keywords(query)
                
                for keyword in query_keywords:
                    cursor.execute("""
                        SELECT d.id, d.content, d.doc_type, d.metadata, k.frequency
                        FROM documents d
                        JOIN keyword_index k ON d.id = k.doc_id
                        WHERE k.keyword LIKE ?
                        ORDER BY k.frequency DESC
                        LIMIT ?
                    """, (f"%{keyword}%", limit))
                    
                    for row in cursor.fetchall():
                        doc = Document(
                            id=row[0],
                            content=row[1],
                            doc_type=DocumentType(row[2]),
                            metadata=json.loads(row[3] or "{}")
                        )
                        score = row[4] / 10.0  # æ­£è¦åŒ–
                        results.append(RetrievalResult(doc, score, "keyword_match"))
            
            elif strategy == "similarity":
                # é¡ä¼¼æ€§æ¤œç´¢ï¼ˆç°¡æ˜“ç‰ˆ - å®Ÿéš›ã®å®Ÿè£…ã§ã¯ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã‚’ä½¿ç”¨ï¼‰
                cursor.execute("""
                    SELECT id, content, doc_type, metadata
                    FROM documents
                    WHERE content LIKE ?
                    ORDER BY LENGTH(content) ASC
                    LIMIT ?
                """, (f"%{query}%", limit))
                
                for row in cursor.fetchall():
                    doc = Document(
                        id=row[0],
                        content=row[1],
                        doc_type=DocumentType(row[2]),
                        metadata=json.loads(row[3] or "{}")
                    )
                    # ç°¡æ˜“é¡ä¼¼åº¦è¨ˆç®—
                    similarity = min(0.9, len(set(query.lower().split()) & set(doc.content.lower().split())) / len(query.split()))
                    results.append(RetrievalResult(doc, similarity, "content_similarity"))
            
            else:  # hybrid
                # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
                keyword_results = await self._search_documents(query, "keyword", limit // 2)
                similarity_results = await self._search_documents(query, "similarity", limit // 2)
                
                results = keyword_results["results"] + similarity_results["results"]
            
            conn.close()
            
            # é‡è¤‡é™¤å»ã¨ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
            unique_results = {}
            for result in results:
                if isinstance(result, dict):
                    doc_id = result["document"]["id"]
                    if doc_id not in unique_results or result["score"] > unique_results[doc_id]["score"]:
                        unique_results[doc_id] = result
                else:
                    doc_id = result.document.id
                    if doc_id not in unique_results or result.score > unique_results[doc_id].score:
                        unique_results[doc_id] = result
            
            final_results = list(unique_results.values())
            final_results.sort(key=lambda x: x.score if hasattr(x, 'score') else x["score"], reverse=True)
            final_results = final_results[:limit]
            
            # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            formatted_results = []
            for result in final_results:
                if hasattr(result, 'document'):
                    formatted_results.append({
                        "document": {
                            "id": result.document.id,
                            "content": result.document.content[:500] + "..." if len(result.document.content) > 500 else result.document.content,
                            "doc_type": result.document.doc_type.value,
                            "metadata": result.document.metadata
                        },
                        "score": result.score,
                        "relevance": result.relevance
                    })
                else:
                    formatted_results.append(result)
            
            return {
                "status": "success",
                "query": query,
                "strategy": strategy,
                "results": formatted_results,
                "count": len(formatted_results)
            }
            
        except Exception as e:
            self.logger.error(f"Error searching documents: {e}")
            return {
                "status": "error",
                "message": str(e),
                "query": query,
                "results": []
            }
    
    async def _generate_answer(self, query: str, context: List[str]) -> Dict[str, Any]:
        """
        å›ç­”ç”Ÿæˆ
        
        Args:
            query: è³ªå•
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå›ç­”
        """
        try:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆã¯æ¤œç´¢
            if not context:
                search_result = await self._search_documents(query, "hybrid", 3)
                if search_result["status"] == "success":
                    context = [result["document"]["content"] for result in search_result["results"]]
            
            # ç°¡æ˜“å›ç­”ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯LLMã‚’ä½¿ç”¨ï¼‰
            if context:
                answer = f"Based on the available information: {' '.join(context[:500])}"
                confidence = 0.8
            else:
                answer = "I don't have enough information to answer this question accurately."
                confidence = 0.2
            
            return {
                "status": "success",
                "query": query,
                "answer": answer,
                "confidence": confidence,
                "sources_count": len(context),
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error generating answer: {e}")
            return {
                "status": "error",
                "message": str(e),
                "query": query
            }
    
    async def _get_document(self, doc_id: str) -> Dict[str, Any]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—
        
        Args:
            doc_id: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            
        Returns:
            ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±
        """
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT id, content, doc_type, metadata, created_at, updated_at
                FROM documents WHERE id = ?
            """, (doc_id,))
            
            row = cursor.fetchone()
            conn.close()
            
            if row:
                return {
                    "status": "success",
                    "document": {
                        "id": row[0],
                        "content": row[1],
                        "doc_type": row[2],
                        "metadata": json.loads(row[3] or "{}"),
                        "created_at": row[4],
                        "updated_at": row[5]
                    }
                }
            else:
                return {
                    "status": "not_found",
                    "message": f"Document not found: {doc_id}",
                    "doc_id": doc_id
                }
                
        except Exception as e:
            self.logger.error(f"Error getting document: {e}")
            return {
                "status": "error",
                "message": str(e),
                "doc_id": doc_id
            }
    
    async def _delete_document(self, doc_id: str) -> Dict[str, Any]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤
        
        Args:
            doc_id: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            
        Returns:
            å‰Šé™¤çµæœ
        """
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # å­˜åœ¨ç¢ºèª
            cursor.execute("SELECT id FROM documents WHERE id = ?", (doc_id,))
            if not cursor.fetchone():
                conn.close()
                return {
                    "status": "not_found",
                    "message": f"Document not found: {doc_id}",
                    "doc_id": doc_id
                }
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
            cursor.execute("DELETE FROM keyword_index WHERE doc_id = ?", (doc_id,))
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤
            cursor.execute("DELETE FROM documents WHERE id = ?", (doc_id,))
            
            conn.commit()
            conn.close()
            
            # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
            if doc_id in self.document_index:
                del self.document_index[doc_id]
            
            for keyword_set in self.keyword_index.values():
                keyword_set.discard(doc_id)
            
            return {
                "status": "success",
                "message": f"Document deleted successfully",
                "doc_id": doc_id
            }
            
        except Exception as e:
            self.logger.error(f"Error deleting document: {e}")
            return {
                "status": "error",
                "message": str(e),
                "doc_id": doc_id
            }
    
    async def _get_stats(self) -> Dict[str, Any]:
        """
        çµ±è¨ˆæƒ…å ±å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±
        """
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
            cursor.execute("SELECT COUNT(*) FROM documents")
            total_docs = cursor.fetchone()[0]
            
            # ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
            cursor.execute("SELECT doc_type, COUNT(*) FROM documents GROUP BY doc_type")
            type_counts = dict(cursor.fetchall())
            
            # ç·ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°
            cursor.execute("SELECT COUNT(DISTINCT keyword) FROM keyword_index")
            total_keywords = cursor.fetchone()[0]
            
            # æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            cursor.execute("""
                SELECT id, doc_type, created_at FROM documents 
                ORDER BY created_at DESC LIMIT 5
            """)
            recent_docs = cursor.fetchall()
            
            conn.close()
            
            return {
                "status": "success",
                "stats": {
                    "total_documents": total_docs,
                    "total_keywords": total_keywords,
                    "type_distribution": type_counts,
                    "recent_documents": [
                        {"id": row[0], "type": row[1], "created_at": row[2]}
                        for row in recent_docs
                    ]
                }
            }
            
        except Exception as e:
            self.logger.error(f"Error getting stats: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def _health_check(self) -> Dict[str, Any]:
        """
        ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        
        Returns:
            ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM documents")
            doc_count = cursor.fetchone()[0]
            conn.close()
            
            return {
                "status": "healthy",
                "database": "connected",
                "document_count": doc_count,
                "index_size": len(self.document_index),
                "keyword_index_size": len(self.keyword_index),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }


# Convenience function for quick access
async def create_rag_manager(db_path: str = "data/rag_knowledge.db", config: Optional[Dict[str, Any]] = None) -> RAGManager:
    """
    RAGç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ
    
    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        config: è¨­å®šè¾æ›¸
        
    Returns:
        RAGManagerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return RAGManager(db_path, config)


if __name__ == "__main__":
    async def test_rag_manager():
        """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        rag = RAGManager("test_rag.db")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ãƒ†ã‚¹ãƒˆ
        result = await rag.process_request({
            "operation": "add_document",
            "content": "This is a test document about Python programming.",
            "doc_type": "documentation",
            "metadata": {"author": "test", "tags": ["python", "programming"]}
        })
        print("Add document:", result)
        
        # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        result = await rag.process_request({
            "operation": "search_documents",
            "query": "Python programming",
            "strategy": "hybrid",
            "limit": 3
        })
        print("Search results:", result)
        
        # çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ
        result = await rag.process_request({
            "operation": "get_stats"
        })
        print("Stats:", result)
    
    asyncio.run(test_rag_manager())