"""
Rate Limit Queue Processor
åˆ¶é™æ¤œçŸ¥æ™‚ã®è‡ªå‹•ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°å‡¦ç†ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼çµ±åˆ
"""

import json
import time
import logging
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from anthropic import RateLimitError, APIError
import pika

from .priority_queue_manager import PriorityQueueManager, TaskPriority, TaskStatus
from .claude_client_with_rotation import ClaudeClientWithRotation

class RateLimitQueueProcessor:
    """
    ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ™‚ã®è‡ªå‹•ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°å‡¦ç†å™¨
    """
    
    def __init__(self, config_path: str = None):
        self.logger = logging.getLogger(__name__)
        self.config_path = config_path
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.queue_manager = PriorityQueueManager(config_path)
        self.claude_client = ClaudeClientWithRotation(config_path)
        
        # å‡¦ç†çŠ¶æ…‹ç®¡ç†
        self.processing = False
        self.processor_thread = None
        self.rate_limited = False
        self.last_successful_request = datetime.now()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'queued_tasks': 0,
            'processed_tasks': 0,
            'rate_limited_tasks': 0,
            'failed_tasks': 0,
            'queue_processing_start': None,
            'last_rate_limit': None,
            'recovery_time': None
        }
        
        # RabbitMQè¨­å®š
        self.connection = None
        self.channel = None
        self._setup_rabbitmq()
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.on_task_completed: Optional[Callable] = None
        self.on_rate_limit_detected: Optional[Callable] = None
        self.on_queue_recovery: Optional[Callable] = None
    
    def _setup_rabbitmq(self):
        """RabbitMQæ¥ç¶šã¨ã‚­ãƒ¥ãƒ¼è¨­å®š"""
        try:
            self.connection = pika.BlockingConnection(
                pika.ConnectionParameters('localhost')
            )
            self.channel = self.connection.channel()
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™é–¢é€£ã‚­ãƒ¥ãƒ¼ã‚’å®£è¨€
            self.channel.queue_declare(queue='rate_limited_queue', durable=True)
            self.channel.queue_declare(queue='priority_processing_queue', durable=True)
            
            self.logger.info("Rate Limit Queue Processor - RabbitMQæ¥ç¶šæˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"RabbitMQæ¥ç¶šå¤±æ•—: {e}")
    
    def start_processing(self):
        """ã‚­ãƒ¥ãƒ¼å‡¦ç†é–‹å§‹"""
        if self.processing:
            self.logger.warning("Already processing queues")
            return
        
        self.processing = True
        self.stats['queue_processing_start'] = datetime.now()
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†é–‹å§‹
        self.queue_manager.start_background_processing()
        
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.processor_thread = threading.Thread(target=self._process_queue_worker, daemon=True)
        self.processor_thread.start()
        
        self.logger.info("ğŸš€ Rate Limit Queue Processing é–‹å§‹")
    
    def stop_processing(self):
        """ã‚­ãƒ¥ãƒ¼å‡¦ç†åœæ­¢"""
        self.processing = False
        
        if self.processor_thread:
            self.processor_thread.join(timeout=10)
        
        self.queue_manager.stop_background_processing()
        
        self.logger.info("ğŸ›‘ Rate Limit Queue Processing åœæ­¢")
    
    def process_task_with_fallback(self, 
                                 task_id: str,
                                 prompt: str,
                                 priority: int = TaskPriority.NORMAL.value,
                                 task_type: str = "general",
                                 max_immediate_retries: int = 2) -> Dict[str, Any]:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãã‚¿ã‚¹ã‚¯å‡¦ç†
        åˆ¶é™æ™‚ã¯è‡ªå‹•çš„ã«ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        """
        
        # å³åº§ã«å‡¦ç†ã‚’è©¦è¡Œ
        for attempt in range(max_immediate_retries + 1):
            try:
                self.logger.info(f"ğŸ”„ Taskå‡¦ç†è©¦è¡Œ {attempt + 1}/{max_immediate_retries + 1}: {task_id}")
                
                messages = [{"role": "user", "content": prompt}]
                
                response = self.claude_client.create_message(
                    messages=messages,
                    max_tokens=4096,
                    temperature=0.7
                )
                
                # æˆåŠŸæ™‚ã®å‡¦ç†
                self.last_successful_request = datetime.now()
                self.rate_limited = False
                
                if self.stats['last_rate_limit'] and not self.stats['recovery_time']:
                    self.stats['recovery_time'] = datetime.now()
                    self._handle_queue_recovery()
                
                self.stats['processed_tasks'] += 1
                
                return {
                    'success': True,
                    'response': response,
                    'processed_immediately': True,
                    'attempt': attempt + 1,
                    'task_id': task_id
                }\n                \n            except RateLimitError as e:\n                self.logger.warning(f"â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ¤œçŸ¥ (è©¦è¡Œ {attempt + 1}): {task_id}")\n                \n                if attempt < max_immediate_retries:\n                    # çŸ­ã„å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤\n                    wait_time = (2 ** attempt) * 5  # 5, 10, 20ç§’\n                    time.sleep(wait_time)\n                    continue\n                else:\n                    # æœ€çµ‚è©¦è¡Œã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ \n                    return self._handle_rate_limit_fallback(task_id, prompt, priority, task_type, e)\n                    \n            except APIError as e:\n                self.logger.error(f"âŒ API Error: {e}")\n                # API Errorã®å ´åˆã‚‚ã‚­ãƒ¥ãƒ¼ã§å†è©¦è¡Œ\n                return self._handle_rate_limit_fallback(task_id, prompt, priority, task_type, e)\n                \n            except Exception as e:\n                self.logger.error(f"âŒ Unexpected Error: {e}")\n                return {\n                    'success': False,\n                    'error': str(e),\n                    'queued': False,\n                    'task_id': task_id\n                }\n        \n        # ã“ã“ã«ã¯åˆ°é”ã—ãªã„ã¯ãš\n        return {'success': False, 'error': 'Unexpected flow', 'task_id': task_id}\n    \n    def _handle_rate_limit_fallback(self, task_id: str, prompt: str, priority: int, task_type: str, error: Exception) -> Dict[str, Any]:\n        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""\n        \n        self.rate_limited = True\n        self.stats['last_rate_limit'] = datetime.now()\n        self.stats['rate_limited_tasks'] += 1\n        \n        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ\n        if self.on_rate_limit_detected:\n            try:\n                self.on_rate_limit_detected(task_id, error)\n            except Exception as e:\n                self.logger.error(f"Rate limit callback error: {e}")\n        \n        # é«˜å„ªå…ˆåº¦ã§ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ \n        queue_priority = max(1, priority - 1)  # å„ªå…ˆåº¦ã‚’1ã¤ä¸Šã’ã‚‹\n        \n        queued = self.queue_manager.add_task(\n            task_id=task_id,\n            prompt=prompt,\n            priority=queue_priority,\n            task_type=task_type,\n            requester="rate_limit_fallback",\n            metadata={\n                'original_priority': priority,\n                'rate_limit_error': str(error),\n                'fallback_time': datetime.now().isoformat()\n            }\n        )\n        \n        if queued:\n            self.stats['queued_tasks'] += 1\n            self.logger.info(f"ğŸ“¥ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Šã‚­ãƒ¥ãƒ¼ã«è¿½åŠ : {task_id} (å„ªå…ˆåº¦: {queue_priority})")\n        \n        return {\n            'success': False,\n            'queued': queued,\n            'queue_priority': queue_priority,\n            'error': str(error),\n            'estimated_delay': self._estimate_processing_delay(),\n            'task_id': task_id\n        }\n    \n    def _handle_queue_recovery(self):\n        """ã‚­ãƒ¥ãƒ¼å¾©æ—§æ™‚ã®å‡¦ç†"""\n        \n        self.logger.info("ğŸ‰ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‹ã‚‰å¾©æ—§ - ã‚­ãƒ¥ãƒ¼å‡¦ç†å†é–‹")\n        \n        if self.on_queue_recovery:\n            try:\n                self.on_queue_recovery()\n            except Exception as e:\n                self.logger.error(f"Recovery callback error: {e}")\n    \n    def _process_queue_worker(self):\n        """ã‚­ãƒ¥ãƒ¼å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰"""\n        \n        processing_interval = 2  # 2ç§’é–“éš”\n        consecutive_failures = 0\n        max_consecutive_failures = 5\n        \n        while self.processing:\n            try:\n                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä¸­ã¯å‡¦ç†ã‚’æ§ãˆã‚‹\n                if self.rate_limited:\n                    time_since_limit = (datetime.now() - self.stats['last_rate_limit']).total_seconds()\n                    if time_since_limit < 60:  # 1åˆ†é–“ã¯å¾…æ©Ÿ\n                        time.sleep(processing_interval * 2)\n                        continue\n                \n                # æ¬¡ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—\n                task = self.queue_manager.get_next_task()\n                \n                if task is None:\n                    time.sleep(processing_interval)\n                    continue\n                \n                self.logger.info(f"ğŸ“‹ ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã‚¿ã‚¹ã‚¯å‡¦ç†é–‹å§‹: {task.task_id}")\n                \n                # ã‚¿ã‚¹ã‚¯å‡¦ç†å®Ÿè¡Œ\n                success = self._process_queued_task(task)\n                \n                if success:\n                    consecutive_failures = 0\n                    self.queue_manager.mark_task_completed(task.task_id, True)\n                    \n                    # æˆåŠŸæ™‚ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯\n                    if self.on_task_completed:\n                        try:\n                            self.on_task_completed(task)\n                        except Exception as e:\n                            self.logger.error(f"Task completion callback error: {e}")\n                else:\n                    consecutive_failures += 1\n                    \n                    if consecutive_failures >= max_consecutive_failures:\n                        self.logger.error(f"é€£ç¶šå¤±æ•—ä¸Šé™åˆ°é” ({max_consecutive_failures}) - å‡¦ç†ä¸€æ™‚åœæ­¢")\n                        time.sleep(300)  # 5åˆ†é–“å¾…æ©Ÿ\n                        consecutive_failures = 0\n                \n                time.sleep(processing_interval)\n                \n            except Exception as e:\n                self.logger.error(f"Queue worker error: {e}")\n                time.sleep(processing_interval * 2)\n    \n    def _process_queued_task(self, task) -> bool:\n        """ã‚­ãƒ¥ãƒ¼ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®å‡¦ç†"""\n        \n        try:\n            messages = [{"role": "user", "content": task.prompt}]\n            \n            response = self.claude_client.create_message(\n                messages=messages,\n                max_tokens=4096,\n                temperature=0.7\n            )\n            \n            # æˆåŠŸæ™‚ã®å‡¦ç†\n            self.last_successful_request = datetime.now()\n            self.rate_limited = False\n            self.stats['processed_tasks'] += 1\n            \n            self.logger.info(f"âœ… ã‚­ãƒ¥ãƒ¼ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯å‡¦ç†å®Œäº†: {task.task_id}")\n            \n            # çµæœã‚’RabbitMQã«é€ä¿¡\n            self._send_task_result(task, response, True)\n            \n            return True\n            \n        except RateLimitError as e:\n            self.logger.warning(f"â³ ã‚­ãƒ¥ãƒ¼å‡¦ç†ä¸­ã‚‚ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {task.task_id}")\n            self.queue_manager.mark_task_rate_limited(task.task_id)\n            self.rate_limited = True\n            self.stats['last_rate_limit'] = datetime.now()\n            return False\n            \n        except Exception as e:\n            self.logger.error(f"âŒ ã‚­ãƒ¥ãƒ¼ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯å‡¦ç†å¤±æ•—: {task.task_id} - {e}")\n            self.queue_manager.mark_task_completed(task.task_id, False)\n            self.stats['failed_tasks'] += 1\n            return False\n    \n    def _send_task_result(self, task, response, success: bool):\n        """ã‚¿ã‚¹ã‚¯çµæœã‚’RabbitMQã«é€ä¿¡"""\n        \n        if not self.channel:\n            return\n        \n        try:\n            result_data = {\n                "task_id": task.task_id,\n                "worker": "rate_limit_queue_processor",\n                "status": "completed" if success else "failed",\n                "response": response.get('content', '') if success else '',\n                "queued_processing": True,\n                "priority": task.priority,\n                "queue_wait_time": (datetime.now() - task.created_at).total_seconds(),\n                "metadata": task.metadata,\n                "timestamp": datetime.now().isoformat()\n            }\n            \n            self.channel.basic_publish(\n                exchange='',\n                routing_key='ai_results',\n                body=json.dumps(result_data),\n                properties=pika.BasicProperties(delivery_mode=2)\n            )\n            \n        except Exception as e:\n            self.logger.error(f"Result publication failed: {e}")\n    \n    def _estimate_processing_delay(self) -> int:\n        """å‡¦ç†é…å»¶ã®æ¨å®šï¼ˆç§’ï¼‰"""\n        \n        queue_size = self.queue_manager.get_queue_size()\n        avg_processing_time = 30  # å¹³å‡30ç§’ã¨ä»®å®š\n        \n        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ãŸæ¨å®š\n        if self.rate_limited:\n            base_delay = 300  # 5åˆ†ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³\n        else:\n            base_delay = 0\n        \n        return base_delay + (queue_size * avg_processing_time)\n    \n    def get_status(self) -> Dict[str, Any]:\n        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""\n        \n        queue_status = self.queue_manager.get_queue_status()\n        \n        return {\n            'processing': self.processing,\n            'rate_limited': self.rate_limited,\n            'last_successful_request': self.last_successful_request.isoformat(),\n            'estimated_delay_seconds': self._estimate_processing_delay(),\n            'statistics': self.stats.copy(),\n            'queue_status': queue_status,\n            'claude_client_stats': self.claude_client.get_client_stats()\n        }\n    \n    def force_queue_processing(self):\n        """å¼·åˆ¶çš„ã«ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚’é–‹å§‹ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""\n        \n        self.rate_limited = False\n        self.logger.info("ğŸ”§ å¼·åˆ¶ã‚­ãƒ¥ãƒ¼å‡¦ç†é–‹å§‹")\n    \n    def clear_rate_limit_state(self):\n        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢"""\n        \n        self.rate_limited = False\n        self.stats['recovery_time'] = datetime.now()\n        self.logger.info("ğŸ”„ ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ")\n    \n    def close(self):\n        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""\n        \n        self.stop_processing()\n        self.queue_manager.close()\n        \n        if self.connection and not self.connection.is_closed:\n            self.connection.close()\n        \n        self.logger.info("Rate Limit Queue Processor çµ‚äº†")