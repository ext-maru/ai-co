#!/usr/bin/env python3
"""
Scaling Policy - ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ¤æ–­ãƒ­ã‚¸ãƒƒã‚¯
"""
import logging
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger("ScalingPolicy")


class ScalingPolicy:
    def __init__(self, config_file=None):
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã®åˆæœŸåŒ–"""
        if config_file is None:
            config_file = Path(__file__).parent.parent / "config" / "scaling.conf"
        self.config = self._load_config(config_file)
        self.last_scaling_time = None
        self.scaling_history = []

    def _load_config(self, config_file):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        config = {
            "MIN_WORKERS": 1,
            "MAX_WORKERS": 5,
            "SCALE_UP_QUEUE_LENGTH": 5,
            "SCALE_DOWN_QUEUE_LENGTH": 1,
            "COOLDOWN_SECONDS": 60,
            "MAX_CPU_PERCENT": 80,
            "MAX_MEMORY_PERCENT": 80,
        }

        try:
            with open(config_file, "r") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#") and "=" in line:
                        key, value = line.split("=", 1)
                        try:
                            config[key] = int(value)
                        except ValueError:
                            config[key] = value
        except Exception as e:
            logger.error(f"è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        return config

    def should_scale(self, metrics):
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå¿…è¦ã‹åˆ¤æ–­"""
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ãƒã‚§ãƒƒã‚¯
        if self.last_scaling_time:
            elapsed = (datetime.now() - self.last_scaling_time).seconds
            if elapsed < self.config["COOLDOWN_SECONDS"]:
                logger.info(
                    f"â³ ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­: ã‚ã¨{self.config['COOLDOWN_SECONDS'] - elapsed}ç§’"
                )
                return "none", None

        current_workers = metrics["active_workers"]
        queue_length = metrics["queue_length"]
        cpu_percent = metrics["system"]["cpu_percent"]
        memory_percent = metrics["system"]["memory_percent"]

        # ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—åˆ¤å®š
        if self._should_scale_up(
            current_workers, queue_length, cpu_percent, memory_percent
        ):
            target = min(current_workers + 1, self.config["MAX_WORKERS"])
            if target > current_workers:
                return "up", target

        # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³åˆ¤å®š
        if self._should_scale_down(
            current_workers, queue_length, cpu_percent, memory_percent
        ):
            target = max(current_workers - 1, self.config["MIN_WORKERS"])
            if target < current_workers:
                return "down", target

        return "none", None

    def _should_scale_up(self, workers, queue_length, cpu, memory):
        """ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯"""
        # æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã«é”ã—ã¦ã„ã‚‹å ´åˆ
        if workers >= self.config["MAX_WORKERS"]:
            return False

        # ã‚­ãƒ¥ãƒ¼ãŒæºœã¾ã£ã¦ã„ã‚‹å ´åˆ
        if queue_length > self.config["SCALE_UP_QUEUE_LENGTH"]:
            logger.info(
                f"ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ¡ä»¶: ã‚­ãƒ¥ãƒ¼é•· {queue_length} > {self.config['SCALE_UP_QUEUE_LENGTH']}"
            )
            return True

        # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã«å¯¾ã—ã¦ã‚­ãƒ¥ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆ
        if workers > 0 and queue_length > workers * 3:
            logger.info(
                f"ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ¡ä»¶: ã‚­ãƒ¥ãƒ¼/ãƒ¯ãƒ¼ã‚«ãƒ¼æ¯” {queue_length}/{workers} > 3"
            )
            return True

        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã«ä½™è£•ãŒã‚ã‚‹å ´åˆã§ã‚­ãƒ¥ãƒ¼ãŒã‚ã‚‹
        if queue_length > 0 and cpu < 50 and memory < 50:
            logger.info(
                f"ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ¡ä»¶: ãƒªã‚½ãƒ¼ã‚¹ä½™è£•ã‚ã‚Š (CPU:{cpu}%, Mem:{memory}%)"
            )
            return True

        return False

    def _should_scale_down(self, workers, queue_length, cpu, memory):
        """ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯"""
        # æœ€å°ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®å ´åˆ
        if workers <= self.config["MIN_WORKERS"]:
            return False

        # ã‚­ãƒ¥ãƒ¼ãŒå°‘ãªã„å ´åˆ
        if queue_length <= self.config["SCALE_DOWN_QUEUE_LENGTH"]:
            # è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã‚­ãƒ¥ãƒ¼ãŒã»ã¼ãªã„å ´åˆ
            if workers > 2 and queue_length == 0:
                logger.info(f"ğŸ“‰ ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ¡ä»¶: ã‚­ãƒ¥ãƒ¼ãªã—ã€ãƒ¯ãƒ¼ã‚«ãƒ¼éå‰°")
                return True
            # æœ€å°é™ã‚’è¶…ãˆã¦ã„ã¦ã‚­ãƒ¥ãƒ¼ãŒé–¾å€¤ä»¥ä¸‹
            elif workers > self.config["MIN_WORKERS"]:
                logger.info(
                    f"ğŸ“‰ ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ¡ä»¶: ã‚­ãƒ¥ãƒ¼é•· {queue_length} <= {self.config['SCALE_DOWN_QUEUE_LENGTH']}"
                )
                return True

        return False

    def record_scaling(self, action, from_workers, to_workers):
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿè¡Œã‚’è¨˜éŒ²"""
        self.last_scaling_time = datetime.now()
        self.scaling_history.append(
            {
                "timestamp": self.last_scaling_time,
                "action": action,
                "from": from_workers,
                "to": to_workers,
            }
        )

        # å±¥æ­´ã¯æœ€æ–°100ä»¶ã¾ã§ä¿æŒ
        if len(self.scaling_history) > 100:
            self.scaling_history = self.scaling_history[-100:]

    def get_scaling_stats(self):
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆã‚’å–å¾—"""
        if not self.scaling_history:
            return {
                "total_scaling": 0,
                "scale_ups": 0,
                "scale_downs": 0,
                "last_scaling": None,
            }

        scale_ups = sum(1 for h in self.scaling_history if h["action"] == "up")
        scale_downs = sum(1 for h in self.scaling_history if h["action"] == "down")

        return {
            "total_scaling": len(self.scaling_history),
            "scale_ups": scale_ups,
            "scale_downs": scale_downs,
            "last_scaling": (
                self.scaling_history[-1]["timestamp"].isoformat()
                if self.scaling_history
                else None
            ),
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    logging.basicConfig(level=logging.INFO)
    policy = ScalingPolicy()

    # ãƒ†ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
    test_metrics = {
        "active_workers": 2,
        "queue_length": 10,
        "system": {"cpu_percent": 30, "memory_percent": 40},
    }

    action, target = policy.should_scale(test_metrics)
    print(f"ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ¤å®š: {action}, ç›®æ¨™ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {target}")
