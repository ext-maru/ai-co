#!/usr/bin/env python3
"""
Worker Health Monitor - é©åˆ‡ãªå®Ÿè£…
Elder Councilæ‰¿èªæ¸ˆã¿è¨­è¨ˆã«åŸºã¥ãå®Œå…¨ãªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

çµ±åˆç›£è¦–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¸€éƒ¨ã¨ã—ã¦å®Ÿè£…
Phase 2: è»½é‡å®Ÿè£…ï¼ˆå³åº§ã«å‹•ä½œã™ã‚‹æœ€å°é™ã®æ©Ÿèƒ½ï¼‰
"""

import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import time
import psutil
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from collections import defaultdict, deque
import threading
import json

logger = logging.getLogger(__name__)

class MetricsCollector:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨"""
    
    def __init__(self):
        self.metrics_history = deque(maxlen=1000)
        self._lock = threading.RLock()
    
    def collect_system_metrics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†"""
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            return {
                'timestamp': datetime.now().isoformat(),
                'cpu': {
                    'percent': cpu_percent,
                    'count': psutil.cpu_count()
                },
                'memory': {
                    'percent': memory.percent,
                    'available': memory.available,
                    'total': memory.total
                },
                'disk': {
                    'percent': disk.percent,
                    'free': disk.free,
                    'total': disk.total
                }
            }
        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")
            return {}
    
    def collect_process_metrics(self, pattern: str = "worker") -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†"""
        processes = {}
        try:
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_info']):
                if pattern in proc.info['name']:
                    processes[proc.info['pid']] = {
                        'name': proc.info['name'],
                        'cpu_percent': proc.info['cpu_percent'],
                        'memory_mb': proc.info['memory_info'].rss / 1024 / 1024
                    }
        except Exception as e:
            logger.error(f"Failed to collect process metrics: {e}")
        
        return processes

class HealthChecker:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚«ãƒ¼"""
    
    def __init__(self):
        self.health_thresholds = {
            'cpu_critical': 90,
            'cpu_warning': 70,
            'memory_critical': 90,
            'memory_warning': 80,
            'disk_critical': 95,
            'disk_warning': 85
        }
    
    def check_system_health(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã®ãƒã‚§ãƒƒã‚¯"""
        health_status = {
            'overall': 'healthy',
            'issues': [],
            'warnings': []
        }
        
        # CPU ãƒã‚§ãƒƒã‚¯
        cpu_percent = metrics.get('cpu', {}).get('percent', 0)
        if cpu_percent > self.health_thresholds['cpu_critical']:
            health_status['overall'] = 'critical'
            health_status['issues'].append(f"CPU usage critical: {cpu_percent}%")
        elif cpu_percent > self.health_thresholds['cpu_warning']:
            health_status['warnings'].append(f"CPU usage high: {cpu_percent}%")
        
        # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
        memory_percent = metrics.get('memory', {}).get('percent', 0)
        if memory_percent > self.health_thresholds['memory_critical']:
            health_status['overall'] = 'critical'
            health_status['issues'].append(f"Memory usage critical: {memory_percent}%")
        elif memory_percent > self.health_thresholds['memory_warning']:
            health_status['warnings'].append(f"Memory usage high: {memory_percent}%")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
        disk_percent = metrics.get('disk', {}).get('percent', 0)
        if disk_percent > self.health_thresholds['disk_critical']:
            health_status['overall'] = 'critical'
            health_status['issues'].append(f"Disk usage critical: {disk_percent}%")
        elif disk_percent > self.health_thresholds['disk_warning']:
            health_status['warnings'].append(f"Disk usage high: {disk_percent}%")
        
        if health_status['warnings'] and health_status['overall'] == 'healthy':
            health_status['overall'] = 'warning'
        
        return health_status

class ScalingEngine:
    """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆè»½é‡ç‰ˆï¼‰"""
    
    def __init__(self):
        self.scaling_rules = {
            'cpu_scale_up': 80,
            'cpu_scale_down': 30,
            'queue_length_scale_up': 100,
            'queue_length_scale_down': 10
        }
    
    def analyze(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æï¼ˆç¾æ™‚ç‚¹ã§ã¯æ¨å¥¨ã®ã¿ã€å®Ÿè¡Œã¯ã—ãªã„ï¼‰"""
        recommendations = {}
        
        # CPU ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        system_load = metrics.get('system_load', 0)
        if system_load > self.scaling_rules['cpu_scale_up'] / 100:
            recommendations['system'] = {
                'action': 'scale_up',
                'reason': f'High system load: {system_load * 100:.1f}%',
                'priority': 'medium'
            }
        elif system_load < self.scaling_rules['cpu_scale_down'] / 100:
            recommendations['system'] = {
                'action': 'scale_down',
                'reason': f'Low system load: {system_load * 100:.1f}%',
                'priority': 'low'
            }
        
        # ã‚­ãƒ¥ãƒ¼ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        queue_lengths = metrics.get('queue_lengths', {})
        for queue_name, length in queue_lengths.items():
            if length > self.scaling_rules['queue_length_scale_up']:
                recommendations[queue_name] = {
                    'action': 'scale_up',
                    'reason': f'Queue length high: {length}',
                    'priority': 'high'
                }
            elif length < self.scaling_rules['queue_length_scale_down']:
                recommendations[queue_name] = {
                    'action': 'scale_down',
                    'reason': f'Queue length low: {length}',
                    'priority': 'low'
                }
        
        return recommendations

class WorkerHealthMonitor:
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼æœ¬ä½“"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.health_checker = HealthChecker()
        self.scaling_engine = ScalingEngine()
        self.start_time = datetime.now()
        
        logger.info("WorkerHealthMonitor initialized (proper implementation)")
    
    def collect_comprehensive_metrics(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            system_metrics = self.metrics_collector.collect_system_metrics()
            process_metrics = self.metrics_collector.collect_process_metrics()
            
            # ãƒ¯ãƒ¼ã‚«ãƒ¼æƒ…å ±ã®æ•´å½¢
            workers = {}
            for pid, proc_info in process_metrics.items():
                worker_name = proc_info['name'].replace('.py', '')
                workers[worker_name] = {
                    'pid': pid,
                    'status': 'running',
                    'cpu_percent': proc_info['cpu_percent'],
                    'memory_mb': proc_info['memory_mb'],
                    'health': 'healthy'
                }
            
            # ã‚·ã‚¹ãƒ†ãƒ å¥åº·çŠ¶æ…‹ã‚’è©•ä¾¡
            overall_healthy = all(worker.get('health') == 'healthy' for worker in workers.values())
            system_healthy = system_metrics.get('cpu', {}).get('percent', 0) < 80
            
            return {
                'timestamp': datetime.now().isoformat(),
                'system': system_metrics,
                'workers': workers,
                'system_health': {
                    'overall_healthy': overall_healthy and system_healthy,
                    'system_cpu_ok': system_healthy,
                    'all_workers_healthy': overall_healthy,
                    'healthy_worker_count': sum(1 for w in workers.values() if w.get('health') == 'healthy'),
                    'total_worker_count': len(workers)
                },
                'uptime': str(datetime.now() - self.start_time)
            }
        except Exception as e:
            logger.error(f"Failed to collect comprehensive metrics: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def get_health_status(self) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å–å¾—"""
        metrics = self.collect_comprehensive_metrics()
        system_health = self.health_checker.check_system_health(metrics.get('system', {}))
        
        return {
            'timestamp': datetime.now().isoformat(),
            'system_health': system_health,
            'worker_count': len(metrics.get('workers', {})),
            'metrics': metrics
        }
    
    def get_scaling_recommendations(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¨å¥¨äº‹é …ã®å–å¾—"""
        try:
            return self.scaling_engine.analyze(metrics)
        except Exception as e:
            logger.error(f"Failed to get scaling recommendations: {e}")
            return {}
    
    def restart_unhealthy_workers(self) -> Dict[str, Any]:
        """ä¸å¥å…¨ãªãƒ¯ãƒ¼ã‚«ãƒ¼ã®å†èµ·å‹•"""
        try:
            # ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ã‚’å–å¾—
            metrics = self.collect_comprehensive_metrics()
            workers = metrics.get('workers', {})
            
            restart_results = {}
            restarted_count = 0
            
            for worker_name, worker_info in workers.items():
                # ä¸å¥å…¨ãªãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ç‰¹å®š
                if worker_info.get('health') != 'healthy':
                    try:
                        # å®Ÿéš›ã®å†èµ·å‹•å‡¦ç†ï¼ˆå®‰å…¨ãªå®Ÿè£…ï¼‰
                        pid = worker_info.get('pid')
                        if pid:
                            logger.warning(f"Worker {worker_name} (PID: {pid}) is unhealthy, preparing restart")
                            
                            # å®Ÿéš›ã®å†èµ·å‹•ã¯æ…é‡ã«è¡Œã†ï¼ˆç¾åœ¨ã¯è¨˜éŒ²ã®ã¿ï¼‰
                            restart_results[worker_name] = {
                                'action': 'restart_scheduled',
                                'reason': f"Health status: {worker_info.get('health', 'unknown')}",
                                'pid': pid,
                                'timestamp': datetime.now().isoformat()
                            }
                            restarted_count += 1
                        else:
                            restart_results[worker_name] = {
                                'action': 'restart_failed',
                                'reason': 'No PID available',
                                'timestamp': datetime.now().isoformat()
                            }
                    except Exception as e:
                        restart_results[worker_name] = {
                            'action': 'restart_error',
                            'reason': str(e),
                            'timestamp': datetime.now().isoformat()
                        }
            
            logger.info(f"Worker restart check completed: {restarted_count} workers processed")
            
            return {
                'timestamp': datetime.now().isoformat(),
                'total_workers_checked': len(workers),
                'unhealthy_workers_found': restarted_count,
                'restart_results': restart_results,
                'status': 'completed'
            }
            
        except Exception as e:
            logger.error(f"Failed to restart unhealthy workers: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'status': 'error',
                'error': str(e)
            }
    
    def get_system_status(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å–å¾— (Elder Council Summonerç”¨)"""
        try:
            health_status = self.get_health_status()
            
            # Elder Council Summoner ãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«å¤‰æ›
            return {
                'timestamp': datetime.now().isoformat(),
                'status': health_status['system_health']['overall'],
                'system_metrics': health_status['metrics']['system'],
                'worker_count': health_status['worker_count'],
                'workers': health_status['metrics']['workers'],
                'uptime': health_status['metrics']['uptime'],
                'issues': health_status['system_health']['issues'],
                'warnings': health_status['system_health']['warnings']
            }
        except Exception as e:
            logger.error(f"Failed to get system status: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'status': 'error',
                'error': str(e)
            }
    
    def start_monitoring(self, interval: int = 30):
        """ç›£è¦–ã®é–‹å§‹ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼‰"""
        logger.info("Starting standalone monitoring...")
        
        while True:
            try:
                metrics = self.collect_comprehensive_metrics()
                health = self.get_health_status()
                
                if health['system_health']['overall'] != 'healthy':
                    logger.warning(f"System health issue: {health['system_health']}")
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å±¥æ­´ã«è¿½åŠ 
                self.metrics_collector.metrics_history.append(metrics)
                
                time.sleep(interval)
            except KeyboardInterrupt:
                logger.info("Monitoring stopped by user")
                break
            except Exception as e:
                logger.error(f"Monitoring error: {e}")
                time.sleep(interval)

# äº’æ›æ€§ã®ãŸã‚ã®ã‚¯ãƒ©ã‚¹ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›æ€§ï¼‰
class WorkerPerformanceAnalyzer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨"""
    def __init__(self):
        logger.info("WorkerPerformanceAnalyzer initialized")
        self.bottleneck_thresholds = {
            'queue_length': 100,
            'processing_time': 5000,  # ms
            'error_rate': 0.1,
            'cpu_usage': 80.0,
            'memory_usage': 80.0
        }
    
    def detect_bottlenecks(self, worker_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º"""
        bottlenecks = {}
        
        for worker_name, metrics in worker_metrics.items():
            issues = []
            
            # ã‚­ãƒ¥ãƒ¼é•·ãƒã‚§ãƒƒã‚¯
            queue_length = metrics.get('queue_length', 0)
            if queue_length > self.bottleneck_thresholds['queue_length']:
                issues.append({
                    'type': 'queue_overload',
                    'severity': 'high' if queue_length > self.bottleneck_thresholds['queue_length'] * 2 else 'medium',
                    'details': f'Queue length: {queue_length}'
                })
            
            # å‡¦ç†æ™‚é–“ãƒã‚§ãƒƒã‚¯
            processing_time = metrics.get('processing_time', 0)
            if processing_time > self.bottleneck_thresholds['processing_time']:
                issues.append({
                    'type': 'slow_processing',
                    'severity': 'high' if processing_time > self.bottleneck_thresholds['processing_time'] * 2 else 'medium',
                    'details': f'Processing time: {processing_time}ms'
                })
            
            # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯
            error_rate = metrics.get('error_rate', 0)
            if error_rate > self.bottleneck_thresholds['error_rate']:
                issues.append({
                    'type': 'high_error_rate',
                    'severity': 'critical' if error_rate > 0.2 else 'high',
                    'details': f'Error rate: {error_rate:.2%}'
                })
            
            if issues:
                bottlenecks[worker_name] = {
                    'issues': issues,
                    'timestamp': datetime.now().isoformat()
                }
        
        return bottlenecks

class WorkerAutoScaler:
    """è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰"""
    def __init__(self):
        logger.info("WorkerAutoScaler initialized (placeholder)")

# ãƒ‡ãƒ¢ãƒ»ãƒ†ã‚¹ãƒˆé–¢æ•°
def demo_health_monitor():
    """ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸ¥ Worker Health Monitor Demo")
    print("=" * 60)
    
    monitor = WorkerHealthMonitor()
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    metrics = monitor.collect_comprehensive_metrics()
    print("\nğŸ“Š Comprehensive Metrics:")
    print(json.dumps(metrics, indent=2, default=str))
    
    # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    health = monitor.get_health_status()
    print("\nğŸ’— Health Status:")
    print(json.dumps(health, indent=2, default=str))
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¨å¥¨
    test_metrics = {
        'system_load': 0.85,
        'queue_lengths': {
            'task_queue': 150,
            'pm_queue': 5
        }
    }
    recommendations = monitor.get_scaling_recommendations(test_metrics)
    print("\nğŸ“ˆ Scaling Recommendations:")
    print(json.dumps(recommendations, indent=2))
    
    print("\nâœ… Demo completed successfully!")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demo_health_monitor()