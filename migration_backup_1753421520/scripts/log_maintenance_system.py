#!/usr/bin/env python3
"""
Log Maintenance System - ãƒ­ã‚°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ 
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã¨ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

ğŸ§¹ æ©Ÿèƒ½:
- å¤§å®¹é‡ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
- å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•å‰Šé™¤
- ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
- ãƒ­ã‚°çµ±è¨ˆã®ç”Ÿæˆ
"""

import gzip
import json
import logging
import shutil
import sys
from datetime import datetime
from datetime import timedelta
from pathlib import Path
from typing import Dict
from typing import List


class LogMaintenanceSystem:
    """ãƒ­ã‚°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_dir: str = "/home/aicompany/ai_co"):
        self.project_dir = Path(project_dir)
        self.logs_dir = self.project_dir / "logs"
        self.archive_dir = self.logs_dir / "archive"
        self.config_file = self.project_dir / "config" / "log_maintenance.json"

        # è¨­å®š
        self.max_file_size_mb = 10  # MB
        self.max_age_days = 30  # æ—¥
        self.compress_older_than_days = 7  # æ—¥
        self.keep_compressed_days = 60  # æ—¥

        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.archive_dir.mkdir(exist_ok=True)

        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(self.logs_dir / "log_maintenance.log"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def analyze_logs(self) -> Dict:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ"""
        self.logger.info("ğŸ” ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æé–‹å§‹")

        analysis = {
            "total_files": 0,
            "total_size_mb": 0,
            "large_files": [],  # 10MBä»¥ä¸Š
            "old_files": [],  # 30æ—¥ä»¥ä¸Š
            "empty_files": [],  # ç©ºãƒ•ã‚¡ã‚¤ãƒ«
            "by_extension": {},
            "by_date": {},
        }

        for log_file in self.logs_dir.glob("*.log"):
            if not log_file.is_file():
                continue

            stat = log_file.stat()
            size_mb = stat.st_size / (1024 * 1024)
            modified_date = datetime.fromtimestamp(stat.st_mtime)
            age_days = (datetime.now() - modified_date).days

            analysis["total_files"] += 1
            analysis["total_size_mb"] += size_mb

            # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«
            if size_mb > self.max_file_size_mb:
                analysis["large_files"].append(
                    {
                        "file": str(log_file.name),
                        "size_mb": round(size_mb, 2),
                        "age_days": age_days,
                    }
                )

            # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«
            if age_days > self.max_age_days:
                analysis["old_files"].append(
                    {
                        "file": str(log_file.name),
                        "size_mb": round(size_mb, 2),
                        "age_days": age_days,
                    }
                )

            # ç©ºãƒ•ã‚¡ã‚¤ãƒ«
            if stat.st_size == 0:
                analysis["empty_files"].append(str(log_file.name))

            # æ‹¡å¼µå­åˆ¥
            ext = log_file.suffix
            if ext not in analysis["by_extension"]:
                analysis["by_extension"][ext] = {"count": 0, "size_mb": 0}
            analysis["by_extension"][ext]["count"] += 1
            analysis["by_extension"][ext]["size_mb"] += size_mb

            # æ—¥ä»˜åˆ¥
            date_str = modified_date.strftime("%Y-%m-%d")
            if date_str not in analysis["by_date"]:
                analysis["by_date"][date_str] = {"count": 0, "size_mb": 0}
            analysis["by_date"][date_str]["count"] += 1
            analysis["by_date"][date_str]["size_mb"] += size_mb

        analysis["total_size_mb"] = round(analysis["total_size_mb"], 2)

        self.logger.info(
            f"ğŸ“Š åˆ†æå®Œäº†: {analysis['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«, {analysis['total_size_mb']}MB"
        )
        return analysis

    def rotate_large_files(self) -> List[str]:
        """å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        self.logger.info("ğŸ”„ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")

        rotated_files = []

        for log_file in self.logs_dir.glob("*.log"):
            if not log_file.is_file():
                continue

            size_mb = log_file.stat().st_size / (1024 * 1024)

            if size_mb > self.max_file_size_mb:
                self.logger.info(
                    f"ğŸ“¦ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {log_file.name} ({size_mb:0.1f}MB)"
                )

                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                archived_name = f"{log_file.stem}_{timestamp}.log"
                archived_path = self.archive_dir / archived_name

                # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
                shutil.move(str(log_file), str(archived_path))

                # æ–°ã—ã„ç©ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                log_file.touch()

                # åœ§ç¸®
                self._compress_file(archived_path)

                rotated_files.append(str(log_file.name))

        self.logger.info(f"âœ… ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {len(rotated_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return rotated_files

    def compress_old_files(self) -> List[str]:
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®åœ§ç¸®"""
        self.logger.info("ğŸ—œï¸ å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®é–‹å§‹")

        compressed_files = []
        cutoff_date = datetime.now() - timedelta(days=self.compress_older_than_days)

        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æœªåœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«
        for log_file in self.archive_dir.glob("*.log"):
            if not log_file.is_file():
                continue

            modified_date = datetime.fromtimestamp(log_file.stat().st_mtime)

            if modified_date < cutoff_date:
                self.logger.info(f"ğŸ—œï¸ åœ§ç¸®: {log_file.name}")
                self._compress_file(log_file)
                compressed_files.append(str(log_file.name))

        self.logger.info(f"âœ… åœ§ç¸®å®Œäº†: {len(compressed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return compressed_files

    def cleanup_old_files(self) -> List[str]:
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤"""
        self.logger.info("ğŸ—‘ï¸ å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤é–‹å§‹")

        deleted_files = []
        cutoff_date = datetime.now() - timedelta(days=self.keep_compressed_days)

        # å¤ã„åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for gz_file in self.archive_dir.glob("*.gz"):
            if not gz_file.is_file():
                continue

            modified_date = datetime.fromtimestamp(gz_file.stat().st_mtime)

            if modified_date < cutoff_date:
                self.logger.info(f"ğŸ—‘ï¸ å‰Šé™¤: {gz_file.name}")
                gz_file.unlink()
                deleted_files.append(str(gz_file.name))

        # ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        for log_file in self.logs_dir.glob("*.log"):
            if log_file.is_file() and log_file.stat().st_size == 0:
                # æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„å ´åˆã®ã¿å‰Šé™¤
                created_date = datetime.fromtimestamp(log_file.stat().st_mtime)
                if (datetime.now() - created_date).days > 1:
                    self.logger.info(f"ğŸ—‘ï¸ ç©ºãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {log_file.name}")
                    log_file.unlink()
                    deleted_files.append(str(log_file.name))

        self.logger.info(f"âœ… å‰Šé™¤å®Œäº†: {len(deleted_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return deleted_files

    def _compress_file(self, file_path: Path):
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        compressed_path = file_path.with_suffix(file_path.suffix + ".gz")

        with open(file_path, "rb") as f_in:
            with gzip.open(compressed_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)

        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        file_path.unlink()

    def generate_logrotate_config(self):
        """logrotateè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        config_content = f"""# Elders Guild Log Rotation Configuration
{self.logs_dir}/*.log {{
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 0644 aicompany aicompany
    size {self.max_file_size_mb}M

    postrotate
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã«ãƒ­ã‚°å†é–‹ã‚·ã‚°ãƒŠãƒ«é€ä¿¡
        pkill -USR1 -f "python.*worker" 2>/dev/null || true
    endscript
}}

# ç‰¹åˆ¥ãªè¨­å®šãŒå¿…è¦ãªå¤§å®¹é‡ãƒ­ã‚°
{self.logs_dir}/elf_forest.log {{
    hourly
    size 50M
    rotate 48
    compress
    delaycompress
    missingok
    notifempty
    create 0644 aicompany aicompany
}}
"""

        logrotate_config = self.project_dir / "config" / "logrotate.conf"
        logrotate_config.parent.mkdir(exist_ok=True)

        with open(logrotate_config, "w") as f:
            f.write(config_content)

        self.logger.info(f"ğŸ“ logrotateè¨­å®šç”Ÿæˆ: {logrotate_config}")
        return str(logrotate_config)

    def setup_cron_job(self):
        """cronè¨­å®šã®ç”Ÿæˆ"""
        cron_entry = f"""# Elders Guild Log Maintenance
0 2 * * * {sys.executable} {__file__} --maintenance 2>&1 | logger -t log_maintenance
0 */6 * * * {sys.executable} {__file__} --rotate 2>&1 | logger -t log_maintenance
"""

        cron_file = self.project_dir / "config" / "log_maintenance.cron"
        with open(cron_file, "w") as f:
            f.write(cron_entry)

        self.logger.info(f"â° cronè¨­å®šç”Ÿæˆ: {cron_file}")
        self.logger.info("æ‰‹å‹•ã§crontabã«è¿½åŠ ã—ã¦ãã ã•ã„:")
        self.logger.info(f"crontab -e && cat {cron_file}")

        return str(cron_file)

    def run_maintenance(self):
        """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œ"""
        self.logger.info("ğŸ§¹ ãƒ­ã‚°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹")

        # åˆ†æ
        analysis = self.analyze_logs()

        # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œ
        rotated = self.rotate_large_files()
        compressed = self.compress_old_files()
        deleted = self.cleanup_old_files()

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        logrotate_config = self.generate_logrotate_config()
        cron_file = self.setup_cron_job()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            "timestamp": datetime.now().isoformat(),
            "analysis": analysis,
            "actions": {
                "rotated_files": rotated,
                "compressed_files": compressed,
                "deleted_files": deleted,
            },
            "configs": {"logrotate_config": logrotate_config, "cron_file": cron_file},
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = (
            self.logs_dir
            / f"maintenance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_file, "w") as f:
            json.dump(report, f, indent=2)

        self.logger.info(f"ğŸ“Š ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        self.logger.info("âœ… ãƒ­ã‚°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†")

        return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Log Maintenance System")
    parser.add_argument("--analyze", action="store_true", help="ãƒ­ã‚°åˆ†æã®ã¿å®Ÿè¡Œ")
    parser.add_argument("--rotate", action="store_true", help="ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿å®Ÿè¡Œ")
    parser.add_argument(
        "--maintenance", action="store_true", help="ãƒ•ãƒ«ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œ"
    )
    parser.add_argument("--config", action="store_true", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿")

    args = parser.parse_args()

    maintenance = LogMaintenanceSystem()

    if args.analyze:
        analysis = maintenance.analyze_logs()
        print(json.dumps(analysis, indent=2, ensure_ascii=False))
    elif args.rotate:
        rotated = maintenance.rotate_large_files()
        print(f"ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {rotated}")
    elif args.config:
        logrotate_config = maintenance.generate_logrotate_config()
        cron_file = maintenance.setup_cron_job()
        print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {logrotate_config}, {cron_file}")
    elif args.maintenance:
        maintenance.run_maintenance()
        print("ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†")
    else:
        print("ğŸ§¹ Elders Guild Log Maintenance System")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  --analyze     : ãƒ­ã‚°åˆ†æ")
        print("  --rotate      : å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")
        print("  --maintenance : ãƒ•ãƒ«ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹")
        print("  --config      : è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")


if __name__ == "__main__":
    main()
