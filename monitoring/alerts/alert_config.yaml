---
# Elder Tree階層システム アラート設定
# Grand Elder maru統治下の異常検知体制

alert_system:
  name: "Elder Tree Alert System"
  version: "1.0.0"
  enabled: true
  
# アラートレベル定義
alert_levels:
  critical:
    symbol: "🔴"
    priority: 1
    description: "システム停止リスク - 即座の対応が必要"
    notification:
      - slack: immediate
      - email: immediate
      - pager: immediate
    auto_escalate: true
    escalation_time: 300  # 5分
    
  high:
    symbol: "🟠"
    priority: 2
    description: "機能障害発生 - 早急な対応が必要"
    notification:
      - slack: immediate
      - email: immediate
    auto_escalate: true
    escalation_time: 900  # 15分
    
  medium:
    symbol: "🟡"
    priority: 3
    description: "パフォーマンス劣化 - 監視強化が必要"
    notification:
      - slack: batch
      - email: hourly
    auto_escalate: false
    
  low:
    symbol: "🟢"
    priority: 4
    description: "情報通知 - 記録のみ"
    notification:
      - log: only
    auto_escalate: false

# Elder Tree接続異常検知
elder_tree_alerts:
  grand_elder_disconnection:
    level: critical
    condition: "grand_elder.status != 'active' for 30s"
    message: "Grand Elder maru接続断 - システム統治不能"
    actions:
      - notify_all_channels
      - activate_emergency_protocol
      - attempt_auto_recovery
      
  elder_council_quorum_loss:
    level: critical
    condition: "active_council_members < 5"
    message: "Elder Council定足数不足 - 意思決定不能"
    actions:
      - notify_admins
      - activate_backup_elders
      
  elder_tree_communication_delay:
    level: high
    condition: "avg_response_time > 1000ms for 60s"
    message: "Elder Tree通信遅延検知"
    actions:
      - increase_monitoring_frequency
      - analyze_network_status

# ワーカー異常検知
worker_alerts:
  worker_mass_failure:
    level: critical
    condition: "failed_workers > 16"  # 50%以上
    message: "ワーカー大量障害 - 処理能力50%以下"
    actions:
      - emergency_worker_restart
      - scale_up_backup_workers
      
  worker_high_failure_rate:
    level: high
    condition: "failed_workers > 8"  # 25%以上
    message: "ワーカー障害率上昇"
    actions:
      - restart_failed_workers
      - investigate_failure_cause
      
  worker_resource_exhaustion:
    level: high
    condition: "avg_worker_cpu > 80% or avg_worker_memory > 85%"
    message: "ワーカーリソース枯渇警告"
    actions:
      - optimize_task_distribution
      - consider_scaling
      
  worker_idle_excess:
    level: medium
    condition: "idle_workers > 24 for 300s"  # 75%以上が5分間アイドル
    message: "ワーカー稼働率低下"
    actions:
      - analyze_task_queue
      - consider_scale_down

# Four Sages異常検知
four_sages_alerts:
  sage_unresponsive:
    level: critical
    condition: "any_sage.status != 'active' for 60s"
    message: "Sage応答なし - {sage_name}"
    actions:
      - restart_sage_service
      - activate_backup_sage
      
  incident_sage_overload:
    level: high
    condition: "incident_sage.active_incidents > 50"
    message: "Incident Sage過負荷 - 異常処理遅延リスク"
    actions:
      - prioritize_critical_incidents
      - scale_incident_workers
      
  knowledge_sage_storage_full:
    level: high
    condition: "knowledge_sage.storage_used > 90%"
    message: "Knowledge Sageストレージ逼迫"
    actions:
      - archive_old_knowledge
      - expand_storage_capacity
      
  task_sage_queue_overflow:
    level: high
    condition: "task_sage.queue_length > 1000"
    message: "Task Sageキュー溢れ警告"
    actions:
      - increase_worker_allocation
      - optimize_task_scheduling
      
  rag_sage_slow_response:
    level: medium
    condition: "rag_sage.avg_response_time > 500ms"
    message: "RAG Sage応答遅延"
    actions:
      - optimize_indexes
      - cache_frequent_queries

# リソース閾値アラート
resource_alerts:
  cpu_critical:
    level: critical
    condition: "system_cpu > 95% for 120s"
    message: "CPU使用率危険域"
    actions:
      - identify_cpu_consumers
      - throttle_non_critical_tasks
      
  memory_critical:
    level: critical
    condition: "system_memory > 95%"
    message: "メモリ枯渇警告"
    actions:
      - trigger_garbage_collection
      - restart_memory_intensive_services
      
  disk_space_low:
    level: high
    condition: "disk_free < 10%"
    message: "ディスク容量不足"
    actions:
      - cleanup_old_logs
      - archive_historical_data
      
  network_saturation:
    level: medium
    condition: "network_utilization > 80%"
    message: "ネットワーク帯域逼迫"
    actions:
      - analyze_traffic_patterns
      - optimize_data_transfers

# 異常パターン検知
anomaly_detection:
  patterns:
    - name: "cascade_failure"
      description: "連鎖的障害パターン"
      conditions:
        - "worker_failures increasing exponentially"
        - "multiple_sages reporting errors"
      level: critical
      
    - name: "performance_degradation"
      description: "段階的性能劣化"
      conditions:
        - "response_times increasing linearly"
        - "throughput decreasing"
      level: high
      
    - name: "unusual_activity"
      description: "異常な活動パターン"
      conditions:
        - "task_patterns != historical_baseline"
        - "access_patterns anomalous"
      level: medium

# アラート通知設定
notifications:
  channels:
    slack:
      webhook_url: "${SLACK_WEBHOOK_URL}"
      critical_channel: "#alerts-critical"
      high_channel: "#alerts-high"
      default_channel: "#alerts-general"
      
    email:
      smtp_server: "smtp.gmail.com"
      smtp_port: 587
      from_address: "elder-tree-alerts@aicompany.com"
      admin_list:
        - "admin@aicompany.com"
        - "oncall@aicompany.com"
        
    pager:
      service: "pagerduty"
      api_key: "${PAGERDUTY_API_KEY}"
      
  templates:
    critical:
      subject: "🔴 CRITICAL: {alert_name}"
      body: |
        Elder Tree Critical Alert
        
        Alert: {alert_name}
        Level: CRITICAL
        Time: {timestamp}
        Message: {message}
        
        Affected Components:
        {components}
        
        Automated Actions Taken:
        {actions}
        
        Manual Intervention Required: YES
        
    high:
      subject: "🟠 HIGH: {alert_name}"
      body: |
        Elder Tree High Priority Alert
        
        Alert: {alert_name}
        Level: HIGH
        Time: {timestamp}
        Message: {message}
        
        Current Status:
        {status}
        
        Recommended Actions:
        {recommendations}

# アラート抑制ルール
suppression_rules:
  - name: "maintenance_window"
    condition: "during_scheduled_maintenance"
    suppress: ["low", "medium"]
    
  - name: "known_issue"
    condition: "alert_id in known_issues_list"
    suppress: ["all"]
    duration: 3600  # 1時間
    
  - name: "duplicate_prevention"
    condition: "same_alert within 300s"
    suppress: ["duplicate"]
    
  - name: "storm_control"
    condition: "alert_rate > 100 per minute"
    action: "batch_and_summarize"

# 自動回復アクション
auto_recovery:
  enabled: true
  max_attempts: 3
  actions:
    restart_worker:
      command: "systemctl restart aicompany-worker@{worker_id}"
      timeout: 30
      
    restart_sage:
      command: "systemctl restart aicompany-sage-{sage_name}"
      timeout: 60
      
    clear_cache:
      command: "redis-cli FLUSHDB"
      timeout: 10
      
    scale_workers:
      command: "kubectl scale deployment workers --replicas={count}"
      timeout: 120

# アラート統計とレポート
reporting:
  enabled: true
  intervals:
    - daily: "00:00"
    - weekly: "monday 00:00"
    - monthly: "1st 00:00"
    
  metrics:
    - total_alerts_by_level
    - mttr_by_component  # Mean Time To Recovery
    - false_positive_rate
    - auto_recovery_success_rate
    - top_10_recurring_alerts
    
  destinations:
    - email: "reports@aicompany.com"
    - slack: "#monitoring-reports"
    - dashboard: "/monitoring/reports/"