#!/usr/bin/env python3
"""
ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’è©³ç´°ã«åˆ†æ
"""

import ast
import json
from pathlib import Path
from typing import Dict, Any, List
import re

class CodeQualityAnalyzer:
    """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æå™¨"""
    
    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªåˆ†æ"""
        code = file_path.read_text()
        tree = ast.parse(code)
        
        analysis = {
            'file': str(file_path),
            'metrics': self._calculate_metrics(code, tree),
            'patterns': self._analyze_patterns(code, tree),
            'elder_flow_compatibility': self._check_elder_flow_compatibility(code, tree),
            'best_practices': self._check_best_practices(code, tree),
            'score': 0
        }
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        analysis['score'] = self._calculate_score(analysis)
        
        return analysis
    
    def _calculate_metrics(self, code: str, tree: ast.AST) -> Dict[str, Any]:
        """åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        lines = code.split('\n')
        
        # ASTã‚¦ã‚©ãƒ¼ã‚«ãƒ¼ã§ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã‚’åé›†
        classes = []
        functions = []
        docstrings = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                classes.append(node)
            elif isinstance(node, ast.FunctionDef):
                functions.append(node)
            elif isinstance(node, ast.Expr) and isinstance(node.value, ast.Str):
                docstrings.append(node)
        
        # å‹ãƒ’ãƒ³ãƒˆã®ã‚ã‚‹é–¢æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        typed_functions = sum(1 for f in functions if f.returns or any(arg.annotation for arg in f.args.args))
        
        return {
            'total_lines': len(lines),
            'code_lines': len([l for l in lines if l.strip() and not l.strip().startswith('#')]),
            'comment_lines': len([l for l in lines if l.strip().startswith('#')]),
            'blank_lines': len([l for l in lines if not l.strip()]),
            'classes': len(classes),
            'functions': len(functions),
            'docstrings': len(docstrings),
            'type_hints': typed_functions,
            'type_hint_ratio': typed_functions / max(len(functions), 1),
            'complexity': self._calculate_complexity(tree),
        }
    
    def _calculate_complexity(self, tree: ast.AST) -> Dict[str, Any]:
        """å¾ªç’°çš„è¤‡é›‘åº¦ã®è¨ˆç®—"""
        complexity = {
            'if_statements': 0,
            'for_loops': 0,
            'while_loops': 0,
            'try_blocks': 0,
            'total': 0
        }
        
        for node in ast.walk(tree):
            if isinstance(node, ast.If):
                complexity['if_statements'] += 1
            elif isinstance(node, ast.For):
                complexity['for_loops'] += 1
            elif isinstance(node, ast.While):
                complexity['while_loops'] += 1
            elif isinstance(node, ast.Try):
                complexity['try_blocks'] += 1
        
        complexity['total'] = sum(complexity.values()) - complexity['total']
        return complexity
    
    def _analyze_patterns(self, code: str, tree: ast.AST) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        patterns = {
            'error_handling': {
                'try_except': len(re.findall(r'\btry\s*:', code)),
                'custom_exceptions': len(re.findall(r'class\s+\w+\(.*Exception.*\)', code)),
                'logging_errors': len(re.findall(r'logger\.(error|exception)', code)),
            },
            'logging': {
                'logger_usage': len(re.findall(r'logger\.', code)),
                'log_levels': {
                    'debug': len(re.findall(r'logger\.debug', code)),
                    'info': len(re.findall(r'logger\.info', code)),
                    'warning': len(re.findall(r'logger\.warning', code)),
                    'error': len(re.findall(r'logger\.error', code)),
                }
            },
            'async_usage': {
                'async_functions': len(re.findall(r'async\s+def', code)),
                'await_calls': len(re.findall(r'\bawait\s+', code)),
            },
            'imports': {
                'standard_lib': len(re.findall(r'^import\s+(?:os|sys|re|json|time|datetime)', code, re.MULTILINE)),
                'third_party': len(
                    re.findall(r'^(?:import|from)\s+(?:pandas|numpy|requests|aiohttp)',
                    code,
                    re.MULTILINE)
                ),
                'project_imports': len(re.findall(r'^from\s+(?:libs|workers|commands)', code, re.MULTILINE)),
            }
        }
        
        return patterns
    
    def _check_elder_flow_compatibility(self, code: str, tree: ast.AST) -> Dict[str, bool]:
        """Elder Flowäº’æ›æ€§ãƒã‚§ãƒƒã‚¯"""
        return {
            'has_execute_method': bool(re.search(r'def\s+execute\s*\(', code)),
            'returns_dict': bool(re.search(r'->\s*Dict\[str,\s*Any\]', code)),
            'has_logging': 'logger' in code,
            'has_error_handling': 'try:' in code,
            'has_docstrings': '"""' in code,
            'follows_naming_convention': bool(re.search(r'class\s+Issue\d+Implementation', code)),
        }
    
    def _check_best_practices(self, code: str, tree: ast.AST) -> Dict[str, bool]:
        """ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒã‚§ãƒƒã‚¯"""
        return {
            'no_bare_except': not bool(re.search(r'except\s*:', code)),
            'no_print_statements': 'print(' not in code,
            'has_main_guard': 'if __name__ == "__main__":' in code,
            'uses_pathlib': 'Path(' in code,
            'uses_context_managers': 'with ' in code,
            'no_global_variables': not bool(re.findall(r'^[a-zA-Z_]\w*\s*=', code, re.MULTILINE)),
        }
    
    def _calculate_score(self, analysis: Dict[str, Any]) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰"""
        score = 0
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆ40ç‚¹ï¼‰
        metrics = analysis['metrics']
        score += min(20, metrics['type_hint_ratio'] * 20)  # å‹ãƒ’ãƒ³ãƒˆ
        score += min(10, (metrics['docstrings'] / max(metrics['classes'] + metrics['functions'], 1)) * 10)  # Docstring
        score += min(10, 10 if metrics['complexity']['total'] < 20 else 5)  # è¤‡é›‘åº¦
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ï¼ˆ30ç‚¹ï¼‰
        patterns = analysis['patterns']
        score += min(10, patterns['error_handling']['try_except'] * 2)  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        score += min(10, min(patterns['logging']['logger_usage'], 5) * 2)  # ãƒ­ã‚®ãƒ³ã‚°
        score += min(10, 10 if patterns['imports']['project_imports'] == 0 else 5)  # ç‹¬ç«‹æ€§
        
        # Elder Flowäº’æ›æ€§ï¼ˆ20ç‚¹ï¼‰
        elder_flow = analysis['elder_flow_compatibility']
        score += sum(3.33 for v in elder_flow.values() if v)
        
        # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼ˆ10ç‚¹ï¼‰
        best_practices = analysis['best_practices']
        score += sum(1.67 for v in best_practices.values() if v)
        
        return min(100, round(score, 1))

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*80)
    print("ğŸ“Š ç”Ÿæˆã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ")
    print("="*80)
    
    analyzer = CodeQualityAnalyzer()
    output_dir = Path("generated_code_samples")
    
    if not output_dir.exists():
        print("âŒ generated_code_samplesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ç”Ÿæˆã•ã‚ŒãŸPythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦åˆ†æ
    python_files = list(output_dir.glob("*.py"))
    
    if not python_files:
        print("âŒ åˆ†æå¯¾è±¡ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    results = []
    
    # ç¹°ã‚Šè¿”ã—å‡¦ç†
    for file_path in python_files:
        print(f"\nğŸ“„ åˆ†æä¸­: {file_path.name}")
        
        try:
            analysis = analyzer.analyze_file(file_path)
            results.append(analysis)
            
            # çµæœè¡¨ç¤º
            print(f"\n  ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
            print(f"    - ç·è¡Œæ•°: {analysis['metrics']['total_lines']}è¡Œ")
            print(f"    - ã‚³ãƒ¼ãƒ‰è¡Œæ•°: {analysis['metrics']['code_lines']}è¡Œ")
            print(f"    - ã‚¯ãƒ©ã‚¹æ•°: {analysis['metrics']['classes']}")
            print(f"    - é–¢æ•°æ•°: {analysis['metrics']['functions']}")
            print(f"    - å‹ãƒ’ãƒ³ãƒˆç‡: {analysis['metrics']['type_hint_ratio']*100:.1f}%")
            print(f"    - å¾ªç’°çš„è¤‡é›‘åº¦: {analysis['metrics']['complexity']['total']}")
            
            print(f"\n  ğŸ¯ Elder Flowäº’æ›æ€§:")
            for key, value in analysis['elder_flow_compatibility'].items():
                print(f"    - {key}: {'âœ…' if value else 'âŒ'}")
            
            print(f"\n  ğŸ† ç·åˆã‚¹ã‚³ã‚¢: {analysis['score']}/100ç‚¹")
            
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚µãƒãƒªãƒ¼
    if results:
        print("\n" + "="*80)
        print("ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼")
        print("="*80)
        
        avg_score = sum(r['score'] for r in results) / len(results)
        print(f"\n  - åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}")
        print(f"  - å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_score:.1f}/100ç‚¹")
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
        if avg_score >= 90:
            grade = "A (Production Ready)"
        elif avg_score >= 80:
            grade = "B (High Quality)"
        elif avg_score >= 70:
            grade = "C (Acceptable)"
        else:
            grade = "D (Needs Improvement)"
        
        print(f"  - å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰: {grade}")
        
        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = {
            'timestamp': Path("processing_summary.json").read_text() \
                if Path("processing_summary.json").exists() \
                else "N/A",
            'files_analyzed': len(results),
            'average_score': avg_score,
            'grade': grade,
            'detailed_results': results
        }
        
        report_path = output_dir / "quality_analysis_report.json"
        report_path.write_text(json.dumps(report, indent=2, ensure_ascii=False))
        print(f"\n  ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

if __name__ == "__main__":
    main()