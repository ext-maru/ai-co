#!/usr/bin/env python3
"""
CLAUDE.mdç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
CorePostgres Phase 1 - æœ€é‡è¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç§»è¡Œ
"""

import os
import sys
import asyncio
import asyncpg
import json
from datetime import datetime
import re

# OpenAIè¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

from openai import OpenAI

client = OpenAI(api_key=OPENAI_API_KEY)


class CLAUDEMDMigrator:
    """CLAUDE.mdç§»è¡Œã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.conn = None

    async def connect(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        self.conn = await asyncpg.connect(
            host="localhost",
            port=5432,
            database="elders_knowledge",
            user="elders_guild",
            password="elders_2025",
        )

    async def setup_migration_table(self):
        """ç§»è¡Œç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        await self.conn.execute(
            """
            CREATE TABLE IF NOT EXISTS knowledge_base.core_documents (
                id SERIAL PRIMARY KEY,
                file_path VARCHAR(500) NOT NULL,
                section_title VARCHAR(255),
                section_content TEXT NOT NULL,
                section_type VARCHAR(100),
                priority INTEGER DEFAULT 5,
                tags TEXT[],
                embedding vector(1536),
                search_vector tsvector,
                metadata JSONB DEFAULT '{}',
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
        """
        )

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        await self.conn.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_core_docs_embedding
            ON knowledge_base.core_documents
            USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
        """
        )

        await self.conn.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_core_docs_search
            ON knowledge_base.core_documents
            USING gin(search_vector)
        """
        )

        print("âœ… ç§»è¡Œç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")

    def parse_claude_md(self, content: str):
        """CLAUDE.mdã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«è§£æ"""
        sections = []
        current_section = None
        current_content = []

        lines = content.split("\n")

        for line in lines:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®æ¤œå‡º
            if line.startswith("#"):
                # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                if current_section:
                    sections.append(
                        {
                            "title": current_section,
                            "content": "\n".join(current_content).strip(),
                            "level": current_section.count("#"),
                        }
                    )

                # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹
                current_section = line
                current_content = []
            else:
                current_content.append(line)

        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if current_section:
            sections.append(
                {
                    "title": current_section,
                    "content": "\n".join(current_content).strip(),
                    "level": current_section.count("#"),
                }
            )

        return sections

    def categorize_section(self, title: str, content: str):
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åˆ†é¡"""
        title_lower = title.lower()
        content_lower = content.lower()

        if "4è³¢è€…" in title or "è³¢è€…" in title:
            return "sages_system"
        elif "tdd" in title_lower or "ãƒ†ã‚¹ãƒˆ" in title:
            return "development_practice"
        elif "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰" in title or "elders guild" in title_lower:
            return "guild_overview"
        elif "ã‚³ãƒãƒ³ãƒ‰" in title or "command" in title_lower:
            return "commands"
        elif "ã‚¬ã‚¤ãƒ‰" in title or "guide" in title_lower:
            return "guides"
        elif "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ" in title or "project" in title_lower:
            return "project_structure"
        else:
            return "general"

    def extract_tags(self, title: str, content: str):
        """ã‚¿ã‚°æŠ½å‡º"""
        tags = []

        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¿ã‚°æŠ½å‡º
        if "4è³¢è€…" in title:
            tags.extend(["4è³¢è€…", "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰"])
        if "TDD" in title:
            tags.extend(["TDD", "ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º"])
        if "ã‚³ãƒãƒ³ãƒ‰" in title:
            tags.extend(["CLI", "ã‚³ãƒãƒ³ãƒ‰"])

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = [
            "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…",
            "ã‚¿ã‚¹ã‚¯è³¢è€…",
            "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…",
            "RAGè³¢è€…",
            "PostgreSQL",
            "pgvector",
            "CorePostgres",
            "ã‚°ãƒ©ãƒ³ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼",
            "ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ«ãƒ€ãƒ¼",
        ]

        for keyword in keywords:
            if keyword in content:
                tags.append(keyword)

        return list(set(tags))  # é‡è¤‡å‰Šé™¤

    async def create_embeddings_with_context(
        self, title: str, content: str, category: str
    ):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãembeddingç”Ÿæˆ"""
        # é«˜ç²¾åº¦embeddingç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
        context_text = f"""
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡: {category}
        ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«: {title}

        å†…å®¹: {content}

        é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ 4è³¢è€… ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… ã‚¿ã‚¹ã‚¯è³¢è€… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€… RAGè³¢è€… CorePostgres
        """

        response = client.embeddings.create(
            model="text-embedding-ada-002", input=context_text
        )

        return response.data[0].embedding

    async def migrate_section(self, file_path: str, section: dict):
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç§»è¡Œ"""
        category = self.categorize_section(section["title"], section["content"])
        tags = self.extract_tags(section["title"], section["content"])

        # é«˜ç²¾åº¦embeddingç”Ÿæˆ
        embedding = await self.create_embeddings_with_context(
            section["title"], section["content"], category
        )

        # å…¨æ–‡æ¤œç´¢ç”¨ãƒ†ã‚­ã‚¹ãƒˆ
        search_text = f"{section['title']} {section['content']}"

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
        await self.conn.execute(
            """
            INSERT INTO knowledge_base.core_documents
            (file_path, section_title, section_content, section_type,
             priority, tags, embedding, search_vector, metadata)
            VALUES ($1, $2, $3, $4, $5, $6, $7::vector, to_tsvector('english', $8), $9)
        """,
            file_path,
            section["title"],
            section["content"],
            category,
            10 - section["level"],  # ãƒ¬ãƒ™ãƒ«ãŒé«˜ã„ã»ã©å„ªå…ˆåº¦é«˜
            tags,
            str(embedding),
            search_text,
            json.dumps(
                {
                    "migration_date": datetime.now().isoformat(),
                    "original_level": section["level"],
                    "word_count": len(section["content"].split()),
                }
            ),
        )


async def migrate_claude_md():
    """CLAUDE.mdç§»è¡Œå®Ÿè¡Œ"""

    print("ğŸ“š CLAUDE.mdç§»è¡Œé–‹å§‹")
    print("=" * 60)

    migrator = CLAUDEMDMigrator()
    await migrator.connect()

    try:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        await migrator.setup_migration_table()

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
        await migrator.conn.execute("TRUNCATE knowledge_base.core_documents")

        # CLAUDE.mdãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        claude_md_paths = [
            "/home/aicompany/ai_co/CLAUDE.md",
            "/home/aicompany/CLAUDE.md",
        ]

        for path in claude_md_paths:
            if os.path.exists(path):
                print(f"ğŸ“– {path} ã‚’èª­ã¿è¾¼ã¿ä¸­...")

                with open(path, "r", encoding="utf-8") as f:
                    content = f.read()

                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³è§£æ
                sections = migrator.parse_claude_md(content)
                print(f"âœ… {len(sections)}å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º")

                # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç§»è¡Œ
                for i, section in enumerate(sections):
                    if (
                        len(section["content"].strip()) > 50
                    ):  # çŸ­ã™ãã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚¹ã‚­ãƒƒãƒ—
                        await migrator.migrate_section(path, section)
                        print(f"  ğŸ“ ç§»è¡Œå®Œäº†: {section['title'][:50]}...")

                break
        else:
            print("âŒ CLAUDE.mdãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

        # ç§»è¡Œçµæœç¢ºèª
        count = await migrator.conn.fetchval(
            """
            SELECT COUNT(*) FROM knowledge_base.core_documents
        """
        )

        categories = await migrator.conn.fetch(
            """
            SELECT section_type, COUNT(*) as count
            FROM knowledge_base.core_documents
            GROUP BY section_type
            ORDER BY count DESC
        """
        )

        print(f"\nğŸ“Š ç§»è¡Œçµæœ:")
        print(f"  ç·ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {count}")
        print(f"  ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
        for cat in categories:
            print(f"    {cat['section_type']}: {cat['count']}ä»¶")

        # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ” æ¤œç´¢ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")

        test_queries = [
            "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦",
            "TDDã®æ–¹æ³•",
            "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã¨ã¯",
            "ã‚³ãƒãƒ³ãƒ‰ã®ä½¿ã„æ–¹",
        ]

        for query in test_queries:
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=f"è³ªå•: {query}"
            )
            query_embedding = response.data[0].embedding

            results = await migrator.conn.fetch(
                """
                SELECT
                    section_title,
                    section_type,
                    1 - (embedding <=> $1::vector) as similarity
                FROM knowledge_base.core_documents
                ORDER BY embedding <=> $1::vector
                LIMIT 3
            """,
                str(query_embedding),
            )

            if results:
                top_result = results[0]
                print(
                    f"  '{query}' â†’ {top_result['section_title'][:40]}... (é¡ä¼¼åº¦: {top_result['similarity']:.3f})"
                )

        print(f"\nğŸ‰ CLAUDE.mdç§»è¡Œå®Œäº†ï¼")
        return True

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        if migrator.conn:
            await migrator.conn.close()


if __name__ == "__main__":
    success = asyncio.run(migrate_claude_md())
    print(f"\n{'âœ… ç§»è¡ŒæˆåŠŸ' if success else 'âŒ ç§»è¡Œå¤±æ•—'}")
