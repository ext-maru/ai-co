#!/usr/bin/env python3
"""
Invalid Violations Cleaner
å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢ã™ã‚‹é•åã‚’DBã‹ã‚‰å‰Šé™¤
"""

import sqlite3
from pathlib import Path
import json
from datetime import datetime


def clean_invalid_violations():
    """å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®é•åã‚’å‰Šé™¤"""

    # å‰Šé™¤å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«
    invalid_files = [
        "intelligent_pm_worker_simple.py",
        "simple_task_worker.py"
    ]

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    db_path = Path("data/abstract_violations.db")
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # å‰Šé™¤å‰ã®é•åæ•°ã‚’å–å¾—
    cursor.execute("SELECT COUNT(*) FROM violations")
    before_count = cursor.fetchone()[0]
    print(f"ğŸ“Š å‰Šé™¤å‰ã®é•åæ•°: {before_count}")

    # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢ã™ã‚‹é•åã‚’å‰Šé™¤
    deleted_count = 0
    for invalid_file in invalid_files:
        cursor.execute(
            "DELETE FROM violations WHERE file_path LIKE ?",
            (f"%{invalid_file}%",)
        )
        deleted = cursor.rowcount
        deleted_count += deleted
        print(f"ğŸ—‘ï¸  {invalid_file}: {deleted}ä»¶å‰Šé™¤")

    conn.commit()

    # å‰Šé™¤å¾Œã®é•åæ•°ã‚’å–å¾—
    cursor.execute("SELECT COUNT(*) FROM violations")
    after_count = cursor.fetchone()[0]
    print(f"\nâœ… å‰Šé™¤å®Œäº†")
    print(f"ğŸ“Š å‰Šé™¤å¾Œã®é•åæ•°: {after_count}")
    print(f"ğŸ”§ å‰Šé™¤ã—ãŸé•åæ•°: {deleted_count}")

    # æ®‹ã£ã¦ã„ã‚‹é•åã‚’è¡¨ç¤º
    cursor.execute("""
        SELECT DISTINCT
            file_path,
            COUNT(*) as count
        FROM violations
        GROUP BY file_path
        ORDER BY count DESC
    """)

    remaining = cursor.fetchall()
    if remaining:
        print(f"\nğŸ“‹ æ®‹ã£ã¦ã„ã‚‹é•åãƒ•ã‚¡ã‚¤ãƒ«:")
        for file, count in remaining:
            print(f"  - {file}: {count}ä»¶")

    conn.close()

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°
    log_path = Path("logs/identity_violations.json")
    if log_path.exists():
        with open(log_path, 'r') as f:
            data = json.load(f)

        # greeting_systemã®é•åã‚’é™¤å¤–
        original_count = len(data.get("violations", []))
        filtered_violations = [
            v for v in data.get("violations", [])
            if not any(invalid in v.get("file", "") for invalid in invalid_files)
        ]

        data["violations"] = filtered_violations
        data["total_violations"] = len(filtered_violations)
        data["last_updated"] = datetime.now().isoformat()

        with open(log_path, 'w') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“ identity_violations.jsonæ›´æ–°:")
        print(f"  - å…ƒã®é•åæ•°: {original_count}")
        print(f"  - æ›´æ–°å¾Œ: {len(filtered_violations)}")


if __name__ == "__main__":
    print("ğŸ§¹ Invalid Violations Cleaner")
    print("=" * 50)
    clean_invalid_violations()
