#!/usr/bin/env python3
"""
System Cleanup Tool - ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã¨ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–

ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡:
- Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« (.pyc, __pycache__)
- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« (.tmp, .bak, *~)
- ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«
- å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
"""

import os
import sys
import shutil
import hashlib
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Set
from collections import defaultdict

class SystemCleanup:
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_dir: str = "/home/aicompany/ai_co"):
        self.project_dir = Path(project_dir)
        self.logs_dir = self.project_dir / "logs"
        
        # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.exclude_dirs = {
            '.git', 'node_modules', '.venv', 'venv', '__pycache__',
            '.pytest_cache', '.mypy_cache', 'dist', 'build'
        }
        
        # å‰Šé™¤å¯¾è±¡æ‹¡å¼µå­
        self.cleanup_extensions = {
            '.pyc', '.pyo', '.tmp', '.bak', '.swp', '.swo', 
            '.orig', '.rej', '.patch', '.DS_Store'
        }
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.logs_dir / 'system_cleanup.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def clean_python_cache(self) -> Dict[str, int]:
        """Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.logger.info("ğŸ Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        stats = {
            "pycache_dirs": 0,
            "pyc_files": 0,
            "size_freed_mb": 0
        }
        
        total_size = 0
        
        # __pycache__ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
        for pycache_dir in self.project_dir.rglob("__pycache__"):
            if pycache_dir.is_dir():
                try:
                    # ã‚µã‚¤ã‚ºè¨ˆç®—
                    dir_size = sum(f.stat().st_size for f in pycache_dir.rglob('*') if f.is_file())
                    total_size += dir_size
                    
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤
                    shutil.rmtree(pycache_dir)
                    stats["pycache_dirs"] += 1
                    self.logger.debug(f"å‰Šé™¤: {pycache_dir}")
                except Exception as e:
                    self.logger.warning(f"å‰Šé™¤å¤±æ•— {pycache_dir}: {e}")
        
        # å€‹åˆ¥ .pyc ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        for pyc_file in self.project_dir.rglob("*.pyc"):
            try:
                file_size = pyc_file.stat().st_size
                total_size += file_size
                pyc_file.unlink()
                stats["pyc_files"] += 1
            except Exception as e:
                self.logger.warning(f"å‰Šé™¤å¤±æ•— {pyc_file}: {e}")
        
        stats["size_freed_mb"] = total_size / (1024 * 1024)
        
        self.logger.info(f"ğŸ Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: "
                        f"{stats['pycache_dirs']}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª, "
                        f"{stats['pyc_files']}ãƒ•ã‚¡ã‚¤ãƒ«, "
                        f"{stats['size_freed_mb']:.1f}MBè§£æ”¾")
        
        return stats
    
    def clean_temp_files(self) -> Dict[str, int]:
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.logger.info("ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        stats = {
            "temp_files": 0,
            "size_freed_mb": 0
        }
        
        total_size = 0
        
        for file_path in self.project_dir.rglob("*"):
            if not file_path.is_file():
                continue
                
            # æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
            if file_path.suffix in self.cleanup_extensions:
                try:
                    file_size = file_path.stat().st_size
                    total_size += file_size
                    file_path.unlink()
                    stats["temp_files"] += 1
                    self.logger.debug(f"å‰Šé™¤: {file_path}")
                except Exception as e:
                    self.logger.warning(f"å‰Šé™¤å¤±æ•— {file_path}: {e}")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ«å°¾~ï¼‰
            elif file_path.name.endswith('~'):
                try:
                    file_size = file_path.stat().st_size
                    total_size += file_size
                    file_path.unlink()
                    stats["temp_files"] += 1
                    self.logger.debug(f"å‰Šé™¤: {file_path}")
                except Exception as e:
                    self.logger.warning(f"å‰Šé™¤å¤±æ•— {file_path}: {e}")
        
        stats["size_freed_mb"] = total_size / (1024 * 1024)
        
        self.logger.info(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: "
                        f"{stats['temp_files']}ãƒ•ã‚¡ã‚¤ãƒ«, "
                        f"{stats['size_freed_mb']:.1f}MBè§£æ”¾")
        
        return stats
    
    def clean_empty_directories(self) -> int:
        """ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤"""
        self.logger.info("ğŸ“ ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        removed_dirs = 0
        
        # ä¸‹ä½ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸Šä½ã«å‘ã‹ã£ã¦å‡¦ç†
        all_dirs = sorted([d for d in self.project_dir.rglob("*") if d.is_dir()], 
                         key=lambda x: len(x.parts), reverse=True)
        
        for dir_path in all_dirs:
            # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—
            if dir_path.name in self.exclude_dirs:
                continue
            
            # é‡è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—
            if any(important in str(dir_path) for important in ['.git', 'node_modules']):
                continue
            
            try:
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç©ºã‹ãƒã‚§ãƒƒã‚¯
                if dir_path.is_dir() and not any(dir_path.iterdir()):
                    dir_path.rmdir()
                    removed_dirs += 1
                    self.logger.debug(f"ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {dir_path}")
            except Exception as e:
                self.logger.debug(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤å¤±æ•— {dir_path}: {e}")
        
        self.logger.info(f"ğŸ“ ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {removed_dirs}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤")
        return removed_dirs
    
    def find_duplicate_files(self) -> Dict[str, List[Path]]:
        """é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º"""
        self.logger.info("ğŸ” é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºé–‹å§‹")
        
        file_hashes = defaultdict(list)
        
        for file_path in self.project_dir.rglob("*"):
            if not file_path.is_file():
                continue
            
            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒã‚§ãƒƒã‚¯ (1KBä»¥ä¸Š)
            if file_path.stat().st_size < 1024:
                continue
            
            # ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‚„ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if file_path.suffix in {'.pyc', '.pyo', '.so', '.dll', '.exe'}:
                continue
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
                hasher = hashlib.md5()
                with open(file_path, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        hasher.update(chunk)
                file_hash = hasher.hexdigest()
                file_hashes[file_hash].append(file_path)
            except Exception as e:
                self.logger.debug(f"ãƒãƒƒã‚·ãƒ¥è¨ˆç®—å¤±æ•— {file_path}: {e}")
        
        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿æŠ½å‡º
        duplicates = {hash_val: paths for hash_val, paths in file_hashes.items() if len(paths) > 1}
        
        total_duplicates = sum(len(paths) - 1 for paths in duplicates.values())
        self.logger.info(f"ğŸ” é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºå®Œäº†: {len(duplicates)}ã‚°ãƒ«ãƒ¼ãƒ—, {total_duplicates}å€‹ã®é‡è¤‡")
        
        return duplicates
    
    def clean_old_logs(self, days_to_keep: int = 30) -> Dict[str, int]:
        """å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.logger.info(f"ğŸ“‹ å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹ ({days_to_keep}æ—¥ã‚ˆã‚Šå¤ã„)")
        
        stats = {
            "old_logs": 0,
            "size_freed_mb": 0
        }
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        total_size = 0
        
        for log_file in self.logs_dir.rglob("*.log"):
            if not log_file.is_file():
                continue
            
            try:
                modified_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if modified_time < cutoff_date:
                    file_size = log_file.stat().st_size
                    total_size += file_size
                    log_file.unlink()
                    stats["old_logs"] += 1
                    self.logger.debug(f"å¤ã„ãƒ­ã‚°å‰Šé™¤: {log_file}")
            except Exception as e:
                self.logger.warning(f"ãƒ­ã‚°å‰Šé™¤å¤±æ•— {log_file}: {e}")
        
        stats["size_freed_mb"] = total_size / (1024 * 1024)
        
        self.logger.info(f"ğŸ“‹ å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: "
                        f"{stats['old_logs']}ãƒ•ã‚¡ã‚¤ãƒ«, "
                        f"{stats['size_freed_mb']:.1f}MBè§£æ”¾")
        
        return stats
    
    def optimize_git_repository(self) -> Dict[str, any]:
        """Git ãƒªãƒã‚¸ãƒˆãƒªã®æœ€é©åŒ–"""
        self.logger.info("ğŸ“¦ Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–é–‹å§‹")
        
        stats = {
            "git_gc_run": False,
            "size_before_mb": 0,
            "size_after_mb": 0,
            "error": None
        }
        
        git_dir = self.project_dir / ".git"
        if not git_dir.exists():
            self.logger.info("Git ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return stats
        
        try:
            # .git ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºï¼ˆå‰ï¼‰
            size_before = sum(f.stat().st_size for f in git_dir.rglob('*') if f.is_file())
            stats["size_before_mb"] = size_before / (1024 * 1024)
            
            # Git ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            import subprocess
            result = subprocess.run(
                ["git", "gc", "--aggressive", "--prune=now"],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                stats["git_gc_run"] = True
                
                # .git ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºï¼ˆå¾Œï¼‰
                size_after = sum(f.stat().st_size for f in git_dir.rglob('*') if f.is_file())
                stats["size_after_mb"] = size_after / (1024 * 1024)
                
                self.logger.info(f"ğŸ“¦ Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–å®Œäº†: "
                               f"{stats['size_before_mb']:.1f}MB â†’ {stats['size_after_mb']:.1f}MB")
            else:
                stats["error"] = result.stderr
                self.logger.warning(f"Git æœ€é©åŒ–å¤±æ•—: {result.stderr}")
                
        except Exception as e:
            stats["error"] = str(e)
            self.logger.error(f"Git æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        return stats
    
    def run_full_cleanup(self, include_duplicates: bool = False, 
                        include_old_logs: bool = True) -> Dict[str, any]:
        """ãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        self.logger.info("ğŸš€ ãƒ•ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        results = {
            "start_time": datetime.now().isoformat(),
            "python_cache": None,
            "temp_files": None,
            "empty_dirs": 0,
            "duplicates": None,
            "old_logs": None,
            "git_optimization": None,
            "total_size_freed_mb": 0
        }
        
        # Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        results["python_cache"] = self.clean_python_cache()
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        results["temp_files"] = self.clean_temp_files()
        
        # ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        results["empty_dirs"] = self.clean_empty_directories()
        
        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºï¼ˆå‰Šé™¤ã¯æ‰‹å‹•ï¼‰
        if include_duplicates:
            results["duplicates"] = self.find_duplicate_files()
        
        # å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if include_old_logs:
            results["old_logs"] = self.clean_old_logs()
        
        # Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–
        results["git_optimization"] = self.optimize_git_repository()
        
        # åˆè¨ˆè§£æ”¾å®¹é‡è¨ˆç®—
        total_freed = 0
        if results["python_cache"]:
            total_freed += results["python_cache"]["size_freed_mb"]
        if results["temp_files"]:
            total_freed += results["temp_files"]["size_freed_mb"]
        if results["old_logs"]:
            total_freed += results["old_logs"]["size_freed_mb"]
        
        results["total_size_freed_mb"] = total_freed
        results["end_time"] = datetime.now().isoformat()
        
        self.logger.info(f"âœ… ãƒ•ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {total_freed:.1f}MBè§£æ”¾")
        
        return results
    
    def print_summary(self, results: Dict[str, any]):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ§¹ Elders Guild System Cleanup Report")
        print("="*60)
        
        print(f"\nğŸ“Š Summary:")
        print(f"  Total Space Freed: {results['total_size_freed_mb']:.1f} MB")
        
        if results["python_cache"]:
            pc = results["python_cache"]
            print(f"\nğŸ Python Cache Cleanup:")
            print(f"  __pycache__ dirs removed: {pc['pycache_dirs']}")
            print(f"  .pyc files removed: {pc['pyc_files']}")
            print(f"  Space freed: {pc['size_freed_mb']:.1f} MB")
        
        if results["temp_files"]:
            tf = results["temp_files"]
            print(f"\nğŸ—‘ï¸ Temporary Files Cleanup:")
            print(f"  Files removed: {tf['temp_files']}")
            print(f"  Space freed: {tf['size_freed_mb']:.1f} MB")
        
        print(f"\nğŸ“ Empty Directories:")
        print(f"  Directories removed: {results['empty_dirs']}")
        
        if results["duplicates"]:
            dup = results["duplicates"]
            total_dups = sum(len(paths) - 1 for paths in dup.values())
            print(f"\nğŸ” Duplicate Files (not removed):")
            print(f"  Duplicate groups: {len(dup)}")
            print(f"  Total duplicates: {total_dups}")
        
        if results["old_logs"]:
            ol = results["old_logs"]
            print(f"\nğŸ“‹ Old Logs Cleanup:")
            print(f"  Files removed: {ol['old_logs']}")
            print(f"  Space freed: {ol['size_freed_mb']:.1f} MB")
        
        if results["git_optimization"]:
            git = results["git_optimization"]
            if git["git_gc_run"]:
                print(f"\nğŸ“¦ Git Repository Optimization:")
                print(f"  Size before: {git['size_before_mb']:.1f} MB")
                print(f"  Size after: {git['size_after_mb']:.1f} MB")
                saved = git['size_before_mb'] - git['size_after_mb']
                print(f"  Space saved: {saved:.1f} MB")
        
        print("\n" + "="*60)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="System Cleanup Tool")
    parser.add_argument("--full", action="store_true", help="ãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ")
    parser.add_argument("--python-cache", action="store_true", help="Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
    parser.add_argument("--temp-files", action="store_true", help="ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
    parser.add_argument("--empty-dirs", action="store_true", help="ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
    parser.add_argument("--find-duplicates", action="store_true", help="é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã®ã¿")
    parser.add_argument("--git-optimize", action="store_true", help="Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–ã®ã¿")
    parser.add_argument("--include-duplicates", action="store_true", help="é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã‚’å«ã‚ã‚‹")
    parser.add_argument("--skip-old-logs", action="store_true", help="å¤ã„ãƒ­ã‚°å‰Šé™¤ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--save", action="store_true", help="çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜")
    
    args = parser.parse_args()
    
    cleanup = SystemCleanup()
    
    if args.python_cache:
        results = cleanup.clean_python_cache()
        print(f"Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {results}")
    elif args.temp_files:
        results = cleanup.clean_temp_files()
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {results}")
    elif args.empty_dirs:
        count = cleanup.clean_empty_directories()
        print(f"ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {count}å€‹å‰Šé™¤")
    elif args.find_duplicates:
        duplicates = cleanup.find_duplicate_files()
        print(f"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºå®Œäº†: {len(duplicates)}ã‚°ãƒ«ãƒ¼ãƒ—")
        for hash_val, paths in list(duplicates.items())[:5]:  # æœ€åˆã®5ã‚°ãƒ«ãƒ¼ãƒ—è¡¨ç¤º
            print(f"  é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ— {hash_val[:8]}:")
            for path in paths:
                print(f"    {path}")
    elif args.git_optimize:
        results = cleanup.optimize_git_repository()
        print(f"Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–å®Œäº†: {results}")
    elif args.full:
        results = cleanup.run_full_cleanup(
            include_duplicates=args.include_duplicates,
            include_old_logs=not args.skip_old_logs
        )
        cleanup.print_summary(results)
        
        if args.save:
            import json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = cleanup.logs_dir / f"cleanup_report_{timestamp}.json"
            with open(report_file, 'w') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“„ Report saved: {report_file}")
    else:
        print("ğŸ§¹ Elders Guild System Cleanup Tool")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  --full            : ãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        print("  --python-cache    : Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        print("  --temp-files      : ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        print("  --empty-dirs      : ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        print("  --find-duplicates : é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º")
        print("  --git-optimize    : Git ãƒªãƒã‚¸ãƒˆãƒªæœ€é©åŒ–")
        print("  --save            : çµæœä¿å­˜ (--fullã¨ä½µç”¨)")

if __name__ == "__main__":
    main()