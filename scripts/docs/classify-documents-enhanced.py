#!/usr/bin/env python3
"""
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ v2.0
ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šä»¤ç¬¬501å·å®Ÿè£… - Iron Willå®Œå…¨æº–æ‹ ç‰ˆ

æ©Ÿèƒ½:
1. ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ï¼ˆãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–ï¼‰
2. 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨çµ±åˆ
3. å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
4. åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å¯¾å¿œ
"""

import os
import re
import shutil
import yaml
import hashlib
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Set
import argparse
from dataclasses import dataclass
import tempfile

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
import stat
from urllib.parse import unquote

# 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
try:
    import sys
    sys.path.append('/home/aicompany/ai_co')
    from libs.four_sages.knowledge.knowledge_sage import KnowledgeSage
    from libs.four_sages.task.task_sage import TaskSage
    from libs.four_sages.incident.incident_sage import IncidentSage
    from libs.four_sages.rag.rag_sage import RAGSage
    FOUR_SAGES_AVAILABLE = True
except ImportError:
    FOUR_SAGES_AVAILABLE = False

# Iron Willéµå®ˆé …ç›®
FORBIDDEN_PATTERNS = ["TODO", "FIXME", "HACK", "XXX", "TEMP"]
SECURITY_RISK_PATTERNS = [
    r"eval\s*\(",
    r"exec\s*\(",
    r"os\.system\s*\(",
    r"subprocess\.",
    r"__import__\s*\(",
    r"getattr\s*\(",
    r"setattr\s*\(",
]

@dataclass
class DocumentInfo:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰"""
    path: Path
    category: str
    subcategory: str
    new_path: Path
    title: str
    audience: str
    difficulty: str
    status: str
    sage_assignment: Optional[str] = None
    security_score: float = 100.0
    iron_will_compliant: bool = True

@dataclass
class ClassificationResult:
    """åˆ†é¡çµæœ"""
    total_files: int = 0
    processed_files: int = 0
    moved_files: int = 0
    skipped_files: int = 0
    error_files: int = 0
    security_violations: int = 0
    iron_will_violations: int = 0
    sage_assignments: Dict[str, int] = None

    def __post_init__(self):
        if self.sage_assignments is None:
            self.sage_assignments = {}

class SecureDocumentClassifier:
    """ã‚»ã‚­ãƒ¥ã‚¢ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡å™¨ï¼ˆIron Willæº–æ‹ ï¼‰"""
    
    def __init__(self, base_path: str = "/home/aicompany/ai_co"):
        self.base_path = Path(base_path).resolve()  # çµ¶å¯¾ãƒ‘ã‚¹åŒ–
        self.docs_path = self.base_path / "docs"
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
        self.max_file_size = 50 * 1024 * 1024  # 50MBåˆ¶é™
        self.allowed_extensions = {'.md', '.txt', '.rst'}
        self.forbidden_chars = {'..', '~', '$', '|', ';', '&'}
        
        # ãƒ­ã‚°è¨­å®š
        self._setup_logging()
        
        # 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self._initialize_four_sages()
        
        # åˆ†é¡ãƒ«ãƒ¼ãƒ«å®šç¾©ï¼ˆ4è³¢è€…å‰²ã‚Šå½“ã¦å«ã‚€ï¼‰
        self.classification_rules = {
            "guides": {
                "patterns": [
                    r".*guide.*\.md$",
                    r".*quickstart.*\.md$", 
                    r".*tutorial.*\.md$",
                    r".*howto.*\.md$",
                    r".*usage.*\.md$"
                ],
                "subcategories": {
                    "user-guides": ["quickstart", "basic", "beginner", "user"],
                    "developer-guides": ["development", "developer", "coding", "contribution"],
                    "administrator-guides": ["admin", "deployment", "maintenance", "security"],
                    "workflow-guides": ["workflow", "process", "github", "git"]
                },
                "sage": "knowledge_sage"
            },
            
            "technical": {
                "patterns": [
                    r".*architecture.*\.md$",
                    r".*design.*\.md$",
                    r".*specification.*\.md$",
                    r".*implementation.*\.md$",
                    r".*technical.*\.md$",
                    r".*system.*\.md$"
                ],
                "subcategories": {
                    "architecture": ["architecture", "system", "component", "overview"],
                    "implementation": ["implementation", "elder-tree", "four-sages", "unified"],
                    "specifications": ["spec", "requirements", "functional", "interface"],
                    "deployment": ["deployment", "infrastructure", "monitoring", "logging"],
                    "research": ["research", "investigation", "analysis", "study"]
                },
                "sage": "rag_sage"
            },
            
            "reports": {
                "patterns": [
                    r".*report.*\.md$",
                    r".*analysis.*\.md$",
                    r".*completion.*\.md$",
                    r".*summary.*\.md$",
                    r".*audit.*\.md$",
                    r".*benchmark.*\.md$"
                ],
                "subcategories": {
                    "development": ["completion", "progress", "sprint", "milestone"],
                    "quality": ["quality", "coverage", "audit", "security"],
                    "analysis": ["analysis", "impact", "risk", "cost"],
                    "operations": ["incident", "maintenance", "usage", "capacity"]
                },
                "sage": "task_sage"
            },
            
            "policies": {
                "patterns": [
                    r".*policy.*\.md$",
                    r".*standard.*\.md$",
                    r".*rule.*\.md$",
                    r".*regulation.*\.md$",
                    r".*protocol.*\.md$"
                ],
                "subcategories": {
                    "development": ["coding", "testing", "review", "workflow"],
                    "quality": ["quality", "iron-will", "oss", "security"],
                    "operations": ["deployment", "incident", "backup", "monitoring"],
                    "governance": ["council", "decision", "escalation", "compliance"]
                },
                "sage": "incident_sage"
            },
            
            "api": {
                "patterns": [
                    r".*api.*\.md$",
                    r".*reference.*\.md$",
                    r".*schema.*\.md$",
                    r".*endpoint.*\.md$"
                ],
                "subcategories": {
                    "reference": ["reference", "api", "rest", "graphql"],
                    "guides": ["getting-started", "authentication", "rate-limiting"],
                    "schemas": ["schema", "openapi", "json", "proto"],
                    "examples": ["examples", "samples", "curl", "sdk"]
                },
                "sage": "rag_sage"
            },
            
            "projects": {
                "patterns": [
                    r".*project.*\.md$",
                    r".*plan.*\.md$",
                    r".*proposal.*\.md$",
                    r".*issue.*\.md$"
                ],
                "subcategories": {
                    "active": ["active", "current", "ongoing"],
                    "completed": ["completed", "finished", "done"],
                    "planning": ["planning", "proposal", "draft", "design"]
                },
                "sage": "task_sage"
            }
        }
        
        # ç‰¹åˆ¥ãªå‡¦ç†ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«
        self.special_files = {
            "README.md": "root",
            "CLAUDE.md": "root", 
            "CHANGELOG.md": "root",
            "CONTRIBUTING.md": "root",
            "LICENSE": "root"
        }
        
        self.logger.info("SecureDocumentClassifieråˆæœŸåŒ–å®Œäº†")
        self.logger.info(f"4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ : {'æœ‰åŠ¹' if FOUR_SAGES_AVAILABLE else 'ç„¡åŠ¹'}")
    
    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('docs_classification.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('DocumentClassifier')
    
    def _initialize_four_sages(self):
        """4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        self.sages = {}
        if FOUR_SAGES_AVAILABLE:
            try:
                self.sages = {
                    'knowledge_sage': KnowledgeSage('knowledge_sage'),
                    'task_sage': TaskSage('task_sage'),
                    'incident_sage': IncidentSage('incident_sage'),
                    'rag_sage': RAGSage('rag_sage')
                }
                self.logger.info("4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
                self.sages = {}
        else:
            self.logger.warning("4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœªæ¤œå‡º")
    
    def validate_security(self, file_path: Path, content: str) -> Tuple[bool, List[str], float]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ï¼ˆIron Willæº–æ‹ ï¼‰"""
        violations = []
        security_score = 100.0
        
        # 1. ãƒ‘ã‚¹æ¤œè¨¼
        try:
            resolved_path = file_path.resolve()
            if not str(resolved_path).startswith(str(self.base_path)):
                violations.append(f"ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ¤œå‡º: {file_path}")
                security_score -= 50
        except (OSError, ValueError) as e:
            violations.append(f"ãƒ‘ã‚¹è§£æ±ºã‚¨ãƒ©ãƒ¼: {e}")
            security_score -= 30
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œè¨¼
        filename = file_path.name
        for forbidden_char in self.forbidden_chars:
            if forbidden_char in filename:
                violations.append(f"ç¦æ­¢æ–‡å­—æ¤œå‡º: {forbidden_char} in {filename}")
                security_score -= 20
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¤œè¨¼
        try:
            file_size = file_path.stat().st_size
            if file_size > self.max_file_size:
                violations.append(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¶…é: {file_size} > {self.max_file_size}")
                security_score -= 25
        except OSError:
            pass  # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # 4. æ‹¡å¼µå­æ¤œè¨¼
        if file_path.suffix.lower() not in self.allowed_extensions:
            violations.append(f"è¨±å¯ã•ã‚Œã¦ã„ãªã„æ‹¡å¼µå­: {file_path.suffix}")
            security_score -= 15
        
        # 5. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
        for pattern in SECURITY_RISK_PATTERNS:
            if re.search(pattern, content, re.IGNORECASE):
                violations.append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: {pattern}")
                security_score -= 30
        
        # 6. Iron WillåŸºæº–ãƒã‚§ãƒƒã‚¯
        for pattern in FORBIDDEN_PATTERNS:
            if pattern in content:
                violations.append(f"Iron Willé•å: {pattern} found")
                security_score -= 10
        
        is_secure = len(violations) == 0 and security_score >= 70
        return is_secure, violations, max(0, security_score)
    
    def secure_path_join(self, base_path: Path, *paths: str) -> Optional[Path]:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‘ã‚¹çµåˆ"""
        try:
            # ãƒ‘ã‚¹æ­£è¦åŒ–
            normalized_paths = []
            for path in paths:
                # URLãƒ‡ã‚³ãƒ¼ãƒ‰
                decoded = unquote(path)
                # å±é™ºãªæ–‡å­—ã‚’é™¤å»
                cleaned = re.sub(r'[<>:"|?*]', '', decoded)
                # ç›¸å¯¾ãƒ‘ã‚¹è¦ç´ ã‚’é™¤å»
                parts = []
                for part in cleaned.split('/'):
                    if part and part not in {'..', '.', '~'}:
                        parts.append(part)
                if parts:
                    normalized_paths.extend(parts)
            
            if not normalized_paths:
                return None
            
            # ãƒ‘ã‚¹çµåˆ
            result_path = base_path
            for part in normalized_paths:
                result_path = result_path / part
            
            # æœ€çµ‚æ¤œè¨¼
            resolved = result_path.resolve()
            if not str(resolved).startswith(str(base_path.resolve())):
                self.logger.warning(f"ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«è©¦è¡Œã‚’é˜»æ­¢: {result_path}")
                return None
            
            return resolved
            
        except Exception as e:
            self.logger.error(f"ã‚»ã‚­ãƒ¥ã‚¢ãƒ‘ã‚¹çµåˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def classify_document(self, file_path: Path) -> Optional[DocumentInfo]:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡"""
        try:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£äº‹å‰ãƒã‚§ãƒƒã‚¯
            if file_path.suffix != '.md':
                return None
            
            # ç‰¹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            if file_path.name in self.special_files:
                return None
            
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            try:
                content = self._read_file_content(file_path)
            except Exception as e:
                self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                return None
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
            is_secure, violations, security_score = self.validate_security(file_path, content)
            if not is_secure:
                self.logger.warning(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼å¤±æ•— {file_path}: {violations}")
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é•åã§ã‚‚åˆ†é¡ã¯ç¶™ç¶šï¼ˆè¨˜éŒ²ç›®çš„ï¼‰
            
            title = self._extract_title(content)
            
            # åˆ†é¡å®Ÿè¡Œ
            for category, rules in self.classification_rules.items():
                if self._matches_patterns(file_path.name, rules["patterns"]):
                    subcategory = self._determine_subcategory(file_path, content, rules["subcategories"])
                    
                    # ã‚»ã‚­ãƒ¥ã‚¢ãªæ–°ãƒ‘ã‚¹ç”Ÿæˆ
                    new_filename = self._generate_secure_filename(file_path.name, category, subcategory)
                    new_path = self.secure_path_join(self.docs_path, category, subcategory, new_filename)
                    
                    if new_path is None:
                        self.logger.error(f"ã‚»ã‚­ãƒ¥ã‚¢ãƒ‘ã‚¹ç”Ÿæˆå¤±æ•—: {file_path}")
                        return None
                    
                    return DocumentInfo(
                        path=file_path,
                        category=category,
                        subcategory=subcategory,
                        new_path=new_path,
                        title=title,
                        audience=self._determine_audience(content, category),
                        difficulty=self._determine_difficulty(content),
                        status="approved" if is_secure else "security_review",
                        sage_assignment=rules.get("sage"),
                        security_score=security_score,
                        iron_will_compliant=len([v for v in violations if "Iron Will" in v]) == 0
                    )
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é¡
            return self._default_secure_classification(file_path, content, title, security_score, violations)
            
        except Exception as e:
            self.logger.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            return None
    
    def _generate_secure_filename(self, original_name: str, category: str, subcategory: str) -> str:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ"""
        # å±é™ºæ–‡å­—é™¤å»
        safe_name = re.sub(r'[<>:"|?*\\]', '', original_name)
        safe_name = safe_name.replace('..', '').replace('~', '')
        
        # åŸºæœ¬ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        name = safe_name.replace('.md', '')
        name = re.sub(r'[^a-zA-Z0-9\s_-]', '', name)
        name = re.sub(r'[\s_]+', '-', name)
        name = name.lower().strip('-')
        
        # é•·ã•åˆ¶é™
        if len(name) > 100:
            name = name[:100]
        
        # ç©ºã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not name:
            name = f"document-{hashlib.md5(original_name.encode()).hexdigest()[:8]}"
        
        return f"{name}.md"
    
    def _default_secure_classification(self, file_path: Path, content: str, title: str, 
                                     security_score: float, violations: List[str]) -> DocumentInfo:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é¡"""
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–¢é€£åˆ¤å®š
        if any(word in file_path.name.lower() for word in ["project", "issue", "plan"]):
            category = "projects"
            subcategory = "planning"  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šå®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            sage = "task_sage"
        else:
            category = "technical"
            subcategory = "research"
            sage = "rag_sage"
        
        new_filename = self._generate_secure_filename(file_path.name, category, subcategory)
        new_path = self.secure_path_join(self.docs_path, category, subcategory, new_filename)
        
        if new_path is None:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: tempãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            temp_dir = self.docs_path / "temp" / "security_review"
            new_path = temp_dir / new_filename
        
        return DocumentInfo(
            path=file_path,
            category=category,
            subcategory=subcategory,
            new_path=new_path,
            title=title,
            audience=self._determine_audience(content, category),
            difficulty=self._determine_difficulty(content),
            status="security_review" if violations else "draft",
            sage_assignment=sage,
            security_score=security_score,
            iron_will_compliant=len([v for v in violations if "Iron Will" in v]) == 0
        )
    
    def secure_move_file(self, source: Path, destination: Path) -> bool:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•"""
        try:
            # ç§»å‹•å‰æ¤œè¨¼
            if not source.exists():
                self.logger.error(f"ç§»å‹•å…ƒãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {source}")
                return False
            
            if not source.is_file():
                self.logger.error(f"ç§»å‹•å…ƒãŒãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„: {source}")
                return False
            
            # ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            # ç§»å‹•å…ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯
            final_destination = destination
            counter = 1
            while final_destination.exists():
                stem = destination.stem
                suffix = destination.suffix
                final_destination = destination.parent / f"{stem}-{counter:03d}{suffix}"
                counter += 1
                if counter > 999:  # ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢
                    self.logger.error(f"ç§»å‹•å…ˆãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆå¤±æ•—ï¼ˆé‡è¤‡å¤šæ•°ï¼‰: {destination}")
                    return False
            
            # æ¨©é™ãƒã‚§ãƒƒã‚¯
            source_stat = source.stat()
            if not (source_stat.st_mode & stat.S_IREAD):
                self.logger.error(f"èª­ã¿å–ã‚Šæ¨©é™ãªã—: {source}")
                return False
            
            # åŸå­çš„ç§»å‹•å®Ÿè¡Œ
            temp_destination = final_destination.with_suffix('.tmp')
            try:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼
                shutil.copy2(source, temp_destination)
                
                # ç§»å‹•å…ˆã«ãƒªãƒãƒ¼ãƒ ï¼ˆåŸå­çš„ï¼‰
                temp_destination.rename(final_destination)
                
                # ç§»å‹•å…ƒå‰Šé™¤
                source.unlink()
                
                self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•æˆåŠŸ: {source} -> {final_destination}")
                return True
                
            except Exception as e:
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if temp_destination.exists():
                    temp_destination.unlink()
                raise e
        
        except Exception as e:
            self.logger.error(f"ã‚»ã‚­ãƒ¥ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ã‚¨ãƒ©ãƒ¼ {source} -> {destination}: {e}")
            return False
    
    def notify_four_sages(self, doc_info: DocumentInfo, operation: str) -> bool:
        """4è³¢è€…ã¸ã®é€šçŸ¥"""
        if not self.sages or not doc_info.sage_assignment:
            return False
        
        try:
            sage = self.sages.get(doc_info.sage_assignment)
            if not sage:
                return False
            
            notification_data = {
                "operation": operation,
                "document_path": str(doc_info.new_path),
                "category": doc_info.category,
                "subcategory": doc_info.subcategory,
                "title": doc_info.title,
                "security_score": doc_info.security_score,
                "iron_will_compliant": doc_info.iron_will_compliant,
                "timestamp": datetime.now().isoformat()
            }
            
            # è³¢è€…ã¸ã®é€šçŸ¥å®Ÿè¡Œï¼ˆå®Ÿè£…ã¯è³¢è€…å´ã«ä¾å­˜ï¼‰
            if hasattr(sage, 'notify_document_change'):
                sage.notify_document_change(notification_data)
            
            self.logger.info(f"4è³¢è€…é€šçŸ¥æˆåŠŸ: {doc_info.sage_assignment} - {operation}")
            return True
            
        except Exception as e:
            self.logger.error(f"4è³¢è€…é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def classify_and_move_secure(self, dry_run: bool = True, add_metadata: bool = True) -> ClassificationResult:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªåˆ†é¡ãƒ»ç§»å‹•å‡¦ç†"""
        result = ClassificationResult()
        
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
            if not dry_run:
                self.create_directory_structure()
            
            # Markdownãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            md_files = []
            for pattern in ["**/*.md", "*.md"]:
                found_files = list(self.base_path.glob(pattern))
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                for f in found_files:
                    try:
                        resolved = f.resolve()
                        if str(resolved).startswith(str(self.base_path)) and not str(resolved).startswith(str(self.docs_path)):
                            md_files.append(resolved)
                    except Exception as e:
                        self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è§£æ±ºã‚¨ãƒ©ãƒ¼ {f}: {e}")
            
            result.total_files = len(md_files)
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            for file_path in md_files:
                try:
                    result.processed_files += 1
                    
                    doc_info = self.classify_document(file_path)
                    if doc_info is None:
                        result.skipped_files += 1
                        continue
                    
                    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é•åã‚«ã‚¦ãƒ³ãƒˆ
                    if doc_info.security_score < 70:
                        result.security_violations += 1
                    
                    if not doc_info.iron_will_compliant:
                        result.iron_will_violations += 1
                    
                    # è³¢è€…å‰²ã‚Šå½“ã¦ã‚«ã‚¦ãƒ³ãƒˆ
                    if doc_info.sage_assignment:
                        result.sage_assignments[doc_info.sage_assignment] = result.sage_assignments.get(doc_info.sage_assignment, 0) + 1
                    
                    if not dry_run:
                        # ã‚»ã‚­ãƒ¥ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
                        if self.secure_move_file(file_path, doc_info.new_path):
                            result.moved_files += 1
                            
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                            if add_metadata:
                                content = self._read_file_content(doc_info.new_path)
                                enhanced_content = self.generate_metadata(doc_info, content)
                                doc_info.new_path.write_text(enhanced_content, encoding='utf-8')
                            
                            # 4è³¢è€…é€šçŸ¥
                            self.notify_four_sages(doc_info, "document_moved")
                        else:
                            result.error_files += 1
                    else:
                        result.moved_files += 1  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã§ã¯æˆåŠŸã¨ã—ã¦æ‰±ã†
                
                except Exception as e:
                    self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                    result.error_files += 1
            
            self.logger.info(f"åˆ†é¡å‡¦ç†å®Œäº†: {result.processed_files}/{result.total_files} files")
            
        except Exception as e:
            self.logger.error(f"åˆ†é¡ãƒ»ç§»å‹•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _matches_patterns(self, filename: str, patterns: List[str]) -> bool:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰"""
        filename_lower = filename.lower()
        for pattern in patterns:
            try:
                if re.match(pattern, filename_lower):
                    return True
            except re.error as e:
                self.logger.warning(f"æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼ {pattern}: {e}")
        return False
    
    def _determine_subcategory(self, file_path: Path, content: str, subcategories: Dict[str, List[str]]) -> str:
        """ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªæ±ºå®šï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰"""
        filename_lower = file_path.name.lower()
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆDoSå¯¾ç­–ï¼‰
        content_lower = content[:10000].lower()  # æœ€åˆã®10KB
        
        for subcategory, keywords in subcategories.items():
            for keyword in keywords:
                if keyword in filename_lower or keyword in content_lower:
                    return subcategory
        
        return list(subcategories.keys())[0]
    
    def _determine_audience(self, content: str, category: str) -> str:
        """å¯¾è±¡èª­è€…æ±ºå®š"""
        content_lower = content[:5000].lower()  # ã‚µã‚¤ã‚ºåˆ¶é™
        
        if "administrator" in content_lower or "admin" in content_lower:
            return "administrators"
        elif "developer" in content_lower or "development" in content_lower:
            return "developers"
        elif "user" in content_lower and "guide" in content_lower:
            return "users"
        elif category == "api":
            return "developers"
        elif category == "policies":
            return "all"
        else:
            return "developers"
    
    def _determine_difficulty(self, content: str) -> str:
        """é›£æ˜“åº¦æ±ºå®š"""
        content_lower = content[:5000].lower()
        
        if any(word in content_lower for word in ["quickstart", "beginner", "getting started", "basic"]):
            return "beginner"
        elif any(word in content_lower for word in ["advanced", "expert", "complex", "sophisticated"]):
            return "advanced"
        else:
            return "intermediate"
    
    def _extract_title(self, content: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º"""
        lines = content.split('\n')[:10]  # æœ€åˆã®10è¡Œã®ã¿
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                title = line[2:].strip()
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                return re.sub(r'[<>:"|?*\\]', '', title)[:100]
        return "Untitled Document"
    
    def _read_file_content(self, file_path: Path) -> str:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if file_path.stat().st_size > self.max_file_size:
                raise ValueError(f"File too large: {file_path.stat().st_size}")
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šãƒ»èª­ã¿è¾¼ã¿
            for encoding in ['utf-8', 'cp932', 'latin-1']:
                try:
                    return file_path.read_text(encoding=encoding)
                except UnicodeDecodeError:
                    continue
            
            # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼
            raise UnicodeDecodeError("All encodings failed")
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            return ""
    
    def generate_metadata(self, doc_info: DocumentInfo, content: str) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        metadata = {
            'title': doc_info.title,
            'description': self._extract_description(content),
            'category': doc_info.category,
            'subcategory': doc_info.subcategory,
            'audience': doc_info.audience,
            'difficulty': doc_info.difficulty,
            'last_updated': datetime.now().strftime('%Y-%m-%d'),
            'version': '1.0.0',
            'status': doc_info.status,
            'related_docs': [],
            'dependencies': [],
            'author': 'claude-elder',
            'reviewers': [],
            'tags': self._generate_tags(content, doc_info.category),
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»å“è³ªæƒ…å ±
            'security_score': doc_info.security_score,
            'iron_will_compliant': doc_info.iron_will_compliant,
            'sage_assignment': doc_info.sage_assignment,
            'classification_date': datetime.now().isoformat()
        }
        
        yaml_content = yaml.dump(metadata, default_flow_style=False, allow_unicode=True)
        return f"---\n{yaml_content}---\n\n{content}"
    
    def _extract_description(self, content: str) -> str:
        """èª¬æ˜æŠ½å‡ºï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰"""
        lines = content.split('\n')[:20]  # æœ€åˆã®20è¡Œ
        description_lines = []
        in_description = False
        
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                in_description = True
                continue
            elif line.startswith('#'):
                break
            elif in_description and line and not line.startswith('**'):
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                clean_line = re.sub(r'[<>:"|?*\\]', '', line)
                description_lines.append(clean_line)
                if len(' '.join(description_lines)) > 200:
                    break
        
        description = ' '.join(description_lines)[:200]
        return description if description else "No description available"
    
    def _generate_tags(self, content: str, category: str) -> List[str]:
        """ã‚¿ã‚°ç”Ÿæˆï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰"""
        tags = [category]
        content_lower = content[:5000].lower()  # ã‚µã‚¤ã‚ºåˆ¶é™
        
        tech_tags = {
            'python': 'python',
            'docker': 'docker', 
            'postgres': 'postgresql',
            'redis': 'redis',
            'a2a': 'a2a-protocol',
            'elder tree': 'elder-tree',
            'four sages': 'four-sages',
            'tdd': 'tdd',
            'pytest': 'testing'
        }
        
        for keyword, tag in tech_tags.items():
            if keyword in content_lower:
                tags.append(tag)
        
        return list(set(tags))[:10]  # æœ€å¤§10ã‚¿ã‚°
    
    def create_directory_structure(self):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ"""
        categories = {
            'guides': ['user-guides', 'developer-guides', 'administrator-guides', 'workflow-guides'],
            'technical': ['architecture', 'implementation', 'specifications', 'deployment', 'research'],
            'reports': ['development', 'quality', 'analysis', 'operations'],
            'policies': ['development', 'quality', 'operations', 'governance'],
            'api': ['reference', 'guides', 'schemas', 'examples'],
            'projects': ['active', 'completed', 'planning'],
            'temp': ['security_review', 'processing']  # ä¸€æ™‚ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨
        }
        
        for category, subcategories in categories.items():
            for subcategory in subcategories:
                path = self.secure_path_join(self.docs_path, category, subcategory)
                if path:
                    path.mkdir(parents=True, exist_ok=True)


def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(description='ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ã‚»ã‚­ãƒ¥ã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ãƒ„ãƒ¼ãƒ« v2.0')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®ç§»å‹•ã¯è¡Œã‚ãªã„ï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼‰')
    parser.add_argument('--no-metadata', action='store_true', help='ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãªã„')
    parser.add_argument('--base-path', default='/home/aicompany/ai_co', help='ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    classifier = SecureDocumentClassifier(args.base_path)
    
    print("ğŸ›ï¸ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ã‚»ã‚­ãƒ¥ã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ v2.0 é–‹å§‹")
    print(f"ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: {args.base_path}")
    print(f"ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: {'æœ‰åŠ¹' if args.dry_run else 'ç„¡åŠ¹'}")
    print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ : {'ç„¡åŠ¹' if args.no_metadata else 'æœ‰åŠ¹'}")
    print(f"4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ : {'æœ‰åŠ¹' if FOUR_SAGES_AVAILABLE else 'ç„¡åŠ¹'}")
    print()
    
    result = classifier.classify_and_move_secure(
        dry_run=args.dry_run,
        add_metadata=not args.no_metadata
    )
    
    print("ğŸ“Š å®Ÿè¡Œçµæœ:")
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {result.total_files}")
    print(f"å‡¦ç†å¯¾è±¡: {result.processed_files}")
    print(f"ç§»å‹•æˆåŠŸ: {result.moved_files}")
    print(f"ã‚¹ã‚­ãƒƒãƒ—: {result.skipped_files}")
    print(f"ã‚¨ãƒ©ãƒ¼: {result.error_files}")
    print(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é•å: {result.security_violations}")
    print(f"Iron Willé•å: {result.iron_will_violations}")
    
    if result.sage_assignments:
        print("\nğŸ§™â€â™‚ï¸ è³¢è€…åˆ¥å‰²ã‚Šå½“ã¦:")
        for sage, count in result.sage_assignments.items():
            print(f"  {sage}: {count}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # å“è³ªåˆ¤å®š
    if result.processed_files > 0:
        success_rate = (result.moved_files / result.processed_files) * 100
        security_compliance = ((result.processed_files - result.security_violations) / result.processed_files) * 100
        iron_will_compliance = ((result.processed_files - result.iron_will_violations) / result.processed_files) * 100
        
        print(f"\nğŸ“ˆ å“è³ªæŒ‡æ¨™:")
        print(f"å‡¦ç†æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æº–æ‹ ç‡: {security_compliance:.1f}%")
        print(f"Iron Willæº–æ‹ ç‡: {iron_will_compliance:.1f}%")
        
        # ç·åˆåˆ¤å®š
        if success_rate >= 95 and security_compliance >= 90 and iron_will_compliance >= 95:
            print("\nâœ… å“è³ªåˆ¤å®š: Iron WillåŸºæº–å®Œå…¨æº–æ‹ ")
        elif success_rate >= 90 and security_compliance >= 80:
            print("\nâš ï¸ å“è³ªåˆ¤å®š: åŸºæº–é”æˆï¼ˆæ”¹å–„ä½™åœ°ã‚ã‚Šï¼‰")
        else:
            print("\nâŒ å“è³ªåˆ¤å®š: æ”¹å–„å¿…è¦")
    
    print(f"\nğŸ¯ åˆ†é¡å®Œäº†: {'ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰' if args.dry_run else 'å®Ÿéš›ã«å®Ÿè¡Œ'}")
    print("ğŸ›ï¸ Iron Will: No Workarounds! ğŸ—¡ï¸")

if __name__ == "__main__":
    main()