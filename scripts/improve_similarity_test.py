#!/usr/bin/env python3
"""
é¡ä¼¼åº¦å‘ä¸Šãƒ†ã‚¹ãƒˆ
ã‚ˆã‚Šé«˜ã„é¡ä¼¼åº¦ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’æ¤œè¨¼
"""

import os
import sys
import asyncio
import asyncpg
import numpy as np
from datetime import datetime
import json

# OpenAIè¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

from openai import OpenAI

client = OpenAI(api_key=OPENAI_API_KEY)


async def test_similarity_improvements():
    """é¡ä¼¼åº¦å‘ä¸Šã®ãƒ†ã‚¹ãƒˆ"""

    print("ğŸ”¬ é¡ä¼¼åº¦å‘ä¸Šãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = await asyncpg.connect(
        host="localhost",
        port=5432,
        database="elders_knowledge",
        user="elders_guild",
        password="elders_2025",
    )

    try:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
        await conn.execute("TRUNCATE knowledge_base.vector_documents")

        # 1. ã‚ˆã‚Šå…·ä½“çš„ã§è©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆ
        print("1ï¸âƒ£ è©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒ†ã‚¹ãƒˆ")

        detailed_texts = [
            # ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰é–¢é€£ï¼ˆã‚ˆã‚Šè©³ç´°ã«ï¼‰
            """ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã¯4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã§æ§‹æˆã•ã‚Œã‚‹éšå±¤çš„ãªé–‹ç™ºçµ„ç¹”ã§ã™ã€‚
            4è³¢è€…ã¨ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ï¼ˆKnowledge Sageï¼‰ã€ã‚¿ã‚¹ã‚¯è³¢è€…ï¼ˆTask Oracleï¼‰ã€
            ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ï¼ˆCrisis Sageï¼‰ã€RAGè³¢è€…ï¼ˆSearch Mysticï¼‰ã®4ã¤ã®å°‚é–€å®¶ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
            ã“ã‚Œã‚‰ã®è³¢è€…ã¯ãã‚Œãã‚ŒçŸ¥è­˜ç®¡ç†ã€ã‚¿ã‚¹ã‚¯ç®¡ç†ã€å±æ©Ÿå¯¾å¿œã€æƒ…å ±æ¤œç´¢ã‚’æ‹…å½“ã—ã¾ã™ã€‚""",
            """4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã¨ãªã‚‹ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã¯ã€éå»ã®é–‹ç™ºçŸ¥è­˜ã‚’è“„ç©ã—ã€
            å°†æ¥ã®é–‹ç™ºã«æ´»ã‹ã™ãŸã‚ã®çŸ¥è­˜ç®¡ç†ã‚’è¡Œã„ã¾ã™ã€‚CLAUDE.mdãªã©ã®é‡è¦æ–‡æ›¸ã‚’ç®¡ç†ã—ã€
            ãƒãƒ¼ãƒ å…¨ä½“ã®çŸ¥è­˜å…±æœ‰ã‚’ä¿ƒé€²ã™ã‚‹å½¹å‰²ã‚’æŒã£ã¦ã„ã¾ã™ã€‚""",
            """ã‚¿ã‚¹ã‚¯è³¢è€…ã¯4è³¢è€…ã®ä¸€å“¡ã¨ã—ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¿ã‚¹ã‚¯ç®¡ç†ã¨é€²æ—è¿½è·¡ã‚’æ‹…å½“ã—ã¾ã™ã€‚
            å„ªå…ˆé †ä½ã®åˆ¤æ–­ã€ä¾å­˜é–¢ä¿‚ã®åˆ†æã€æœ€é©ãªå®Ÿè¡Œé †åºã®æ±ºå®šãªã©ã‚’è¡Œã„ã€
            ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰å…¨ä½“ã®é–‹ç™ºåŠ¹ç‡ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚""",
            """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã¯4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã®å±æ©Ÿç®¡ç†æ‹…å½“ã¨ã—ã¦ã€
            ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã€ãƒã‚°ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œãªã©ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã«å³åº§ã«å¯¾å¿œã—ã¾ã™ã€‚
            éå»ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå±¥æ­´ã‹ã‚‰å­¦ç¿’ã—ã€äºˆé˜²çš„ãªå¯¾ç­–ã‚‚ææ¡ˆã—ã¾ã™ã€‚""",
            """RAGè³¢è€…ï¼ˆRetrieval-Augmented Generation Sageï¼‰ã¯4è³¢è€…ã®æƒ…å ±æ¤œç´¢å°‚é–€å®¶ã§ã™ã€‚
            å¤§é‡ã®æ–‡æ›¸ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’é«˜é€Ÿã«æ¤œç´¢ã—ã€å¿…è¦ãªçŸ¥è­˜ã‚’çµ±åˆã—ã¦æä¾›ã—ã¾ã™ã€‚
            pgvectorã‚’æ´»ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã‚ˆã‚Šã€æ„å‘³çš„ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’ç™ºè¦‹ã—ã¾ã™ã€‚""",
        ]

        # Embeddingã‚’ç”Ÿæˆã—ã¦ä¿å­˜
        for i, text in enumerate(detailed_texts):
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=text
            )
            embedding = response.data[0].embedding

            await conn.execute(
                """
                INSERT INTO knowledge_base.vector_documents
                (title, content, embedding, metadata)
                VALUES ($1, $2, $3::vector, $4)
            """,
                f"è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i+1}",
                text,
                str(embedding),
                json.dumps(
                    {
                        "type": "detailed",
                        "sage_type": (
                            ["knowledge", "task", "incident", "rag"][i]
                            if i < 4
                            else "general"
                        ),
                    }
                ),
            )

        # ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ
        test_queries = [
            "4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ä½•ã§ã™ã‹",
            "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã«ã¤ã„ã¦",
            "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã«ã¤ã„ã¦",
        ]

        print("\nè©³ç´°ãƒ†ã‚­ã‚¹ãƒˆã§ã®æ¤œç´¢çµæœ:")
        for query in test_queries:
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=query
            )
            query_embedding = response.data[0].embedding

            results = await conn.fetch(
                """
                SELECT
                    title,
                    substring(content, 1, 50) as content_preview,
                    1 - (embedding <=> $1::vector) as similarity
                FROM knowledge_base.vector_documents
                ORDER BY embedding <=> $1::vector
                LIMIT 1
            """,
                str(query_embedding),
            )

            if results:
                print(f"ã‚¯ã‚¨ãƒª: '{query}'")
                print(f"  â†’ é¡ä¼¼åº¦: {results[0]['similarity']:.4f}")

        # 2. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆ
        print("\n\n2ï¸âƒ£ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆ")

        # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        long_text = """ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã¯é©æ–°çš„ãªé–‹ç™ºçµ„ç¹”ã§ã™ã€‚
        ãã®ä¸­æ ¸ã¨ãªã‚‹ã®ãŒ4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
        4è³¢è€…ã¨ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã®4ã¤ã§ã™ã€‚
        å„è³¢è€…ã¯å°‚é–€åˆ†é‡ã‚’æŒã¡ã€å”èª¿ã—ã¦å‹•ä½œã—ã¾ã™ã€‚
        ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã¯çŸ¥è­˜ç®¡ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚
        ã‚¿ã‚¹ã‚¯è³¢è€…ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚
        ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã¯å•é¡Œè§£æ±ºã‚’æ‹…å½“ã—ã¾ã™ã€‚
        RAGè³¢è€…ã¯æƒ…å ±æ¤œç´¢ã‚’æ‹…å½“ã—ã¾ã™ã€‚"""

        sentences = [s.strip() for s in long_text.split("ã€‚") if s.strip()]

        # å„æ–‡ã‚’embeddingåŒ–
        for i, sentence in enumerate(sentences):
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=sentence
            )
            embedding = response.data[0].embedding

            await conn.execute(
                """
                INSERT INTO knowledge_base.vector_documents
                (title, content, embedding, metadata)
                VALUES ($1, $2, $3::vector, $4)
            """,
                f"ãƒãƒ£ãƒ³ã‚¯{i+1}",
                sentence,
                str(embedding),
                json.dumps({"type": "chunk", "chunk_index": i}),
            )

        # åŒã˜ã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ
        query = "4è³¢è€…ã¨ã¯"
        response = client.embeddings.create(model="text-embedding-ada-002", input=query)
        query_embedding = response.data[0].embedding

        results = await conn.fetch(
            """
            SELECT
                title,
                content,
                1 - (embedding <=> $1::vector) as similarity
            FROM knowledge_base.vector_documents
            WHERE metadata->>'type' = 'chunk'
            ORDER BY embedding <=> $1::vector
            LIMIT 3
        """,
            str(query_embedding),
        )

        print("\nãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã§ã®æ¤œç´¢çµæœ:")
        print(f"ã‚¯ã‚¨ãƒª: '{query}'")
        for row in results:
            print(
                f"  {row['title']} (é¡ä¼¼åº¦: {row['similarity']:.4f}): {row['content']}"
            )

        # 3. å‰å‡¦ç†ã«ã‚ˆã‚‹æ”¹å–„
        print("\n\n3ï¸âƒ£ å‰å‡¦ç†ã«ã‚ˆã‚‹æ”¹å–„ãƒ†ã‚¹ãƒˆ")

        # æ­£è¦åŒ–ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼·èª¿
        def preprocess_text(text):
            """preprocess_textã‚’å‡¦ç†"""
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¼·èª¿
            keywords = [
                "4è³¢è€…",
                "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰",
                "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…",
                "ã‚¿ã‚¹ã‚¯è³¢è€…",
                "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…",
                "RAGè³¢è€…",
            ]
            for keyword in keywords:
                text = text.replace(keyword, f"{keyword} {keyword}")  # é‡è¦èªã‚’ç¹°ã‚Šè¿”ã™
            return text

        preprocessed_text = preprocess_text(
            "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚"
        )

        response = client.embeddings.create(
            model="text-embedding-ada-002", input=preprocessed_text
        )
        embedding = response.data[0].embedding

        await conn.execute(
            """
            INSERT INTO knowledge_base.vector_documents
            (title, content, embedding, metadata)
            VALUES ($1, $2, $3::vector, $4)
        """,
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            preprocessed_text,
            str(embedding),
            json.dumps({"type": "preprocessed"}),
        )

        # ã‚¯ã‚¨ãƒªã‚‚åŒã˜å‰å‡¦ç†ã‚’é©ç”¨
        preprocessed_query = preprocess_text("4è³¢è€…ã«ã¤ã„ã¦")
        response = client.embeddings.create(
            model="text-embedding-ada-002", input=preprocessed_query
        )
        query_embedding = response.data[0].embedding

        results = await conn.fetch(
            """
            SELECT
                title,
                1 - (embedding <=> $1::vector) as similarity
            FROM knowledge_base.vector_documents
            WHERE metadata->>'type' = 'preprocessed'
            ORDER BY embedding <=> $1::vector
            LIMIT 1
        """,
            str(query_embedding),
        )

        if results:
            print("\nå‰å‡¦ç†ã«ã‚ˆã‚‹æ”¹å–„çµæœ:")
            print(f"ã‚¯ã‚¨ãƒª: '{preprocessed_query}'")
            print(f"  â†’ é¡ä¼¼åº¦: {results[0]['similarity']:.4f}")

        # 4. æœ€çµ‚çš„ãªé¡ä¼¼åº¦æ¯”è¼ƒ
        print("\n\n4ï¸âƒ£ æœ€çµ‚æ¯”è¼ƒ")

        query = "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
        response = client.embeddings.create(model="text-embedding-ada-002", input=query)
        query_embedding = response.data[0].embedding

        all_results = await conn.fetch(
            """
            SELECT
                title,
                metadata->>'type' as doc_type,
                1 - (embedding <=> $1::vector) as similarity
            FROM knowledge_base.vector_documents
            ORDER BY embedding <=> $1::vector
            LIMIT 10
        """,
            str(query_embedding),
        )

        print(f"\nå…¨ä½“ã®é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° (ã‚¯ã‚¨ãƒª: '{query}'):")
        for i, row in enumerate(all_results):
            print(
                f"{i+1}. {row['title']} (ã‚¿ã‚¤ãƒ—: {row['doc_type']}) - é¡ä¼¼åº¦: {row['similarity']:.4f}"
            )

        # æœ€é«˜é¡ä¼¼åº¦ã‚’ç¢ºèª
        max_similarity = all_results[0]["similarity"] if all_results else 0
        print(f"\nğŸ¯ æœ€é«˜é¡ä¼¼åº¦: {max_similarity:.4f}")

        if max_similarity > 0.9:
            print("âœ… éå¸¸ã«é«˜ã„é¡ä¼¼åº¦ã‚’é”æˆã—ã¾ã—ãŸï¼")
        elif max_similarity > 0.85:
            print("â­ é«˜ã„é¡ä¼¼åº¦ã‚’é”æˆã—ã¾ã—ãŸ")
        else:
            print("ğŸ“ˆ ã•ã‚‰ãªã‚‹æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™")

        return max_similarity

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback

        traceback.print_exc()
        return 0

    finally:
        await conn.close()


if __name__ == "__main__":
    max_similarity = asyncio.run(test_similarity_improvements())
    print(f"\næœ€çµ‚çš„ãªæœ€é«˜é¡ä¼¼åº¦: {max_similarity:.4f}")
