#!/usr/bin/env python3
"""
Elders Guild ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã¨ ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½
"""

import asyncio
import json
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List

import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.lightweight_logger import get_logger


class MonitoringDashboard:
    """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.logger = get_logger("monitoring_dashboard")
        self.project_root = PROJECT_ROOT

        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_thresholds = {
            "cpu_percent": 80.0,
            "memory_percent": 85.0,
            "disk_percent": 90.0,
            "queue_length": 1000,
            "error_rate": 5.0,  # %
            "response_time": 30.0,  # seconds
        }

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´
        self.metrics_history = {
            "timestamps": [],
            "cpu": [],
            "memory": [],
            "disk": [],
            "worker_counts": [],
            "queue_sizes": [],
        }

        # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´
        self.alerts = []

        # æœ€å¤§å±¥æ­´ä»¶æ•°
        self.max_history = 1000

    def collect_system_metrics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage("/")

            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
            network = psutil.net_io_counters()

            # ãƒ—ãƒ­ã‚»ã‚¹çµ±è¨ˆ
            process_count = len(psutil.pids())

            metrics = {
                "timestamp": datetime.utcnow().isoformat(),
                "cpu": {
                    "percent": cpu_percent,
                    "count": psutil.cpu_count(),
                    "freq": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else {},
                },
                "memory": {
                    "total": memory.total,
                    "available": memory.available,
                    "percent": memory.percent,
                    "used": memory.used,
                    "free": memory.free,
                },
                "disk": {
                    "total": disk.total,
                    "used": disk.used,
                    "free": disk.free,
                    "percent": disk.percent,
                },
                "network": {
                    "bytes_sent": network.bytes_sent,
                    "bytes_recv": network.bytes_recv,
                    "packets_sent": network.packets_sent,
                    "packets_recv": network.packets_recv,
                },
                "processes": {"total": process_count},
            }

            return metrics

        except Exception as e:
            self.logger.error("Failed to collect system metrics", error=str(e))
            return {}

    def collect_worker_metrics(self) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®æ¤œå‡º
            worker_processes = {}

            for proc in psutil.process_iter(
                ["pid", "name", "cmdline", "cpu_percent", "memory_info"]
            ):
                try:
                    cmdline = " ".join(proc.info["cmdline"] or [])

                    # Elders Guildãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ¤œå‡º
                    if "worker" in cmdline and "python" in cmdline:
                        worker_name = "unknown"

                        if not ("task_worker" in cmdline):
                            continue  # Early return to reduce nesting
                        # Reduced nesting - original condition satisfied
                        if "task_worker" in cmdline:
                            worker_name = "task_worker"
                        elif "pm_worker" in cmdline:
                            worker_name = "pm_worker"
                        elif "result_worker" in cmdline:
                            worker_name = "result_worker"
                        elif "async" in cmdline:
                            if not ("task" in cmdline):
                                continue  # Early return to reduce nesting
                            # Reduced nesting - original condition satisfied
                            if "task" in cmdline:
                                worker_name = "async_task_worker"
                            elif "result" in cmdline:
                                worker_name = "async_result_worker"
                            elif "pm" in cmdline:
                                worker_name = "async_pm_worker"

                        if not (worker_name not in worker_processes):
                            continue  # Early return to reduce nesting
                        # Reduced nesting - original condition satisfied
                        if worker_name not in worker_processes:
                            worker_processes[worker_name] = []

                        worker_processes[worker_name].append(
                            {
                                "pid": proc.info["pid"],
                                "cpu_percent": proc.info["cpu_percent"],
                                "memory_mb": proc.info["memory_info"].rss / 1024 / 1024,
                            }
                        )

                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            # ãƒ¯ãƒ¼ã‚«ãƒ¼çµ±è¨ˆã®è¨ˆç®—
            worker_stats = {}
            for worker_name, processes in worker_processes.items():
                worker_stats[worker_name] = {
                    "process_count": len(processes),
                    "total_cpu_percent": sum(p["cpu_percent"] for p in processes),
                    "total_memory_mb": sum(p["memory_mb"] for p in processes),
                    "avg_cpu_percent": (
                        sum(p["cpu_percent"] for p in processes) / len(processes)
                        if processes
                        else 0
                    ),
                    "avg_memory_mb": (
                        sum(p["memory_mb"] for p in processes) / len(processes)
                        if processes
                        else 0
                    ),
                    "processes": processes,
                }

            return worker_stats

        except Exception as e:
            self.logger.error("Failed to collect worker metrics", error=str(e))
            return {}

    def collect_queue_metrics(self) -> Dict[str, Any]:
        """ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ RabbitMQ Management API ã‚’ä½¿ç”¨
        try:
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            import random

            queues = ["ai_tasks", "ai_pm", "ai_results", "worker_tasks", "dialog_tasks"]
            queue_stats = {}

            for queue in queues:
                # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ API å‘¼ã³å‡ºã—ï¼‰
                size = random.randint(0, 50)
                rate = random.uniform(0, 10)

                queue_stats[queue] = {
                    "messages": size,
                    "consumers": random.randint(0, 3),
                    "message_rate": rate,
                    "publish_rate": rate * 1.1,
                    "consume_rate": rate * 0.9,
                }

            return queue_stats

        except Exception as e:
            self.logger.error("Failed to collect queue metrics", error=str(e))
            return {}

    def check_alerts(
        self, system_metrics: Dict, worker_metrics: Dict, queue_metrics: Dict
    ):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        current_time = datetime.utcnow()
        new_alerts = []

        # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if (
            system_metrics.get("cpu", {}).get("percent", 0)
            > self.alert_thresholds["cpu_percent"]
        ):
            new_alerts.append(
                {
                    "type": "cpu_high",
                    "severity": "warning",
                    "message": f"High CPU usage: {system_metrics['cpu']['percent']:.1f}%",
                    "value": system_metrics["cpu"]["percent"],
                    "threshold": self.alert_thresholds["cpu_percent"],
                    "timestamp": current_time.isoformat(),
                }
            )

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if (
            system_metrics.get("memory", {}).get("percent", 0)
            > self.alert_thresholds["memory_percent"]
        ):
            new_alerts.append(
                {
                    "type": "memory_high",
                    "severity": "warning",
                    "message": f"High memory usage: {system_metrics['memory']['percent']:.1f}%",
                    "value": system_metrics["memory"]["percent"],
                    "threshold": self.alert_thresholds["memory_percent"],
                    "timestamp": current_time.isoformat(),
                }
            )

        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if (
            system_metrics.get("disk", {}).get("percent", 0)
            > self.alert_thresholds["disk_percent"]
        ):
            new_alerts.append(
                {
                    "type": "disk_high",
                    "severity": "critical",
                    "message": f"High disk usage: {system_metrics['disk']['percent']:.1f}%",
                    "value": system_metrics["disk"]["percent"],
                    "threshold": self.alert_thresholds["disk_percent"],
                    "timestamp": current_time.isoformat(),
                }
            )

        # ãƒ¯ãƒ¼ã‚«ãƒ¼åœæ­¢ãƒã‚§ãƒƒã‚¯
        expected_workers = ["task_worker", "pm_worker", "result_worker"]
        for worker in expected_workers:
            if (
                worker not in worker_metrics
                or worker_metrics[worker]["process_count"] == 0
            ):
                new_alerts.append(
                    {
                        "type": "worker_down",
                        "severity": "critical",
                        "message": f"Worker {worker} is not running",
                        "worker": worker,
                        "timestamp": current_time.isoformat(),
                    }
                )

        # ã‚­ãƒ¥ãƒ¼é•·ãƒã‚§ãƒƒã‚¯
        for queue_name, stats in queue_metrics.items():
            if stats.get("messages", 0) > self.alert_thresholds["queue_length"]:
                new_alerts.append(
                    {
                        "type": "queue_backlog",
                        "severity": "warning",
                        "message": f"Queue {queue_name} has {stats['messages']} messages",
                        "queue": queue_name,
                        "value": stats["messages"],
                        "threshold": self.alert_thresholds["queue_length"],
                        "timestamp": current_time.isoformat(),
                    }
                )

        # æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å±¥æ­´ã«è¿½åŠ 
        self.alerts.extend(new_alerts)

        # å¤ã„ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff_time = current_time - timedelta(hours=24)
        self.alerts = [
            alert
            for alert in self.alerts
            if datetime.fromisoformat(alert["timestamp"]) > cutoff_time
        ]

        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ­ã‚°
        for alert in new_alerts:
            alert_data = alert.copy()
            alert_message = alert_data.pop("message", "Alert triggered")
            self.logger.warning(alert_message, **alert_data)

        return new_alerts

    def update_metrics_history(self, system_metrics: Dict, worker_metrics: Dict):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã®æ›´æ–°"""
        current_time = datetime.utcnow()

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¿½åŠ 
        self.metrics_history["timestamps"].append(current_time.isoformat())

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ 
        self.metrics_history["cpu"].append(
            system_metrics.get("cpu", {}).get("percent", 0)
        )
        self.metrics_history["memory"].append(
            system_metrics.get("memory", {}).get("percent", 0)
        )
        self.metrics_history["disk"].append(
            system_metrics.get("disk", {}).get("percent", 0)
        )

        # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°è¿½åŠ 
        total_workers = sum(
            stats.get("process_count", 0) for stats in worker_metrics.values()
        )
        self.metrics_history["worker_counts"].append(total_workers)

        # å±¥æ­´ã‚µã‚¤ã‚ºã®åˆ¶é™
        for key in self.metrics_history:
            if len(self.metrics_history[key]) > self.max_history:
                self.metrics_history[key] = self.metrics_history[key][
                    -self.max_history :
                ]

    def generate_dashboard_data(self) -> Dict[str, Any]:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        system_metrics = self.collect_system_metrics()
        worker_metrics = self.collect_worker_metrics()
        queue_metrics = self.collect_queue_metrics()

        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        new_alerts = self.check_alerts(system_metrics, worker_metrics, queue_metrics)

        # å±¥æ­´æ›´æ–°
        self.update_metrics_history(system_metrics, worker_metrics)

        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        dashboard_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "system": system_metrics,
            "workers": worker_metrics,
            "queues": queue_metrics,
            "alerts": {
                "active": [
                    a
                    for a in self.alerts
                    if a["timestamp"]
                    > (datetime.utcnow() - timedelta(hours=1)).isoformat()
                ],
                "recent": new_alerts,
                "total_count": len(self.alerts),
            },
            "history": {
                "last_24h": {
                    "timestamps": self.metrics_history["timestamps"][
                        -144:
                    ],  # 10åˆ†é–“éš”ã§24æ™‚é–“
                    "cpu": self.metrics_history["cpu"][-144:],
                    "memory": self.metrics_history["memory"][-144:],
                    "worker_counts": self.metrics_history["worker_counts"][-144:],
                }
            },
            "summary": {
                "total_workers": sum(
                    stats.get("process_count", 0) for stats in worker_metrics.values()
                ),
                "active_alerts": len(
                    [
                        a
                        for a in self.alerts
                        if a["timestamp"]
                        > (datetime.utcnow() - timedelta(hours=1)).isoformat()
                    ]
                ),
                "system_health": (
                    "healthy"
                    if not new_alerts
                    else (
                        "warning"
                        if any(a["severity"] == "warning" for a in new_alerts)
                        else "critical"
                    )
                ),
            },
        }

        return dashboard_data

    def print_dashboard(self, data: Dict[str, Any]):
        """ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ–¥ï¸  Elders Guild Monitoring Dashboard")
        print("=" * 80)
        print(f"ğŸ“… Time: {data['timestamp']}")
        print(f"ğŸ¥ Health: {data['summary']['system_health'].upper()}")

        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        print(f"\nğŸ“Š System Metrics:")
        if "system" in data:
            sys_data = data["system"]
            print(f"  ğŸ’» CPU: {sys_data.get('cpu', {}).get('percent', 0):.1f}%")
            print(f"  ğŸ§  Memory: {sys_data.get('memory', {}).get('percent', 0):.1f}%")
            print(f"  ğŸ’¾ Disk: {sys_data.get('disk', {}).get('percent', 0):.1f}%")

        # ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹
        print(f"\nğŸ‘· Workers ({data['summary']['total_workers']} total):")
        for worker_name, stats in data.get("workers", {}).items():
            status = "ğŸŸ¢" if stats["process_count"] > 0 else "ğŸ”´"
            print(
                f"  {status} {worker_name}: {stats['process_count']} processes, "
                f"CPU {stats['avg_cpu_percent']:.1f}%, "
                f"Memory {stats['avg_memory_mb']:.1f}MB"
            )

        # ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹
        print(f"\nğŸ“¬ Queues:")
        for queue_name, stats in data.get("queues", {}).items():
            status = "âš ï¸" if stats["messages"] > 100 else "âœ…"
            print(
                f"  {status} {queue_name}: {stats['messages']} messages, "
                f"{stats['consumers']} consumers"
            )

        # ã‚¢ãƒ©ãƒ¼ãƒˆ
        active_alerts = data.get("alerts", {}).get("active", [])
        if active_alerts:
            print(f"\nğŸš¨ Active Alerts ({len(active_alerts)}):")
            for alert in active_alerts[-5:]:  # æœ€æ–°5ä»¶
                severity_icon = {"critical": "ğŸ”´", "warning": "âš ï¸", "info": "â„¹ï¸"}.get(
                    alert["severity"], "â“"
                )
                print(f"  {severity_icon} {alert['message']}")
        else:
            print(f"\nâœ… No active alerts")

        print("=" * 80)

    async def run_monitoring_loop(self, interval: int = 60):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ"""
        self.logger.info("Starting monitoring loop", interval=interval)

        try:
            while True:
                dashboard_data = self.generate_dashboard_data()
                self.print_dashboard(dashboard_data)

                # ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                data_file = self.project_root / "data" / "monitoring_data.json"
                data_file.parent.mkdir(exist_ok=True)

                with open(data_file, "w") as f:
                    json.dump(dashboard_data, f, indent=2)

                await asyncio.sleep(interval)

        except KeyboardInterrupt:
            self.logger.info("Monitoring stopped by user")
        except Exception as e:
            self.logger.error("Monitoring loop error", error=str(e))


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Elders Guild Monitoring Dashboard")
    parser.add_argument(
        "--interval",
        type=int,
        default=60,
        help="Monitoring interval in seconds (default: 60)",
    )
    parser.add_argument("--once", action="store_true", help="Run once and exit")

    args = parser.parse_args()

    dashboard = MonitoringDashboard()

    if args.once:
        # ä¸€å›ã ã‘å®Ÿè¡Œ
        data = dashboard.generate_dashboard_data()
        dashboard.print_dashboard(data)

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
        data_file = Path(__file__).parent.parent / "data" / "monitoring_data.json"
        data_file.parent.mkdir(exist_ok=True)

        with open(data_file, "w") as f:
            import json

            json.dump(data, f, indent=2)
    else:
        # ç¶™ç¶šç›£è¦–
        try:
            asyncio.run(dashboard.run_monitoring_loop(args.interval))
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Monitoring stopped")


if __name__ == "__main__":
    main()
