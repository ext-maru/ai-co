#!/usr/bin/env python3
"""
pgvector å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼†å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
çŸ¥è­˜ã®ã‚³ã‚¢éƒ¨åˆ† - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢åŸºç›¤ã®å®Œå…¨å®Ÿè£…
"""

import os
import sys
import asyncio
import asyncpg
import numpy as np
from datetime import datetime
import json

# OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("   source /home/aicompany/ai_co/.env ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    sys.exit(1)

from openai import OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

async def setup_pgvector():
    """pgvector ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨å‹•ä½œç¢ºèª"""

    print("ğŸ˜ pgvector å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = await asyncpg.connect(
        host='localhost',
        port=5432,
        database='elders_knowledge',
        user='elders_guild',
        password='elders_2025'
    )

    try:
        # 1. pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®ä½œæˆã‚’è©¦ã¿ã‚‹
        print("ğŸ“¦ pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–...")
        try:
            await conn.execute('CREATE EXTENSION IF NOT EXISTS vector')
            print("âœ… pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ pgvectoræœ‰åŠ¹åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print("\nâš ï¸  ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
            print("cd /tmp/pgvector_install/pgvector")
            print("sudo make install")
            print("ãã®å¾Œã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return False

        # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        print("\nğŸ“‹ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­...")
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS knowledge_base.vector_documents (
                id SERIAL PRIMARY KEY,
                title VARCHAR(255) NOT NULL,
                content TEXT NOT NULL,
                embedding vector(1536),  -- OpenAI ada-002ã®æ¬¡å…ƒæ•°
                metadata JSONB DEFAULT '{}',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_vector_documents_embedding
            ON knowledge_base.vector_documents
            USING ivfflat (embedding vector_cosine_ops)
            WITH (lists = 100)
        """)

        print("âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

        # 3. OpenAI APIã§embeddingç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\nğŸ¤– OpenAI embeddingç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        test_texts = [
            "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã¯4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã§æ§‹æˆã•ã‚Œã‚‹",
            "TDDï¼ˆãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼‰ã¯Red-Green-Refactorã‚µã‚¤ã‚¯ãƒ«",
            "pgvectorã¯é«˜é€Ÿãªãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹"
        ]

        embeddings = []
        for text in test_texts:
            response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=text
            )
            embedding = response.data[0].embedding
            embeddings.append(embedding)
            print(f"âœ… Embeddingç”ŸæˆæˆåŠŸ: {text[:30]}... (æ¬¡å…ƒ: {len(embedding)})")

        # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
        print("\nğŸ’¾ ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­...")
        for i, (text, embedding) in enumerate(zip(test_texts, embeddings)):
            await conn.execute("""
                INSERT INTO knowledge_base.vector_documents
                (title, content, embedding, metadata)
                VALUES ($1, $2, $3::vector, $4)
            """,
                f"ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i+1}",
                text,
                str(embedding),  # ãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                json.dumps({"test": True, "index": i})
            )
        print("âœ… 3ä»¶ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

        # 5. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        print("\nğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ...")
        query_text = "4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦"

        # ã‚¯ã‚¨ãƒªã®embeddingç”Ÿæˆ
        query_response = client.embeddings.create(
            model="text-embedding-ada-002",
            input=query_text
        )
        query_embedding = query_response.data[0].embedding

        # é¡ä¼¼æ¤œç´¢å®Ÿè¡Œ
        results = await conn.fetch("""
            SELECT
                id,
                title,
                content,
                1 - (embedding <=> $1::vector) as similarity
            FROM knowledge_base.vector_documents
            ORDER BY embedding <=> $1::vector
            LIMIT 3
        """, str(query_embedding))

        print(f"\nã‚¯ã‚¨ãƒª: '{query_text}'")
        print("æ¤œç´¢çµæœ:")
        for row in results:
            print(f"  - {row['title']} (é¡ä¼¼åº¦: {row['similarity']:.4f})")
            print(f"    å†…å®¹: {row['content'][:60]}...")

        # 6. çµ±è¨ˆæƒ…å ±
        count = await conn.fetchval("""
            SELECT COUNT(*) FROM knowledge_base.vector_documents
        """)

        print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±:")
        print(f"  - ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {count}")
        print(f"  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ—: IVFFlat")
        print(f"  - ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•°: 1536")

        print("\nğŸ‰ pgvectorå®Œå…¨å‹•ä½œç¢ºèªæˆåŠŸï¼")
        print("=" * 60)

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "pgvector_enabled": True,
            "test_documents": count,
            "embedding_model": "text-embedding-ada-002",
            "vector_dimension": 1536,
            "search_results": [
                {
                    "title": row['title'],
                    "similarity": float(row['similarity'])
                } for row in results
            ]
        }

        with open('pgvector_setup_result.json', 'w') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        return True

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        await conn.close()

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    success = await setup_pgvector()

    if success:
        print("\nâœ… çŸ¥è­˜ã®ã‚³ã‚¢éƒ¨åˆ†ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰ãŒå®Œå…¨ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        print("\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. CLAUDE.mdãªã©ã®é‡è¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç§»è¡Œ")
        print("2. 4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ")
        print("3. æœ¬æ ¼çš„ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")
    else:
        print("\nâš ï¸  ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒæœªå®Œäº†ã§ã™")
        print("ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€pgvectorã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    asyncio.run(main())
