#!/usr/bin/env python3
"""
PostgreSQL MCPçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ (ä¿®æ­£ç‰ˆ)
æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½
"""

import os
import sys
import asyncio
import asyncpg
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
import unittest
from unittest.mock import Mock, patch

# OpenAIè¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

from openai import OpenAI

client = OpenAI(api_key=OPENAI_API_KEY)


class PostgreSQLMCPIntegrationTest:
    """PostgreSQL MCPçµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ï¼ˆæ—¢å­˜DBä½¿ç”¨ç‰ˆï¼‰"""

    def __init__(self):
        self.conn = None
        self.test_results = []
        self.fallback_results = []

    async def setup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ—¢å­˜DBä½¿ç”¨ï¼‰"""
        print("ğŸ”§ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹...")

        # æ—¢å­˜ã®elders_knowledge DBã«æ¥ç¶š
        self.conn = await asyncpg.connect(
            host="localhost",
            port=5432,
            database="elders_knowledge",
            user="elders_guild",
            password="elders_2025",
        )

        # ãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¸€æ™‚çš„ã«ä½œæˆ
        await self.conn.execute(
            """
            CREATE TABLE IF NOT EXISTS knowledge_base.mcp_test_temp (
                id SERIAL PRIMARY KEY,
                content TEXT,
                embedding vector(1536),
                created_at TIMESTAMP DEFAULT NOW()
            )
        """
        )

        # ãƒ†ã‚¹ãƒˆç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        await self.conn.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_mcp_test_embedding
            ON knowledge_base.mcp_test_temp
            USING ivfflat (embedding vector_cosine_ops) WITH (lists = 10)
        """
        )

        print("âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    async def test_basic_connectivity(self):
        """åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        test_name = "åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ"
        print(f"\nğŸ” {test_name}...")

        try:
            # æ¥ç¶šç¢ºèª
            result = await self.conn.fetchval("SELECT 1")
            assert result == 1, "åŸºæœ¬æ¥ç¶šå¤±æ•—"

            # pgvectorç¢ºèª
            result = await self.conn.fetchval(
                "SELECT 1 FROM pg_extension WHERE extname = 'vector'"
            )
            assert result == 1, "pgvectoræ‹¡å¼µãŒè¦‹ã¤ã‹ã‚‰ãªã„"

            # æ—¢å­˜ã®core_documentsãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
            result = await self.conn.fetchval(
                """
                SELECT COUNT(*) FROM knowledge_base.core_documents
            """
            )

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f"æ¥ç¶šOKã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {result}ä»¶",
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_existing_vector_search(self):
        """æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
        test_name = "æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ"
        print(f"\nğŸ” {test_name}...")

        try:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸæ¤œç´¢ãƒ†ã‚¹ãƒˆ
            query = "4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=query
            )
            query_embedding = response.data[0].embedding

            start_time = time.time()
            results = await self.conn.fetch(
                """
                SELECT
                    section_title,
                    section_content,
                    1 - (embedding <=> $1::vector) as similarity
                FROM knowledge_base.core_documents
                ORDER BY embedding <=> $1::vector
                LIMIT 5
            """,
                str(query_embedding),
            )
            end_time = time.time()

            search_time = (end_time - start_time) * 1000  # ãƒŸãƒªç§’

            assert len(results) > 0, "æ¤œç´¢çµæœãŒç©º"
            assert search_time < 200, f"æ¤œç´¢æ™‚é–“ãŒé…ã„: {search_time}ms"

            best_similarity = results[0]["similarity"]
            assert best_similarity > 0.3, f"é¡ä¼¼åº¦ãŒä½ã„: {best_similarity}"

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f"æ¤œç´¢æ™‚é–“: {search_time:.2f}ms, æœ€é«˜é¡ä¼¼åº¦: {best_similarity:.3f}",
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ (æ™‚é–“: {search_time:.2f}ms)")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_mcp_interface_simulation(self):
        """MCP ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        test_name = "MCP ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
        print(f"\nğŸ” {test_name}...")

        try:
            # MCPé¢¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ
            class PostgreSQLMCPInterface:
                def __init__(self, conn):
                    self.conn = conn

                async def search_knowledge(
                    self, query: str, limit: int = 5
                ) -> List[Dict]:
                    """çŸ¥è­˜æ¤œç´¢ (MCPé¢¨)"""
                    response = client.embeddings.create(
                        model="text-embedding-ada-002", input=query
                    )
                    query_embedding = response.data[0].embedding

                    results = await self.conn.fetch(
                        """
                        SELECT
                            section_title,
                            section_content,
                            section_type,
                            1 - (embedding <=> $1::vector) as similarity
                        FROM knowledge_base.core_documents
                        ORDER BY embedding <=> $1::vector
                        LIMIT $2
                    """,
                        str(query_embedding),
                        limit,
                    )

                    return [
                        {
                            "title": r["section_title"],
                            "content": (
                                r["section_content"][:200] + "..."
                                if len(r["section_content"]) > 200
                                else r["section_content"]
                            ),
                            "type": r["section_type"],
                            "similarity": float(r["similarity"]),
                            "source": "postgres_mcp",
                        }
                        for r in results
                    ]

                async def search_with_context(
                    self, query: str, context: str = None
                ) -> List[Dict]:
                    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãæ¤œç´¢"""
                    enhanced_query = f"{context} {query}" if context else query
                    return await self.search_knowledge(enhanced_query)

                async def get_statistics(self) -> Dict:
                    """çµ±è¨ˆæƒ…å ±å–å¾—"""
                    stats = await self.conn.fetchrow(
                        """
                        SELECT
                            COUNT(*) as total_documents,
                            COUNT(DISTINCT section_type) as unique_types,
                            AVG(LENGTH(section_content)) as avg_content_length
                        FROM knowledge_base.core_documents
                    """
                    )

                    return {
                        "total_documents": stats["total_documents"],
                        "unique_types": stats["unique_types"],
                        "avg_content_length": float(stats["avg_content_length"]),
                    }

            # MCP ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
            mcp = PostgreSQLMCPInterface(self.conn)

            # åŸºæœ¬æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            search_results = await mcp.search_knowledge("ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰", 3)
            assert len(search_results) > 0, "æ¤œç´¢çµæœãŒç©º"

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãæ¤œç´¢ãƒ†ã‚¹ãƒˆ
            context_results = await mcp.search_with_context("è³¢è€…", "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰")
            assert len(context_results) > 0, "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢å¤±æ•—"

            # çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆ
            stats = await mcp.get_statistics()
            assert stats["total_documents"] > 0, "çµ±è¨ˆæƒ…å ±å–å¾—å¤±æ•—"

            # é¡ä¼¼åº¦ç¢ºèª
            best_match = search_results[0]
            assert (
                best_match["similarity"] > 0.1
            ), f"é¡ä¼¼åº¦ä¸è¶³: {best_match['similarity']}"

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f'MCPçµ±åˆOK - æ–‡æ›¸æ•°: {stats["total_documents"]}, é¡ä¼¼åº¦: {best_match["similarity"]:.3f}',
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_fallback_mechanism(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ãƒ†ã‚¹ãƒˆ"""
        test_name = "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ãƒ†ã‚¹ãƒˆ"
        print(f"\nğŸ” {test_name}...")

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            class FileBasedFallback:
                def __init__(self):
                    self.knowledge_db = {
                        "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ": {
                            "content": "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã§æ§‹æˆã•ã‚Œã‚‹",
                            "similarity": 0.85,
                        },
                        "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰": {
                            "content": "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸­å¿ƒã¨ã—ãŸè‡ªå¾‹çš„ãªé–‹ç™ºçµ„ç¹”",
                            "similarity": 0.80,
                        },
                        "PostgreSQL": {
                            "content": "ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
                            "similarity": 0.75,
                        },
                    }

                def search(self, query: str) -> List[Dict]:
                    results = []
                    for key, data in self.knowledge_db.items():
                        if any(word in key.lower() for word in query.lower().split()):
                            results.append(
                                {
                                    "title": key,
                                    "content": data["content"],
                                    "similarity": data["similarity"],
                                    "source": "file_fallback",
                                }
                            )
                    return sorted(results, key=lambda x: x["similarity"], reverse=True)

            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
            class HybridSearchSystem:
                def __init__(self, mcp_conn, fallback_system):
                    self.mcp_conn = mcp_conn
                    self.fallback = fallback_system

                async def search(self, query: str, use_fallback=False) -> List[Dict]:
                    results = []

                    if not use_fallback:
                        try:
                            # ã¾ãšPostgreSQLã§æ¤œç´¢
                            response = client.embeddings.create(
                                model="text-embedding-ada-002", input=query
                            )
                            query_embedding = response.data[0].embedding

                            postgres_results = await self.mcp_conn.fetch(
                                """
                                SELECT
                                    section_title,
                                    section_content,
                                    1 - (embedding <=> $1::vector) as similarity
                                FROM knowledge_base.core_documents
                                ORDER BY embedding <=> $1::vector
                                LIMIT 3
                            """,
                                str(query_embedding),
                            )

                            for r in postgres_results:
                                results.append(
                                    {
                                        "title": r["section_title"],
                                        "content": r["section_content"][:100] + "...",
                                        "similarity": float(r["similarity"]),
                                        "source": "postgres_mcp",
                                    }
                                )

                            # çµæœãŒä¸ååˆ†ãªå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            if (
                                not results
                                or max(r["similarity"] for r in results) < 0.3
                            ):
                                fallback_results = self.fallback.search(query)
                                results.extend(fallback_results)

                        except Exception as e:
                            # PostgreSQLéšœå®³æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            print(f"PostgreSQLéšœå®³æ¤œå‡º: {e}")
                            results = self.fallback.search(query)
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åˆ¶å®Ÿè¡Œ
                        results = self.fallback.search(query)

                    return results

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            fallback_system = FileBasedFallback()
            hybrid_system = HybridSearchSystem(self.conn, fallback_system)

            # æ­£å¸¸æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            normal_results = await hybrid_system.search("4è³¢è€…ã«ã¤ã„ã¦")
            assert len(normal_results) > 0, "æ­£å¸¸æ¤œç´¢å¤±æ•—"

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åˆ¶ãƒ†ã‚¹ãƒˆ
            fallback_results = await hybrid_system.search(
                "4è³¢è€…ã«ã¤ã„ã¦", use_fallback=True
            )
            assert len(fallback_results) > 0, "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—"
            assert any(
                r["source"] == "file_fallback" for r in fallback_results
            ), "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœãŒå«ã¾ã‚Œã¦ã„ãªã„"

            self.fallback_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ­£å¸¸å‹•ä½œ - é€šå¸¸: {len(normal_results)}ä»¶, ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {len(fallback_results)}ä»¶",
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.fallback_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_concurrent_access(self):
        """åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"""
        test_name = "åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"
        print(f"\nğŸ” {test_name}...")

        try:
            # åŒæ™‚æ¤œç´¢ã‚¿ã‚¹ã‚¯
            async def search_task(query_id):
                query = f"ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ {query_id}"
                response = client.embeddings.create(
                    model="text-embedding-ada-002", input=query
                )
                query_embedding = response.data[0].embedding

                results = await self.conn.fetch(
                    """
                    SELECT
                        section_title,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM knowledge_base.core_documents
                    ORDER BY embedding <=> $1::vector
                    LIMIT 1
                """,
                    str(query_embedding),
                )

                return len(results) > 0

            # 5å€‹ã®åŒæ™‚æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            tasks = [search_task(i) for i in range(5)]
            results = await asyncio.gather(*tasks)
            end_time = time.time()

            total_time = (end_time - start_time) * 1000
            success_count = sum(results)

            assert success_count == 5, f"åŒæ™‚æ¤œç´¢å¤±æ•—: {success_count}/5"
            assert total_time < 10000, f"åŒæ™‚æ¤œç´¢æ™‚é–“éå¤§: {total_time}ms"

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f"åŒæ™‚æ¤œç´¢æˆåŠŸ: {success_count}/5, æ™‚é–“: {total_time:.2f}ms",
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_data_integrity(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        test_name = "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"
        print(f"\nğŸ” {test_name}...")

        try:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ç¢ºèª
            integrity_check = await self.conn.fetchrow(
                """
                SELECT
                    COUNT(*) as total_count,
                    COUNT(embedding) as embedding_count,
                    COUNT(DISTINCT section_type) as type_count
                FROM knowledge_base.core_documents
            """
            )

            assert integrity_check["total_count"] > 0, "ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„"
            assert (
                integrity_check["embedding_count"] == integrity_check["total_count"]
            ), "embeddingsæ¬ æ"
            assert integrity_check["type_count"] > 0, "ã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã—ãªã„"

            # ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèª
            quality_check = await self.conn.fetchrow(
                """
                SELECT
                    AVG(LENGTH(section_content)) as avg_length,
                    MIN(LENGTH(section_content)) as min_length,
                    MAX(LENGTH(section_content)) as max_length
                FROM knowledge_base.core_documents
            """
            )

            assert quality_check["avg_length"] > 10, "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒçŸ­ã™ãã‚‹"
            assert quality_check["min_length"] > 0, "ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå­˜åœ¨"

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f'ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§OK - ç·ä»¶æ•°: {
                        integrity_check["total_count"]},
                        å¹³å‡é•·: {quality_check["avg_length"]:.0f
                    }',
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def test_performance_benchmark(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        test_name = "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"
        print(f"\nğŸ” {test_name}...")

        try:
            # è¤‡æ•°ã®æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
            queries = [
                "4è³¢è€…ã«ã¤ã„ã¦",
                "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰",
                "TDDé–‹ç™º",
                "PostgreSQL",
                "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…",
            ]

            total_time = 0
            all_results = []

            for query in queries:
                response = client.embeddings.create(
                    model="text-embedding-ada-002", input=query
                )
                query_embedding = response.data[0].embedding

                start_time = time.time()
                results = await self.conn.fetch(
                    """
                    SELECT
                        section_title,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM knowledge_base.core_documents
                    ORDER BY embedding <=> $1::vector
                    LIMIT 5
                """,
                    str(query_embedding),
                )
                end_time = time.time()

                search_time = (end_time - start_time) * 1000
                total_time += search_time
                all_results.extend(results)

            avg_time = total_time / len(queries)
            avg_similarity = sum(float(r["similarity"]) for r in all_results) / len(
                all_results
            )

            assert avg_time < 100, f"å¹³å‡æ¤œç´¢æ™‚é–“ãŒé…ã„: {avg_time}ms"
            assert avg_similarity > 0.1, f"å¹³å‡é¡ä¼¼åº¦ãŒä½ã„: {avg_similarity}"

            self.test_results.append(
                {
                    "test": test_name,
                    "status": "PASS",
                    "message": f"å¹³å‡æ¤œç´¢æ™‚é–“: {avg_time:.2f}ms, å¹³å‡é¡ä¼¼åº¦: {avg_similarity:.3f}",
                }
            )
            print(f"âœ… {test_name} - æˆåŠŸ")

        except Exception as e:
            self.test_results.append(
                {"test": test_name, "status": "FAIL", "message": str(e)}
            )
            print(f"âŒ {test_name} - å¤±æ•—: {e}")

    async def cleanup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...")

        if self.conn:
            # ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤
            await self.conn.execute("DROP TABLE IF EXISTS knowledge_base.mcp_test_temp")
            await self.conn.close()

        print("âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

    def generate_test_report(self):
        """ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ğŸ“Š PostgreSQL MCPçµ±åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)

        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r["status"] == "PASS")
        failed_tests = sum(1 for r in self.test_results if r["status"] == "FAIL")
        skipped_tests = sum(1 for r in self.test_results if r["status"] == "SKIP")

        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"æˆåŠŸ: {passed_tests}")
        print(f"å¤±æ•—: {failed_tests}")
        print(f"ã‚¹ã‚­ãƒƒãƒ—: {skipped_tests}")

        if total_tests > 0:
            print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")

        print("\nğŸ” ãƒ†ã‚¹ãƒˆè©³ç´°:")
        for result in self.test_results:
            status_emoji = (
                "âœ…"
                if result["status"] == "PASS"
                else "âŒ" if result["status"] == "FAIL" else "âš ï¸"
            )
            print(f"  {status_emoji} {result['test']}: {result['message']}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœ
        if self.fallback_results:
            print("\nğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ãƒ†ã‚¹ãƒˆ:")
            for result in self.fallback_results:
                status_emoji = "âœ…" if result["status"] == "PASS" else "âŒ"
                print(f"  {status_emoji} {result['test']}: {result['message']}")

        # æ¨å¥¨äº‹é …
        print("\nğŸ“‹ æ¨å¥¨äº‹é …:")
        if failed_tests == 0:
            print("  ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸã€‚")
            print("  âœ… PostgreSQL MCPçµ±åˆã‚’å®‰å…¨ã«é€²ã‚ã‚‰ã‚Œã¾ã™ã€‚")
            print("  ğŸ”§ æ®µéšçš„ãªå°å…¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚")
        else:
            print("  âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
            print("  ğŸ”§ å•é¡Œã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰çµ±åˆã‚’é€²ã‚ã¦ãã ã•ã„ã€‚")

        print("  ğŸ“Š ç¶™ç¶šçš„ãªç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰ãŒé‡è¦ã§ã™ã€‚")
        print("  ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã®ä¿æŒã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        print("  ğŸš€ æœ¬ç•ªç’°å¢ƒã§ã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚")

        return failed_tests == 0


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ PostgreSQL MCPçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
    print("=" * 80)

    tester = PostgreSQLMCPIntegrationTest()

    try:
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        await tester.setup_test_environment()
        await tester.test_basic_connectivity()
        await tester.test_existing_vector_search()
        await tester.test_mcp_interface_simulation()
        await tester.test_fallback_mechanism()
        await tester.test_concurrent_access()
        await tester.test_data_integrity()
        await tester.test_performance_benchmark()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        success = tester.generate_test_report()

        if success:
            print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
            print("PostgreSQL MCPçµ±åˆã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚")
        else:
            print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
            print("å•é¡Œã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰çµ±åˆã‚’é€²ã‚ã¦ãã ã•ã„ã€‚")

        return success

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        await tester.cleanup_test_environment()


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
