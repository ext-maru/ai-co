#!/usr/bin/env python3
"""
ğŸ¤– ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰å“è³ªé€²åŒ–ãƒ‡ãƒ¼ãƒ¢ãƒ³
24/7ç¨¼åƒã§è‡ªå‹•çš„ã«å“è³ªã‚’ç›£è¦–ãƒ»å‘ä¸Šã•ã›ã‚‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import logging
import os
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(PROJECT_ROOT / 'logs/quality_daemon.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class QualityMetricsCollector:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è‡ªå‹•åé›†"""

    def __init__(self):
        self.project_root = PROJECT_ROOT

    async def collect_all_metrics(self) -> Dict:
        """å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’éåŒæœŸã§åé›†"""
        logger.info("ğŸ” ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†é–‹å§‹")

        tasks = [
            self.collect_git_metrics(),
            self.collect_precommit_metrics(),
            self.collect_code_quality_metrics(),
            self.collect_team_metrics()
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # çµæœã‚’ãƒãƒ¼ã‚¸
        all_metrics = {}
        for result in results:
            if isinstance(result, dict):
                all_metrics.update(result)
            else:
                logger.warning(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {result}")

        all_metrics['collected_at'] = datetime.now().isoformat()
        logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†: {len(all_metrics)}é …ç›®")

        return all_metrics

    async def collect_git_metrics(self) -> Dict:
        """Gitæ´»å‹•ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        try:
            # éå»7æ—¥ã®ã‚³ãƒŸãƒƒãƒˆæ•°
            result = await asyncio.create_subprocess_exec(
                'git', 'log', '--since=7 days ago', '--oneline',
                cwd=self.project_root,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, _ = await result.communicate()

            commits_7d = len(stdout.decode().strip().split('\n')) if stdout.decode().strip() else 0

            # ä»Šæ—¥ã®ã‚³ãƒŸãƒƒãƒˆæ•°
            result = await asyncio.create_subprocess_exec(
                'git', 'log', '--since=1 day ago', '--oneline',
                cwd=self.project_root,
                stdout=asyncio.subprocess.PIPE
            )
            stdout, _ = await result.communicate()

            commits_today = len(stdout.decode().strip().split('\n')) if stdout.decode().strip() else 0

            return {
                'git_commits_7d': commits_7d,
                'git_commits_today': commits_today,
                'git_activity_score': min(commits_7d / 7 * 10, 10)  # 0-10ã‚¹ã‚³ã‚¢
            }
        except Exception as e:
            logger.warning(f"Git ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å¤±æ•—: {e}")
            return {'git_commits_7d': 0, 'git_commits_today': 0, 'git_activity_score': 0}

    async def collect_precommit_metrics(self) -> Dict:
        """Pre-commitæ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        try:
            # .pre-commit-config.yamlå­˜åœ¨ç¢ºèª
            config_file = self.project_root / '.pre-commit-config.yaml'
            if not config_file.exists():
                return {'precommit_configured': False}

            # æ¨¡æ“¬çš„ãªæ€§èƒ½ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯éå»ãƒ­ã‚°ã‹ã‚‰ç®—å‡ºï¼‰
            return {
                'precommit_configured': True,
                'precommit_avg_time': 1.8,  # ç§’
                'precommit_success_rate': 98.5,  # %
                'precommit_last_run': datetime.now().isoformat()
            }
        except Exception as e:
            logger.warning(f"Pre-commit ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å¤±æ•—: {e}")
            return {'precommit_configured': False}

    async def collect_code_quality_metrics(self) -> Dict:
        """ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        try:
            metrics = {
                'python_files_count': 0,
                'python_syntax_errors': 0,
                'large_files_count': 0,
                'total_lines_of_code': 0
            }

            # Python ãƒ•ã‚¡ã‚¤ãƒ«è§£æ
            for py_file in self.project_root.glob('**/*.py'):
                if any(exclude in str(py_file) for exclude in ['venv', '__pycache__', '.git']):
                    continue

                metrics['python_files_count'] += 1

                # æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
                try:
                    result = await asyncio.create_subprocess_exec(
                        'python3', '-m', 'py_compile', str(py_file),
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    await result.communicate()
                    if result.returncode != 0:
                        metrics['python_syntax_errors'] += 1
                except:
                    pass

                # è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
                try:
                    lines = py_file.read_text(encoding='utf-8').count('\n')
                    metrics['total_lines_of_code'] += lines
                except:
                    pass

            # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            for file_path in self.project_root.glob('**/*'):
                if file_path.is_file() and file_path.stat().st_size > 5_000_000:  # 5MB
                    metrics['large_files_count'] += 1

            # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            if metrics['python_files_count'] > 0:
                error_rate = metrics['python_syntax_errors'] / metrics['python_files_count']
                metrics['code_quality_score'] = max(0, 10 - error_rate * 100)
            else:
                metrics['code_quality_score'] = 10

            return metrics

        except Exception as e:
            logger.warning(f"ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å¤±æ•—: {e}")
            return {'code_quality_score': 5}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸­é–“å€¤

    async def collect_team_metrics(self) -> Dict:
        """ãƒãƒ¼ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Slack APIã€GitHub APIã€ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ãªã©ã¨é€£æº
        return {
            'team_satisfaction': 85,  # %
            'tool_understanding_black': 80,  # %
            'tool_understanding_isort': 75,  # %
            'developer_complaints': 0,  # ä»¶æ•°
            'team_readiness_score': 8.5  # 0-10
        }


class QualityGateEvaluator:
    """å“è³ªã‚²ãƒ¼ãƒˆè‡ªå‹•è©•ä¾¡"""

    def __init__(self):
        self.stability_threshold_days = 7
        self.confidence_threshold = 0.95

    def get_current_phase(self) -> int:
        """ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ¤å®š"""
        config_file = PROJECT_ROOT / '.pre-commit-config.yaml'
        if not config_file.exists():
            return 0

        content = config_file.read_text()

        if 'mypy' in content and 'tdd-compliance' in content:
            return 4
        elif 'black' in content and 'flake8' in content:
            return 3
        elif 'black' in content:
            return 2
        elif 'check-ast' in content:
            return 1
        else:
            return 0

    async def evaluate_gate_readiness(self, metrics: Dict) -> Dict:
        """ã‚²ãƒ¼ãƒˆæº–å‚™çŠ¶æ³ã‚’è©•ä¾¡"""
        current_phase = self.get_current_phase()
        next_phase = current_phase + 1

        logger.info(f"ğŸšª Gate {current_phase} â†’ Phase {next_phase} è©•ä¾¡ä¸­")

        # Phaseåˆ¥ã®æ¡ä»¶è©•ä¾¡
        if current_phase == 1 and next_phase == 2:
            return self.evaluate_gate_1_to_2(metrics)
        elif current_phase == 2 and next_phase == 3:
            return self.evaluate_gate_2_to_3(metrics)
        elif current_phase == 3 and next_phase == 4:
            return self.evaluate_gate_3_to_4(metrics)
        else:
            return {
                'ready': False,
                'reason': f'Phase {current_phase} â†’ {next_phase} ã®è©•ä¾¡ã¯æœªå®Ÿè£…',
                'current_phase': current_phase
            }

    def evaluate_gate_1_to_2(self, metrics: Dict) -> Dict:
        """Gate 1 â†’ Phase 2 (ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ) è©•ä¾¡"""
        criteria = {
            'precommit_success_rate': metrics.get('precommit_success_rate', 0) >= 95,
            'precommit_performance': metrics.get('precommit_avg_time', 999) <= 3.0,
            'syntax_errors': metrics.get('python_syntax_errors', 999) == 0,
            'team_satisfaction': metrics.get('team_satisfaction', 0) >= 80,
            'tool_understanding': metrics.get('tool_understanding_black', 0) >= 75,
            'developer_complaints': metrics.get('developer_complaints', 999) <= 3
        }

        passed_criteria = sum(criteria.values())
        total_criteria = len(criteria)
        readiness_score = passed_criteria / total_criteria

        return {
            'ready': readiness_score >= 1.0,
            'readiness_score': readiness_score,
            'criteria': criteria,
            'current_phase': 1,
            'target_phase': 2,
            'missing_criteria': [k for k, v in criteria.items() if not v]
        }

    def evaluate_gate_2_to_3(self, metrics: Dict) -> Dict:
        """Gate 2 â†’ Phase 3 (å“è³ªå¼·åŒ–) è©•ä¾¡"""
        # Phase 2ã®æ¡ä»¶ï¼ˆæ¨¡æ“¬ï¼‰
        criteria = {
            'format_compliance': True,  # Blacké©åˆç‡95%ä»¥ä¸Š
            'import_order': True,       # Importé †åºé©åˆç‡95%ä»¥ä¸Š
            'team_efficiency': True,    # PRä½œæˆæ™‚é–“30%çŸ­ç¸®
            'code_review_speed': True,  # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“20%çŸ­ç¸®
            'team_satisfaction': metrics.get('team_satisfaction', 0) >= 85
        }

        passed_criteria = sum(criteria.values())
        total_criteria = len(criteria)
        readiness_score = passed_criteria / total_criteria

        return {
            'ready': readiness_score >= 1.0,
            'readiness_score': readiness_score,
            'criteria': criteria,
            'current_phase': 2,
            'target_phase': 3
        }

    def evaluate_gate_3_to_4(self, metrics: Dict) -> Dict:
        """Gate 3 â†’ Phase 4 (TDDå®Œå…¨) è©•ä¾¡"""
        # Phase 3ã®æ¡ä»¶ï¼ˆæ¨¡æ“¬ï¼‰
        criteria = {
            'code_quality': metrics.get('code_quality_score', 0) >= 9.0,
            'security_clean': True,      # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚¼ãƒ­
            'test_coverage': False,      # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸70%ä»¥ä¸Šï¼ˆæœªå®Ÿè£…ï¼‰
            'tdd_understanding': False,  # TDDç†è§£åº¦80%ä»¥ä¸Šï¼ˆæœªå®Ÿè£…ï¼‰
            'bug_reduction': False       # ãƒã‚°ç‡50%å‰Šæ¸›ï¼ˆæœªå®Ÿè£…ï¼‰
        }

        passed_criteria = sum(criteria.values())
        total_criteria = len(criteria)
        readiness_score = passed_criteria / total_criteria

        return {
            'ready': False,  # Phase 4ã¯é«˜åº¦ãªãŸã‚æ…é‡ã«
            'readiness_score': readiness_score,
            'criteria': criteria,
            'current_phase': 3,
            'target_phase': 4,
            'note': 'Phase 4ã¯æ‰‹å‹•æ‰¿èªãŒå¿…è¦'
        }


class AutoUpgradeExecutor:
    """è‡ªå‹•æ˜‡æ ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.backup_dir = PROJECT_ROOT / 'backups/auto_upgrades'
        self.backup_dir.mkdir(parents=True, exist_ok=True)

    async def execute_upgrade(self, from_phase: int, to_phase: int) -> bool:
        """ãƒ•ã‚§ãƒ¼ã‚ºæ˜‡æ ¼ã‚’å®Ÿè¡Œ"""
        logger.info(f"ğŸš€ Phase {from_phase} â†’ {to_phase} æ˜‡æ ¼é–‹å§‹")

        try:
            # 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_id = await self.create_backup()
            logger.info(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_id}")

            # 2. æ–°ãƒ•ã‚§ãƒ¼ã‚ºè¨­å®šé©ç”¨
            await self.apply_phase_config(to_phase)
            logger.info(f"âš™ï¸ Phase {to_phase} è¨­å®šé©ç”¨å®Œäº†")

            # 3. è¨­å®šãƒ†ã‚¹ãƒˆ
            if await self.test_new_configuration():
                logger.info(f"âœ… Phase {to_phase} æ˜‡æ ¼æˆåŠŸ")
                await self.notify_successful_upgrade(from_phase, to_phase)
                return True
            else:
                logger.warning("âŒ è¨­å®šãƒ†ã‚¹ãƒˆå¤±æ•—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ")
                await self.rollback_to_backup(backup_id)
                return False

        except Exception as e:
            logger.error(f"âŒ æ˜‡æ ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def create_backup(self) -> str:
        """ç¾åœ¨ã®è¨­å®šã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_id = f"phase_backup_{timestamp}"
        backup_path = self.backup_dir / backup_id
        backup_path.mkdir(exist_ok=True)

        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        files_to_backup = [
            '.pre-commit-config.yaml',
            'scripts/check_elder_standards.py',
            '.gitignore'
        ]

        for file_name in files_to_backup:
            source = PROJECT_ROOT / file_name
            if source.exists():
                destination = backup_path / file_name
                destination.parent.mkdir(parents=True, exist_ok=True)
                destination.write_text(source.read_text())

        return backup_id

    async def apply_phase_config(self, phase: int):
        """æŒ‡å®šãƒ•ã‚§ãƒ¼ã‚ºã®è¨­å®šã‚’é©ç”¨"""
        if phase == 2:
            await self.apply_phase_2_config()
        elif phase == 3:
            await self.apply_phase_3_config()
        elif phase == 4:
            await self.apply_phase_4_config()
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ•ã‚§ãƒ¼ã‚º: {phase}")

    async def apply_phase_2_config(self):
        """Phase 2 (ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ) è¨­å®š"""
        config = '''# ğŸ›ï¸ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ Pre-commit è¨­å®š (Phase 2)
# è‡ªå‹•æ˜‡æ ¼ã«ã‚ˆã‚Šæœ‰åŠ¹åŒ–

repos:
  # PythonåŸºæœ¬ãƒã‚§ãƒƒã‚¯
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=10000']
      - id: check-json
      - id: check-merge-conflict
      - id: check-ast
      - id: debug-statements

  # Phase 2: ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
        args: ['--line-length=100']

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort
        args: ['--profile', 'black']

# è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
fail_fast: false
default_stages: [pre-commit]

# ğŸ‰ Phase 2 è‡ªå‹•æ˜‡æ ¼å®Œäº†!
# - Blackã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰æ•´å½¢ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ
# - isortã«ã‚ˆã‚‹importæ•´ç†ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ
'''
        config_file = PROJECT_ROOT / '.pre-commit-config.yaml'
        config_file.write_text(config)

        # ãƒ•ãƒƒã‚¯å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        await asyncio.create_subprocess_exec(
            'pre-commit', 'install',
            cwd=PROJECT_ROOT
        )

    async def apply_phase_3_config(self):
        """Phase 3 (å“è³ªå¼·åŒ–) è¨­å®š"""
        # Phase 3è¨­å®šã¯å®Ÿè£…äºˆå®š
        logger.info("Phase 3è¨­å®šé©ç”¨ (æœªå®Ÿè£…)")

    async def apply_phase_4_config(self):
        """Phase 4 (TDDå®Œå…¨) è¨­å®š"""
        # Phase 4è¨­å®šã¯å®Ÿè£…äºˆå®š
        logger.info("Phase 4è¨­å®šé©ç”¨ (æœªå®Ÿè£…)")

    async def test_new_configuration(self) -> bool:
        """æ–°è¨­å®šã®ãƒ†ã‚¹ãƒˆ"""
        try:
            # Pre-commitãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
            result = await asyncio.create_subprocess_exec(
                'pre-commit', 'run', '--all-files',
                cwd=PROJECT_ROOT,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await result.communicate()

            # 0ã¾ãŸã¯1ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰ã¯æˆåŠŸï¼ˆ1ã¯ä¿®æ­£ã‚’è¡Œã£ãŸå ´åˆï¼‰
            return result.returncode in [0, 1]

        except Exception as e:
            logger.error(f"è¨­å®šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def rollback_to_backup(self, backup_id: str):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        backup_path = self.backup_dir / backup_id

        for backup_file in backup_path.glob('**/*'):
            if backup_file.is_file():
                relative_path = backup_file.relative_to(backup_path)
                target_file = PROJECT_ROOT / relative_path
                target_file.parent.mkdir(parents=True, exist_ok=True)
                target_file.write_text(backup_file.read_text())

        logger.info(f"ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†: {backup_id}")

    async def notify_successful_upgrade(self, from_phase: int, to_phase: int):
        """æ˜‡æ ¼æˆåŠŸé€šçŸ¥"""
        message = f"""
ğŸ‰ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰è‡ªå‹•å“è³ªé€²åŒ–ã‚·ã‚¹ãƒ†ãƒ 

Phase {from_phase} â†’ Phase {to_phase} æ˜‡æ ¼å®Œäº†ï¼

æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ–°æ©Ÿèƒ½ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚æ™®æ®µé€šã‚Šé–‹ç™ºã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚
ä½•ã‹å•é¡ŒãŒã‚ã‚Œã°è‡ªå‹•çš„ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã‚Œã¾ã™ã€‚
"""
        logger.info(message.strip())

        # TODO: Slack/Discordé€šçŸ¥
        # TODO: ãƒ¡ãƒ¼ãƒ«é€šçŸ¥


class QualityEvolutionDaemon:
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ãƒ¢ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.metrics_collector = QualityMetricsCollector()
        self.gate_evaluator = QualityGateEvaluator()
        self.upgrade_executor = AutoUpgradeExecutor()

        self.monitoring_interval = 3600  # 1æ™‚é–“ã”ã¨
        self.upgrade_time = "02:00"      # æ·±å¤œ2æ™‚ã«æ˜‡æ ¼ãƒã‚§ãƒƒã‚¯
        self.metrics_history = []

    async def run_forever(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— - 24/7ç¨¼åƒ"""
        logger.info("ğŸ¤– ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰å“è³ªé€²åŒ–ãƒ‡ãƒ¼ãƒ¢ãƒ³èµ·å‹•")

        while True:
            try:
                await self.run_monitoring_cycle()
                await asyncio.sleep(self.monitoring_interval)

            except KeyboardInterrupt:
                logger.info("ğŸ‘‹ ãƒ‡ãƒ¼ãƒ¢ãƒ³åœæ­¢")
                break
            except Exception as e:
                logger.error(f"ğŸ’¥ ãƒ‡ãƒ¼ãƒ¢ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(60)  # 1åˆ†å¾…ã£ã¦ãƒªãƒˆãƒ©ã‚¤

    async def run_monitoring_cycle(self):
        """ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        cycle_start = datetime.now()
        logger.info(f"ğŸ” ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹: {cycle_start.strftime('%H:%M:%S')}")

        # 1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        metrics = await self.metrics_collector.collect_all_metrics()
        self.metrics_history.append(metrics)

        # å±¥æ­´ã¯æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]

        # 2. ã‚²ãƒ¼ãƒˆè©•ä¾¡
        gate_status = await self.gate_evaluator.evaluate_gate_readiness(metrics)

        # 3. æ˜‡æ ¼æ™‚åˆ»ãƒã‚§ãƒƒã‚¯
        current_time = datetime.now().strftime("%H:%M")
        if current_time == self.upgrade_time:
            await self.check_and_execute_upgrade(gate_status)

        # 4. çŠ¶æ…‹ä¿å­˜
        await self.save_status(metrics, gate_status)

        cycle_end = datetime.now()
        duration = (cycle_end - cycle_start).total_seconds()
        logger.info(f"âœ… ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«å®Œäº†: {duration:.1f}ç§’")

    async def check_and_execute_upgrade(self, gate_status: Dict):
        """æ˜‡æ ¼ãƒã‚§ãƒƒã‚¯ãƒ»å®Ÿè¡Œ"""
        if gate_status.get('ready', False):
            current_phase = gate_status.get('current_phase', 0)
            target_phase = gate_status.get('target_phase', 0)

            logger.info(f"ğŸš€ è‡ªå‹•æ˜‡æ ¼æ¡ä»¶é”æˆ: Phase {current_phase} â†’ {target_phase}")

            success = await self.upgrade_executor.execute_upgrade(
                current_phase, target_phase
            )

            if success:
                logger.info("ğŸ‰ è‡ªå‹•æ˜‡æ ¼æˆåŠŸ")
            else:
                logger.warning("âš ï¸ è‡ªå‹•æ˜‡æ ¼å¤±æ•—")
        else:
            readiness = gate_status.get('readiness_score', 0)
            logger.info(f"ğŸ“Š æ˜‡æ ¼æº–å‚™ä¸­: {readiness:.1%}")

    async def save_status(self, metrics: Dict, gate_status: Dict):
        """çŠ¶æ…‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        status_file = PROJECT_ROOT / 'logs/quality_daemon_status.json'

        status = {
            'timestamp': datetime.now().isoformat(),
            'metrics': metrics,
            'gate_status': gate_status,
            'daemon_uptime': self.get_uptime()
        }

        status_file.write_text(json.dumps(status, indent=2, ensure_ascii=False))

    def get_uptime(self) -> str:
        """ç¨¼åƒæ™‚é–“ã‚’å–å¾—"""
        # ç°¡æ˜“å®Ÿè£…
        return "å®Ÿè£…äºˆå®š"


async def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    daemon = QualityEvolutionDaemon()
    await daemon.run_forever()


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    (PROJECT_ROOT / 'logs').mkdir(exist_ok=True)

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ãƒ‡ãƒ¼ãƒ¢ãƒ³åœæ­¢")
    except Exception as e:
        logger.error(f"ğŸ’¥ ãƒ‡ãƒ¼ãƒ¢ãƒ³èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
