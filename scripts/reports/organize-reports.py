#!/usr/bin/env python3
"""
ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¨ãƒ«ãƒ€ãƒ¼è©•è­°ä¼šä»¤ç¬¬600å· - ãƒ¬ãƒãƒ¼ãƒˆç®¡ç†åŠ¹ç‡åŒ–ä»¤

æ©Ÿèƒ½:
1. æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®åˆ†æãƒ»åˆ†é¡
2. æ™‚ç³»åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ¥æ•´ç†
3. é‡è¤‡ãƒ¬ãƒãƒ¼ãƒˆæ¤œå‡º
4. ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¨å¥¨
"""

import os
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import shutil
import argparse
from dataclasses import dataclass
import hashlib

@dataclass
class ReportInfo:
    """ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±"""
    path: Path
    date: datetime
    category: str
    type: str  # daily, weekly, monthly, adhoc
    size: int
    hash: str
    title: str

class ReportOrganizer:
    """ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†å™¨"""
    
    def __init__(self, base_path: str = "/home/aicompany/ai_co"):
        self.base_path = Path(base_path)
        self.reports_path = self.base_path / "docs" / "reports"
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚«ãƒ†ã‚´ãƒªå®šç¾©
        self.categories = {
            "development": ["completion", "progress", "phase", "implementation"],
            "quality": ["test", "coverage", "quality", "benchmark"],
            "operations": ["incident", "emergency", "repair", "fix"],
            "analysis": ["analysis", "investigation", "research", "study"],
            "council": ["council", "elder", "sage", "decision"]
        }
        
        # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.date_patterns = [
            r"(\d{4})[_-]?(\d{2})[_-]?(\d{2})",  # YYYY-MM-DD or YYYYMMDD
            r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥",   # Japanese format
            r"week[_-]?(\d+)",                     # Week number
            r"phase[_-]?(\d+)",                    # Phase number
        ]
    
    def analyze_reports(self) -> Dict[str, List[ReportInfo]]:
        """æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®åˆ†æ"""
        reports = {
            "periodic": [],
            "category": [],
            "uncategorized": [],
            "duplicates": []
        }
        
        # ãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰
        hash_map = {}
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        report_files = []
        for pattern in ["**/*report*.md", "**/*analysis*.md", "**/*completion*.md"]:
            report_files.extend(self.base_path.glob(pattern))
        
        # ä»®æƒ³ç’°å¢ƒã¨gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é™¤å¤–
        report_files = [f for f in report_files 
                       if not any(p in str(f) for p in ["venv", ".git", "__pycache__"])]
        
        for file_path in report_files:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
                content = file_path.read_text(encoding='utf-8')
                file_hash = hashlib.md5(content.encode()).hexdigest()
                
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if file_hash in hash_map:
                    reports["duplicates"].append((file_path, hash_map[file_hash]))
                    continue
                
                hash_map[file_hash] = file_path
                
                # ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±ç”Ÿæˆ
                report_info = self._create_report_info(file_path, content)
                
                # åˆ†é¡
                if report_info.type in ["daily", "weekly", "monthly"]:
                    reports["periodic"].append(report_info)
                elif report_info.category != "uncategorized":
                    reports["category"].append(report_info)
                else:
                    reports["uncategorized"].append(report_info)
                    
            except Exception as e:
                print(f"Error processing {file_path}: {e}")
        
        return reports
    
    def _create_report_info(self, file_path: Path, content: str) -> ReportInfo:
        """ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±ç”Ÿæˆ"""
        # æ—¥ä»˜æŠ½å‡º
        date = self._extract_date(file_path.name, content)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
        category = self._determine_category(file_path.name, content)
        
        # ã‚¿ã‚¤ãƒ—åˆ¤å®š
        report_type = self._determine_type(file_path.name, content)
        
        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
        title = self._extract_title(content)
        
        return ReportInfo(
            path=file_path,
            date=date,
            category=category,
            type=report_type,
            size=file_path.stat().st_size,
            hash=hashlib.md5(content.encode()).hexdigest(),
            title=title
        )
    
    def _extract_date(self, filename: str, content: str) -> datetime:
        """æ—¥ä»˜æŠ½å‡º"""
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰
        for pattern in self.date_patterns[:2]:
            match = re.search(pattern, filename)
            if match:
                try:
                    if len(match.groups()) == 3:
                        year, month, day = match.groups()
                        return datetime(int(year), int(month), int(day))
                except:
                    pass
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰
        lines = content.split('\n')[:30]  # æœ€åˆã®30è¡Œ
        for line in lines:
            for pattern in self.date_patterns[:2]:
                match = re.search(pattern, line)
                if match:
                    try:
                        if len(match.groups()) == 3:
                            year, month, day = match.groups()
                            return datetime(int(year), int(month), int(day))
                    except:
                        pass
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ—¥æ™‚ï¼‰
        return datetime.now()
    
    def _determine_category(self, filename: str, content: str) -> str:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š"""
        text = (filename + " " + content[:1000]).lower()
        
        for category, keywords in self.categories.items():
            for keyword in keywords:
                if keyword in text:
                    return category
        
        return "uncategorized"
    
    def _determine_type(self, filename: str, content: str) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        text = (filename + " " + content[:500]).lower()
        
        if "daily" in text or "æ—¥æ¬¡" in text:
            return "daily"
        elif "weekly" in text or "é€±æ¬¡" in text:
            return "weekly"
        elif "monthly" in text or "æœˆæ¬¡" in text:
            return "monthly"
        else:
            return "adhoc"
    
    def _extract_title(self, content: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º"""
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                return line[2:].strip()
        return "Untitled Report"
    
    def organize_reports(self, dry_run: bool = True) -> Dict[str, int]:
        """ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†å®Ÿè¡Œ"""
        results = {
            "moved": 0,
            "archived": 0,
            "deduplicated": 0,
            "errors": 0
        }
        
        # åˆ†æå®Ÿè¡Œ
        report_analysis = self.analyze_reports()
        
        # æ–°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        if not dry_run:
            self._create_directory_structure()
        
        # å®šæœŸãƒ¬ãƒãƒ¼ãƒˆæ•´ç†
        for report in report_analysis["periodic"]:
            try:
                new_path = self._get_periodic_path(report)
                if not dry_run:
                    new_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(report.path), str(new_path))
                results["moved"] += 1
            except Exception as e:
                print(f"Error moving {report.path}: {e}")
                results["errors"] += 1
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†
        for report in report_analysis["category"]:
            try:
                new_path = self._get_category_path(report)
                if not dry_run:
                    new_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(report.path), str(new_path))
                results["moved"] += 1
            except Exception as e:
                print(f"Error moving {report.path}: {e}")
                results["errors"] += 1
        
        # é‡è¤‡å‡¦ç†
        for duplicate_pair in report_analysis["duplicates"]:
            try:
                if isinstance(duplicate_pair, tuple) and len(duplicate_pair) == 2:
                    original, duplicate = duplicate_pair
                    if not dry_run and duplicate.exists():
                        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
                        archive_path = self.base_path / "archives" / "duplicate_reports"
                        archive_path.mkdir(parents=True, exist_ok=True)
                        shutil.move(str(duplicate), str(archive_path / duplicate.name))
                    results["deduplicated"] += 1
            except Exception as e:
                print(f"Error archiving duplicate: {e}")
                results["errors"] += 1
        
        return results
    
    def _create_directory_structure(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ"""
        # å®šæœŸãƒ¬ãƒãƒ¼ãƒˆ
        for report_type in ["daily", "weekly", "monthly"]:
            path = self.reports_path / "periodic" / report_type / "2025"
            path.mkdir(parents=True, exist_ok=True)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥
        for category in self.categories.keys():
            path = self.reports_path / "category" / category
            path.mkdir(parents=True, exist_ok=True)
    
    def _get_periodic_path(self, report: ReportInfo) -> Path:
        """å®šæœŸãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹ç”Ÿæˆ"""
        if report.type == "daily":
            return self.reports_path / "periodic" / "daily" / \
                   f"{report.date.year}" / f"{report.date.month:02d}" / \
                   f"{report.date.day:02d}" / report.path.name
        elif report.type == "weekly":
            week = report.date.isocalendar()[1]
            return self.reports_path / "periodic" / "weekly" / \
                   f"{report.date.year}" / f"week-{week:02d}" / report.path.name
        else:  # monthly
            return self.reports_path / "periodic" / "monthly" / \
                   f"{report.date.year}" / f"{report.date.month:02d}" / report.path.name
    
    def _get_category_path(self, report: ReportInfo) -> Path:
        """ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ç”Ÿæˆ"""
        return self.reports_path / "category" / report.category / \
               f"{report.date.year}" / report.path.name
    
    def generate_summary(self, analysis: Dict[str, List[ReportInfo]]) -> str:
        """ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        total = sum(len(v) for k, v in analysis.items() if k != "duplicates")
        duplicates = len(analysis["duplicates"])
        
        summary = f"""
ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆåˆ†æçµæœ:
ç·ãƒ¬ãƒãƒ¼ãƒˆæ•°: {total}
é‡è¤‡: {duplicates}

ã‚«ãƒ†ã‚´ãƒªåˆ¥:
- å®šæœŸãƒ¬ãƒãƒ¼ãƒˆ: {len(analysis["periodic"])}
  - æ—¥æ¬¡: {sum(1 for r in analysis["periodic"] if r.type == "daily")}
  - é€±æ¬¡: {sum(1 for r in analysis["periodic"] if r.type == "weekly")}
  - æœˆæ¬¡: {sum(1 for r in analysis["periodic"] if r.type == "monthly")}
- ã‚«ãƒ†ã‚´ãƒªåˆ¥: {len(analysis["category"])}
"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        category_dist = {}
        for report in analysis["category"]:
            category_dist[report.category] = category_dist.get(report.category, 0) + 1
        
        for cat, count in sorted(category_dist.items()):
            summary += f"  - {cat}: {count}\n"
        
        summary += f"- æœªåˆ†é¡: {len(analysis['uncategorized'])}\n"
        
        return summary

def main():
    parser = argparse.ArgumentParser(description='ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®ç§»å‹•ã¯è¡Œã‚ãªã„')
    parser.add_argument('--analyze-only', action='store_true', help='åˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--base-path', default='/home/aicompany/ai_co', help='ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    organizer = ReportOrganizer(args.base_path)
    
    print("ğŸ›ï¸ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ ãƒ¬ãƒãƒ¼ãƒˆæ•´ç†ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆåˆ†æä¸­...")
    
    analysis = organizer.analyze_reports()
    print(organizer.generate_summary(analysis))
    
    if args.analyze_only:
        return
    
    print(f"\nğŸ”§ æ•´ç†å®Ÿè¡Œï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: {'æœ‰åŠ¹' if args.dry_run else 'ç„¡åŠ¹'}ï¼‰")
    results = organizer.organize_reports(dry_run=args.dry_run)
    
    print(f"""
âœ… å®Ÿè¡Œçµæœ:
- ç§»å‹•: {results['moved']}
- ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {results['archived']}
- é‡è¤‡é™¤å»: {results['deduplicated']}
- ã‚¨ãƒ©ãƒ¼: {results['errors']}
""")

if __name__ == "__main__":
    main()