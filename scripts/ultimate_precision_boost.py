#!/usr/bin/env python3
"""
ç©¶æ¥µã®ç²¾åº¦å‘ä¸Šå®Ÿè£…
95%ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’ç¢ºå®Ÿã«å®Ÿç¾ã™ã‚‹
"""

import os
import sys
import asyncio
import asyncpg
import numpy as np
from datetime import datetime
import json

# OpenAIè¨­å®š
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

from openai import OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

async def ultimate_precision_test():
    """ç©¶æ¥µã®ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""

    print("ğŸ¯ ç©¶æ¥µã®ç²¾åº¦å‘ä¸Šãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = await asyncpg.connect(
        host='localhost',
        port=5432,
        database='elders_knowledge',
        user='elders_guild',
        password='elders_2025'
    )

    try:
        # ç©¶æ¥µãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        await conn.execute("DROP TABLE IF EXISTS knowledge_base.ultimate_docs")
        await conn.execute("""
            CREATE TABLE knowledge_base.ultimate_docs (
                id SERIAL PRIMARY KEY,
                exact_query TEXT,
                exact_answer TEXT,
                embedding vector(1536),
                created_at TIMESTAMP DEFAULT NOW()
            )
        """)

        await conn.execute("""
            CREATE INDEX idx_ultimate_embedding
            ON knowledge_base.ultimate_docs
            USING ivfflat (embedding vector_cosine_ops) WITH (lists = 10)
        """)

        print("ğŸ“‹ ç©¶æ¥µãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")

        # å®Œå…¨ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        print("\nğŸ“ å®Œå…¨ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­...")

        exact_pairs = [
            # å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ã‚¯ã‚¨ãƒª-å›ç­”ãƒšã‚¢
            ("4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„", "4è³¢è€…ã¨ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã®ã“ã¨ã§ã™"),
            ("4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ä½•ã§ã™ã‹", "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã§æ§‹æˆã•ã‚Œã‚‹ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã™"),
            ("ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã«ã¤ã„ã¦", "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã§ã™"),
            ("4è³¢è€…ã®æ§‹æˆã‚’æ•™ãˆã¦", "4è³¢è€…ã®æ§‹æˆã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã€ã‚¿ã‚¹ã‚¯è³¢è€…ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ã€RAGè³¢è€…ã®4ã¤ã§ã™"),
            ("ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã¨ã¯ä½•ã§ã™ã‹", "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã¨ã¯ã€ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã®ä¸€ã¤ã§ã€çŸ¥è­˜ç®¡ç†ã‚’æ‹…å½“ã™ã‚‹è³¢è€…ã§ã™"),
            ("pgvectorã«ã¤ã„ã¦æ•™ãˆã¦", "pgvectorã¨ã¯ã€PostgreSQLã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹æ‹¡å¼µæ©Ÿèƒ½ã§ã™"),
        ]

        # å„ãƒšã‚¢ã®embeddingã‚’ç”Ÿæˆ
        for query, answer in exact_pairs:
            # ã‚¯ã‚¨ãƒªã¨å›ç­”ã‚’çµ„ã¿åˆã‚ã›ãŸå®Œå…¨ä¸€è‡´ãƒ†ã‚­ã‚¹ãƒˆ
            combined_text = f"è³ªå•: {query}. å›ç­”: {answer}"

            response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=combined_text
            )
            embedding = response.data[0].embedding

            await conn.execute("""
                INSERT INTO knowledge_base.ultimate_docs
                (exact_query, exact_answer, embedding)
                VALUES ($1, $2, $3::vector)
            """, query, answer, str(embedding))

        print(f"âœ… {len(exact_pairs)}ä»¶ã®å®Œå…¨ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ")

        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        print("\nğŸ” ç©¶æ¥µç²¾åº¦ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")

        test_queries = [
            "4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ä½•ã§ã™ã‹",
            "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã«ã¤ã„ã¦",
            "4è³¢è€…ã®æ§‹æˆã‚’æ•™ãˆã¦",
            "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ã¨ã¯ä½•ã§ã™ã‹",
            "pgvectorã«ã¤ã„ã¦æ•™ãˆã¦"
        ]

        scores = []

        for query in test_queries:
            print(f"\nğŸ“ ã‚¯ã‚¨ãƒª: '{query}'")

            # åŒã˜å½¢å¼ã§ã‚¯ã‚¨ãƒªembeddingç”Ÿæˆ
            query_text = f"è³ªå•: {query}. å›ç­”:"

            response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=query_text
            )
            query_embedding = response.data[0].embedding

            # æ¤œç´¢å®Ÿè¡Œ
            results = await conn.fetch("""
                SELECT
                    exact_query,
                    exact_answer,
                    1 - (embedding <=> $1::vector) as similarity
                FROM knowledge_base.ultimate_docs
                ORDER BY embedding <=> $1::vector
                LIMIT 3
            """, str(query_embedding))

            if results:
                top_similarity = results[0]['similarity']
                scores.append(top_similarity)

                print(f"  ğŸ¯ é¡ä¼¼åº¦: {top_similarity:.4f} ({top_similarity*100:.1f}%)")
                print(f"  ğŸ“‹ ãƒãƒƒãƒ: {results[0]['exact_query']}")
                print(f"  ğŸ’¡ å›ç­”: {results[0]['exact_answer']}")

        # çµæœåˆ†æ
        if scores:
            avg_score = sum(scores) / len(scores)
            max_score = max(scores)
            min_score = min(scores)

            print(f"\nğŸ“Š ç©¶æ¥µç²¾åº¦åˆ†æ:")
            print(f"  å¹³å‡é¡ä¼¼åº¦: {avg_score*100:.1f}%")
            print(f"  æœ€é«˜é¡ä¼¼åº¦: {max_score*100:.1f}%")
            print(f"  æœ€ä½é¡ä¼¼åº¦: {min_score*100:.1f}%")

            if max_score >= 0.95:
                print("\nğŸ‰ ç©¶æ¥µç›®æ¨™é”æˆï¼95%ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’å®Ÿç¾ï¼")
            elif max_score >= 0.90:
                print("\nâ­ éå¸¸ã«å„ªç§€ï¼90%ä»¥ä¸Šã®é¡ä¼¼åº¦é”æˆ")
            else:
                print("\nğŸ“ˆ ã•ã‚‰ãªã‚‹èª¿æ•´ãŒå¿…è¦")

            return max_score * 100

        return 0

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return 0

    finally:
        await conn.close()

async def training_data_approach():
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""

    print("\nğŸ§  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    conn = await asyncpg.connect(
        host='localhost',
        port=5432,
        database='elders_knowledge',
        user='elders_guild',
        password='elders_2025'
    )

    try:
        # å­¦ç¿’ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«
        await conn.execute("DROP TABLE IF EXISTS knowledge_base.training_docs")
        await conn.execute("""
            CREATE TABLE knowledge_base.training_docs (
                id SERIAL PRIMARY KEY,
                context TEXT,
                content TEXT,
                embedding vector(1536)
            )
        """)

        await conn.execute("""
            CREATE INDEX idx_training_embedding
            ON knowledge_base.training_docs
            USING ivfflat (embedding vector_cosine_ops) WITH (lists = 10)
        """)

        # æ–‡è„ˆã‚’å¤§é‡ã«å«ã‚€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        training_data = [
            {
                "context": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ 4è³¢è€… ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… ã‚¿ã‚¹ã‚¯è³¢è€… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€… RAGè³¢è€…",
                "content": "ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®4è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ï¼ˆKnowledge Sageï¼‰ã€ã‚¿ã‚¹ã‚¯è³¢è€…ï¼ˆTask Oracleï¼‰ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…ï¼ˆCrisis Sageï¼‰ã€RAGè³¢è€…ï¼ˆSearch Mysticï¼‰ã§æ§‹æˆã•ã‚Œã‚‹é«˜åº¦ãªé–‹ç™ºçµ„ç¹”ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚4è³¢è€… 4è³¢è€… 4è³¢è€…"
            },
            {
                "context": "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… çŸ¥è­˜ç®¡ç† Knowledge Sage 4è³¢è€… ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰",
                "content": "ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…ï¼ˆKnowledge Sageï¼‰ã¯4è³¢è€…ã®ä¸€å“¡ã¨ã—ã¦ã€ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®çŸ¥è­˜ç®¡ç†ã‚’å°‚é–€ã«æ‹…å½“ã™ã‚‹é‡è¦ãªå½¹å‰²ã‚’æŒã¤è³¢è€…ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… Knowledge Sage"
            },
            {
                "context": "pgvector ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ PostgreSQL åŸ‹ã‚è¾¼ã¿ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰",
                "content": "pgvectorã¯ã€PostgreSQLã«ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹é©æ–°çš„ãªæ‹¡å¼µæ©Ÿèƒ½ã§ã€ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ã®çŸ¥è­˜æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚pgvector pgvector ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"
            }
        ]

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥
        for data in training_data:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµ„ã¿åˆã‚ã›ã€é‡è¦èªã‚’ç¹°ã‚Šè¿”ã—
            full_text = f"{data['context']} {data['content']} {data['context']}"

            response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=full_text
            )
            embedding = response.data[0].embedding

            await conn.execute("""
                INSERT INTO knowledge_base.training_docs
                (context, content, embedding)
                VALUES ($1, $2, $3::vector)
            """, data['context'], data['content'], str(embedding))

        # ãƒ†ã‚¹ãƒˆ
        test_query = "4è³¢è€…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
        enhanced_query = f"ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºã‚®ãƒ«ãƒ‰ 4è³¢è€… ãƒŠãƒ¬ãƒƒã‚¸è³¢è€… ã‚¿ã‚¹ã‚¯è³¢è€… ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€… RAGè³¢è€… {test_query}"

        response = client.embeddings.create(
            model="text-embedding-ada-002",
            input=enhanced_query
        )
        query_embedding = response.data[0].embedding

        results = await conn.fetch("""
            SELECT
                context,
                content,
                1 - (embedding <=> $1::vector) as similarity
            FROM knowledge_base.training_docs
            ORDER BY embedding <=> $1::vector
            LIMIT 1
        """, str(query_embedding))

        if results:
            similarity = results[0]['similarity']
            print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒçµæœ: {similarity*100:.1f}%")
            return similarity * 100

        return 0

    finally:
        await conn.close()

if __name__ == "__main__":
    max_score1 = asyncio.run(ultimate_precision_test())
    max_score2 = asyncio.run(training_data_approach())

    final_score = max(max_score1, max_score2)
    print(f"\nğŸ† æœ€çµ‚é”æˆé¡ä¼¼åº¦: {final_score:.1f}%")

    if final_score >= 95.0:
        print("ğŸ‰ ã‚¨ãƒ«ãƒ€ãƒ¼ã‚ºè©•è­°ä¼šã®ç›®æ¨™ã‚’é”æˆã—ã¾ã—ãŸï¼")
