#!/usr/bin/env python3
"""
çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  å®Œå…¨å‹•ä½œãƒ†ã‚¹ãƒˆ
Issue #309: è‡ªå‹•åŒ–å“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

ç›®çš„: Phase 1-4 ã®å…¨å®Ÿè£…ã‚’çµ±åˆã—ã¦å®Ÿéš›ã«å‹•ä½œç¢ºèª
"""

import asyncio
import tempfile
import shutil
from pathlib import Path
import time

# Import all implemented components
from libs.quality.static_analysis_engine import StaticAnalysisEngine
from libs.quality.test_automation_engine import TestAutomationEngine  
from libs.quality.comprehensive_quality_engine import ComprehensiveQualityEngine
from libs.quality.unified_quality_pipeline import UnifiedQualityPipeline
from libs.quality.pipeline_performance_optimizer import PipelinePerformanceOptimizer
from libs.quality.quality_metrics_monitor import QualityMetricsMonitor

# Import servants
from libs.elder_servants.quality_watcher_judgment import QualityWatcherJudgment
from libs.elder_servants.test_forge_judgment import TestForgeJudgment


async def create_test_project():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ"""
    temp_dir = tempfile.mkdtemp()
    project_path = Path(temp_dir)
    
    # ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    main_file = project_path / "calculator.py"
    main_file.write_text('''"""
Calculator module for testing unified quality pipeline.
"""

def add(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

def subtract(a: int, b: int) -> int:
    """Subtract b from a."""
    return a - b

def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

def divide(a: int, b: int) -> float:
    """Divide a by b."""
    if b == 0:
        raise ValueError("Division by zero!")
    return a / b

class Calculator:
    """Calculator class with memory."""
    
    def __init__(self):
        self.memory = 0
    
    def add_to_memory(self, value: float) -> None:
        """Add value to memory."""
        self.memory += value
    
    def clear_memory(self) -> None:
        """Clear memory."""
        self.memory = 0
    
    def get_memory(self) -> float:
        """Get memory value."""
        return self.memory
''')
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    test_file = project_path / "test_calculator.py"
    test_file.write_text('''"""
Tests for calculator module.
"""

import pytest
from calculator import add, subtract, multiply, divide, Calculator


def test_add():
    """Test addition."""
    assert add(2, 3) == 5
    assert add(-1, 1) == 0
    assert add(0, 0) == 0


def test_subtract():
    """Test subtraction."""
    assert subtract(5, 3) == 2
    assert subtract(0, 5) == -5
    assert subtract(-5, -3) == -2


def test_multiply():
    """Test multiplication."""
    assert multiply(3, 4) == 12
    assert multiply(-2, 3) == -6
    assert multiply(0, 100) == 0


def test_divide():
    """Test division."""
    assert divide(10, 2) == 5.0
    assert divide(7, 2) == 3.5
    
    with pytest.raises(ValueError):
        divide(5, 0)


class TestCalculator:
    """Test Calculator class."""
    
    def test_memory_operations(self):
        """Test memory operations."""
        calc = Calculator()
        assert calc.get_memory() == 0
        
        calc.add_to_memory(10)
        assert calc.get_memory() == 10
        
        calc.add_to_memory(-5)
        assert calc.get_memory() == 5
        
        calc.clear_memory()
        assert calc.get_memory() == 0
''')
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    setup_cfg = project_path / "setup.cfg"
    setup_cfg.write_text('''[metadata]
name = test-project
version = 1.0.0

[mypy]
python_version = 3.12
warn_return_any = True
warn_unused_configs = True

[tool:pytest]
testpaths = .
python_files = test_*.py
''')
    
    # pyproject.toml
    pyproject = project_path / "pyproject.toml"
    pyproject.write_text('''[tool.black]
line-length = 88
target-version = ['py312']

[tool.isort]
profile = "black"
line_length = 88
''')
    
    return str(project_path)


async def run_unified_quality_pipeline_test():
    """çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œå…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  å‹•ä½œãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    test_project_path = await create_test_project()
    print(f"ğŸ“ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ: {test_project_path}")
    
    try:
        # Phase 1: å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        print("\nğŸ“Š Phase 1: å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        monitor = QualityMetricsMonitor(monitoring_interval=5.0)
        monitor.start_monitoring()
        print("âœ… ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•å®Œäº†")
        
        # Phase 2: çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        print("\nğŸ—ï¸ Phase 2: çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–")
        pipeline = UnifiedQualityPipeline()
        print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
        
        # Phase 3: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆç›£è¦–ä»˜ãï¼‰
        print("\nâš¡ Phase 3: å“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ")
        start_time = time.time()
        
        result = await pipeline.execute_complete_quality_pipeline(test_project_path)
        
        execution_time = time.time() - start_time
        print(f"âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†: {execution_time:.2f}ç§’")
        
        # å®Ÿè¡Œçµæœã‚’ãƒ¢ãƒ‹ã‚¿ãƒ¼ã«è¨˜éŒ²
        monitor.record_pipeline_execution(result, execution_time, "TEST-001")
        
        # Phase 4: çµæœåˆ†æ
        print("\nğŸ“ˆ Phase 4: å®Ÿè¡Œçµæœåˆ†æ")
        print(f"- çµ±åˆå“è³ªã‚¹ã‚³ã‚¢: {result.unified_quality_score:.1f}/100")
        print(f"- Elderæ‰¿èªçŠ¶æ…‹: {result.overall_status}")
        print(f"- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŠ¹ç‡: {result.pipeline_efficiency:.1f}%")
        
        if result.graduation_certificate:
            print(f"ğŸ“ å“è³ªå’æ¥­è¨¼æ˜æ›¸ç™ºè¡Œ: {result.graduation_certificate}")
        
        # Phase 5: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
        print("\nâš¡ Phase 5: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Ÿè¡Œ")
        optimizer = PipelinePerformanceOptimizer()
        
        optimization_result = await optimizer.optimize_unified_pipeline_performance(
            pipeline, test_project_path, "comprehensive"
        )
        
        print(f"âœ… æœ€é©åŒ–å®Œäº†: {optimization_result.improvement_percentage:.1f}%æ”¹å–„")
        
        # æœ€é©åŒ–çµæœã‚’ãƒ¢ãƒ‹ã‚¿ãƒ¼ã«è¨˜éŒ²
        if optimization_result.success:
            monitor.record_pipeline_execution(
                result, 
                optimization_result.optimized_metrics.execution_time,
                "TEST-002-OPTIMIZED"
            )
        
        # Phase 6: ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\nğŸ“‹ Phase 6: ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
        monitoring_report = monitor.generate_monitoring_report(period_hours=1)
        
        print(f"- ç·å®Ÿè¡Œå›æ•°: {monitoring_report.total_executions}")
        print(f"- æˆåŠŸå®Ÿè¡Œæ•°: {monitoring_report.successful_executions}")
        print(f"- å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {monitoring_report.average_quality_score:.1f}")
        print(f"- Elderæ‰¿èªç‡: {monitoring_report.elder_approval_rate:.1f}%")
        print(f"- åŠ¹ç‡ãƒˆãƒ¬ãƒ³ãƒ‰: {monitoring_report.pipeline_efficiency_trend}")
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª
        if monitoring_report.active_alerts:
            print(f"âš ï¸ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {len(monitoring_report.active_alerts)}ä»¶")
            for alert in monitoring_report.active_alerts:
                print(f"  - {alert.alert_level.value}: {alert.message}")
        
        # ç›£è¦–çµ±è¨ˆ
        stats = monitor.get_monitoring_statistics()
        print(f"\nğŸ“Š ç›£è¦–çµ±è¨ˆ:")
        print(f"- è¨˜éŒ²ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ•°: {stats['total_metrics_recorded']}")
        print(f"- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {stats['active_alerts_count']}")
        print(f"- è§£æ±ºæ¸ˆã¿ã‚¢ãƒ©ãƒ¼ãƒˆ: {stats['resolved_alerts_count']}")
        
        # æœ€çµ‚çµæœ
        print("\n" + "=" * 80)
        print("ğŸ† çµ±åˆå“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")
        print(f"æœ€çµ‚å“è³ªã‚¹ã‚³ã‚¢: {result.unified_quality_score:.1f}/100")
        print(f"Elderæ‰¿èªçŠ¶æ…‹: {result.overall_status}")
        print(f"å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’ â†’ {optimization_result.optimized_metrics.execution_time:.2f}ç§’")
        print(f"æ€§èƒ½æ”¹å–„: {optimization_result.improvement_percentage:.1f}%")
        
        # ç›£è¦–åœæ­¢
        monitor.stop_monitoring()
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        shutil.rmtree(test_project_path, ignore_errors=True)
        print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


if __name__ == "__main__":
    # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success = asyncio.run(run_unified_quality_pipeline_test())
    
    if success:
        print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("è‡ªå‹•åŒ–å“è³ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")