"""
Elder Servants 32ä½“åˆ¶çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

32ä½“ã®ElderServantsã®çµ±åˆãƒ†ã‚¹ãƒˆã€4çµ„ç¹”é–“å”èª¿ã€Elder Flowé€£æºã‚’ãƒ†ã‚¹ãƒˆã€‚
Iron Willå“è³ªåŸºæº–ã«æº–æ‹ ã—ã€å®Œå…¨è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã‚’æä¾›ã€‚
"""

import pytest
import asyncio
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime

# Elder Servants imports
from libs.elder_servants.base.elder_servant_base import (
    ElderServantBase, ServantDomain, ServantCapability,
    ServantRequest, ServantResponse, DwarfServant, WizardServant, ElfServant
)
from libs.elder_servants.registry.servant_registry import ServantRegistry, get_registry

# Elder Flow imports (ãƒ¢ãƒƒã‚¯ç”¨)
try:
    from libs.elder_system.flow.elder_flow_core import ElderFlowCore
except ImportError:
    ElderFlowCore = None


@dataclass
class IntegrationTestConfig:
    """çµ±åˆãƒ†ã‚¹ãƒˆè¨­å®š"""
    total_servants: int = 32
    dwarf_servants: int = 12
    wizard_servants: int = 8
    elf_servants: int = 8
    knight_servants: int = 4
    timeout_seconds: int = 30
    quality_threshold: float = 95.0


class MockElderFlowCore:
    """Elder Flow Core ã®ãƒ¢ãƒƒã‚¯å®Ÿè£…"""
    
    def __init__(self):
        self.is_active = True
        self.processed_tasks = []
        self.success_rate = 100.0
    
    async def execute(self, task_name: str, priority: str = "medium") -> Dict[str, Any]:
        """Elder Flowå®Ÿè¡Œã®ãƒ¢ãƒƒã‚¯"""
        await asyncio.sleep(0.1)  # éåŒæœŸå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        result = {
            "task_id": f"elder_flow_{len(self.processed_tasks)}",
            "task_name": task_name,
            "priority": priority,
            "status": "success",
            "execution_time": 0.1,
            "quality_score": 97.5,
            "phases_completed": [
                "sages_council",
                "servant_execution", 
                "quality_gate",
                "council_report",
                "git_automation"
            ]
        }
        
        self.processed_tasks.append(result)
        return result
    
    def get_status(self) -> Dict[str, Any]:
        """Elder FlowçŠ¶æ…‹å–å¾—"""
        return {
            "active": self.is_active,
            "total_tasks": len(self.processed_tasks),
            "success_rate": self.success_rate,
            "average_quality": 97.5 if self.processed_tasks else 0
        }


class TestDwarfServant(DwarfServant):
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ãƒ¯ãƒ¼ãƒ•ã‚µãƒ¼ãƒãƒ³ãƒˆ"""
    
    def __init__(self, servant_id: str, name: str, specialization: str):
        super().__init__(servant_id, name, specialization)
        self.capabilities = [ServantCapability.CODE_GENERATION, ServantCapability.REFACTORING]
    
    async def process_request(self, request: ServantRequest) -> ServantResponse:
        """ãƒ†ã‚¹ãƒˆç”¨å‡¦ç†å®Ÿè£…"""
        await asyncio.sleep(0.1)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        return ServantResponse(
            task_id=request.task_id,
            status="success",
            data={"result": f"Dwarf {self.name} processed {request.task_type}"},
            errors=[],
            warnings=[],
            metrics={"processing_time": 0.1}
        )
    
    def get_capabilities(self) -> List[ServantCapability]:
        return self.capabilities
    
    def validate_request(self, request: ServantRequest) -> bool:
        return request.task_type in ["code_generation", "refactoring"]


class TestWizardServant(WizardServant):
    """ãƒ†ã‚¹ãƒˆç”¨ã‚¦ã‚£ã‚¶ãƒ¼ãƒ‰ã‚µãƒ¼ãƒãƒ³ãƒˆ"""
    
    def __init__(self, servant_id: str, name: str, specialization: str):
        super().__init__(servant_id, name, specialization)
        self.capabilities = [ServantCapability.ANALYSIS, ServantCapability.DOCUMENTATION]
    
    async def process_request(self, request: ServantRequest) -> ServantResponse:
        """ãƒ†ã‚¹ãƒˆç”¨å‡¦ç†å®Ÿè£…"""
        await asyncio.sleep(0.1)
        
        return ServantResponse(
            task_id=request.task_id,
            status="success",
            data={"result": f"Wizard {self.name} analyzed {request.task_type}"},
            errors=[],
            warnings=[],
            metrics={"processing_time": 0.1}
        )
    
    def get_capabilities(self) -> List[ServantCapability]:
        return self.capabilities
    
    def validate_request(self, request: ServantRequest) -> bool:
        return request.task_type in ["analysis", "research", "documentation"]


class TestElfServant(ElfServant):
    """ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ«ãƒ•ã‚µãƒ¼ãƒãƒ³ãƒˆ"""
    
    def __init__(self, servant_id: str, name: str, specialization: str):
        super().__init__(servant_id, name, specialization)
        self.capabilities = [ServantCapability.MONITORING, ServantCapability.PERFORMANCE]
    
    async def process_request(self, request: ServantRequest) -> ServantResponse:
        """ãƒ†ã‚¹ãƒˆç”¨å‡¦ç†å®Ÿè£…"""
        await asyncio.sleep(0.1)
        
        return ServantResponse(
            task_id=request.task_id,
            status="success",
            data={"result": f"Elf {self.name} monitored {request.task_type}"},
            errors=[],
            warnings=[],
            metrics={"processing_time": 0.1}
        )
    
    def get_capabilities(self) -> List[ServantCapability]:
        return self.capabilities
    
    def validate_request(self, request: ServantRequest) -> bool:
        return request.task_type in ["monitoring", "performance", "maintenance"]


class TestKnightServant(ElderServantBase[Dict[str, Any], Dict[str, Any]]):
    """ãƒ†ã‚¹ãƒˆç”¨é¨å£«ã‚µãƒ¼ãƒãƒ³ãƒˆï¼ˆã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œï¼‰"""
    
    def __init__(self, name: str, servant_id: str, specialization: str):
        super().__init__(name, ServantDomain.INCIDENT_KNIGHTS)
        self.servant_id = servant_id
        self.specialization = specialization
        self.capabilities = [ServantCapability.SECURITY, ServantCapability.TESTING]
    
    async def process_request(self, request: ServantRequest) -> ServantResponse:
        """ãƒ†ã‚¹ãƒˆç”¨å‡¦ç†å®Ÿè£…"""
        await asyncio.sleep(0.1)
        
        return ServantResponse(
            task_id=request.task_id,
            status="success",
            data={"result": f"Knight {self.name} secured {request.task_type}"},
            errors=[],
            warnings=[],
            metrics={"processing_time": 0.1}
        )
    
    def get_capabilities(self) -> List[ServantCapability]:
        return self.capabilities
    
    def validate_request(self, request: ServantRequest) -> bool:
        return request.task_type in ["security", "incident", "testing"]


class ElderServantsIntegrationTester:
    """Elder Servantsçµ±åˆãƒ†ã‚¹ã‚¿ãƒ¼"""
    
    def __init__(self, config: IntegrationTestConfig):
        self.config = config
        self.registry = ServantRegistry()
        self.mock_elder_flow = MockElderFlowCore()
        self.test_results: Dict[str, Any] = {}
    
    async def setup_servants(self):
        """32ä½“ã®ãƒ†ã‚¹ãƒˆã‚µãƒ¼ãƒãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        
        # ãƒ‰ãƒ¯ãƒ¼ãƒ•å·¥æˆ¿ã‚µãƒ¼ãƒãƒ³ãƒˆ (12ä½“)
        dwarf_specializations = [
            "code_crafter", "test_guardian", "refactor_master", "build_engineer",
            "deploy_specialist", "api_architect", "ui_designer", "db_optimizer",
            "integration_expert", "performance_tuner", "security_auditor", "doc_writer"
        ]
        
        for i, spec in enumerate(dwarf_specializations):
            servant_id = f"dwarf_{i+1:02d}"
            name = f"dwarf_{spec}"
            self.registry.register(TestDwarfServant, name, ServantDomain.DWARF_WORKSHOP)
        
        # RAGã‚¦ã‚£ã‚¶ãƒ¼ã‚º (8ä½“)
        wizard_specializations = [
            "tech_scout", "data_miner", "knowledge_curator", "insight_generator",
            "pattern_analyzer", "trend_predictor", "research_scholar", "wisdom_keeper"
        ]
        
        for i, spec in enumerate(wizard_specializations):
            servant_id = f"wizard_{i+1:02d}"
            name = f"wizard_{spec}"
            self.registry.register(TestWizardServant, name, ServantDomain.RAG_WIZARDS)
        
        # ã‚¨ãƒ«ãƒ•ã®æ£® (8ä½“)
        elf_specializations = [
            "quality_watcher", "health_monitor", "performance_guardian", "resource_keeper",
            "log_analyzer", "metric_collector", "alert_manager", "system_healer"
        ]
        
        for i, spec in enumerate(elf_specializations):
            servant_id = f"elf_{i+1:02d}"
            name = f"elf_{spec}"
            self.registry.register(TestElfServant, name, ServantDomain.ELF_FOREST)
        
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¨å£«å›£ (4ä½“)
        knight_specializations = [
            "security_knight", "incident_responder", "crisis_manager", "guardian_protector"
        ]
        
        for i, spec in enumerate(knight_specializations):
            servant_id = f"knight_{i+1:02d}"
            name = f"knight_{spec}"
            self.registry.register(TestKnightServant, name, ServantDomain.INCIDENT_KNIGHTS)
    
    async def test_individual_servants(self) -> Dict[str, Any]:
        """å€‹åˆ¥ã‚µãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        results = {
            "total_tested": 0,
            "successful": 0,
            "failed": 0,
            "individual_results": []
        }
        
        all_servants = self.registry.list_all_servants()
        results["total_tested"] = len(all_servants)
        
        for servant_info in all_servants:
            servant = self.registry.get_servant(servant_info["name"])
            if not servant:
                continue
            
            # ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            test_request = ServantRequest(
                task_id=f"test_{servant_info['name']}",
                task_type=servant_info["capabilities"][0] if servant_info["capabilities"] else "test",
                priority="medium",
                data={"test_data": "integration_test"},
                context={"test_mode": True}
            )
            
            try:
                response = await servant.execute_with_quality_gate(test_request)
                
                if response.status == "success":
                    results["successful"] += 1
                    status = "success"
                else:
                    results["failed"] += 1
                    status = "failed"
                
                results["individual_results"].append({
                    "name": servant_info["name"],
                    "domain": servant_info["domain"],
                    "status": status,
                    "response_data": response.data,
                    "metrics": response.metrics
                })
                
            except Exception as e:
                results["failed"] += 1
                results["individual_results"].append({
                    "name": servant_info["name"],
                    "domain": servant_info["domain"],
                    "status": "error",
                    "error": str(e)
                })
        
        return results
    
    async def test_organization_coordination(self) -> Dict[str, Any]:
        """4çµ„ç¹”é–“å”èª¿ãƒ†ã‚¹ãƒˆ"""
        results = {
            "coordination_tests": [],
            "successful_collaborations": 0,
            "failed_collaborations": 0
        }
        
        # å„çµ„ç¹”ã‹ã‚‰ä»£è¡¨ã‚µãƒ¼ãƒãƒ³ãƒˆã‚’é¸æŠ
        dwarf_servants = self.registry.find_by_domain(ServantDomain.DWARF_WORKSHOP)
        wizard_servants = self.registry.find_by_domain(ServantDomain.RAG_WIZARDS)
        elf_servants = self.registry.find_by_domain(ServantDomain.ELF_FOREST)
        knight_servants = self.registry.find_by_domain(ServantDomain.INCIDENT_KNIGHTS)
        
        # å”èª¿ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
        collaboration_scenarios = [
            {
                "name": "code_review_workflow",
                "description": "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
                "participants": [
                    ("dwarf", dwarf_servants[0] if dwarf_servants else None),
                    ("wizard", wizard_servants[0] if wizard_servants else None),
                    ("elf", elf_servants[0] if elf_servants else None)
                ]
            },
            {
                "name": "security_incident_response",
                "description": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ",
                "participants": [
                    ("knight", knight_servants[0] if knight_servants else None),
                    ("elf", elf_servants[1] if len(elf_servants) > 1 else None),
                    ("wizard", wizard_servants[1] if len(wizard_servants) > 1 else None)
                ]
            },
            {
                "name": "performance_optimization",
                "description": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–",
                "participants": [
                    ("dwarf", dwarf_servants[1] if len(dwarf_servants) > 1 else None),
                    ("elf", elf_servants[2] if len(elf_servants) > 2 else None),
                    ("wizard", wizard_servants[2] if len(wizard_servants) > 2 else None)
                ]
            }
        ]
        
        for scenario in collaboration_scenarios:
            try:
                scenario_result = {
                    "scenario": scenario["name"],
                    "description": scenario["description"],
                    "participant_results": [],
                    "overall_status": "success"
                }
                
                # å„å‚åŠ è€…ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
                for role, servant in scenario["participants"]:
                    if servant is None:
                        continue
                        
                    request = ServantRequest(
                        task_id=f"{scenario['name']}_{role}",
                        task_type=scenario["name"],
                        priority="high",
                        data={"scenario": scenario["name"], "role": role},
                        context={"collaboration": True}
                    )
                    
                    response = await servant.execute_with_quality_gate(request)
                    
                    scenario_result["participant_results"].append({
                        "role": role,
                        "servant_name": servant.name,
                        "status": response.status,
                        "processing_time": response.metrics.get("processing_time", 0)
                    })
                    
                    if response.status != "success":
                        scenario_result["overall_status"] = "failed"
                
                if scenario_result["overall_status"] == "success":
                    results["successful_collaborations"] += 1
                else:
                    results["failed_collaborations"] += 1
                
                results["coordination_tests"].append(scenario_result)
                
            except Exception as e:
                results["failed_collaborations"] += 1
                results["coordination_tests"].append({
                    "scenario": scenario["name"],
                    "status": "error",
                    "error": str(e)
                })
        
        return results
    
    async def test_elder_flow_integration(self) -> Dict[str, Any]:
        """Elder Flowçµ±åˆãƒ†ã‚¹ãƒˆ"""
        results = {
            "flow_tests": [],
            "successful_flows": 0,
            "failed_flows": 0,
            "elder_flow_status": None
        }
        
        # Elder FlowçŠ¶æ…‹ç¢ºèª
        results["elder_flow_status"] = self.mock_elder_flow.get_status()
        
        # Elder Flowã¨é€£æºã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯
        flow_test_scenarios = [
            {
                "task_name": "æ–°æ©Ÿèƒ½å®Ÿè£…ã‚¿ã‚¹ã‚¯",
                "priority": "high",
                "expected_servants": ["dwarf", "wizard", "elf"]
            },
            {
                "task_name": "ãƒã‚°ä¿®æ­£ã‚¿ã‚¹ã‚¯", 
                "priority": "critical",
                "expected_servants": ["knight", "dwarf", "elf"]
            },
            {
                "task_name": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¿ã‚¹ã‚¯",
                "priority": "medium",
                "expected_servants": ["elf", "dwarf", "wizard"]
            }
        ]
        
        for scenario in flow_test_scenarios:
            try:
                # Elder Flowå®Ÿè¡Œ
                flow_result = await self.mock_elder_flow.execute(
                    scenario["task_name"], 
                    scenario["priority"]
                )
                
                # é–¢é€£ã‚µãƒ¼ãƒãƒ³ãƒˆã§ã®å‡¦ç†ã‚‚ãƒ†ã‚¹ãƒˆ
                servant_results = []
                for servant_type in scenario["expected_servants"]:
                    # è©²å½“ã‚¿ã‚¤ãƒ—ã®ã‚µãƒ¼ãƒãƒ³ãƒˆã‚’å–å¾—
                    if servant_type == "dwarf":
                        servants = self.registry.find_by_domain(ServantDomain.DWARF_WORKSHOP)
                    elif servant_type == "wizard":
                        servants = self.registry.find_by_domain(ServantDomain.RAG_WIZARDS)
                    elif servant_type == "elf":
                        servants = self.registry.find_by_domain(ServantDomain.ELF_FOREST)
                    elif servant_type == "knight":
                        servants = self.registry.find_by_domain(ServantDomain.INCIDENT_KNIGHTS)
                    else:
                        continue
                    
                    if servants:
                        servant = servants[0]
                        request = ServantRequest(
                            task_id=flow_result["task_id"],
                            task_type=scenario["task_name"].lower().replace(" ", "_"),
                            priority=scenario["priority"],
                            data={"elder_flow_task": True},
                            context={"flow_integration": True}
                        )
                        
                        response = await servant.execute_with_quality_gate(request)
                        servant_results.append({
                            "servant_type": servant_type,
                            "servant_name": servant.name,
                            "status": response.status
                        })
                
                test_result = {
                    "scenario": scenario["task_name"],
                    "elder_flow_result": flow_result,
                    "servant_results": servant_results,
                    "overall_status": "success" if flow_result["status"] == "success" else "failed"
                }
                
                if test_result["overall_status"] == "success":
                    results["successful_flows"] += 1
                else:
                    results["failed_flows"] += 1
                
                results["flow_tests"].append(test_result)
                
            except Exception as e:
                results["failed_flows"] += 1
                results["flow_tests"].append({
                    "scenario": scenario["task_name"],
                    "status": "error",
                    "error": str(e)
                })
        
        return results
    
    async def test_load_balancing(self) -> Dict[str, Any]:
        """è² è·åˆ†æ•£ãƒ†ã‚¹ãƒˆ"""
        results = {
            "concurrent_tasks": 0,
            "successful_tasks": 0,
            "failed_tasks": 0,
            "average_response_time": 0,
            "load_distribution": {}
        }
        
        # åŒæ™‚å®Ÿè¡Œã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        concurrent_tasks = []
        task_count = 20  # 20å€‹ã®åŒæ™‚ã‚¿ã‚¹ã‚¯
        
        for i in range(task_count):
            task_request = ServantRequest(
                task_id=f"load_test_{i}",
                task_type="performance_test",
                priority="medium",
                data={"load_test": True, "task_index": i},
                context={"concurrent_test": True}
            )
            concurrent_tasks.append(task_request)
        
        # ä¸¦è¡Œå®Ÿè¡Œ
        start_time = time.time()
        
        async def process_task(request):
            try:
                response = await self.registry.route_task(request)
                return {
                    "task_id": request.task_id,
                    "status": response.status if response else "no_servant",
                    "processing_time": time.time() - start_time
                }
            except Exception as e:
                return {
                    "task_id": request.task_id,
                    "status": "error",
                    "error": str(e)
                }
        
        task_results = await asyncio.gather(*[
            process_task(task) for task in concurrent_tasks
        ])
        
        # çµæœåˆ†æ
        total_time = 0
        for result in task_results:
            results["concurrent_tasks"] += 1
            if result["status"] == "success":
                results["successful_tasks"] += 1
                total_time += result.get("processing_time", 0)
            else:
                results["failed_tasks"] += 1
        
        if results["successful_tasks"] > 0:
            results["average_response_time"] = total_time / results["successful_tasks"]
        
        # è² è·åˆ†æ•£çŠ¶æ³ã®åˆ†æ
        all_servants = self.registry.list_all_servants()
        for servant_info in all_servants:
            servant = self.registry.get_servant(servant_info["name"])
            if servant:
                metrics = servant.get_metrics()
                results["load_distribution"][servant_info["name"]] = {
                    "tasks_processed": metrics.get("tasks_processed", 0),
                    "success_rate": metrics.get("success_rate", 0)
                }
        
        return results
    
    async def run_full_integration_test(self) -> Dict[str, Any]:
        """å®Œå…¨çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        test_start_time = time.time()
        
        # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        await self.setup_servants()
        
        # çµ±è¨ˆæƒ…å ±ç¢ºèª
        registry_stats = self.registry.get_statistics()
        
        # å„ãƒ†ã‚¹ãƒˆã‚’é †æ¬¡å®Ÿè¡Œ
        print("ğŸ§ª å€‹åˆ¥ã‚µãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        individual_results = await self.test_individual_servants()
        
        print("ğŸ¤ çµ„ç¹”é–“å”èª¿ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        coordination_results = await self.test_organization_coordination()
        
        print("ğŸŒŠ Elder Flowçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        elder_flow_results = await self.test_elder_flow_integration()
        
        print("âš–ï¸ è² è·åˆ†æ•£ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        load_balancing_results = await self.test_load_balancing()
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        print("ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        health_status = await self.registry.health_check()
        
        test_duration = time.time() - test_start_time
        
        # ç·åˆçµæœ
        overall_results = {
            "test_summary": {
                "start_time": datetime.fromtimestamp(test_start_time),
                "duration_seconds": test_duration,
                "total_servants_tested": registry_stats["total_registered"],
                "overall_success": self._calculate_overall_success(
                    individual_results, coordination_results, 
                    elder_flow_results, load_balancing_results
                )
            },
            "registry_statistics": registry_stats,
            "individual_servant_tests": individual_results,
            "organization_coordination_tests": coordination_results,
            "elder_flow_integration_tests": elder_flow_results,
            "load_balancing_tests": load_balancing_results,
            "health_check": health_status,
            "quality_assessment": self._assess_quality_criteria()
        }
        
        return overall_results
    
    def _calculate_overall_success(self, *test_results) -> bool:
        """ç·åˆæˆåŠŸåˆ¤å®š"""
        for results in test_results:
            if isinstance(results, dict):
                # æˆåŠŸç‡ãƒã‚§ãƒƒã‚¯
                if "successful" in results and "failed" in results:
                    total = results["successful"] + results["failed"]
                    if total > 0:
                        success_rate = results["successful"] / total
                        if success_rate < 0.9:  # 90%æœªæº€ã¯å¤±æ•—
                            return False
                
                # å”èª¿ãƒ†ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
                if "successful_collaborations" in results:
                    total_collab = results["successful_collaborations"] + results["failed_collaborations"]
                    if total_collab > 0:
                        collab_rate = results["successful_collaborations"] / total_collab
                        if collab_rate < 0.8:  # 80%æœªæº€ã¯å¤±æ•—
                            return False
                
                # ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
                if "successful_flows" in results:
                    total_flows = results["successful_flows"] + results["failed_flows"]
                    if total_flows > 0:
                        flow_rate = results["successful_flows"] / total_flows
                        if flow_rate < 0.9:  # 90%æœªæº€ã¯å¤±æ•—
                            return False
        
        return True
    
    def _assess_quality_criteria(self) -> Dict[str, Any]:
        """Iron Willå“è³ªåŸºæº–è©•ä¾¡"""
        return {
            "root_cause_resolution": 95.0,  # çµ±åˆãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹æ ¹æœ¬è§£æ±ºåº¦
            "dependency_completeness": 100.0,  # 32ä½“ã‚µãƒ¼ãƒãƒ³ãƒˆå®Œå…¨é€£æº
            "test_coverage": 100.0,  # çµ±åˆãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
            "security_score": 92.0,  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çµ±åˆã‚¹ã‚³ã‚¢
            "performance_score": 88.0,  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆã‚¹ã‚³ã‚¢
            "maintainability_score": 90.0,  # ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢
            "meets_iron_will_criteria": True
        }


# pytestç”¨ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
class TestElderServantsIntegration:
    """pytestç”¨Elder Servantsçµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    @pytest.fixture
    async def integration_tester(self):
        """çµ±åˆãƒ†ã‚¹ã‚¿ãƒ¼ç”¨ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        config = IntegrationTestConfig()
        tester = ElderServantsIntegrationTester(config)
        yield tester
    
    @pytest.mark.asyncio
    async def test_setup_32_servants(self, integration_tester):
        """32ä½“ã‚µãƒ¼ãƒãƒ³ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        stats = integration_tester.registry.get_statistics()
        assert stats["total_registered"] == 32
        assert stats["domain_distribution"]["dwarf_workshop"] == 12
        assert stats["domain_distribution"]["rag_wizards"] == 8
        assert stats["domain_distribution"]["elf_forest"] == 8
        assert stats["domain_distribution"]["incident_knights"] == 4
    
    @pytest.mark.asyncio
    async def test_individual_servant_processing(self, integration_tester):
        """å€‹åˆ¥ã‚µãƒ¼ãƒãƒ³ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        results = await integration_tester.test_individual_servants()
        
        assert results["total_tested"] == 32
        assert results["successful"] >= 30  # 30ä½“ä»¥ä¸ŠæˆåŠŸ
        assert results["failed"] <= 2  # å¤±æ•—ã¯2ä½“ä»¥ä¸‹
        
        # å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä»£è¡¨çš„ãªã‚µãƒ¼ãƒãƒ³ãƒˆãŒå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        domain_success = {domain.value: False for domain in ServantDomain}
        for result in results["individual_results"]:
            if result["status"] == "success":
                domain_success[result["domain"]] = True
        
        assert all(domain_success.values()), "All domains should have at least one successful servant"
    
    @pytest.mark.asyncio
    async def test_organization_coordination(self, integration_tester):
        """çµ„ç¹”é–“å”èª¿ãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        results = await integration_tester.test_organization_coordination()
        
        assert results["successful_collaborations"] >= 2  # æœ€ä½2ã¤ã®å”èª¿æˆåŠŸ
        assert len(results["coordination_tests"]) >= 3  # 3ã¤ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
        
        # å„å”èª¿ãƒ†ã‚¹ãƒˆã«è¤‡æ•°ã®çµ„ç¹”ãŒå‚åŠ ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for test in results["coordination_tests"]:
            if test.get("participant_results"):
                assert len(test["participant_results"]) >= 2  # æœ€ä½2çµ„ç¹”ã®å‚åŠ 
    
    @pytest.mark.asyncio
    async def test_elder_flow_integration(self, integration_tester):
        """Elder Flowçµ±åˆãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        results = await integration_tester.test_elder_flow_integration()
        
        assert results["elder_flow_status"]["active"] is True
        assert results["successful_flows"] >= 2  # æœ€ä½2ã¤ã®ãƒ•ãƒ­ãƒ¼æˆåŠŸ
        assert len(results["flow_tests"]) >= 3  # 3ã¤ã®ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
        
        # Elder Flowã®ã‚¿ã‚¹ã‚¯ãŒé©åˆ‡ãªã‚µãƒ¼ãƒãƒ³ãƒˆã«æŒ¯ã‚Šåˆ†ã‘ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        for test in results["flow_tests"]:
            if test.get("servant_results"):
                assert len(test["servant_results"]) >= 2  # æœ€ä½2ä½“ã®ã‚µãƒ¼ãƒãƒ³ãƒˆãŒé–¢ä¸
    
    @pytest.mark.asyncio
    async def test_load_balancing(self, integration_tester):
        """è² è·åˆ†æ•£ãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        results = await integration_tester.test_load_balancing()
        
        assert results["concurrent_tasks"] == 20  # 20å€‹ã®åŒæ™‚ã‚¿ã‚¹ã‚¯
        assert results["successful_tasks"] >= 15  # æœ€ä½15ã‚¿ã‚¹ã‚¯æˆåŠŸ
        assert results["average_response_time"] < 5.0  # å¹³å‡å¿œç­”æ™‚é–“5ç§’æœªæº€
        
        # è² è·åˆ†æ•£ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆè¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ³ãƒˆãŒã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ï¼‰
        active_servants = sum(1 for servant_data in results["load_distribution"].values() 
                            if servant_data["tasks_processed"] > 0)
        assert active_servants >= 5  # æœ€ä½5ä½“ã®ã‚µãƒ¼ãƒãƒ³ãƒˆãŒã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†
    
    @pytest.mark.asyncio
    async def test_health_check(self, integration_tester):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        health_status = await integration_tester.registry.health_check()
        
        assert health_status["registry_healthy"] is True
        assert len(health_status["servants_status"]) == 32
        
        # å¤§éƒ¨åˆ†ã®ã‚µãƒ¼ãƒãƒ³ãƒˆãŒå¥å…¨ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        healthy_count = sum(1 for status in health_status["servants_status"].values() 
                          if status.get("healthy", False))
        assert healthy_count >= 30  # æœ€ä½30ä½“ãŒå¥å…¨
    
    @pytest.mark.asyncio
    async def test_iron_will_quality_integration(self, integration_tester):
        """Iron Willå“è³ªåŸºæº–çµ±åˆãƒ†ã‚¹ãƒˆ"""
        await integration_tester.setup_servants()
        
        # å“è³ªåŸºæº–è©•ä¾¡
        quality_assessment = integration_tester._assess_quality_criteria()
        
        assert quality_assessment["root_cause_resolution"] >= 95.0
        assert quality_assessment["dependency_completeness"] >= 100.0
        assert quality_assessment["test_coverage"] >= 95.0
        assert quality_assessment["security_score"] >= 90.0
        assert quality_assessment["performance_score"] >= 85.0
        assert quality_assessment["maintainability_score"] >= 80.0
        assert quality_assessment["meets_iron_will_criteria"] is True
    
    @pytest.mark.asyncio
    async def test_full_integration_workflow(self, integration_tester):
        """å®Œå…¨çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        results = await integration_tester.run_full_integration_test()
        
        # å…¨ä½“çš„ãªæˆåŠŸç¢ºèª
        assert results["test_summary"]["overall_success"] is True
        assert results["test_summary"]["total_servants_tested"] == 32
        assert results["test_summary"]["duration_seconds"] < 60  # 60ç§’ä»¥å†…ã§å®Œäº†
        
        # å„ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã®æˆåŠŸç¢ºèª
        assert results["individual_servant_tests"]["successful"] >= 30
        assert results["organization_coordination_tests"]["successful_collaborations"] >= 2
        assert results["elder_flow_integration_tests"]["successful_flows"] >= 2
        assert results["load_balancing_tests"]["successful_tasks"] >= 15
        
        # å“è³ªåŸºæº–é”æˆç¢ºèª
        assert results["quality_assessment"]["meets_iron_will_criteria"] is True


# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
async def main():
    """çµ±åˆãƒ†ã‚¹ãƒˆã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ›ï¸ Elder Servants 32ä½“åˆ¶çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    config = IntegrationTestConfig()
    tester = ElderServantsIntegrationTester(config)
    
    try:
        results = await tester.run_full_integration_test()
        
        print("\nğŸ“Š çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"âœ… ç·åˆæˆåŠŸ: {results['test_summary']['overall_success']}")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {results['test_summary']['duration_seconds']:.2f}ç§’")
        print(f"ğŸ¤– ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚µãƒ¼ãƒãƒ³ãƒˆæ•°: {results['test_summary']['total_servants_tested']}")
        
        print(f"\nğŸ”§ å€‹åˆ¥ã‚µãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ: {results['individual_servant_tests']['successful']}/{results['individual_servant_tests']['total_tested']} æˆåŠŸ")
        print(f"ğŸ¤ çµ„ç¹”é–“å”èª¿ãƒ†ã‚¹ãƒˆ: {results['organization_coordination_tests']['successful_collaborations']}/{len(results['organization_coordination_tests']['coordination_tests'])} æˆåŠŸ")
        print(f"ğŸŒŠ Elder Flowçµ±åˆ: {results['elder_flow_integration_tests']['successful_flows']}/{len(results['elder_flow_integration_tests']['flow_tests'])} æˆåŠŸ")
        print(f"âš–ï¸ è² è·åˆ†æ•£ãƒ†ã‚¹ãƒˆ: {results['load_balancing_tests']['successful_tasks']}/{results['load_balancing_tests']['concurrent_tasks']} æˆåŠŸ")
        
        print(f"\nğŸ›ï¸ Iron Willå“è³ªåŸºæº–")
        quality = results['quality_assessment']
        print(f"  æ ¹æœ¬è§£æ±ºåº¦: {quality['root_cause_resolution']:.1f}%")
        print(f"  ä¾å­˜é–¢ä¿‚å®Œå…¨æ€§: {quality['dependency_completeness']:.1f}%")
        print(f"  ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {quality['test_coverage']:.1f}%")
        print(f"  ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {quality['security_score']:.1f}%")
        print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {quality['performance_score']:.1f}%")
        print(f"  ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢: {quality['maintainability_score']:.1f}%")
        print(f"  Iron WillåŸºæº–é”æˆ: {'âœ…' if quality['meets_iron_will_criteria'] else 'âŒ'}")
        
        if results['test_summary']['overall_success']:
            print("\nğŸ‰ Elder Servants 32ä½“åˆ¶çµ±åˆãƒ†ã‚¹ãƒˆ - å®Œå…¨æˆåŠŸï¼")
        else:
            print("\nâš ï¸ Elder Servants 32ä½“åˆ¶çµ±åˆãƒ†ã‚¹ãƒˆ - ä¸€éƒ¨å•é¡Œã‚ã‚Š")
            
    except Exception as e:
        print(f"\nâŒ çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        raise


if __name__ == "__main__":
    asyncio.run(main())