#!/usr/bin/env python3
"""
å‹•çš„çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import sys
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from libs.dynamic_knowledge_graph import (
    ConceptRelation,
    DynamicKnowledgeGraph,
    KnowledgeCluster,
    KnowledgeEdge,
    KnowledgeNode,
    SemanticEmbedding,
)


def test_knowledge_node_creation():
    """çŸ¥è­˜ãƒãƒ¼ãƒ‰ä½œæˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜ãƒãƒ¼ãƒ‰ä½œæˆãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    node = graph.create_node(
        content="Machine learning algorithms improve system performance",
        node_type="concept",
        metadata={"domain": "AI", "confidence": 0.95},
    )

    tests_passed = 0
    tests_total = 4

    if isinstance(node, KnowledgeNode):
        print("  âœ… KnowledgeNodeã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ")
        tests_passed += 1
    else:
        print("  âŒ Wrong node type")

    if node.content == "Machine learning algorithms improve system performance":
        print("  âœ… ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Content mismatch")

    if node.node_type == "concept":
        print("  âœ… ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Node type mismatch")

    if hasattr(node, "node_id") and node.node_id:
        print(f"  âœ… ãƒãƒ¼ãƒ‰IDç”Ÿæˆ: {node.node_id[:12]}...")
        tests_passed += 1
    else:
        print("  âŒ No node ID")

    return tests_passed, tests_total


def test_node_importance_scoring():
    """ãƒãƒ¼ãƒ‰é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ãƒãƒ¼ãƒ‰é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    central_node = KnowledgeNode("central", "Core machine learning concept", "concept")

    connections = [
        {"target": "node1", "strength": 0.8},
        {"target": "node2", "strength": 0.7},
        {"target": "node3", "strength": 0.9},
        {"target": "node4", "strength": 0.6},
    ]

    importance = graph.calculate_node_importance(central_node, connections)

    tests_passed = 0
    tests_total = 3

    if 0 <= importance <= 1:
        print(f"  âœ… é‡è¦åº¦ç¯„å›²OK: {importance:.3f}")
        tests_passed += 1
    # è¤‡é›‘ãªæ¡ä»¶åˆ¤å®š
    else:
        print(f"  âŒ Invalid importance: {importance}")

    if importance > 0.5:
        print("  âœ… å¤šæ¥ç¶šã«ã‚ˆã‚‹é«˜é‡è¦åº¦")
        tests_passed += 1
    else:
        print(f"  âŒ Expected high importance, got {importance:.3f}")

    if isinstance(importance, float):
        print("  âœ… æ•°å€¤å‹")
        tests_passed += 1
    else:
        print("  âŒ Wrong type")

    return tests_passed, tests_total


def test_node_similarity_calculation():
    """ãƒãƒ¼ãƒ‰é¡ä¼¼åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ãƒãƒ¼ãƒ‰é¡ä¼¼åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    node1 = KnowledgeNode("n1", "Machine learning algorithms", "concept")
    node2 = KnowledgeNode("n2", "Deep learning neural networks", "concept")
    node3 = KnowledgeNode("n3", "Database optimization techniques", "concept")

    similarity_high = graph.calculate_node_similarity(node1, node2)
    similarity_low = graph.calculate_node_similarity(node1, node3)

    tests_passed = 0
    tests_total = 3

    if 0 <= similarity_high <= 1 and 0 <= similarity_low <= 1:
        print(f"  âœ… é¡ä¼¼åº¦ç¯„å›²OK: é«˜={similarity_high:.3f}, ä½={similarity_low:.3f}")
        tests_passed += 1
    else:
        print(f"  âŒ Invalid similarity ranges")

    if similarity_high > similarity_low:
        print("  âœ… MLé–¢é€£ã¯é«˜é¡ä¼¼åº¦")
        tests_passed += 1
    else:
        print(
            f"  âŒ Expected high > low, got {similarity_high:.3f} vs {similarity_low:.3f}"
        )

    if similarity_high > 0.1:  # ä½•ã‚‰ã‹ã®é¡ä¼¼åº¦ã¯å­˜åœ¨
        print("  âœ… æœ‰æ„ãªé¡ä¼¼åº¦æ¤œå‡º")
        tests_passed += 1
    else:
        print("  âŒ Too low similarity")

    return tests_passed, tests_total


def test_knowledge_edge_creation():
    """çŸ¥è­˜ã‚¨ãƒƒã‚¸ä½œæˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜ã‚¨ãƒƒã‚¸ä½œæˆãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    edge = graph.create_edge(
        source_id="node1",
        target_id="node2",
        relation_type="related_to",
        strength=0.75,
        metadata={"discovered_at": datetime.now()},
    )

    tests_passed = 0
    tests_total = 4

    if isinstance(edge, KnowledgeEdge):
        print("  âœ… KnowledgeEdgeã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ")
        tests_passed += 1
    else:
        print("  âŒ Wrong edge type")

    if edge.source_id == "node1" and edge.target_id == "node2":
        print("  âœ… ã‚½ãƒ¼ã‚¹ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆIDæ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ ID mismatch")

    if edge.relation_type == "related_to":
        print("  âœ… é–¢ä¿‚ã‚¿ã‚¤ãƒ—æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Relation type mismatch")

    if edge.strength == 0.75:
        print("  âœ… å¼·åº¦æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Strength mismatch")

    return tests_passed, tests_total


def test_edge_strength_calculation():
    """ã‚¨ãƒƒã‚¸å¼·åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ã‚¨ãƒƒã‚¸å¼·åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    concept1 = "neural networks"
    concept2 = "deep learning"
    context = {
        "co_occurrence_frequency": 15,
        "semantic_similarity": 0.89,
        "domain_overlap": 0.95,
    }

    strength = graph.calculate_edge_strength(concept1, concept2, context)

    tests_passed = 0
    tests_total = 2

    if 0 <= strength <= 1:
        print(f"  âœ… å¼·åº¦ç¯„å›²OK: {strength:.3f}")
    # è¤‡é›‘ãªæ¡ä»¶åˆ¤å®š
        tests_passed += 1
    else:
        print(f"  âŒ Invalid strength: {strength}")

    if strength > 0.7:
        print("  âœ… å¼·ã„é–¢é€£æ€§ã«ã‚ˆã‚‹é«˜å¼·åº¦")
        tests_passed += 1
    else:
        print(f"  âŒ Expected high strength, got {strength:.3f}")

    return tests_passed, tests_total


def test_semantic_embedding_generation():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    text = "Machine learning models require extensive training data"
    embedding = graph.generate_embedding(text)

    tests_passed = 0
    tests_total = 4

    if isinstance(embedding, SemanticEmbedding):
        print("  âœ… SemanticEmbeddingã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ")
        tests_passed += 1
    else:
        print("  âŒ Wrong embedding type")

    if embedding.text == text:
        print("  âœ… ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Text mismatch")

    if isinstance(embedding.vector, (list, np.ndarray)) and len(embedding.vector) > 0:
        print(f"  âœ… ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ: æ¬¡å…ƒ={len(embedding.vector)}")
        tests_passed += 1
    else:
        print("  âŒ Invalid vector")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ
    embedding2 = graph.generate_embedding(text)
    if embedding.vector == embedding2.vector:
        print("  âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½æ­£å¸¸")
        tests_passed += 1
    else:
        print("  âŒ Cache not working")

    return tests_passed, tests_total


def test_embedding_similarity_search():
    """åŸ‹ã‚è¾¼ã¿é¡ä¼¼æ€§æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª åŸ‹ã‚è¾¼ã¿é¡ä¼¼æ€§æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    query_embedding = SemanticEmbedding(
        "neural network training", [0.1, 0.8, 0.3, 0.6, 0.2]
    )

    candidate_embeddings = [
        SemanticEmbedding("deep learning models", [0.2, 0.9, 0.1, 0.7, 0.1]),
        SemanticEmbedding("database queries", [0.9, 0.1, 0.8, 0.2, 0.9]),
        SemanticEmbedding(
            "machine learning algorithms", [0.15, 0.85, 0.25, 0.65, 0.15]
        ),
    ]

    similar = graph.find_similar_embeddings(
        query_embedding, candidate_embeddings, top_k=2
    )

    tests_passed = 0
    tests_total = 3

    if len(similar) <= 2:
        print(f"  âœ… Top-Kåˆ¶é™æ­£å¸¸: {len(similar)}ä»¶")
        tests_passed += 1
    else:
        print(f"  âŒ Too many results: {len(similar)}")

    if all(isinstance(item, tuple) for item in similar):
        print("  âœ… çµæœå½¢å¼æ­£å¸¸ (embedding, score)")
        tests_passed += 1
    else:
        print("  âŒ Wrong result format")

    if len(similar) > 1 and similar[0][1] >= similar[1][1]:
        print(f"  âœ… é¡ä¼¼åº¦ã‚½ãƒ¼ãƒˆæ­£å¸¸: {similar[0][1]:.3f} >= {similar[1][1]:.3f}")
        tests_passed += 1
    elif len(similar) == 1:
        print(f"  âœ… å˜ä¸€çµæœ: {similar[0][1]:.3f}")
        tests_passed += 1
    else:
        print("  âŒ Sorting issue")

    return tests_passed, tests_total


async def test_concept_relations_discovery():
    """ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–¢ä¿‚ç™ºè¦‹ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–¢ä¿‚ç™ºè¦‹ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    text_corpus = [
        "Machine learning algorithms improve system performance",
        "Deep learning models require GPU acceleration",
        "Neural networks are a type of machine learning algorithm",
        "System performance can be optimized using caching strategies",
        "GPU acceleration significantly speeds up training",
    ]

    relations = await graph.discover_concept_relations(text_corpus)

    tests_passed = 0
    tests_total = 3

    if isinstance(relations, list):
        print(f"  âœ… é–¢ä¿‚ãƒªã‚¹ãƒˆå–å¾—: {len(relations)}ä»¶")
        tests_passed += 1
    else:
        print("  âŒ Wrong relations type")

    if relations and all(isinstance(rel, ConceptRelation) for rel in relations):
        print("  âœ… ConceptRelationã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
        tests_passed += 1
    elif not relations:
        print("  âš ï¸ é–¢ä¿‚æœªç™ºè¦‹ï¼ˆæ­£å¸¸ãªå ´åˆã‚‚ã‚ã‚‹ï¼‰")
        tests_passed += 1
    else:
        print("  âŒ Wrong relation types")

    if relations:
        first_relation = relations[0]
        if (
            hasattr(first_relation, "confidence")
            and 0 <= first_relation.confidence <= 1
        ):
            print(f"  âœ… ä¿¡é ¼åº¦æ­£å¸¸: {first_relation.confidence:.3f}")
            tests_passed += 1
        else:
            print("  âŒ Invalid confidence")
    else:
        tests_passed += 1  # é–¢ä¿‚ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

    return tests_passed, tests_total


def test_knowledge_clustering():
    """çŸ¥è­˜ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    nodes = [
        KnowledgeNode("n1", "Machine learning algorithms", "concept"),
        KnowledgeNode("n2", "Deep learning models", "concept"),
        KnowledgeNode("n3", "Neural network training", "concept"),
        KnowledgeNode("n4", "Database optimization", "concept"),
        KnowledgeNode("n5", "SQL query performance", "concept"),
        KnowledgeNode("n6", "Index management", "concept"),
    ]

    clusters = graph.cluster_knowledge(nodes, num_clusters=2)

    tests_passed = 0
    tests_total = 3

    if isinstance(clusters, list) and len(clusters) <= 2:
        print(f"  âœ… ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç”Ÿæˆ: {len(clusters)}å€‹")
        tests_passed += 1
    else:
        print(
            f"  âŒ Wrong cluster count: {len(clusters) if isinstance(clusters, list) else 'not list'}"
        )

    if clusters and all(isinstance(cluster, KnowledgeCluster) for cluster in clusters):
        print("  âœ… KnowledgeClusterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
        tests_passed += 1
    elif not clusters:
        print("  âš ï¸ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æœªç”Ÿæˆ")
        tests_passed += 1
    else:
        print("  âŒ Wrong cluster types")

    if clusters and all(len(cluster.nodes) > 0 for cluster in clusters):
        print("  âœ… å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ãƒãƒ¼ãƒ‰ã‚ã‚Š")
        tests_passed += 1
    else:
        print("  âŒ Empty clusters found")

    return tests_passed, tests_total


def test_cluster_coherence_measurement():
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸€è²«æ€§æ¸¬å®šãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸€è²«æ€§æ¸¬å®šãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    coherent_cluster = KnowledgeCluster(
        "ml_cluster",
        [
            KnowledgeNode("n1", "machine learning", "concept"),
            KnowledgeNode("n2", "neural networks", "concept"),
            KnowledgeNode("n3", "deep learning", "concept"),
        ],
        [0.5, 0.8, 0.3],
    )

    coherence = graph.measure_cluster_coherence(coherent_cluster)

    tests_passed = 0
    tests_total = 2

    if 0 <= coherence <= 1:
    # è¤‡é›‘ãªæ¡ä»¶åˆ¤å®š
        print(f"  âœ… ä¸€è²«æ€§ç¯„å›²OK: {coherence:.3f}")
        tests_passed += 1
    else:
        print(f"  âŒ Invalid coherence: {coherence}")

    if coherence > 0.3:  # MLé–¢é€£ãªã®ã§ä¸€å®šã®ä¸€è²«æ€§ã‚’æœŸå¾…
        print("  âœ… é–¢é€£æ¦‚å¿µã«ã‚ˆã‚‹é«˜ä¸€è²«æ€§")
        tests_passed += 1
    else:
        print(f"  âŒ Expected higher coherence, got {coherence:.3f}")

    return tests_passed, tests_total


async def test_dynamic_graph_update():
    """å‹•çš„ã‚°ãƒ©ãƒ•æ›´æ–°ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª å‹•çš„ã‚°ãƒ©ãƒ•æ›´æ–°ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    new_information = {
        "content": "Transformer models revolutionize natural language processing",
        "source": "recent_research",
        "confidence": 0.92,
    }

    update_result = await graph.update_graph_dynamically(new_information)

    tests_passed = 0
    tests_total = 3

    if hasattr(update_result, "update_type"):
        print(f"  âœ… æ›´æ–°ã‚¿ã‚¤ãƒ—: {update_result.update_type}")
        tests_passed += 1
    else:
        print("  âŒ No update type")

    if hasattr(update_result, "target") and update_result.target:
        print(f"  âœ… æ›´æ–°å¯¾è±¡: {update_result.target[:12]}...")
        tests_passed += 1
    else:
        print("  âŒ No target")

    if hasattr(update_result, "data") and isinstance(update_result.data, dict):
        print(f"  âœ… æ›´æ–°ãƒ‡ãƒ¼ã‚¿: {len(update_result.data)}é …ç›®")
        tests_passed += 1
    else:
        print("  âŒ Invalid data")

    return tests_passed, tests_total


def test_knowledge_evolution_tracking():
    """çŸ¥è­˜é€²åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜é€²åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    evolution_events = [
        {
            "timestamp": datetime.now() - timedelta(days=7),
            "type": "concept_added",
            "concept": "GPT",
        },
        {
            "timestamp": datetime.now() - timedelta(days=5),
            "type": "relation_discovered",
            "relation": "GPT->NLP",
        },
        {
            "timestamp": datetime.now() - timedelta(days=2),
            "type": "concept_updated",
            "concept": "GPT",
        },
        {
            "timestamp": datetime.now(),
            "type": "cluster_formed",
            "cluster": "transformer_models",
        },
    ]

    evolution_summary = graph.track_knowledge_evolution(evolution_events)

    tests_passed = 0
    tests_total = 4

    expected_fields = [
        "evolution_rate",
        "concept_growth",
        "relation_growth",
        "total_events",
    ]
    for field in expected_fields:
        if field in evolution_summary and evolution_summary[field] >= 0:
            print(f"  âœ… {field}: {evolution_summary[field]}")
            tests_passed += 1
        else:
            print(f"  âŒ Missing or invalid {field}")

    return tests_passed, tests_total


async def test_knowledge_inference():
    """çŸ¥è­˜æ¨è«–ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜æ¨è«–ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    existing_relations = [
        ConceptRelation("A", "B", "causes", 0.8),
        ConceptRelation("B", "C", "causes", 0.7),
        ConceptRelation("machine learning", "performance", "related_to", 0.9),
    ]

    inferred = await graph.infer_new_knowledge(existing_relations)

    tests_passed = 0
    tests_total = 3

    if isinstance(inferred, list):
        print(f"  âœ… æ¨è«–çµæœãƒªã‚¹ãƒˆ: {len(inferred)}ä»¶")
        tests_passed += 1
    else:
        print("  âŒ Wrong inference type")

    if inferred and all(isinstance(rel, ConceptRelation) for rel in inferred):
        print("  âœ… ConceptRelationã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
        tests_passed += 1
    elif not inferred:
        print("  âš ï¸ æ¨è«–ãªã—ï¼ˆæ­£å¸¸ãªå ´åˆã‚‚ã‚ã‚‹ï¼‰")
        tests_passed += 1
    else:
        print("  âŒ Wrong relation types")

    # A -> C æ¨ç§»çš„æ¨è«–ã®ç¢ºèª
    ac_relation = None
    if inferred:
        ac_relation = next(
            (r for r in inferred if r.concept_a == "A" and r.concept_b == "C"), None
        )

    if ac_relation and ac_relation.relation_type == "causes":
        print(f"  âœ… æ¨ç§»çš„æ¨è«–æˆåŠŸ: A->C (ä¿¡é ¼åº¦: {ac_relation.confidence:.3f})")
        tests_passed += 1
    elif not inferred:
        tests_passed += 1  # æ¨è«–ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    else:
        print("  âŒ Transitive inference not found")

    return tests_passed, tests_total


def test_anomaly_detection_in_knowledge():
    """çŸ¥è­˜ç•°å¸¸æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜ç•°å¸¸æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    knowledge_statements = [
        {
            "concept_a": "machine learning",
            "concept_b": "algorithms",
            "confidence": 0.95,
        },
        {
            "concept_a": "deep learning",
            "concept_b": "neural networks",
            "confidence": 0.92,
        },
        {"concept_a": "database", "concept_b": "storage", "confidence": 0.88},
        {
            "concept_a": "machine learning",
            "concept_b": "cooking recipes",
            "confidence": 0.15,
        },  # ç•°å¸¸
        {
            "concept_a": "neural networks",
            "concept_b": "car maintenance",
            "confidence": 0.05,
        },  # ç•°å¸¸
    ]

    anomalies = graph.detect_knowledge_anomalies(knowledge_statements)

    tests_passed = 0
    tests_total = 3

    if isinstance(anomalies, list):
        print(f"  âœ… ç•°å¸¸ãƒªã‚¹ãƒˆ: {len(anomalies)}ä»¶")
        tests_passed += 1
    else:
        print("  âŒ Wrong anomalies type")

    if len(anomalies) >= 2:
        print("  âœ… è¤‡æ•°ç•°å¸¸æ¤œå‡º")
        tests_passed += 1
    else:
        print(f"  âŒ Expected >= 2 anomalies, got {len(anomalies)}")

    if anomalies and all(anom.get("confidence", 1) < 0.3 for anom in anomalies):
        print("  âœ… ä½ä¿¡é ¼åº¦ç•°å¸¸æ¤œå‡º")
        tests_passed += 1
    elif not anomalies:
        print("  âš ï¸ ç•°å¸¸æœªæ¤œå‡º")
        tests_passed += 1
    else:
        print("  âŒ High confidence anomalies detected")

    return tests_passed, tests_total


def test_multilingual_knowledge_integration():
    """å¤šè¨€èªçŸ¥è­˜çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª å¤šè¨€èªçŸ¥è­˜çµ±åˆãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    multilingual_concepts = {
        "en": "machine learning",
        "ja": "æ©Ÿæ¢°å­¦ç¿’",
        "zh": "æœºå™¨å­¦ä¹ ",
        "es": "aprendizaje automÃ¡tico",
    }

    unified_concept = graph.integrate_multilingual_knowledge(multilingual_concepts)

    tests_passed = 0
    tests_total = 3

    required_fields = ["unified_id", "translations", "primary_language"]
    for field in required_fields:
        if field in unified_concept:
            print(
                f"  âœ… {field}: {unified_concept[field] if field != 'translations' else len(unified_concept[field])}è¨€èª"
            )
            tests_passed += 1
        else:
            print(f"  âŒ Missing field: {field}")

    return tests_passed, tests_total


def test_graph_statistics():
    """ã‚°ãƒ©ãƒ•çµ±è¨ˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ã‚°ãƒ©ãƒ•çµ±è¨ˆãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    graph.create_node("Test concept 1", "concept")
    graph.create_node("Test concept 2", "concept")

    stats = graph.get_graph_statistics()

    tests_passed = 0
    tests_total = 6

    expected_metrics = [
        "total_nodes",
        "total_edges",
        "average_degree",
        "clustering_coefficient",
        "graph_density",
        "connected_components",
    ]

    for metric in expected_metrics:
        # è¤‡é›‘ãªæ¡ä»¶åˆ¤å®š
        if (
            metric in stats
            and isinstance(stats[metric], (int, float))
            and stats[metric] >= 0
        ):
            print(f"  âœ… {metric}: {stats[metric]}")
            tests_passed += 1
        else:
            print(f"  âŒ Invalid metric: {metric}")

    return tests_passed, tests_total


def test_knowledge_quality_assessment():
    """çŸ¥è­˜å“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª çŸ¥è­˜å“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    quality_assessment = graph.assess_knowledge_quality()

    tests_passed = 0
    tests_total = 4

    expected_metrics = [
        "overall_quality_score",
        "consistency_score",
        "completeness_score",
        "accuracy_score",
    ]

    for metric in expected_metrics:
        if metric in quality_assessment and 0 <= quality_assessment[metric] <= 1:
            print(f"  âœ… {metric}: {quality_assessment[metric]:.3f}")
            tests_passed += 1
        else:
            print(f"  âŒ Invalid quality metric: {metric}")

    return tests_passed, tests_total


async def test_complete_discovery_workflow():
    """å®Œå…¨ç™ºè¦‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª å®Œå…¨ç™ºè¦‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ")
    graph = DynamicKnowledgeGraph()

    input_documents = [
        "Artificial intelligence transforms business operations",
        "Machine learning algorithms optimize resource allocation",
        "Deep learning models improve prediction accuracy",
        "Neural networks process complex data patterns",
    ]

    discovery_config = {
        "enable_clustering": True,
        "enable_inference": True,
        "similarity_threshold": 0.7,
        "max_relations_per_concept": 5,
    }

    discovery_result = await graph.run_discovery_cycle(
        input_documents, discovery_config
    )

    tests_passed = 0
    tests_total = 3

    if hasattr(discovery_result, "discovery_type"):
        print(f"  âœ… ç™ºè¦‹ã‚¿ã‚¤ãƒ—: {discovery_result.discovery_type}")
        tests_passed += 1
    else:
        print("  âŒ No discovery type")

    if hasattr(discovery_result, "entities") and len(discovery_result.entities) >= 0:
        print(f"  âœ… ç™ºè¦‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {len(discovery_result.entities)}å€‹")
        tests_passed += 1
    else:
        print("  âŒ No entities")

    if (
        hasattr(discovery_result, "confidence")
        and 0 <= discovery_result.confidence <= 1
    ):
        print(f"  âœ… ä¿¡é ¼åº¦: {discovery_result.confidence:.3f}")
        tests_passed += 1
    else:
        print("  âŒ Invalid confidence")

    return tests_passed, tests_total


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸŒ å‹•çš„çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)

    total_passed = 0
    total_tests = 0

    # åŒæœŸãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    sync_tests = [
        test_knowledge_node_creation,
        test_node_importance_scoring,
        test_node_similarity_calculation,
        test_knowledge_edge_creation,
        test_edge_strength_calculation,
        test_semantic_embedding_generation,
        test_embedding_similarity_search,
        test_knowledge_clustering,
        test_cluster_coherence_measurement,
        test_knowledge_evolution_tracking,
        test_anomaly_detection_in_knowledge,
        test_multilingual_knowledge_integration,
        test_graph_statistics,
        test_knowledge_quality_assessment,
    ]

    for test_func in sync_tests:
        passed, total = test_func()
        total_passed += passed
        total_tests += total

    # éåŒæœŸãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    async_tests = [
        test_concept_relations_discovery,
        test_dynamic_graph_update,
        test_knowledge_inference,
        test_complete_discovery_workflow,
    ]

    for test_func in async_tests:
        passed, total = await test_func()
        total_passed += passed
        total_tests += total

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ: {total_passed}/{total_tests} æˆåŠŸ")
    success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0

    if total_passed == total_tests:
        print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("ğŸŒ å‹•çš„çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        print("ğŸ”— çŸ¥è­˜ã®é–¢é€£æ€§è‡ªå‹•ç™ºè¦‹ã¨å¤šè¨€èªå¯¾å¿œãŒå®Œæˆã—ã¾ã—ãŸ")
        return 0
    elif success_rate >= 85:
        print(f"âœ… å¤§éƒ¨åˆ†ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ ({success_rate:.1f}%)")
        print("ğŸŒ çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã¯åŸºæœ¬çš„ã«æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        return 0
    else:
        print(f"âŒ {total_tests - total_passed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        return 1


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
