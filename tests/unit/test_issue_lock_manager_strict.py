#!/usr/bin/env python3
"""
Issue Lock Manager å³æ ¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å¾¹åº•æ¤œè¨¼
"""

import os
import json
import time
import asyncio
import tempfile
import shutil
import threading
import multiprocessing
import signal
import random
import string
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
import pytest
import psutil

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))
from libs.issue_lock_manager import (
    FileLockManager,
    HeartbeatManager,
    ProcessMonitor,
    SafeIssueProcessor
)


class TestRaceConditions:
    """ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®å³å¯†ãªãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def temp_lock_dir(self):
        """ä¸€æ™‚çš„ãªãƒ­ãƒƒã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        temp_dir = tempfile.mkdtemp()
        yield temp_dir
        shutil.rmtree(temp_dir, ignore_errors=True)
        
    @pytest.mark.asyncio
    async def test_simultaneous_lock_acquisition(self, temp_lock_dir):
        """åŒæ™‚ãƒ­ãƒƒã‚¯å–å¾—ã®ç«¶åˆãƒ†ã‚¹ãƒˆ"""
        manager = FileLockManager(lock_dir=temp_lock_dir)
        issue_number = 999
        results = []
        
        async def try_acquire_lock(processor_id: str):
            """ãƒ­ãƒƒã‚¯å–å¾—ã‚’è©¦è¡Œ"""
            # ãƒ©ãƒ³ãƒ€ãƒ ãªå¾®å°é…å»¶ã§å®Ÿéš›ã®ç«¶åˆçŠ¶æ…‹ã‚’å†ç¾
            await asyncio.sleep(random.uniform(0, 0.01))
            result = manager.acquire_lock(issue_number, processor_id)
            results.append((processor_id, result))
            
        # 100å€‹ã®ä¸¦è¡Œã‚¿ã‚¹ã‚¯ã§ãƒ­ãƒƒã‚¯å–å¾—ã‚’è©¦è¡Œ
        tasks = [
            try_acquire_lock(f"processor_{i}")
            for i in range(100)
        ]
        
        await asyncio.gather(*tasks)
        
        # æˆåŠŸã—ãŸãƒ­ãƒƒã‚¯å–å¾—ã¯1ã¤ã ã‘ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        successful_locks = [(pid, res) for pid, res in results if res]
        assert len(successful_locks) == 1, f"Expected 1 successful lock, got {len(successful_locks)}"
        
    def test_multiprocess_lock_competition(self, temp_lock_dir):
        """ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ç’°å¢ƒã§ã®ãƒ­ãƒƒã‚¯ç«¶åˆãƒ†ã‚¹ãƒˆ"""
        def worker_process(worker_id: int, lock_dir: str, result_queue):
            """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹"""
            manager = FileLockManager(lock_dir=lock_dir)
            results = []
            
            for attempt in range(10):
                issue_number = 1000 + attempt
                acquired = manager.acquire_lock(issue_number, f"worker_{worker_id}")
                results.append((issue_number, acquired))
                if acquired:
                    # å°‘ã—ä½œæ¥­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                    time.sleep(0.01)
                    manager.release_lock(issue_number, f"worker_{worker_id}")
                    
            result_queue.put((worker_id, results))
            
        # 10å€‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•
        processes = []
        result_queue = multiprocessing.Queue()
        
        for i in range(10):
            p = multiprocessing.Process(
                target=worker_process,
                args=(i, temp_lock_dir, result_queue)
            )
            p.start()
            processes.append(p)
            
        # ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚»ã‚¹ã®å®Œäº†ã‚’å¾…ã¤
        for p in processes:
            p.join(timeout=30)
            
        # çµæœã‚’åé›†
        all_results = {}
        while not result_queue.empty():
            worker_id, results = result_queue.get()
            all_results[worker_id] = results
            
        # å„Issueç•ªå·ã«å¯¾ã—ã¦ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã§ããŸã®ã¯1ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for issue_num in range(1000, 1010):
            acquired_count = sum(
                1 for worker_results in all_results.values()
                for issue, acquired in worker_results
                if issue == issue_num and acquired
            )
            assert acquired_count <= 10, f"Issue {issue_num}: Too many locks acquired"
            
    @pytest.mark.asyncio
    async def test_rapid_lock_release_reacquire(self, temp_lock_dir):
        """é«˜é€Ÿãªãƒ­ãƒƒã‚¯è§£æ”¾ãƒ»å†å–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        processor = SafeIssueProcessor(lock_dir=temp_lock_dir)
        issue_number = 2000
        success_count = 0
        
        async def rapid_process(attempt: int):
            """é«˜é€Ÿå‡¦ç†"""
            result = await processor.process_issue_safely(
                issue_number,
                lambda _: asyncio.sleep(0.001)  # 1mså‡¦ç†
            )
            return result is not None
            
        # 1000å›ã®é«˜é€Ÿå‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ
        tasks = [rapid_process(i) for i in range(1000)]
        results = await asyncio.gather(*tasks)
        
        # å°‘ãªãã¨ã‚‚1ã¤ã¯æˆåŠŸã—ã€åŒæ™‚å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        success_count = sum(results)
        assert success_count >= 1, "At least one process should succeed"
        assert success_count < 1000, "Not all should succeed (indicates no locking)"


class TestEdgeCases:
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®å³å¯†ãªãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def lock_manager(self, tmp_path):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ­ãƒƒã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        return FileLockManager(lock_dir=str(tmp_path))
        
    def test_corrupted_lock_file_handling(self, lock_manager):
        """ç ´æã—ãŸãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        issue_number = 3000
        lock_file = lock_manager.lock_dir / f"issue_{issue_number}.lock"
        
        # ç ´æã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        test_cases = [
            b"",  # ç©ºãƒ•ã‚¡ã‚¤ãƒ«
            b"invalid json",  # ç„¡åŠ¹ãªJSON
            b'{"incomplete": ',  # ä¸å®Œå…¨ãªJSON
            b'{"processor_id": null}',  # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãªã—
            b'\x00\x01\x02\x03',  # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
        ]
        
        for i, corrupted_data in enumerate(test_cases):
            lock_file.write_bytes(corrupted_data)
            
            # ãƒ­ãƒƒã‚¯å–å¾—ã‚’è©¦è¡Œï¼ˆã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãšã€æ–°ã—ã„ãƒ­ãƒƒã‚¯ãŒä½œæˆã•ã‚Œã‚‹ï¼‰
            result = lock_manager.acquire_lock(issue_number, f"processor_{i}")
            assert result is True, f"Test case {i}: Should acquire lock with corrupted file"
            
            # æ­£ã—ã„ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            with open(lock_file, 'r') as f:
                lock_data = json.load(f)
                assert lock_data['processor_id'] == f"processor_{i}"
                
            lock_manager.release_lock(issue_number)
            
    def test_extremely_long_names(self, lock_manager):
        """æ¥µç«¯ã«é•·ã„åå‰ã®å‡¦ç†"""
        # 1000æ–‡å­—ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ID
        long_processor_id = "processor_" + "x" * 990
        
        # 1000æ¡ã®Issueç•ªå·
        huge_issue_number = 10**100
        
        # ãƒ­ãƒƒã‚¯å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®åˆ¶é™å†…ã§å‹•ä½œã™ã‚‹ã“ã¨ï¼‰
        result = lock_manager.acquire_lock(huge_issue_number, long_processor_id)
        assert result is True
        
        # ãƒ­ãƒƒã‚¯æƒ…å ±ãŒæ­£ã—ãä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        lock_info = lock_manager.get_lock_info(huge_issue_number)
        assert lock_info is not None
        assert lock_info['processor_id'] == long_processor_id
        
    def test_special_characters_in_processor_id(self, lock_manager):
        """ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼IDã®ãƒ†ã‚¹ãƒˆ"""
        special_ids = [
            "processor/../../../etc/passwd",  # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«è©¦è¡Œ
            "processor'; rm -rf /",  # ã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è©¦è¡Œ
            "processor\x00null",  # ãƒŒãƒ«æ–‡å­—
            "processor\n\r\t",  # åˆ¶å¾¡æ–‡å­—
            "processoræ—¥æœ¬èª",  # ãƒãƒ«ãƒãƒã‚¤ãƒˆæ–‡å­—
            "processorğŸ”’ğŸ”‘",  # çµµæ–‡å­—
        ]
        
        for i, special_id in enumerate(special_ids):
            issue_number = 4000 + i
            
            # ãƒ­ãƒƒã‚¯å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ã«å‡¦ç†ã•ã‚Œã‚‹ï¼‰
            result = lock_manager.acquire_lock(issue_number, special_id)
            assert result is True
            
            # ãƒ­ãƒƒã‚¯æƒ…å ±ãŒæ­£ã—ãä¿å­˜ã•ã‚Œã¦ã„ã‚‹
            lock_info = lock_manager.get_lock_info(issue_number)
            assert lock_info['processor_id'] == special_id
            
            lock_manager.release_lock(issue_number, special_id)


class TestSecurityAudit:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ãƒ†ã‚¹ãƒˆ"""
    
    def test_file_permissions(self, tmp_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã®ãƒ†ã‚¹ãƒˆ"""
        lock_manager = FileLockManager(lock_dir=str(tmp_path))
        
        # ãƒ­ãƒƒã‚¯ä½œæˆ
        lock_manager.acquire_lock(5000, "security_test")
        lock_file = tmp_path / "issue_5000.lock"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã®ç¢ºèªï¼ˆä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰èª­ã¿å–ã‚Šä¸å¯ï¼‰
        stat = os.stat(lock_file)
        mode = stat.st_mode & 0o777
        
        # æ‰€æœ‰è€…ã®ã¿èª­ã¿æ›¸ãå¯èƒ½ï¼ˆ0o600ï¼‰ã§ã‚ã‚‹ã“ã¨ãŒç†æƒ³
        # ãŸã ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        assert mode & 0o077 == 0, f"Lock file has too permissive mode: {oct(mode)}"
        
    def test_directory_traversal_prevention(self, tmp_path):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã®é˜²æ­¢ãƒ†ã‚¹ãƒˆ"""
        lock_manager = FileLockManager(lock_dir=str(tmp_path))
        
        # æ‚ªæ„ã®ã‚ã‚‹Issueç•ªå·ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«ã‚’è©¦è¡Œ
        malicious_numbers = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32",
            "/etc/shadow",
            "C:\\Windows\\System32\\config\\SAM",
        ]
        
        for malicious in malicious_numbers:
            # æ•°å€¤å¤‰æ›æ™‚ã«ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…
            try:
                # ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«åã¯ "issue_{number}.lock" å½¢å¼
                # æ•°å€¤ä»¥å¤–ã¯å—ã‘ä»˜ã‘ãªã„ã¯ãš
                lock_file = lock_manager.lock_dir / f"issue_{malicious}.lock"
                # å®Ÿéš›ã®ä½¿ç”¨ã§ã¯ issue_number ã¯æ•´æ•°å‹ãªã®ã§ã€ã“ã®æ”»æ’ƒã¯ä¸å¯èƒ½
            except Exception:
                pass
                
    def test_concurrent_file_access_security(self, tmp_path):
        """ä¸¦è¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
        lock_manager = FileLockManager(lock_dir=str(tmp_path))
        issue_number = 6000
        
        def attacker_thread():
            """æ”»æ’ƒè€…ã‚¹ãƒ¬ãƒƒãƒ‰ï¼šãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ”¹ã–ã‚“ã—ã‚ˆã†ã¨ã™ã‚‹"""
            lock_file = Path(tmp_path) / f"issue_{issue_number}.lock"
            
            for _ in range(100):
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥æ”¹ã–ã‚“ã—ã‚ˆã†ã¨ã™ã‚‹
                    if lock_file.exists():
                        with open(lock_file, 'w') as f:
                            json.dump({"processor_id": "attacker", "hacked": True}, f)
                except Exception:
                    pass  # å¤±æ•—ã¯æƒ³å®šå†…
                time.sleep(0.001)
                
        def legitimate_thread():
            """æ­£è¦ã‚¹ãƒ¬ãƒƒãƒ‰ï¼šæ­£å¸¸ã«ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨"""
            for i in range(50):
                acquired = lock_manager.acquire_lock(issue_number, f"legitimate_{i}")
                if acquired:
                    time.sleep(0.01)
                    lock_manager.release_lock(issue_number, f"legitimate_{i}")
                    
        # æ”»æ’ƒè€…ã¨æ­£è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŒæ™‚å®Ÿè¡Œ
        attacker = threading.Thread(target=attacker_thread)
        legitimate = threading.Thread(target=legitimate_thread)
        
        attacker.start()
        legitimate.start()
        
        attacker.join()
        legitimate.join()
        
        # æœ€çµ‚çš„ãªãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        lock_info = lock_manager.get_lock_info(issue_number)
        if lock_info:
            assert 'hacked' not in lock_info, "Lock file was compromised"


class TestPerformanceUnderLoad:
    """é«˜è² è·ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_massive_concurrent_operations(self, tmp_path):
        """å¤§é‡ä¸¦è¡Œå‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        processor = SafeIssueProcessor(lock_dir=str(tmp_path), timeout=30)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šç”¨
        start_time = time.time()
        processed_count = 0
        error_count = 0
        
        async def process_issue_load_test(issue_num: int):
            """è² è·ãƒ†ã‚¹ãƒˆç”¨ã®å‡¦ç†"""
            nonlocal processed_count, error_count
            
            try:
                result = await processor.process_issue_safely(
                    issue_num,
                    lambda n: asyncio.sleep(random.uniform(0.001, 0.01))
                )
                if result is not None:
                    processed_count += 1
            except Exception:
                error_count += 1
                
        # 10000å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆï¼ˆ100å€‹ã®Issueã‚’100å›ãšã¤å‡¦ç†ï¼‰
        tasks = []
        for issue_num in range(7000, 7100):
            for _ in range(100):
                tasks.append(process_issue_load_test(issue_num))
                
        # ãƒãƒƒãƒå‡¦ç†ï¼ˆãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’è€ƒæ…®ï¼‰
        batch_size = 1000
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i + batch_size]
            await asyncio.gather(*batch, return_exceptions=True)
            
        elapsed_time = time.time() - start_time
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        print(f"\nPerformance Test Results:")
        print(f"Total tasks: {len(tasks)}")
        print(f"Processed: {processed_count}")
        print(f"Errors: {error_count}")
        print(f"Elapsed time: {elapsed_time:.2f}s")
        print(f"Throughput: {len(tasks) / elapsed_time:.2f} tasks/s")
        
        # åŸºæº–: ã‚¨ãƒ©ãƒ¼ç‡1%æœªæº€
        assert error_count < len(tasks) * 0.01, f"Error rate too high: {error_count}/{len(tasks)}"
        
        # åŸºæº–: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ100 tasks/sä»¥ä¸Š
        throughput = len(tasks) / elapsed_time
        assert throughput > 100, f"Throughput too low: {throughput:.2f} tasks/s"
        
    def test_lock_cleanup_performance(self, tmp_path):
        """å¤§é‡ãƒ­ãƒƒã‚¯ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"""
        lock_manager = FileLockManager(lock_dir=str(tmp_path))
        process_monitor = ProcessMonitor(lock_manager)
        
        # 10000å€‹ã®ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ
        dead_pid = 99999  # å­˜åœ¨ã—ãªã„PID
        for i in range(10000):
            lock_file = Path(tmp_path) / f"issue_{i}.lock"
            lock_data = {
                'processor_id': f'dead_processor_{i}',
                'locked_at': datetime.now().isoformat(),
                'pid': dead_pid,
                'hostname': os.uname().nodename
            }
            with open(lock_file, 'w') as f:
                json.dump(lock_data, f)
                
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        start_time = time.time()
        cleaned = process_monitor.cleanup_dead_locks()
        elapsed = time.time() - start_time
        
        print(f"\nCleanup Performance:")
        print(f"Cleaned locks: {cleaned}")
        print(f"Elapsed time: {elapsed:.2f}s")
        print(f"Rate: {cleaned / elapsed:.2f} locks/s")
        
        # åŸºæº–: 1000 locks/sä»¥ä¸Šã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é€Ÿåº¦
        assert cleaned / elapsed > 1000, f"Cleanup too slow: {cleaned / elapsed:.2f} locks/s"


class TestFailureInjection:
    """éšœå®³æ³¨å…¥ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_process_kill_during_operation(self, tmp_path):
        """å‡¦ç†ä¸­ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚­ãƒ«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        
        async def simulate_process_crash():
            """ãƒ—ãƒ­ã‚»ã‚¹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            processor = SafeIssueProcessor(lock_dir=str(tmp_path))
            
            # ãƒ­ãƒƒã‚¯å–å¾—
            lock_acquired = processor.lock_manager.acquire_lock(8000, processor.processor_id)
            assert lock_acquired
            
            # ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé–‹å§‹
            processor.heartbeat_manager.start_heartbeat(8000, processor.processor_id)
            
            # å‡¦ç†ä¸­ã«"ã‚¯ãƒ©ãƒƒã‚·ãƒ¥"ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            # é€šå¸¸ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ãƒã‚¤ãƒ‘ã‚¹ã—ã¦å¼·åˆ¶çµ‚äº†ã‚’æ¨¡æ“¬
            processor._cleanup_registered = True  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ç„¡åŠ¹åŒ–
            
            # ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã«ã¯é–¢æ•°ã‚’æŠœã‘ã‚‹ã ã‘ï¼‰
            return
            
        # ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await simulate_process_crash()
        
        # åˆ¥ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡ºã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        new_processor = SafeIssueProcessor(lock_dir=str(tmp_path))
        
        # å°‘ã—å¾…æ©Ÿï¼ˆãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        await asyncio.sleep(0.1)
        
        # æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒ­ãƒƒã‚¯ã‚’å–å¾—ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
        result = await new_processor.process_issue_safely(
            8000,
            lambda _: "processed"
        )
        
        assert result == "processed", "Should be able to acquire lock after crash"
        
    def test_disk_full_simulation(self, tmp_path):
        """ãƒ‡ã‚£ã‚¹ã‚¯æº€æ¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        lock_manager = FileLockManager(lock_dir=str(tmp_path))
        
        # ãƒ‡ã‚£ã‚¹ã‚¯æº€æ¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆæ›¸ãè¾¼ã¿ã‚’å¤±æ•—ã•ã›ã‚‹ï¼‰
        original_open = open
        write_count = 0
        
        def mock_open(*args, **kwargs):
            nonlocal write_count
            if 'w' in str(args[1:]) and write_count > 5:
                raise IOError("No space left on device")
            write_count += 1
            return original_open(*args, **kwargs)
            
        with patch('builtins.open', mock_open):
            # æœ€åˆã®æ•°å›ã¯æˆåŠŸ
            for i in range(5):
                result = lock_manager.acquire_lock(9000 + i, f"processor_{i}")
                assert result is True
                
            # ãã®å¾Œã¯å¤±æ•—
            for i in range(5, 10):
                result = lock_manager.acquire_lock(9000 + i, f"processor_{i}")
                assert result is False
                
    def test_network_partition_simulation(self, tmp_path):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ–­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆåˆ†æ•£ç’°å¢ƒã‚’æƒ³å®šï¼‰"""
        # 2ã¤ã®"ãƒãƒ¼ãƒ‰"ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        node1_locks = FileLockManager(lock_dir=str(tmp_path))
        node2_locks = FileLockManager(lock_dir=str(tmp_path))
        
        # Node1ãŒãƒ­ãƒƒã‚¯ã‚’å–å¾—
        assert node1_locks.acquire_lock(10000, "node1_processor")
        
        # "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ–­"ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        # ï¼ˆå®Ÿéš›ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ãªã®ã§å½±éŸ¿ãªã—ï¼‰
        
        # Node2ã¯åŒã˜ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã§ããªã„
        assert not node2_locks.acquire_lock(10000, "node2_processor")
        
        # ã“ã‚Œã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ã®åˆ©ç‚¹ã‚’ç¤ºã™


class TestCodeQualityAudit:
    """ã‚³ãƒ¼ãƒ‰å“è³ªç›£æŸ»"""
    
    def test_no_race_condition_in_atomic_operations(self):
        """ã‚¢ãƒˆãƒŸãƒƒã‚¯æ“ä½œã§ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ãŒãªã„ã“ã¨ã‚’ç¢ºèª"""
        # FileLockManagerã®acquire_lockãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ¤œæŸ»
        import inspect
        source = inspect.getsource(FileLockManager.acquire_lock)
        
        # ã‚¢ãƒˆãƒŸãƒƒã‚¯æ“ä½œã®ä½¿ç”¨ã‚’ç¢ºèª
        assert 'rename' in source, "Should use atomic rename operation"
        assert 'temp_file' in source or '.tmp' in source, "Should use temporary file pattern"
        
    def test_proper_exception_handling(self):
        """é©åˆ‡ãªä¾‹å¤–å‡¦ç†ã®ç¢ºèª"""
        import inspect
        
        # SafeIssueProcessorã®ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ¤œæŸ»
        source = inspect.getsource(SafeIssueProcessor.process_issue_safely)
        
        # try-finally ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½¿ç”¨ã‚’ç¢ºèª
        assert 'try:' in source, "Should have try block"
        assert 'finally:' in source, "Should have finally block for cleanup"
        assert 'release_lock' in source, "Should release lock in finally"
        
    def test_no_hardcoded_secrets(self):
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç§˜å¯†æƒ…å ±ãŒãªã„ã“ã¨ã‚’ç¢ºèª"""
        import inspect
        
        # ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æ¤œæŸ»
        classes = [FileLockManager, HeartbeatManager, ProcessMonitor, SafeIssueProcessor]
        
        for cls in classes:
            source = inspect.getsource(cls)
            
            # ä¸€èˆ¬çš„ãªç§˜å¯†æƒ…å ±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            suspicious_patterns = [
                'password=',
                'secret=',
                'api_key=',
                'token=',
                'private_key='
            ]
            
            for pattern in suspicious_patterns:
                assert pattern not in source.lower(), f"Found suspicious pattern '{pattern}' in {cls.__name__}"


# çµ±åˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
@pytest.mark.asyncio
async def test_comprehensive_stress_test(tmp_path):
    """åŒ…æ‹¬çš„ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Comprehensive Stress Test ===")
    
    # è¤‡æ•°ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’ä½œæˆ
    processors = [
        SafeIssueProcessor(lock_dir=str(tmp_path))
        for _ in range(5)
    ]
    
    # çµ±è¨ˆæƒ…å ±
    stats = {
        'total_attempts': 0,
        'successful_processes': 0,
        'lock_contentions': 0,
        'errors': 0
    }
    
    async def stress_worker(processor_id: int, processor: SafeIssueProcessor):
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚«ãƒ¼"""
        for round in range(100):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªIssueã‚’é¸æŠï¼ˆç«¶åˆã‚’ç™ºç”Ÿã•ã›ã‚‹ï¼‰
            issue_number = 20000 + random.randint(0, 20)
            
            stats['total_attempts'] += 1
            
            try:
                # å‡¦ç†æ™‚é–“ã‚‚ãƒ©ãƒ³ãƒ€ãƒ 
                process_time = random.uniform(0.001, 0.05)
                
                result = await processor.process_issue_safely(
                    issue_number,
                    lambda n: asyncio.sleep(process_time)
                )
                
                if result is not None:
                    stats['successful_processes'] += 1
                else:
                    stats['lock_contentions'] += 1
                    
            except Exception as e:
                stats['errors'] += 1
                print(f"Error in processor {processor_id}: {e}")
                
            # å°‘ã—å¾…æ©Ÿ
            await asyncio.sleep(random.uniform(0, 0.01))
            
    # ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã§ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    tasks = [
        stress_worker(i, processor)
        for i, processor in enumerate(processors)
    ]
    
    start_time = time.time()
    await asyncio.gather(*tasks)
    elapsed = time.time() - start_time
    
    # çµæœãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\nStress Test Results:")
    print(f"Duration: {elapsed:.2f}s")
    print(f"Total attempts: {stats['total_attempts']}")
    print(f"Successful: {stats['successful_processes']}")
    print(f"Lock contentions: {stats['lock_contentions']}")
    print(f"Errors: {stats['errors']}")
    print(f"Success rate: {stats['successful_processes'] / stats['total_attempts'] * 100:.1f}%")
    print(f"Error rate: {stats['errors'] / stats['total_attempts'] * 100:.1f}%")
    
    # å“è³ªåŸºæº–
    assert stats['errors'] < stats['total_attempts'] * 0.01, "Error rate > 1%"
    assert stats['successful_processes'] > 0, "No successful processes"
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç¢ºèª
    remaining_locks = len(list(Path(tmp_path).glob("*.lock")))
    print(f"Remaining locks: {remaining_locks}")
    assert remaining_locks < 25, "Too many locks remaining"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])