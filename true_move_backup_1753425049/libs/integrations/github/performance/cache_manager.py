#!/usr/bin/env python3
"""
ğŸ’¾ GitHub Integration Cache Manager
Iron Will Compliant - Performance Optimization
"""

import asyncio
import hashlib
import json
import logging
import pickle
import time
from collections import OrderedDict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Callable, Dict, Optional, Union

logger = logging.getLogger(__name__)


class CacheManager:
    """
    ğŸ’¾ é«˜æ€§èƒ½ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    
    Features:
    - Multi-level caching (memory + disk)
    - TTL management
    - LRU eviction policy
    - Cache warming
    - Invalidation strategies
    - Performance metrics
    """
    
    def __init__(
        self,
        memory_size: int = 1000,
        disk_cache_dir: Optional[Path] = None,
        default_ttl: int = 3600
    ):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        
        Args:
            memory_size: ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
            disk_cache_dir: ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            default_ttl: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTTLï¼ˆç§’ï¼‰
        """
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆLRUï¼‰
        self.memory_cache = OrderedDict()
        self.memory_size = memory_size
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.disk_cache_dir = disk_cache_dir or Path.home() / ".github_cache"
        self.disk_cache_dir.mkdir(parents=True, exist_ok=True)
        
        # TTLç®¡ç†
        self.default_ttl = default_ttl
        self.ttl_map = {}
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
        self.stats = {
            "memory_hits": 0,
            "memory_misses": 0,
            "disk_hits": 0,
            "disk_misses": 0,
            "total_requests": 0,
            "evictions": 0,
            "invalidations": 0
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°
        self.warming_tasks = {}
        
        logger.info(f"CacheManager initialized: memory_size={memory_size}, disk_cache={self.disk_cache_dir}")
    
    def _generate_cache_key(self, key: Union[str, Dict[str, Any]]) -> str:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
        
        Args:
            key: ã‚­ãƒ¼ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯è¾æ›¸ï¼‰
            
        Returns:
            ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸã‚­ãƒ¼
        """
        if isinstance(key, dict):
            key_str = json.dumps(key, sort_keys=True)
        else:
            key_str = str(key)
        
        return hashlib.sha256(key_str.encode()).hexdigest()
    
    async def get(
        self,
        key: Union[str, Dict[str, Any]],
        fetch_func: Optional[Callable] = None,
        ttl: Optional[int] = None
    ) -> Optional[Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å€¤ã‚’å–å¾—
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            fetch_func: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚ã®å–å¾—é–¢æ•°
            ttl: TTLï¼ˆç§’ï¼‰
            
        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã¾ãŸã¯None
        """
        self.stats["total_requests"] += 1
        cache_key = self._generate_cache_key(key)
        
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        value = self._get_from_memory(cache_key)
        if value is not None:
            self.stats["memory_hits"] += 1
            logger.debug(f"Memory cache hit: {cache_key[:8]}...")
            return value
        
        self.stats["memory_misses"] += 1
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        value = await self._get_from_disk(cache_key)
        if value is not None:
            self.stats["disk_hits"] += 1
            logger.debug(f"Disk cache hit: {cache_key[:8]}...")
            # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æ˜‡æ ¼
            self._set_to_memory(cache_key, value, ttl or self.default_ttl)
            return value
        
        self.stats["disk_misses"] += 1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ - å–å¾—é–¢æ•°å®Ÿè¡Œ
        if fetch_func:
            logger.debug(f"Cache miss, fetching: {cache_key[:8]}...")
            try:
                value = await fetch_func() if asyncio.iscoroutinefunction(fetch_func) else fetch_func()
                await self.set(key, value, ttl)
                return value
            except Exception as e:
                logger.error(f"Fetch function failed: {str(e)}")
                return None
        
        return None
    
    async def set(
        self,
        key: Union[str, Dict[str, Any]],
        value: Any,
        ttl: Optional[int] = None
    ):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å€¤ã‚’è¨­å®š
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            value: ä¿å­˜ã™ã‚‹å€¤
            ttl: TTLï¼ˆç§’ï¼‰
        """
        cache_key = self._generate_cache_key(key)
        ttl = ttl or self.default_ttl
        
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¨­å®š
        self._set_to_memory(cache_key, value, ttl)
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«éåŒæœŸã§è¨­å®š
        asyncio.create_task(self._set_to_disk(cache_key, value, ttl))
        
        logger.debug(f"Cache set: {cache_key[:8]}... (ttl={ttl}s)")
    
    def _get_from_memory(self, cache_key: str) -> Optional[Any]:
        """
        ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        
        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            
        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã¾ãŸã¯None
        """
        if cache_key in self.memory_cache:
            # TTLãƒã‚§ãƒƒã‚¯
            if cache_key in self.ttl_map:
                if time.time() > self.ttl_map[cache_key]:
                    # TTLæœŸé™åˆ‡ã‚Œ
                    self._remove_from_memory(cache_key)
                    return None
            
            # LRUæ›´æ–°ï¼ˆæœ€å¾Œã«ç§»å‹•ï¼‰
            self.memory_cache.move_to_end(cache_key)
            return self.memory_cache[cache_key]
        
        return None
    
    def _set_to_memory(self, cache_key: str, value: Any, ttl: int):
        """
        ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¨­å®š
        
        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            value: å€¤
            ttl: TTLï¼ˆç§’ï¼‰
        """
        # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if len(self.memory_cache) >= self.memory_size:
            # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆLRUï¼‰
            oldest_key = next(iter(self.memory_cache))
            self._remove_from_memory(oldest_key)
            self.stats["evictions"] += 1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ 
        self.memory_cache[cache_key] = value
        self.ttl_map[cache_key] = time.time() + ttl
    
    def _remove_from_memory(self, cache_key: str):
        """ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤"""
        if cache_key in self.memory_cache:
            del self.memory_cache[cache_key]
        if cache_key in self.ttl_map:
            del self.ttl_map[cache_key]
    
    async def _get_from_disk(self, cache_key: str) -> Optional[Any]:
        """
        ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        
        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            
        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã¾ãŸã¯None
        """
        cache_file = self.disk_cache_dir / f"{cache_key}.cache"
        
        if cache_file.exists():
            try:
                with open(cache_file, "rb") as f:
                    data = pickle.load(f)
                
                # TTLãƒã‚§ãƒƒã‚¯
                if time.time() > data["expires_at"]:
                    # TTLæœŸé™åˆ‡ã‚Œ
                    cache_file.unlink()
                    return None
                
                return data["value"]
                
            except Exception as e:
                logger.error(f"Disk cache read error: {str(e)}")
                # ç ´æã—ãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                cache_file.unlink(missing_ok=True)
        
        return None
    
    async def _set_to_disk(self, cache_key: str, value: Any, ttl: int):
        """
        ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¨­å®š
        
        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            value: å€¤
            ttl: TTLï¼ˆç§’ï¼‰
        """
        cache_file = self.disk_cache_dir / f"{cache_key}.cache"
        
        try:
            data = {
                "value": value,
                "expires_at": time.time() + ttl,
                "created_at": time.time()
            }
            
            with open(cache_file, "wb") as f:
                pickle.dump(data, f)
                
        except Exception as e:
            logger.error(f"Disk cache write error: {str(e)}")
    
    async def invalidate(self, key: Union[str, Dict[str, Any]]):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
        """
        cache_key = self._generate_cache_key(key)
        
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤
        self._remove_from_memory(cache_key)
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤
        cache_file = self.disk_cache_dir / f"{cache_key}.cache"
        cache_file.unlink(missing_ok=True)
        
        self.stats["invalidations"] += 1
        logger.debug(f"Cache invalidated: {cache_key[:8]}...")
    
    async def invalidate_pattern(self, pattern: str):
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
        
        Args:
            pattern: ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: "user:*"ï¼‰
        """
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
        keys_to_remove = []
        for key in self.memory_cache:
            if self._match_pattern(key, pattern):
                keys_to_remove.append(key)
        
        for key in keys_to_remove:
            self._remove_from_memory(key)
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        for cache_file in self.disk_cache_dir.glob("*.cache"):
            if self._match_pattern(cache_file.stem, pattern):
                cache_file.unlink()
        
        invalidated_count = len(keys_to_remove)
        self.stats["invalidations"] += invalidated_count
        logger.info(f"Invalidated {invalidated_count} cache entries matching pattern: {pattern}")
    
    def _match_pattern(self, key: str, pattern: str) -> bool:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        import fnmatch
        return fnmatch.fnmatch(key, pattern)
    
    async def warm_cache(
        self,
        key: Union[str, Dict[str, Any]],
        fetch_func: Callable,
        ttl: Optional[int] = None,
        interval: Optional[int] = None
    ):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ï¼ˆå®šæœŸçš„ã«æ›´æ–°ï¼‰
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            fetch_func: å–å¾—é–¢æ•°
            ttl: TTLï¼ˆç§’ï¼‰
            interval: æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰
        """
        cache_key = self._generate_cache_key(key)
        
        async def warming_task():
            """warming_taskãƒ¡ã‚½ãƒƒãƒ‰"""
            while True:
                try:
                    value = await fetch_func() if asyncio.iscoroutinefunction(fetch_func) else fetch_func()
                    await self.set(key, value, ttl)
                    logger.debug(f"Cache warmed: {cache_key[:8]}...")
                except Exception as e:
                    logger.error(f"Cache warming failed: {str(e)}")
                
                await asyncio.sleep(interval or (ttl or self.default_ttl) * 0.8)
        
        # æ—¢å­˜ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if cache_key in self.warming_tasks:
            self.warming_tasks[cache_key].cancel()
        
        # æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self.warming_tasks[cache_key] = asyncio.create_task(warming_task())
        logger.info(f"Cache warming started: {cache_key[:8]}...")
    
    def stop_warming(self, key: Union[str, Dict[str, Any]]):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°åœæ­¢"""
        cache_key = self._generate_cache_key(key)
        
        if cache_key in self.warming_tasks:
            self.warming_tasks[cache_key].cancel()
            del self.warming_tasks[cache_key]
            logger.info(f"Cache warming stopped: {cache_key[:8]}...")
    
    async def clear_all(self):
        """ã™ã¹ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        self.memory_cache.clear()
        self.ttl_map.clear()
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        for cache_file in self.disk_cache_dir.glob("*.cache"):
            cache_file.unlink()
        
        # ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯åœæ­¢
        for task in self.warming_tasks.values():
            task.cancel()
        self.warming_tasks.clear()
        
        logger.info("All cache cleared")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±è¾æ›¸
        """
        total_hits = self.stats["memory_hits"] + self.stats["disk_hits"]
        total_misses = self.stats["memory_misses"] + self.stats["disk_misses"]
        
        hit_rate = (total_hits / self.stats["total_requests"] * 100) if self.stats["total_requests"] > 0 else 0
        
        return {
            **self.stats,
            "hit_rate": f"{hit_rate:0.2f}%",
            "memory_usage": f"{len(self.memory_cache)}/{self.memory_size}",
            "disk_files": len(list(self.disk_cache_dir.glob("*.cache"))),
            "warming_tasks": len(self.warming_tasks)
        }


# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ for easy caching
def cached(ttl: int = 3600, key_func: Optional[Callable] = None):
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    
    Args:
        ttl: TTLï¼ˆç§’ï¼‰
        key_func: ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼ç”Ÿæˆé–¢æ•°
    """
    def decorator(func):
        """decoratorãƒ¡ã‚½ãƒƒãƒ‰"""
        cache_manager = CacheManager()
        
        async def async_wrapper(*args, **kwargs):
            """async_wrapperãƒ¡ã‚½ãƒƒãƒ‰"""
            # ã‚­ãƒ¼ç”Ÿæˆ
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã¾ãŸã¯å®Ÿè¡Œ
            return await cache_manager.get(
                cache_key,
                lambda: func(*args, **kwargs),
                ttl
            )
        
        def sync_wrapper(*args, **kwargs):
            """sync_wrapperãƒ¡ã‚½ãƒƒãƒ‰"""
            # åŒæœŸé–¢æ•°ç”¨ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
            
            result = cache_manager._get_from_memory(cache_manager._generate_cache_key(cache_key))
            if result is None:
                result = func(*args, **kwargs)
                cache_manager._set_to_memory(
                    cache_manager._generate_cache_key(cache_key),
                    result,
                    ttl
                )
            return result
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    
    return decorator


# ä½¿ç”¨ä¾‹
async def example_usage():
    """ä½¿ç”¨ä¾‹"""
    cache = CacheManager(memory_size=100)
    
    # åŸºæœ¬çš„ãªä½¿ç”¨
    async def fetch_user_data(user_id: int):
        """fetch_user_dataãƒ¡ã‚½ãƒƒãƒ‰"""
        # å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await asyncio.sleep(1)
        return {"id": user_id, "name": f"User {user_id}"}
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµŒç”±ã§å–å¾—
    user_data = await cache.get(
        {"type": "user", "id": 123},
        lambda: fetch_user_data(123),
        ttl=300
    )
    print(f"User data: {user_data}")
    
    # çµ±è¨ˆè¡¨ç¤º
    print(f"Cache stats: {cache.get_stats()}")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°
    await cache.warm_cache(
        {"type": "popular_repos"},
        lambda: ["repo1", "repo2", "repo3"],
        ttl=600,
        interval=300
    )
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    await cache.clear_all()


if __name__ == "__main__":
    asyncio.run(example_usage())