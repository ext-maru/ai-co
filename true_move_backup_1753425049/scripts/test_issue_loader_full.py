#!/usr/bin/env python3
"""
ã‚¤ã‚·ãƒ¥ãƒ¼ãƒ­ãƒ¼ãƒ€ãƒ¼å®Œå…¨æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
4è³¢è€…ä¿®æ­£å¾Œã®æ€§èƒ½ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå“è³ªã‚’è©•ä¾¡
"""

import asyncio
import json
import time
import os
import sys
from pathlib import Path
from datetime import datetime
import tempfile

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from libs.integrations.github.auto_issue_processor import AutoIssueProcessor
from libs.code_generation.template_manager import CodeGenerationTemplateManager
from libs.code_generation.pattern_learning import PatternLearningEngine
from github import Github

async def test_full_issue_processing():
    """ã‚¤ã‚·ãƒ¥ãƒ¼ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®Œå…¨ãƒ†ã‚¹ãƒˆ"""
    print("=" * 80)
    print("ğŸ§ª ã‚¤ã‚·ãƒ¥ãƒ¼ãƒ­ãƒ¼ãƒ€ãƒ¼å®Œå…¨æ€§èƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # é–‹å§‹æ™‚åˆ»ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    start_time = time.time()
    start_memory = get_memory_usage()
    
    print(f"\nğŸ“Š åˆæœŸçŠ¶æ…‹:")
    print(f"  - é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  - åˆæœŸãƒ¡ãƒ¢ãƒª: {start_memory:0.1f} MB")
    
    try:
        # AutoIssueProcessorã®åˆæœŸåŒ–
        print("\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        init_start = time.time()
        processor = AutoIssueProcessor()
        init_end = time.time()
        print(f"  âœ… åˆæœŸåŒ–å®Œäº† ({init_end - init_start:0.2f}ç§’)")
        
        # Issue #193ã‚’å–å¾—
        print("\nğŸ“‹ Issue #193ã‚’å–å¾—ä¸­...")
        fetch_start = time.time()
        
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("GITHUB_REPO_OWNER", "ext-maru")
        repo_name = os.getenv("GITHUB_REPO_NAME", "ai-co")
        
        github = Github(github_token)
        repo = github.get_repo(f"{repo_owner}/{repo_name}")
        issue = repo.get_issue(193)
        
        fetch_end = time.time()
        print(f"  âœ… Issueå–å¾—å®Œäº† ({fetch_end - fetch_start:0.2f}ç§’)")
        print(f"  - ã‚¿ã‚¤ãƒˆãƒ«: {issue.title}")
        print(f"  - æœ¬æ–‡é•·: {len(issue.body or '')} æ–‡å­—")
        
        # è¤‡é›‘åº¦è©•ä¾¡
        print("\nğŸ” è¤‡é›‘åº¦è©•ä¾¡ä¸­...")
        eval_start = time.time()
        complexity = await processor.evaluator.evaluate(issue)
        eval_end = time.time()
        
        print(f"  âœ… è¤‡é›‘åº¦è©•ä¾¡å®Œäº† ({eval_end - eval_start:0.2f}ç§’)")
        print(f"  - è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢: {complexity.score:0.3f}")
        print(f"  - å‡¦ç†å¯èƒ½: {'âœ… Yes' if complexity.is_processable else 'âŒ No'}")
        
        # 4è³¢è€…ç›¸è«‡ï¼ˆä¿®æ­£ç‰ˆï¼‰
        print("\nğŸ§™â€â™‚ï¸ 4è³¢è€…ç›¸è«‡ï¼ˆä¿®æ­£ç‰ˆï¼‰ãƒ†ã‚¹ãƒˆ...")
        sage_start = time.time()
        sage_advice = await processor.consult_four_sages(issue)
        sage_end = time.time()
        
        print(f"  âœ… 4è³¢è€…ç›¸è«‡å®Œäº† ({sage_end - sage_start:0.2f}ç§’)")
        print(f"  - ãƒŠãƒ¬ãƒƒã‚¸è³¢è€…: {len(sage_advice.get('knowledge', []))}ä»¶ã®çŸ¥è­˜")
        print(f"  - ã‚¿ã‚¹ã‚¯è³¢è€…: {'âœ… è¨ˆç”»ä½œæˆ' if sage_advice.get('plan') else 'âŒ å¤±æ•—'}")
        print(f"  - ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè³¢è€…: ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« {sage_advice.get('risks', {}).get('risk_level', 'N/A')}")
        print(f"  - RAGè³¢è€…: {len(sage_advice.get('solution', []))}ä»¶ã®è§£æ±ºç­–")
        
        errors = sage_advice.get('consultation_errors', [])
        if errors:
            print(f"  âš ï¸  ã‚¨ãƒ©ãƒ¼: {len(errors)}ä»¶")
            for error in errors:
                print(f"    - {error}")
        
        # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\nğŸ”¨ ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        codegen_start = time.time()
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨
        template_manager = CodeGenerationTemplateManager()
        pattern_learner = PatternLearningEngine()
        
        # Issueæƒ…å ±ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        issue_data = {
            'number': issue.number,
            'title': issue.title,
            'body': issue.body or '',
            'labels': [label.name for label in issue.labels],
            'tech_stack': 'web',  # ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãªã®ã§webç³»
        }
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¸æŠã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        # æ­£ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå: 'class' ã¾ãŸã¯ 'class_enhanced'
        template_type = 'class'
        tech_stack = 'web'  # ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãªã®ã§webç³»
        generated_files = []
        
        if template_manager.has_template(template_type, tech_stack):
            context = {
                'issue_number': issue.number,
                'issue_title': issue.title,
                'issue_body': issue.body or '',
                'service_name': 'ObservabilityDashboard',
                'class_name': 'ObservabilityDashboard',
                'module_name': 'observability_dashboard',
                'description': 'Auto Issue Processorç›£è¦–ãƒ»å¯è¦³æ¸¬æ€§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰',
                'tech_details': {
                    'framework': 'FastAPI',
                    'monitoring': 'Prometheus',
                    'logging': 'Structured JSON',
                    'dashboard': 'Grafana'
                },
                'endpoints': [
                    {'path': '/health', 'method': 'GET', 'description': 'ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯'},
                    {'path': '/metrics', 'method': 'GET', 'description': 'Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹'},
                    {'path': '/dashboard', 'method': 'GET', 'description': 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º'},
                ],
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿…é ˆå¤‰æ•°
                'quality_improvements': [
                    'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–',
                    'éåŒæœŸå‡¦ç†ã®æœ€é©åŒ–',
                    'åŒ…æ‹¬çš„ãªãƒ­ã‚°è¨˜éŒ²'
                ],
                'similar_implementations': [],
                'naming_guide': {'suggested_class_name': 'ObservabilityDashboard'},
                'enhanced_imports': [],
                'learned_patterns': {},
                'framework_type': 'fastapi',
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                'project_context': {
                    'architectural_patterns': {
                        'elder_flow_compatibility': 'Elder Flowçµ±åˆå¯¾å¿œ'
                    }
                }
            }
            
            # generate_codeãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
            code = template_manager.generate_code(
                template_type=template_type,
                tech_stack=tech_stack,
                context=context,
                use_enhanced=False  # æ¨™æº–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ï¼ˆå¼·åŒ–ç‰ˆã¯è¤‡é›‘ã™ãã‚‹ï¼‰
            )
            generated_files.append({
                'name': 'observability_dashboard.py',
                'content': code,
                'lines': len(code.split('\n'))
            })
        else:
            print(f"  âš ï¸  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_type}' ({tech_stack}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        codegen_end = time.time()
        
        print(f"  âœ… ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({codegen_end - codegen_start:0.2f}ç§’)")
        print(f"  - ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(generated_files)}")
        for file in generated_files:
            print(f"    - {file['name']}: {file['lines']}è¡Œ")
        
        # ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ
        if generated_files:
            print("\nğŸ“Š ç”Ÿæˆã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ...")
            code_content = generated_files[0]['content']
            
            # åŸºæœ¬çš„ãªå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
            quality_metrics = analyze_code_quality(code_content)
            
            print(f"  - å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡: {quality_metrics['type_hints_ratio']:0.1%}")
            print(f"  - docstringä½¿ç”¨ç‡: {quality_metrics['docstring_ratio']:0.1%}")
            print(f"  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: {'âœ…' if quality_metrics['has_error_handling'] else 'âŒ'}")
            print(f"  - async/awaitä½¿ç”¨: {'âœ…' if quality_metrics['uses_async'] else 'âŒ'}")
            print(f"  - ãƒ­ã‚®ãƒ³ã‚°å®Ÿè£…: {'âœ…' if quality_metrics['has_logging'] else 'âŒ'}")
            
            # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰è¡¨ç¤º
            print("\nğŸ“ ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®30è¡Œï¼‰:")
            print("-" * 60)
            lines = code_content.split('\n')[:30]
            for i, line in enumerate(lines, 1):
                print(f"{i:3d} | {line}")
            print("-" * 60)
        
        # ãƒ†ã‚¹ãƒˆç”Ÿæˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        print("\nğŸ§ª ãƒ†ã‚¹ãƒˆè‡ªå‹•ç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        test_start = time.time()
        
        # ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        test_template_type = 'test'
        test_tech_stack = 'web'
        test_code = None
        
        if template_manager.has_template(test_template_type, test_tech_stack):
            test_context = {
                'issue_number': issue.number,
                'issue_title': issue.title,
                'issue_body': issue.body or '',
                'service_name': 'ObservabilityDashboard',
                'class_name': 'ObservabilityDashboard',
                'module_name': 'observability_dashboard',
                'test_cases': [
                    'test_health_endpoint',
                    'test_metrics_format',
                    'test_dashboard_rendering',
                    'test_error_handling'
                ],
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿…é ˆå¤‰æ•°
                'requirements': {'imports': [], 'classes': [], 'functions': []}
            }
            test_code = template_manager.generate_code(
                template_type=test_template_type,
                tech_stack=test_tech_stack,
                context=test_context,
                use_enhanced=False  # ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯æ¨™æº–ç‰ˆã®ã¿
            )
        else:
            # ç°¡æ˜“ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
            test_code = generate_simple_test_code('ObservabilityDashboard', 'observability_dashboard')
        
        test_end = time.time()
        
        if test_code:
            print(f"  âœ… ãƒ†ã‚¹ãƒˆç”Ÿæˆå®Œäº† ({test_end - test_start:0.2f}ç§’)")
            print(f"  - ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰è¡Œæ•°: {len(test_code.split('\n'))}è¡Œ")
        else:
            print(f"  âŒ ãƒ†ã‚¹ãƒˆç”Ÿæˆå¤±æ•— ({test_end - test_start:0.2f}ç§’)")
        
        # å…¨ä½“ã®æ€§èƒ½ã‚µãƒãƒªãƒ¼
        total_time = time.time() - start_time
        end_memory = get_memory_usage()
        memory_increase = end_memory - start_memory
        
        print("\n" + "=" * 80)
        print("ğŸ“Š å®Œå…¨ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        print(f"  - ç·å‡¦ç†æ™‚é–“: {total_time:0.2f}ç§’")
        print(f"  - åˆæœŸåŒ–æ™‚é–“: {init_end - init_start:0.2f}ç§’")
        print(f"  - Issueå–å¾—æ™‚é–“: {fetch_end - fetch_start:0.2f}ç§’")
        print(f"  - è¤‡é›‘åº¦è©•ä¾¡æ™‚é–“: {eval_end - eval_start:0.2f}ç§’")
        print(f"  - 4è³¢è€…ç›¸è«‡æ™‚é–“: {sage_end - sage_start:0.2f}ç§’")
        print(f"  - ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ™‚é–“: {codegen_end - codegen_start:0.2f}ç§’")
        print(f"  - ãƒ†ã‚¹ãƒˆç”Ÿæˆæ™‚é–“: {test_end - test_start:0.2f}ç§’")
        print(f"  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {start_memory:0.1f} MB â†’ {end_memory:0.1f} MB (+{memory_increase:0.1f} MB)")
        
        # å“è³ªã‚µãƒãƒªãƒ¼
        print("\nğŸ¯ å“è³ªè©•ä¾¡ã‚µãƒãƒªãƒ¼:")
        print(f"  - 4è³¢è€…ç›¸è«‡: {'âœ… æˆåŠŸ' if not errors else f'âš ï¸  éƒ¨åˆ†çš„æˆåŠŸï¼ˆ{len(errors)}ã‚¨ãƒ©ãƒ¼ï¼‰'}")
        print(f"  - ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ: {'âœ… æˆåŠŸ' if generated_files else 'âŒ å¤±æ•—'}")
        print(f"  - ãƒ†ã‚¹ãƒˆç”Ÿæˆ: {'âœ… æˆåŠŸ' if test_code else 'âŒ å¤±æ•—'}")
        
        if generated_files and quality_metrics:
            overall_quality = calculate_overall_quality(quality_metrics)
            print(f"  - ã‚³ãƒ¼ãƒ‰å“è³ªã‚¹ã‚³ã‚¢: {overall_quality:0.1f}/100")
            
            if overall_quality >= 80:
                print("  âœ… Production Readyå“è³ª")
            elif overall_quality >= 60:
                print("  âš ï¸  æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
            else:
                print("  âŒ å“è³ªæ”¹å–„ãŒå¿…è¦")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()

def get_memory_usage():
    """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBå˜ä½ï¼‰"""
    try:
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024
    except:
        return 0.0

def analyze_code_quality(code: str) -> dict:
    """ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’åˆ†æ"""
    lines = code.split('\n')
    
    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    total_functions = code.count('def ') + code.count('async def ')
    functions_with_type_hints = len([line for line in lines if 'def ' in line and '->' in line])
    functions_with_docstrings = 0
    
    # docstringæ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
    for i, line in enumerate(lines):
        if 'def ' in line or 'class ' in line:
            if i + 1 < len(lines) and '"""' in lines[i + 1]:
                functions_with_docstrings += 1
    
    return {
        'type_hints_ratio': functions_with_type_hints / max(total_functions, 1),
        'docstring_ratio': functions_with_docstrings / max(total_functions, 1),
        'has_error_handling': 'try:' in code and 'except' in code,
        'uses_async': 'async def' in code,
        'has_logging': 'logger' in code or 'logging' in code,
        'total_lines': len(lines),
        'total_functions': total_functions
    }

def calculate_overall_quality(metrics: dict) -> float:
    """ç·åˆå“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    score = 0
    score += metrics['type_hints_ratio'] * 25  # å‹ãƒ’ãƒ³ãƒˆ: 25ç‚¹
    score += metrics['docstring_ratio'] * 25   # docstring: 25ç‚¹
    score += 20 if metrics['has_error_handling'] else 0  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: 20ç‚¹
    score += 15 if metrics['uses_async'] else 0  # éåŒæœŸå‡¦ç†: 15ç‚¹
    score += 15 if metrics['has_logging'] else 0  # ãƒ­ã‚®ãƒ³ã‚°: 15ç‚¹
    return score

def generate_simple_test_code(class_name: str, module_name: str) -> str:
    """ç°¡æ˜“çš„ãªãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
    return f'''import pytest
from unittest.mock import Mock, patch
from {module_name} import {class_name}

class Test{class_name}:
    """Auto-generated tests for {class_name}"""
    
    @pytest.fixture
    def instance(self):
        """Create test instance"""
        return {class_name}()
    
    def test_initialization(self, instance):
        """Test {class_name} initialization"""
        assert instance is not None
    
    def test_health_check(self, instance):
        """Test health check endpoint"""
        result = instance.health_check()
        assert result["status"] == "healthy"
    
    @pytest.mark.asyncio
    async def test_async_operations(self, instance):
        """Test async operations"""
        # Add async test implementation
        pass
'''

if __name__ == "__main__":
    asyncio.run(test_full_issue_processing())