#!/usr/bin/env python3
"""
ğŸ§™â€â™‚ï¸ Four Sages Overseer Magic ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
4è³¢è€…ç›£ç£ç›£æŸ»é­”æ³•ã®å®Œå…¨ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import json
import logging
import tempfile
import unittest
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any
from unittest.mock import Mock, patch, MagicMock

import pytest

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from libs.ancient_elder.four_sages_overseer import (
    FourSagesOverseer,
    SageConsultationTracker,
    SageActivityAnalyzer,
    SageType,
    SageViolationType
)
from libs.ancient_elder.base import ViolationSeverity


class TestSageConsultationTracker(unittest.TestCase):
    """4è³¢è€…ç›¸è«‡è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.temp_dir = tempfile.mkdtemp()
        self.project_root = Path(self.temp_dir)
        self.tracker = SageConsultationTracker(self.project_root)
        
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        shutil.rmtree(self.temp_dir)
        
    def test_tracker_initialization(self):
        """ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        self.assertIsInstance(self.tracker, SageConsultationTracker)
        self.assertEqual(self.tracker.project_root, self.project_root)
        
        # 4è³¢è€…ã®ãƒ­ã‚°ãƒ‘ã‚¹ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        self.assertIn(SageType.KNOWLEDGE, self.tracker.sage_log_paths)
        self.assertIn(SageType.TASK, self.tracker.sage_log_paths)
        self.assertIn(SageType.INCIDENT, self.tracker.sage_log_paths)
        self.assertIn(SageType.RAG, self.tracker.sage_log_paths)
        
    def test_consultation_pattern_detection(self):
        """ç›¸è«‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        test_messages = [
            ("Consult with knowledge sage for implementation", SageType.KNOWLEDGE),
            ("Task sage consultation needed", SageType.TASK),
            ("Incident sage: emergency response", SageType.INCIDENT),
            ("RAG sage search optimization", SageType.RAG),
            ("çŸ¥è­˜è³¢è€…ã¸ã®ç›¸è«‡", SageType.KNOWLEDGE),
            ("ã‚¿ã‚¹ã‚¯è³¢è€…ã«ç¢ºèª", SageType.TASK),
            ("Regular commit message", None),  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—
        ]
        
        for message, expected_sage in test_messages:
        # ç¹°ã‚Šè¿”ã—å‡¦ç†
            detected_sages = []
            # ç¹°ã‚Šè¿”ã—å‡¦ç†
            for sage_type, patterns in self.tracker.consultation_patterns.items():
                for pattern in patterns:
                    if pattern.search(message):
                        detected_sages.append(sage_type)
                        break
                        
            if expected_sage:
                self.assertIn(expected_sage, detected_sages, 
                             f"Failed to detect {expected_sage} in message: '{message}'")
            else:
                self.assertEqual(len(detected_sages), 0,
                               f"Unexpected detection in message: '{message}'")
                
    @patch('subprocess.run')
    def test_consultation_records_retrieval(self, mock_subprocess):
        """ç›¸è«‡è¨˜éŒ²å–å¾—ãƒ†ã‚¹ãƒˆ"""
        mock_subprocess.return_value.stdout = """abc123|2025-01-20 10:00:00|Knowledge sage consultation for auth|dev
def456|2025-01-20 11:00:00|Task sage: priority update|dev
ghi789|2025-01-20 12:00:00|Regular feature implementation|dev"""
        
        records = self.tracker._get_consultation_records("test.py", timedelta(days=7))
        
        self.assertEqual(len(records), 3)
        self.assertEqual(records[0]["hash"], "abc123")
        self.assertEqual(records[0]["message"], "Knowledge sage consultation for auth")
        
    def test_consultation_analysis(self):
        """ç›¸è«‡åˆ†æãƒ†ã‚¹ãƒˆ"""
        mock_records = [
            {"hash": "abc", "date": "2025-01-20", "message": "Knowledge sage consultation", "author": "dev"},
            {"hash": "def", "date": "2025-01-20", "message": "Task sage priority", "author": "dev"},
            {"hash": "ghi", "date": "2025-01-21", "message": "RAG sage search", "author": "dev"},
        ]
        
        analysis = self.tracker._analyze_consultation_patterns(mock_records)
        
        # å„è³¢è€…ã®åˆ†æçµæœã‚’ç¢ºèª
        self.assertIn(SageType.KNOWLEDGE, analysis)
        self.assertIn(SageType.TASK, analysis)
        self.assertIn(SageType.RAG, analysis)
        
        # Knowledgeè³¢è€…ã®ç›¸è«‡ãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        knowledge_analysis = analysis[SageType.KNOWLEDGE]
        self.assertGreater(knowledge_analysis["consultation_count"], 0)
        self.assertIsNotNone(knowledge_analysis["last_consultation"])
        
    def test_consultation_violation_detection(self):
        """ç›¸è«‡ç¾©å‹™é•åæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        # ä¸ååˆ†ãªç›¸è«‡ã®ã‚±ãƒ¼ã‚¹
        insufficient_analysis = {
            SageType.KNOWLEDGE: {"consultation_count": 0},
            SageType.TASK: {"consultation_count": 1},
            SageType.INCIDENT: {"consultation_count": 0},
            SageType.RAG: {"consultation_count": 0}
        }
        
        violations = self.tracker._detect_consultation_violations(insufficient_analysis, "test.py")
        
        # Knowledge, RAGè³¢è€…ã¸ã®ç›¸è«‡ä¸è¶³ãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        violation_types = [v["sage_type"] for v in violations]
        self.assertIn(SageType.KNOWLEDGE, violation_types)
        self.assertIn(SageType.RAG, violation_types)
        
        # ååˆ†ãªç›¸è«‡ã®ã‚±ãƒ¼ã‚¹
        sufficient_analysis = {
            SageType.KNOWLEDGE: {"consultation_count": 2},
            SageType.TASK: {"consultation_count": 1},
            SageType.INCIDENT: {"consultation_count": 0},  # å¿…é ˆã§ãªã„
            SageType.RAG: {"consultation_count": 1}
        }
        
        violations = self.tracker._detect_consultation_violations(sufficient_analysis, "test.py")
        self.assertEqual(len(violations), 0, "No violations should be detected for sufficient consultations")
        
    def test_consultation_score_calculation(self):
        """ç›¸è«‡ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        # é«˜ã‚¹ã‚³ã‚¢ã‚±ãƒ¼ã‚¹
        high_score_analysis = {
            SageType.KNOWLEDGE: {"consultation_count": 3},
            SageType.TASK: {"consultation_count": 2},
            SageType.INCIDENT: {"consultation_count": 1},
            SageType.RAG: {"consultation_count": 2}
        }
        
        score = self.tracker._calculate_consultation_score(high_score_analysis)
        self.assertGreaterEqual(score, 65.0, "High consultation activity should yield high score")
        
        # ä½ã‚¹ã‚³ã‚¢ã‚±ãƒ¼ã‚¹
        low_score_analysis = {
            SageType.KNOWLEDGE: {"consultation_count": 0},
            SageType.TASK: {"consultation_count": 0},
            SageType.INCIDENT: {"consultation_count": 0},
            SageType.RAG: {"consultation_count": 0}
        }
        
        score = self.tracker._calculate_consultation_score(low_score_analysis)
        self.assertEqual(score, 0.0, "No consultations should yield zero score")


class TestSageActivityAnalyzer(unittest.TestCase):
    """4è³¢è€…æ´»å‹•å®Ÿè³ªæ€§è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.temp_dir = tempfile.mkdtemp()
        self.project_root = Path(self.temp_dir)
        self.analyzer = SageActivityAnalyzer(self.project_root)
        
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        shutil.rmtree(self.temp_dir)
        
    def test_analyzer_initialization(self):
        """ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        self.assertIsInstance(self.analyzer, SageActivityAnalyzer)
        self.assertEqual(self.analyzer.project_root, self.project_root)
        
    def test_individual_sage_activities_analysis(self):
        """å€‹åˆ¥è³¢è€…æ´»å‹•åˆ†æãƒ†ã‚¹ãƒˆ"""
        time_window = timedelta(days=30)
        activities = self.analyzer._analyze_individual_sage_activities(time_window)
        
        # å…¨4è³¢è€…ã®æ´»å‹•åˆ†æãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        self.assertIn(SageType.KNOWLEDGE, activities)
        self.assertIn(SageType.TASK, activities)
        self.assertIn(SageType.INCIDENT, activities)
        self.assertIn(SageType.RAG, activities)
        
        # å„è³¢è€…ã®æ´»å‹•æŒ‡æ¨™ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        for sage_type, activity in activities.items():
            self.assertIn("activity_count", activity)
            self.assertIn("quality_score", activity)
            self.assertIn("responsiveness", activity)
            self.assertIn("expertise_demonstration", activity)
            
    def test_sage_collaboration_analysis(self):
        """è³¢è€…é–“é€£æºåˆ†æãƒ†ã‚¹ãƒˆ"""
        time_window = timedelta(days=30)
        collaboration = self.analyzer._analyze_sage_collaboration(time_window)
        
        self.assertIn("collaboration_frequency", collaboration)
        self.assertIn("collaboration_patterns", collaboration)
        self.assertIn("cross_sage_consultations", collaboration)
        self.assertIn("collaborative_problem_solving", collaboration)
        
        # é€£æºãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        self.assertIsInstance(collaboration["collaboration_patterns"], list)
        
    def test_activity_violation_detection(self):
        """æ´»å‹•é•åæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        # æ´»å‹•ä¸è¶³ã®ã‚±ãƒ¼ã‚¹
        insufficient_activity = {
            SageType.KNOWLEDGE: {"activity_count": 1, "quality_score": 50},
            SageType.TASK: {"activity_count": 2, "quality_score": 60},
            SageType.INCIDENT: {"activity_count": 0, "quality_score": 0},
            SageType.RAG: {"activity_count": 1, "quality_score": 55}
        }
        
        insufficient_collaboration = {
            "collaboration_frequency": 1,
            "cross_sage_consultations": 2
        }
        
        violations = self.analyzer._detect_activity_violations(
            insufficient_activity, insufficient_collaboration, "test.py"
        )
        
        # æ´»å‹•ä¸è¶³é•åãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        activity_violations = [v for v in violations if v["type"] == SageViolationType.INSUFFICIENT_SAGE_ACTIVITY]
        self.assertGreater(len(activity_violations), 0, "Should detect insufficient activity violations")
        
        # é€£æºä¸è¶³é•åãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        collaboration_violations = [v for v in violations if v["type"] == SageViolationType.POOR_SAGE_COLLABORATION]
        self.assertGreater(len(collaboration_violations), 0, "Should detect poor collaboration violations")
        
    def test_activity_score_calculation(self):
        """æ´»å‹•ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        # é«˜å“è³ªæ´»å‹•ã‚±ãƒ¼ã‚¹
        high_quality_activity = {
            SageType.KNOWLEDGE: {"quality_score": 90},
            SageType.TASK: {"quality_score": 85},
            SageType.INCIDENT: {"quality_score": 80},
            SageType.RAG: {"quality_score": 88}
        }
        
        high_collaboration = {"collaborative_problem_solving": 95}
        
        score = self.analyzer._calculate_activity_score(high_quality_activity, high_collaboration)
        self.assertGreaterEqual(score, 85.0, "High quality activities should yield high score")
        
        # ä½å“è³ªæ´»å‹•ã‚±ãƒ¼ã‚¹
        low_quality_activity = {
            SageType.KNOWLEDGE: {"quality_score": 40},
            SageType.TASK: {"quality_score": 35},
            SageType.INCIDENT: {"quality_score": 30},
            SageType.RAG: {"quality_score": 38}
        }
        
        low_collaboration = {"collaborative_problem_solving": 25}
        
        score = self.analyzer._calculate_activity_score(low_quality_activity, low_collaboration)
        self.assertLessEqual(score, 50.0, "Low quality activities should yield low score")


class TestFourSagesOverseer(unittest.TestCase):
    """4è³¢è€…ç›£ç£é­”æ³•ç·åˆãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.temp_dir = tempfile.mkdtemp()
        self.project_root = Path(self.temp_dir)
        self.overseer = FourSagesOverseer(self.project_root)
        
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        shutil.rmtree(self.temp_dir)
        
    def test_overseer_initialization(self):
        """ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¼ã‚¢ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        self.assertIsInstance(self.overseer, FourSagesOverseer)
        self.assertEqual(self.overseer.project_root, self.project_root)
        self.assertIsInstance(self.overseer.consultation_tracker, SageConsultationTracker)
        self.assertIsInstance(self.overseer.activity_analyzer, SageActivityAnalyzer)
        
    @patch.object(SageConsultationTracker, 'track_sage_consultations')
    @patch.object(SageActivityAnalyzer, 'analyze_sage_activity_quality')
    async def test_execute_audit_success(self, mock_activity_analyzer, mock_consultation_tracker):
        """ç›£æŸ»å®Ÿè¡ŒæˆåŠŸãƒ†ã‚¹ãƒˆ"""
        # ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
        mock_consultation_tracker.return_value = {
            "violations": [],
            "overall_consultation_score": 85.0
        }
        
        mock_activity_analyzer.return_value = {
            "violations": [],
            "overall_activity_score": 90.0
        }
        
        result = await self.overseer.execute_audit("test.py")
        
        self.assertEqual(result.auditor_name, "FourSagesOverseer")
        self.assertEqual(result.target_path, "test.py")
        self.assertIsInstance(result.violations, list)
        self.assertIsInstance(result.metrics, dict)
        self.assertIn("overall_sage_score", result.metrics)
        self.assertGreater(result.metrics["overall_sage_score"], 80.0)
        
    @patch.object(SageConsultationTracker, 'track_sage_consultations')
    @patch.object(SageActivityAnalyzer, 'analyze_sage_activity_quality')
    async def test_execute_audit_with_violations(self, mock_activity_analyzer, mock_consultation_tracker):
        """é•åæ¤œå‡ºæ™‚ã®ç›£æŸ»å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        # é•åã‚’å«ã‚€ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
        mock_consultation_tracker.return_value = {
            "violations": [
                {
                    "type": SageViolationType.MISSING_CONSULTATION,
                    "severity": "HIGH",
                    "sage_type": SageType.KNOWLEDGE,
                    "description": "Missing knowledge sage consultation"
                }
            ],
            "overall_consultation_score": 40.0
        }
        
        mock_activity_analyzer.return_value = {
            "violations": [
                {
                    "type": SageViolationType.INSUFFICIENT_SAGE_ACTIVITY,
                    "severity": "MEDIUM",
                    "sage_type": SageType.RAG,
                    "description": "Insufficient RAG sage activity"
                }
            ],
            "overall_activity_score": 55.0
        }
        
        result = await self.overseer.execute_audit("test.py")
        
        # é•åãŒé©åˆ‡ã«çµ±åˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        self.assertEqual(len(result.violations), 2)
        self.assertLessEqual(result.metrics["overall_sage_score"], 50.0)
        
    def test_overall_sage_score_calculation(self):
        """ç·åˆ4è³¢è€…ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        # é«˜ã‚¹ã‚³ã‚¢ã‚±ãƒ¼ã‚¹
        high_metrics = {
            "consultation_score": 90.0,
            "activity_score": 85.0
        }
        
        score = self.overseer._calculate_overall_sage_score(high_metrics)
        expected_score = (90.0 * 0.4) + (85.0 * 0.6)  # 87.0
        self.assertAlmostEqual(score, expected_score, places=1)
        
        # ä½ã‚¹ã‚³ã‚¢ã‚±ãƒ¼ã‚¹
        low_metrics = {
            "consultation_score": 30.0,
            "activity_score": 40.0
        }
        
        score = self.overseer._calculate_overall_sage_score(low_metrics)
        expected_score = (30.0 * 0.4) + (40.0 * 0.6)  # 36.0
        self.assertAlmostEqual(score, expected_score, places=1)
        
    def test_sage_improvement_recommendations(self):
        """4è³¢è€…æ”¹å–„ææ¡ˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        consultation_result = {"overall_consultation_score": 60.0}
        activity_result = {"overall_activity_score": 70.0}
        violations = [
            {
                "type": SageViolationType.MISSING_CONSULTATION,
                "sage_type": SageType.KNOWLEDGE
            }
        ]
        
        recommendations = self.overseer._generate_sage_improvement_recommendations(
            consultation_result, activity_result, violations
        )
        
        self.assertIsInstance(recommendations, list)
        self.assertGreater(len(recommendations), 0, "Should generate improvement recommendations")
        
        # ç›¸è«‡é »åº¦å‘ä¸Šã®ææ¡ˆãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        consultation_recommendations = [r for r in recommendations if "consultation" in r.lower()]
        self.assertGreater(len(consultation_recommendations), 0)


class TestFourSagesOverseerIntegration(unittest.TestCase):
    """4è³¢è€…ç›£ç£é­”æ³•çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.temp_dir = tempfile.mkdtemp()
        self.project_root = Path(self.temp_dir)
        self.overseer = FourSagesOverseer(self.project_root)
        
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        shutil.rmtree(self.temp_dir)
        
    async def test_comprehensive_sage_audit(self):
        """åŒ…æ‹¬çš„4è³¢è€…ç›£æŸ»ãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        test_file = self.project_root / "test_module.py"
        test_file.parent.mkdir(parents=True, exist_ok=True)
        test_file.write_text("""
def process_data():
    # TODO: Implement knowledge sage consultation
    pass

def manage_tasks():
    # Missing task sage consultation
    pass
""")
        
        # çµ±åˆç›£æŸ»å®Ÿè¡Œ
        with patch('subprocess.run') as mock_subprocess:
            mock_subprocess.return_value.stdout = "abc123|2025-01-20|Basic implementation|dev"
            
            result = await self.overseer.execute_audit(str(test_file))
            
        # çµæœæ¤œè¨¼
        self.assertEqual(result.auditor_name, "FourSagesOverseer")
        self.assertIsInstance(result.violations, list)
        self.assertIsInstance(result.metrics, dict)
        self.assertIn("overall_sage_score", result.metrics)
        self.assertIsInstance(result.recommendations, list)
        
    async def test_sage_collaboration_assessment(self):
        """è³¢è€…é€£æºè©•ä¾¡ãƒ†ã‚¹ãƒˆ"""
        test_path = "collaborative_module.py"
        
        # é€£æºä¸è¶³ã®ã‚·ãƒŠãƒªã‚ªã‚’ãƒ†ã‚¹ãƒˆ
        with patch.object(self.overseer.consultation_tracker, 'track_sage_consultations') as mock_consultation:
            with patch.object(self.overseer.activity_analyzer, 'analyze_sage_activity_quality') as mock_activity:
                pass
                
                # é€£æºä¸è¶³ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
                mock_consultation.return_value = {
                    "violations": [],
                    "overall_consultation_score": 50.0
                }
                
                mock_activity.return_value = {
                    "violations": [
                        {
                            "type": SageViolationType.POOR_SAGE_COLLABORATION,
                            "severity": "HIGH",
                            "description": "Poor sage collaboration detected"
                        }
                    ],
                    "overall_activity_score": 45.0
                }
                
                result = await self.overseer.execute_audit(test_path)
                
                # é€£æºä¸è¶³ãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                collaboration_violations = [
                    v for v in result.violations 
                    if v.get("type") == SageViolationType.POOR_SAGE_COLLABORATION
                ]
                self.assertGreater(len(collaboration_violations), 0)
                
                # æ”¹å–„ææ¡ˆãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                self.assertGreater(len(result.recommendations), 0)


if __name__ == "__main__":
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    unittest.main(verbosity=2)